   #alternate Modifier WikipÃ©dia (fr) Flux Atom de WikipÃ©dia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails thÃ©matiques
     * Article au hasard
     * Contact

   Contribuer
     * DÃ©buter sur WikipÃ©dia
     * Aide
     * CommunautÃ©
     * Modifications rÃ©centes
     * Faire un don

   Langues
   Sur cette version linguistique de WikipÃ©dia, les liens interlangues
   sont placÃ©s en haut Ã  droite du titre de lâ€™article.
   Aller en haut.
   WikipÃ©dia l'encyclopÃ©die libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * CrÃ©er un compte
     * Se connecter

   [ ] Outils personnels
     * CrÃ©er un compte
     * Se connecter

   Pages pour les contributeurs dÃ©connectÃ©s en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
     * DÃ©but
     * 1CapacitÃ©s

     2Principes sous-jacents

     3ModalitÃ©s

     4Investissements financiers



   5Transparence du systÃ¨me d'IA ?



   6Vers une rÃ©gulation, une rÃ©glementation et une gestion des risques



   7Ã‰lÃ©ments de prospective



   8RÃ©fÃ©rences



   9Articles connexes

   [ ] Basculer la table des matiÃ¨res

Intelligence artificielle gÃ©nÃ©rative

   [ ] 17 langues
     * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
     * à¦¬à¦¾à¦‚à¦²à¦¾
     * English
     * EspaÃ±ol
     * ÙØ§Ø±Ø³ÛŒ
     * ×¢×‘×¨×™×ª
     * Italiano
     * æ—¥æœ¬èª
     * í•œêµ­ì–´
     * PortuguÃªs
     * Runa Simi
     * Ğ ÑƒÑÑĞºĞ¸Ğ¹
     * TÃ¼rkÃ§e
     * Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°
     * Tiáº¿ng Viá»‡t
     * ä¸­æ–‡
     * IsiZulu

   Modifier les liens

     * Article
     * Discussion

   [ ] franÃ§ais

     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   [ ] Outils
   Outils
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Actions
     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   GÃ©nÃ©ral
     * Pages liÃ©es
     * Suivi des pages liÃ©es
     * TÃ©lÃ©verser un fichier
     * Pages spÃ©ciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * Ã‰lÃ©ment Wikidata

   Imprimerâ€¯/â€¯exporter
     * CrÃ©er un livre
     * TÃ©lÃ©charger comme PDF
     * Version imprimable

   Dans dâ€™autres projets
     * Wikimedia Commons

   Un article de WikipÃ©dia, l'encyclopÃ©die libre.
   Page dâ€™aide sur lâ€™homonymie

   Ne doit pas Ãªtre confondu avec Intelligence artificielle gÃ©nÃ©rale.

   L'intelligence artificielle gÃ©nÃ©rative ou IA gÃ©nÃ©rative (ou GenAI) est
   un type de systÃ¨me d'intelligence artificielle (IA) capable de gÃ©nÃ©rer
   du texte, des images ou d'autres mÃ©dias en rÃ©ponse Ã  des invites (ou
   prompts en anglais)^[1]^,^[2]. Elle est dite multimodale quand elle est
   construite Ã  partir de plusieurs modÃ¨les gÃ©nÃ©ratifs, ou d'un modÃ¨le
   entraÃ®nÃ© sur plusieurs types de donnÃ©es et qu'elle peut produire
   plusieurs types de donnÃ©es. Par exemple, la version GPT-4 d'OpenAI
   accepte les entrÃ©es sous forme de texte et/ou d'image^[3].

   Elle semble avoir des applications possibles dans presque tous les
   domaines, avec une balance des risques et des opportunitÃ©s encore
   discutÃ©e : l'IA gÃ©nÃ©rative est en effet aussi source d'inquiÃ©tudes et
   des dÃ©fis Ã©thiques, techniques et socioÃ©conomiques Ã  la hauteur des
   espoirs qu'elle suscite. Elle peut contribuer Ã  des usages abusifs,
   accidentels ou dÃ©tournÃ©s (militaires notamment), Ã  une suppression
   massive d'emploi, Ã  une manipulation de la population via la crÃ©ation
   de fausses nouvelles (fake news en anglais), de deepfakes^[4] ou de
   nudges numÃ©riques^[5]. Elle questionne aussi philosophiquement la
   nature de la conscience, de la crÃ©ativitÃ©, de la paternitÃ©^[6], et crÃ©e
   de nouvelles interactions homme-machine. L'IA est encore peu rÃ©gulÃ©e et
   la difficultÃ© dâ€™Ã©valuer la qualitÃ© et la fiabilitÃ© des contenus gÃ©nÃ©rÃ©s
   ou lâ€™impact sur la crÃ©ativitÃ© et la propriÃ©tÃ© intellectuelle humaines
   est croissante. Certains experts craignent que des IA gÃ©nÃ©ratives Ã
   venir soient capables de manipuler les humains, d'accÃ©der Ã  des
   systÃ¨mes d'armes, d'exploiter des failles de cybersÃ©curitÃ©, voire
   peut-Ãªtre bientÃ´t d'acquÃ©rir une forme de conscience et/ou de devenir
   incontrÃ´lable au point de menacer l'existence de l'humanitÃ©^[7]. Un
   premier sommet mondial en sÃ»retÃ© de l'IA est organisÃ©e dÃ©but novembre
   2023 Ã  Londres, oÃ¹ la crÃ©ation d'un Ã©quivalent du GIEC pour informer
   sur les risques liÃ©s Ã  l'IA a notamment Ã©tÃ© discutÃ©e^[8].

CapacitÃ©s[modifier | modifier le code]

   Selon une analyse dâ€™OpenAI en 2018 : Â« depuis 2012, la quantitÃ© de
   calcul utilisÃ©e dans les plus grands entraÃ®nements dâ€™IA a augmentÃ© de
   maniÃ¨re exponentielle avec un temps de doublement de 3,4 mois (en
   comparaison, la loi de Moore avait une pÃ©riode de doublement de 2 ans).
   Depuis 2012, cette mÃ©trique^[9] a augmentÃ© de plus de 300 000 fois (une
   pÃ©riode de doublement de 2 ans ne donnerait quâ€™une augmentation de 7
   fois). Â»^[10]. Cette augmentation de la puissance de calcul a facilitÃ©
   lâ€™Ã©mergence dâ€™IA gÃ©nÃ©ratives pouvant crÃ©er des choses originales comme
   des images, des tableaux, de la musique ou du texte, en s'inspirant de
   donnÃ©es existantes sans les copier. Elles ne se contentent pas de
   classer les donnÃ©es d'entrÃ©e qu'on leur a fourni, ni de prÃ©dire des
   donnÃ©es statistiquement probables ; elles gÃ©nÃ¨rent des contenus
   nouveaux dont les bases ne sont qu'en partie similaire aux bases issues
   de donnÃ©es d'apprentissage qu'on leur a fourni^[11].

   Les versions publiques de grands modÃ¨les d'IA gÃ©nÃ©rative disponibles en
   2022/2023 produisent des contenus modulÃ©s et filtrÃ©s de maniÃ¨re Ã
   limiter leurs biais, les contenus mÃ©sinformant, dangereux, racistes,
   biaisÃ©s, choquants, haineux, non sollicitÃ©s, les images pornographiques
   ou sexuellement explicites^[12]^,^[13]^,^[14]^,^[15]. Au dÃ©but des
   annÃ©es 2020, la puissance de calcul de lâ€™IA a doublÃ© tous les six Ã  dix
   mois, permettant aux modÃ¨les dâ€™IA de monter en capacitÃ©s Ã  un rythme
   exponentiel.

   Les anglophones parlent de Â« Frontier AI Â» pour dÃ©signer les modÃ¨les
   d'IA aux capacitÃ©s les plus Ã©levÃ©es et gÃ©nÃ©rales, et qui pourraient
   prÃ©senter des risques nouveaux^[16]. Ce type d'IA s'est faite connaitre
   du public par ChatGPT (et sa variante Bing Chat), un chatbot (agent
   conversationnel programmable) construit par OpenAI Ã  partir de ses
   grands modÃ¨les de langage de fondation GPT-3 et GPT-4^[17], ainsi que
   par Bard, un chatbot de Google basÃ© sur LaMDA. D'autres modÃ¨les d'IA
   gÃ©nÃ©rative incluent des systÃ¨mes artistiques d'intelligence
   artificielle tels que Stable Diffusion, Midjourney et DALL-E^[18]. Ces
   IA ont un trÃ¨s large spectre d'applications potentielles dans des
   domaines crÃ©atifs (arts plastiques, cinÃ©ma, musique, Ã©criture, design,
   mÃ©tÃ©o, architecture...), mais aussi dans les secteurs de la santÃ©, de
   la finance, des jeux vidÃ©o et des simulateurs, dans tous les domaines
   des sciences et techniques, des sciences sociales, de l'industrie et de
   la connaissance. Elles ont rÃ©cemment permis un bond en avant en
   biologie molÃ©culaire et en comprÃ©hension de phÃ©nomÃ¨nes physiques
   complexes. Elles permettent de synthÃ©tiser des visage et des voix
   humaines rÃ©alistes. Elles offrent de nouveaux modes d'exploration
   d'hypothÃ¨ses et de scenarii (notamment depuis peu grÃ¢ce Ã  la production
   de donnÃ©es synthÃ©tiques sophistiquÃ©es, issues du domaine de la
   recherche gÃ©nÃ©rative assistÃ©e par IA)^[rÃ©f. nÃ©cessaire]...

Principes sous-jacents[modifier | modifier le code]

   Les cadres technologiques et conceptuels les plus importants pour
   aborder l'IA gÃ©nÃ©rative sont en cours dâ€™Ã©laboration depuis un certain
   temps^[6], mais ils n'ont vraiment abouti que dans les annÃ©es 2020 Ã
   plusieurs types de modÃ¨les d'IA particuliÃ¨rement efficaces :
     * les rÃ©seaux antagonistes gÃ©nÃ©ratifs (GAN), composÃ©s de deux
       parties : un rÃ©seau gÃ©nÃ©rateur crÃ©ant de nouveaux Ã©chantillons de
       donnÃ©es, et un rÃ©seau discriminateur qui Ã©value si les Ã©chantillons
       sont rÃ©els ou faux. Les deux rÃ©seaux sont formÃ©s ensemble dans le
       cadre d'un processus concurrentiel, le rÃ©seau gÃ©nÃ©rateur essayant
       continuellement de produire des Ã©chantillons de meilleure qualitÃ©
       et plus rÃ©alistes, tandis que le rÃ©seau discriminateur s'efforce
       d'identifier avec prÃ©cision les faux Ã©chantillons ;
     * les auto-encodeurs variationnels (VAE) ;
     * les modÃ¨les de diffusion (ex. : Dall-e, Stable Diffusion)^[19] ;
     * les transformeurs gÃ©nÃ©ratifs prÃ©-entraÃ®nÃ©s (Generative Pretrained
       Transformers, ou GPT en anglais)^[20]^,^[21], qui sont des rÃ©seaux
       de neurones artificiels fondÃ©s sur l'architecture du transformeur,
       prÃ©-entraÃ®nÃ©s sur de grands ensembles de donnÃ©es de texte non
       Ã©tiquetÃ©, Ã©quipÃ©s d'un Â« mÃ©canisme d'attention Â» et capables de
       gÃ©nÃ©rer un nouveau texte de type humain^[22]^,^[23].

   L'IA gÃ©nÃ©rative est encore loin de rÃ©pondre Â« de maniÃ¨re fiable ou
   digne de confiance, et il reste encore beaucoup de travail Ã  faire pour
   rendre ces sources fiables et impartiales Â»^[6], mais elle a des
   applications (actuelles ou potentielles) dans des domaines aussi variÃ©s
   que lâ€™art, l'industrie, le jeu vidÃ©o, la musique, la mÃ©decine, le
   dÃ©veloppement logiciel, le marketing, les biotechnologies, la finance,
   la mode^[24]^,^[25]...

ModalitÃ©s[modifier | modifier le code]

   A detailed oil painting of figures in a futuristic opera scene ThÃ©Ã¢tre
   d'OpÃ©ra Spatial, une image gÃ©nÃ©rÃ©e par Midjourney

   Un systÃ¨me d'IA gÃ©nÃ©rative est construit en appliquant un apprentissage
   automatique non supervisÃ© ou auto-supervisÃ© Ã  un ensemble de donnÃ©es.
   Les capacitÃ©s d'un systÃ¨me d'IA gÃ©nÃ©rative dÃ©pendent de la modalitÃ© ou
   du type d'ensemble de donnÃ©es utilisÃ©.
     * Texte : les systÃ¨mes d'IA gÃ©nÃ©rative formÃ©s sur des mots ou des
       jetons de mots (tokens) incluent GPT-3, LaMDA, LLaMA, BLOOM, GPT-4
       et d'autres. Ils sont capables de traiter du langage naturel, de
       faire de la traduction automatique et de gÃ©nÃ©rer du langage naturel
       et peuvent Ãªtre utilisÃ©s comme modÃ¨les de base pour d'autres
       tÃ¢ches. Les principaux ensembles de donnÃ©es sont BookCorpus,
       WikipÃ©dia et d'autres.
     * Code : Outre les textes en langage naturel, de grands modÃ¨les de
       langage peuvent Ãªtre entraÃ®nÃ©s sur du texte en langage de
       programmation, ce qui leur permet de gÃ©nÃ©rer du code source de
       nouveaux programmes informatiques.
     * Images : Les systÃ¨mes d'IA gÃ©nÃ©rative formÃ©s sur des ensembles
       d'images avec des lÃ©gendes textuelles comprennent Imagen, DALL-E,
       Midjourney, Stable Diffusion et autres. Ils sont couramment
       utilisÃ©s pour la gÃ©nÃ©ration de texte en image et le transfert de
       style neuronal^[26]. Les jeux de donnÃ©es sont notamment LAION-5B et
       d'autres.
     * MolÃ©cules : Les systÃ¨mes d'IA gÃ©nÃ©rative peuvent Ãªtre entraÃ®nÃ©s sur
       des sÃ©quences d'acides aminÃ©s ou des reprÃ©sentations molÃ©culaires
       telles que SMILES reprÃ©sentant l'ADN ou les protÃ©ines. Ces
       systÃ¨mes, comme AlphaFold, sont utilisÃ©s pour la prÃ©diction de la
       structure des protÃ©ines et la dÃ©couverte de mÃ©dicaments^[27]. Les
       ensembles de donnÃ©es comprennent divers ensembles de donnÃ©es
       biologiques.
     * Musique : les systÃ¨mes d'IA gÃ©nÃ©rative tels que MusicLM peuvent
       Ãªtre formÃ©s sur les formes d'ondes sonores de la musique
       enregistrÃ©e avec des annotations textuelles afin de gÃ©nÃ©rer de
       nouveaux Ã©chantillons musicaux fondÃ©s sur des descriptions de texte
       telles qu'Â« une mÃ©lodie de violon apaisante soutenue par un riff de
       guitare distordu Â».
     * VidÃ©o : L'IA gÃ©nÃ©rative entraÃ®nÃ©e sur une vidÃ©o annotÃ©e peut
       gÃ©nÃ©rer des clips vidÃ©o cohÃ©rents dans le temps. Des IA comme Gen1
       par RunwayML^[28] et Make-A-Video de Meta^[29] peuvent gÃ©nÃ©rer des
       vidÃ©os de cette maniÃ¨re.
     * L'IA gÃ©nÃ©rative est dite Â« unimodale Â» quand elle ne peut accepter
       et crÃ©er qu'un seul type de donnÃ©es (du texte par exemple) ; et
       Â« multimodale Â» quand elle peut traiter ou gÃ©nÃ©rer plusieurs types
       de contenus (par exemple du texte, des images et/ou du son)^[30].

Investissements financiers[modifier | modifier le code]

   L'investissement dans l'IA gÃ©nÃ©rative a bondi, Ã  partir du dÃ©but des
   annÃ©es 2020, principalement avec de grandes entreprises telles que
   Microsoft, Google et Baidu, mais aussi avec de nombreuses petites
   entreprises dÃ©veloppant des modÃ¨les d'IA gÃ©nÃ©rative^[1]^,^[31]^,^[32].

Transparence du systÃ¨me d'IA ?[modifier | modifier le code]

   En 2023, il est reprochÃ© aux systÃ¨mes dâ€™ IA et notamment d'IA
   gÃ©nÃ©rative de ne pas Ãªtre transparents, autrement dit d'Ãªtre des
   Â« boites noires Â» dont mÃªme les dÃ©veloppeurs de l'IA ne comprennent pas
   le fonctionnement interne. De grands concepteurs dâ€™IA comme OpenAI^[12]
   et Meta^[33] ont commencÃ© Ã  publier des Â« Fiches SystÃ¨me Â»^[34] (ou
   Â« System Cards Â», inspirÃ©es des Â« Model Cards Â», une norme largement
   acceptÃ©e pour la documentation des modÃ¨les dâ€™IA). Ces fiches
   contiennent des informations sur lâ€™architecture et le fonctionnement de
   leurs IA : objectifs, composants, donnÃ©es, performances, impacts
   potentiels dâ€™un systÃ¨me dâ€™IA et mesures dâ€™attÃ©nuationâ€¦ Câ€™est une
   premiÃ¨re Ã©tape vers une documentation des systÃ¨mes dâ€™IA, lesquels
   combinent souvent plusieurs modÃ¨les et technologies interagissant pour
   accomplir des tÃ¢ches spÃ©cifiques.

   Une Ã©tude rÃ©cente laisse penser qu'il semble cependant possible de
   rendre plus transparente cette boite noire, grÃ¢ce Ã  lâ€™analyse de
   Fourier appliquÃ©e aux rÃ©seaux de neurones profonds. En effet, des
   chercheurs de lâ€™UniversitÃ© Rice, aprÃ¨s avoir formÃ© un rÃ©seau de
   neurones profonds Ã  reconnaÃ®tre les flux complexes dâ€™air ou dâ€™eau et
   prÃ©dire comment ces flux changeraient avec le temps, lui ont ensuite
   appliquÃ© une analyse de Fourier (sur les Ã©quations rÃ©gissant le rÃ©seau
   de neurones). Cette mÃ©thode a rÃ©vÃ©lÃ© ce que le rÃ©seau de neurones avait
   appris, et surtout comment il Ã©tait parvenu Ã  ces connaissances^[35].

Vers une rÃ©gulation, une rÃ©glementation et une gestion des risques[modifier |
modifier le code]

   DiffÃ©rents tests comme HELM^[36] ou MMLU^[37] permettent d'estimer les
   capacitÃ©s ou les comportements indÃ©sirables (rÃ©ponses biaisÃ©es,
   fausses, hallucinations, reprise de contenu protÃ©gÃ© par le droit
   dâ€™auteur...) de grands modÃ¨les de langage.

   L'Union europÃ©enne, les Ã‰tats-Unis et la Chine ont commencÃ© Ã  se doter
   de lÃ©gislations sur le numÃ©rique commenÃ§ant Ã  prendre en compte l'IA,
   mais qui s'est avÃ©rÃ©e dÃ©passÃ©e par les progrÃ¨s rapides de l'IA
   gÃ©nÃ©rative.

   En 2023, de nombreuses alertes ont Ã©tÃ© lancÃ©es par des pionniers du
   deep learning (ex. : Geoffrey Hinton, Yoshua Bengio, Sam Altman ou
   Demis Hassabis). Notamment via une demande de moratoire de 6 mois dans
   le dÃ©veloppement de lâ€™IA (lancÃ© le 28 mars par le Future of Life
   Institute qui sera signÃ©e par plus de 30 000 personnes dont beaucoup de
   sommitÃ©s de lâ€™IA telles que le laurÃ©at du prix Turing Yoshua Bengio et
   Elon Musk). Puis, en mai 2023, une dÃ©claration du Center for AI Safety
   (Â« Centre pour la sÃ»retÃ© de l'IA Â») affirmant que Â« lâ€™attÃ©nuation du
   risque dâ€™extinction de lâ€™humanitÃ© liÃ© Ã  lâ€™IA devrait Ãªtre une prioritÃ©
   mondiale au mÃªme titre que la prÃ©vention des pandÃ©mies et des guerres
   nuclÃ©aires Â» est signÃ©e par d'Ã©minents chercheurs ainsi que par les
   dirigeants de OpenAI, Google DeepMind et Anthropic^[38].

   Selon Heidy Khlaaf (directrice chargÃ©e de lâ€™assurance de
   lâ€™apprentissage automatique chez Trail of Bits, une sociÃ©tÃ© de
   recherche et de conseil en cybersÃ©curitÃ©), les centrales nuclÃ©aires ont
   des milliers de pages de documents pour prouver que le systÃ¨me ne cause
   de tort Ã  personne, et pour Melissa HeikkilÃ¤ : Â« la chose la plus
   importante que la communautÃ© de lâ€™IA pourrait apprendre du risque
   nuclÃ©aire est lâ€™importance de la traÃ§abilitÃ© Â»^[39], deux choses encore
   peu dÃ©veloppÃ©es dans le secteur de l'IA. La rÃ©glementation de l'IA est
   parfois comparÃ©e Ã  la rÃ©glementation du secteur nuclÃ©aire^[40]. Sam
   Altman (PDG dâ€™OpenAI) a suggÃ©rÃ© la mise en place d'un systÃ¨me de
   licences, dans lequel l'entraÃ®nement de systÃ¨mes d'IA ayant des
   capacitÃ©s Ã©levÃ©es nÃ©cessiterait l'octroi d'une licence, et pour ce
   faire de se conformer Ã  des exigences de sÃ©curitÃ© (de mÃªme que les
   opÃ©rateurs dâ€™installations nuclÃ©aires sont tenus dâ€™Ãªtre licenciÃ©s par
   un rÃ©gulateur nuclÃ©aire)^[40]. Aidan Gomez (cofondateur de Cohere) a
   jugÃ© cette formule excessive et dÃ©tournant l'attention de risques -
   selon lui plus rÃ©els - de l'IA mal utilisÃ©e dans les mÃ©dias sociaux et
   la mÃ©decine^[41], de mÃªme que Yann LeCun (embauchÃ© comme scientifique
   en chef de lâ€™IA chez Meta, le groupe qui dÃ©tient Facebook et travaille
   Ã  la crÃ©ation d'un MÃ©tavers) et Joelle Pineau (vice-prÃ©sidente de la
   recherche en IA chez Meta) qui jugent ces craintes ridicules et
   dÃ©raisonnables, affirmant que les IAs comme ChatGPT ne sont pas encore
   conscientes et ne peuvent donc pas selon eux manipuler ou dÃ©truire
   l'humanitÃ©^[42]. Mais en 2023, des chercheurs dâ€™Oxford, de Cambridge,
   de lâ€™UniversitÃ© de Toronto, de lâ€™UniversitÃ© de MontrÃ©al, de Google
   DeepMind, dâ€™OpenAI, dâ€™Anthropic, de plusieurs organismes de recherche Ã
   but non lucratif sur lâ€™IA et Yoshua Bengio (laurÃ©at du prix Turing)
   suggÃ¨rent dans un article^[43] que les crÃ©ateurs des modÃ¨les d'IA les
   plus puissants doivent pouvoir Ã©valuer si leurs IAs ont des capacitÃ©s
   pouvant prÃ©senter des risques Â« extrÃªmes Â» (planification Ã  long terme,
   manipulation, auto-prolifÃ©ration, conscience de la situation, capacitÃ©s
   Ã  mener des cyberattaques ou Ã  acquÃ©rir des armes notamment
   biologiques...). Les dÃ©veloppeurs doivent Ã©galement apprendre Ã  mesurer
   la propension des modÃ¨les Ã  appliquer leurs capacitÃ©s Ã  nuire (ceci
   peut se faire grÃ¢ce Ã  des Â« Ã©valuations dâ€™alignement Â»). Selon eux,
   Â« ces Ã©valuations deviendront cruciales pour informer les dÃ©cideurs
   politiques et les autres parties prenantes, et pour prendre des
   dÃ©cisions responsables concernant lâ€™entraÃ®nement, le dÃ©ploiement et la
   sÃ©curitÃ© des modÃ¨les d'IA Â»^[43]^,^[39].

   Aleksander MÄ…dry (professeur dâ€™informatique au Cadence Design Systems
   du MIT, et directeur du Center for Deployable Machine Learning du MIT)
   a Ã©tÃ© auditÃ© en mars 2023 par le Sous-comitÃ© sur la cybersÃ©curitÃ©, les
   technologies de lâ€™information et lâ€™innovation gouvernementale lors
   d'une cession intitulÃ©e Â« ProgrÃ¨s de lâ€™IA : sommes-nous prÃªts pour une
   rÃ©volution technologique ? Â»^[44]. Selon MÄ…dry, Â« nous sommes Ã  un
   point dâ€™inflexion en ce qui concerne ce que lâ€™IA du futur
   apportera(...) le gouvernement devrait plutÃ´t sâ€™interroger sur
   lâ€™objectif et lâ€™explicabilitÃ© des algorithmes utilisÃ©s par les
   entreprises, en tant que prÃ©curseur Ã  la rÃ©glementation Â» pour
   sâ€™assurer que lâ€™IA est cohÃ©rente avec les objectifs de la sociÃ©tÃ©. Ce
   serait une erreur selon lui de rÃ©glementer lâ€™IA comme si elle Ã©tait
   humaine â€“ par exemple en demandant Ã  lâ€™IA dâ€™expliquer son raisonnement
   et en supposant que les rÃ©ponses qui en rÃ©sultent sont fiables.

   Concernant le risque de suppression massive d'emplois, dans le TIME,
   Altman a annoncÃ© quâ€™OpenAI aborderait en 2024 le sujet de la
   redistribution des richesses (Â« OpenAI mÃ¨ne actuellement une Ã©tude de
   cinq ans sur le revenu universel Â», qui doit se terminer en 2024)^[45].
   Rishi Sunak (premier ministre britannique) a invitÃ© la communautÃ©
   internationale Ã  Bletchey park en novembre 2023 pour un premier sommet
   mondial en sÃ»retÃ© de l'IA, abordant notamment les risques existentiels
   liÃ©s Ã  l'IA^[46]. Sunak propose que soit crÃ©Ã© un groupe dâ€™experts
   internationaux, sur le modÃ¨le du GIEC, qui serait dans un premier temps
   chargÃ© de publier un Ã©tat des lieux de lâ€™IA. Le 1^er novembre, la
   Chine, les Ã‰tats-Unis, lâ€™Union europÃ©enne et une vingtaine de pays ont
   signÃ© la dÃ©claration de Bletchley pour un dÃ©veloppement Â« sÃ»r Â» de
   lâ€™intelligence artificielle^[47]. La veille, trois de ces pays (France,
   Allemagne et Italie) avaient signÃ© Ã  Rome un accord de coopÃ©ration sur
   l'IA Â« dans le prolongement des efforts globaux dÃ©ployÃ©s en faveur de
   la transition numÃ©rique et Ã©cologique Â»^[48].

Ã‰lÃ©ments de prospective[modifier | modifier le code]

   L'IA gÃ©nÃ©rative, telle qu'elle se dÃ©veloppe Ã  partir de 2022 pourrait
   Ã©voluer vers le formes suivantes d'IA :
    1. L'IA interactive, dÃ©jÃ  en cours de dÃ©veloppement, et capable
       d'interagir avec le monde rÃ©el de maniÃ¨re plus complexe, en
       collaborant avec d'autres logiciels, des machines ou des robots.
       Pour Mustafa Suleyman (cofondateur de DeepMind et ex-
       vice-prÃ©sident des produits et des politiques dâ€™IA de Google),
       interrogÃ© par la MIT Technology Review (septembre 2023) c'est
       l'Ã©tape qui suivra l'IA gÃ©nÃ©rative, avec les mÃªmes risques et
       atouts mais plus difficile Ã  contrÃ´ler en cas d'usage
       malveillant^[49]. Pour Demis Hassabis (autre cofondateur de
       DeepMind), elle Â« a le potentiel de transformer de nombreux aspects
       de nos vies".
    2. L'IA autonome, Ã  ses dÃ©buts avec par exemple le vÃ©hicule autonome,
       permettra Ã  des machines d'accomplir des tÃ¢ches sans intervention
       humaine. Elle semble pouvoir notamment concerner les transports, la
       santÃ© et la sÃ©curitÃ©.
    3. L'IA consciente, gÃ©nÃ©ralement considÃ©rÃ©e comme une possibilitÃ©
       encore lointaine, serait capable d'une forme de ressenti des
       Ã©motions et d'avoir une conscience de soi. C'est une technologie
       controversÃ©e, qui soulÃ¨ve des questions Ã©thiques et philosophiques
       complexes.

RÃ©fÃ©rences[modifier | modifier le code]

    1. â†‘ ^a et b (en) Erin Griffith et Cade Metz, Â« Anthropic Said to Be
       Closing In on $300 Million in New A.I. Funding Â», The New York
       Times, 27 janvier 2023 (consultÃ© le 14 mars 2023)
    2. â†‘ (en) Nate Lanxon, Dina Bass et Jackie Davalos, Â« A Cheat Sheet to
       AI Buzzwords and Their Meanings Â», Bloomberg News,â€ 10 mars 2023
       (lire en ligne, consultÃ© le 14 mars 2023)
    3. â†‘ Â« Explainer: What is Generative AI, the technology behind
       OpenAI's ChatGPT? Â», Reuters,â€ 17 mars 2023 (lire en ligne,
       consultÃ© le 17 mars 2023)
    4. â†‘ Ahona Rudra, Â« Risques de cybersÃ©curitÃ© liÃ©s Ã  l'IA gÃ©nÃ©rative Â»,
       sur powerdmarc.com, 26 juillet 2023 (consultÃ© le 27 aoÃ»t 2023)
    5. â†‘ (en) Julia Dhar, Allison Bailey, StÃ©phanie Mingardon et Jennifer
       Tankersley, Â« The Persuasive Power of the Digital Nudge Â», sur BCG
       Global, 8 janvier 2021 (consultÃ© le 9 novembre 2023)
    6. â†‘ ^a b et c (en) Rachel Gordon, Â« MIT CSAIL (Laboratoire
       dâ€™Informatique et dâ€™Intelligence Artificielle) researchers discuss
       frontiers of generative AI Â», sur MIT News, 12 avril 2023 (consultÃ©
       le 31 octobre 2023)
    7. â†‘ (en) Will Douglas Heaven, Â« How existential risk became the
       biggest meme in AI Â», MIT Technology Review,â€ 19 juin 2023 (lire en
       ligne, consultÃ© le 31 octobre 2023)
    8. â†‘ Alexandre Piquard, Â« Intelligence artificielle : au sommet de
       Londres, PDG et dirigeants face au dÃ©fi de la rÃ©gulation Â», Le
       Monde.fr,â€ 2 novembre 2023 (lire en ligne, consultÃ© le 9 novembre
       2023)
    9. â†‘ En gÃ©nÃ©ral, le petaflop/jour est utilisÃ© comme mÃ©trique. Un
       petaflop-jour (pf-jour) consiste Ã  effectuer 10^15 opÃ©rations de
       rÃ©seau neuronal par seconde pendant une journÃ©e, soit un total
       dâ€™environ 10^20 opÃ©rations. Câ€™est une unitÃ© de mesure pratique,
       similaire au kW/h pour lâ€™Ã©nergie. PlutÃ´t que les FLOPS thÃ©oriques
       maximaux du matÃ©riel, on cherche Ã  estimer le nombre rÃ©el
       dâ€™opÃ©rations faites ; additions et multiplications sont comptÃ©es
       comme des opÃ©rations distinctes, et on ignore les modÃ¨les
       dâ€™ensemble. Sur cette pÃ©riode, le temps de doublement pour la ligne
       de meilleure adÃ©quation est de 3,4 mois.
   10. â†‘ (en) Â« AI and compute Â», sur openai.com, 16 mai 2018 (consultÃ© le
       9 novembre 2023)
   11. â†‘ (en) Adam Pasick, Â« Artificial Intelligence Glossary: Neural
       Networks and Other Terms Explained Â», The New York Times,â€ 27 mars
       2023 (lire en ligne, consultÃ© le 22 avril 2023)
   12. â†‘ ^a et b (en) Â« DALLÂ·E 3 system card Â», sur openai.com, 3 octobre
       2023 (consultÃ© le 9 novembre 2023)
   13. â†‘ (en) Charlotte Bird, Eddie L. Ungless et Atoosa Kasirzadeh,
       Â« Typology of Risks of Generative Text-to-Image Models Â», AAAI/ACM
       Conference on AI, Ethics, and Society,â€ 2023 (arXiv 2307.05543)
   14. â†‘ (en) Abeba Birhane, Vinay Uday Prabhu et Emmanuel Kahembwe,
       Â« Multimodal datasets: misogyny, pornography, and malignant
       stereotypes Â», Arxiv,â€ 5 octobre 2021 (arXiv 2110.01963)
   15. â†‘ (en) Jaemin Cho, Abhay Zala et Mohit Bansal, Â« DALL-Eval: Probing
       the Reasoning Skills and Social Biases of Text-to-Image Generation
       Models Â», ICCV 2023,â€ 2022 (arXiv 2202.04053)
   16. â†‘ (en) Â« World leaders gather at UK summit aiming to tackle
       'frontier AI' risks Â», sur France 24, 1^er novembre 2023 (consultÃ©
       le 9 novembre 2023)
   17. â†‘ (en) Cade Metz, Â« OpenAI Plans to Up the Ante in Techâ€™s A.I.
       Race Â», The New York Times,â€ 14 mars 2023 (ISSN 0362-4331, lire en
       ligne, consultÃ© le 9 novembre 2023)
   18. â†‘ (en) Roose, Â« A Coming-Out Party for Generative A.I., Silicon
       Valley's New Craze Â», The New York Times, 21 octobre 2022 (consultÃ©
       le 14 mars 2023)
   19. â†‘ (en) Prafulla Dhariwal et Alex Nichol, Â« Diffusion Models Beat
       GANs on Image Synthesis Â», NeurIPS,â€ 2021 (arXiv 2105.05233)
   20. â†‘ (en) Luhui Hu, Â« Generative AI and Future Â», sur Medium, 15
       novembre 2022 (consultÃ© le 9 novembre 2023)
   21. â†‘ (en) Â« Generative Artificial Intelligence: Trends and
       Prospects Â», sur ieeexplore.ieee.org (consultÃ© le 9 novembre 2023)
   22. â†‘ (en) Â« Generative AI: a game-changer society needs to be ready
       for Â», sur World Economic Forum, 9 janvier 2023 (consultÃ© le 9
       novembre 2023)
   23. â†‘ (en) Billy Perrigo, Â« The A to Z of Artificial Intelligence Â»,
       Time,â€ 13 avril 2023 (lire en ligne, consultÃ© le 2 novembre 2023).
   24. â†‘ (en) Â« Don't fear an AI-induced jobs apocalypse just yet Â», The
       Economist, 6 mars 2023 (consultÃ© le 14 mars 2023)
   25. â†‘ (en) Holger Harreis, Theodora Koullias, Roger Roberts et Kimberly
       Te, Â« Generative AI: Unlocking the future of fashion Â»
   26. â†‘ (en) Aditya Ramesh, Mikhail Pavlov, Gabriel Goh et Scott Gray,
       Â« Zero-Shot Text-to-Image Generation Â», Proceedings of the 38th
       International Conference on Machine Learning, PMLR,â€ 1^er juillet
       2021, p. 8821â€“8831 (arXiv 2102.12092, lire en ligne, consultÃ© le 9
       novembre 2023)
   27. â†‘ (en) Will Douglas Heaven, Â« AI is dreaming up drugs that no one
       has ever seen. Now we've got to see if they work Â», MIT Technology
       Review, Massachusetts Institute of Technology, 15 fÃ©vrier 2023
       (consultÃ© le 15 mars 2023)
   28. â†‘ (en) Cade Metz, Â« Instant Videos Could Represent the Next Leap in
       A.I. Technology Â», The New York Times, 4 avril 2023
   29. â†‘ (en) Queenie Wong, Â« Facebook Parent Meta's AI Tool Can Create
       Artsy Videos From Text Â», cnet.com, 29 septembre 2022 (consultÃ© le
       4 avril 2023)
   30. â†‘ (en) Arham Islam, Â« A History of Generative AI: From GAN to
       GPT-4 Â», sur MarkTechPost, 21 mars 2023 (consultÃ© le 9 novembre
       2023)
   31. â†‘ (en) Â« The race of the AI labs heats up Â», The Economist, 30
       janvier 2023 (consultÃ© le 14 mars 2023)
   32. â†‘ (en) June Yang et Burak Gokturk, Â« Google Cloud brings generative
       AI to developers, businesses, and governments Â», 14 mars 2023
   33. â†‘ ex. : (en) Â« System Cards, a new resource for understanding how
       AI systems work Â», sur ai.meta.com (consultÃ© le 2 novembre 2023)
   34. â†‘ (en) Margaret Mitchell, Simone Wu, Andrew Zaldivar et Parker
       Barnes, Â« Model Cards for Model Reporting Â», ACM Conference on
       Fairness, Accountability, and Transparency, ACM,â€ 29 janvier 2019,
       p. 220â€“229 (ISBN 978-1-4503-6125-5, DOI 10.1145/3287560.3287596,
       arXiv 1810.03993, lire en ligne, consultÃ© le 2 novembre 2023)
   35. â†‘ (en) Charles Q. Choi, Â« 200-Year-Old Math Opens Up AIâ€™s
       Mysterious Black Box - IEEE Spectrum Â», sur spectrum.ieee.org, 25
       fÃ©vrier 2023 (consultÃ© le 28 octobre 2023)
   36. â†‘ (en) Sharon Goldman, Â« Stanford debuts first AI benchmark to help
       understand LLMs Â», sur VentureBeat, 17 novembre 2022 (consultÃ© le 9
       dÃ©cembre 2023)
   37. â†‘ (en) Matthew Sparkes, Â« Google says its Gemini AI outperforms
       both GPT-4 and expert humans Â», sur New Scientist, 6 dÃ©cembre 2023
       (consultÃ© le 9 dÃ©cembre 2023)
   38. â†‘ Â« L'IA pourrait poser un Â« risque d'extinction Â» pour l'humanitÃ©,
       affirment 350 experts Â», sur Les Echos, 30 mai 2023 (consultÃ© le 9
       novembre 2023)
   39. â†‘ ^a et b (en) Melissa HeikkilÃ¤, Â« To avoid AI doom, learn from
       nuclear safety Â», MIT Technology Review,â€ 6 juin 2023 (lire en
       ligne, consultÃ© le 31 octobre 2023)
   40. â†‘ ^a et b (en) Heidy Khlaaf, Â« How AI Can Be Regulated Like Nuclear
       Energy Â», sur TIME, 24 octobre 2023 (consultÃ© le 2 novembre 2023)
   41. â†‘ (en) George Hammond, Â« Aidan Gomez: AI threat to human existence
       is â€˜absurdâ€™ distraction from real risks Â», sur Financial Times, 16
       juin 2023 (consultÃ© le 1^er novembre 2023)
   42. â†‘ (en) Melissa HeikkilÃ¤, Â« Metaâ€™s AI leaders want you to know fears
       over AI existential risk are â€œridiculousâ€ Â», sur MIT Technology
       Review, 20 juin 2023 (consultÃ© le 1^er novembre 2023)
   43. â†‘ ^a et b (en) Toby Shevlane, Sebastian Farquhar, Ben Garfinkel et
       Mary Phuong, Â« Model evaluation for extreme risks Â», Arxiv,â€ 2023
       (DOI 10.48550/ARXIV.2305.15324, arXiv 2305.15324)
   44. â†‘ (en) Â« Advances in AI: Are We Ready For a Tech Revolution? Â», sur
       United States House Committee on Oversight and Accountability, 25
       octobre 2023 (consultÃ© le 31 octobre 2023)
   45. â†‘ (en) Billy Perrigo, Â« OpenAI Could Quit Europe Over New AI Rules,
       CEO Warns Â», sur Time, 24 mai 2023 (consultÃ© le 2 novembre 2023)
   46. â†‘ Â« Intelligence artificielle : Â« Des millions de personnes vont
       bientÃ´t perdre leur travail Â» Â», sur Le Point, 3 novembre 2023
       (consultÃ© le 9 novembre 2023)
   47. â†‘ Â« Les Etats-Unis, la Chine et l'UE signent une premiÃ¨re
       dÃ©claration mondiale sur les risques de l'IA Â», sur BFMTV (consultÃ©
       le 9 novembre 2023)
   48. â†‘ Olivier Tosseri, Â« L'Italie, l'Allemagne et la France renforcent
       leur coopÃ©ration dans l'IA Â», sur Les Echos, 31 octobre 2023
       (consultÃ© le 9 novembre 2023)
   49. â†‘ (en) Will Douglas Heaven, Â« DeepMindâ€™s cofounder: Generative AI
       is just a phase. Whatâ€™s next is interactive AI. Â», MIT Technology
       Review,â€ 15 septembre 2023 (lire en ligne, consultÃ© le 1^er
       novembre 2023)

Articles connexes[modifier | modifier le code]

     * Arts de l'intelligence artificielle
     * Recherche gÃ©nÃ©rative assistÃ©e par intelligence artificielle
     * RÃ©seau antagoniste gÃ©nÃ©ratif
     * Transformateur gÃ©nÃ©ratif prÃ©-entraÃ®nÃ©
     * Grand modÃ¨le de langage
     * Google Gemini
     * Falcon 180B

     * icÃ´ne dÃ©corative Portail de lâ€™informatique
     * icÃ´ne dÃ©corative Portail de lâ€™Ã©criture
     * icÃ´ne dÃ©corative Portail des annÃ©es 2020
     * icÃ´ne dÃ©corative Portail de lâ€™imagerie numÃ©rique

   v Â· m
   Intelligence artificielle (IA)
   Concepts
     * Effet IA
     * Grand modÃ¨le de langage
     * Hallucination (IA)
     * IA gÃ©nÃ©rale
     * IA gÃ©nÃ©rative

   Techniques
     * Analyse prÃ©dictive
     * Apprentissage automatique
     * Apprentissage non supervisÃ©
     * Apprentissage profond
     * Apprentissage supervisÃ©
     * ModÃ¨le de fondation
     * ModÃ¨le des croyances transfÃ©rables
     * IA symbolique
     * RÃ©seau bayÃ©sien
     * RÃ©seau de neurones artificiels
     * RÃ©seau neuronal convolutif
     * Transformeur

   Applications
     * Art crÃ©Ã© par IA
     * ChatGPT
     * DeepL
     * Diagnostic (IA)
     * Ã‰criture assistÃ©e par IA
     * IA dans la santÃ©
     * IA dans le jeu vidÃ©o
     * Perception artificielle
     * Planification (IA)
     * Robotique
     * Traduction automatique
     * Traitement automatique du langage naturel
     * VÃ©hicule autonome
     * Vision par ordinateur

   Enjeux et philosophie
     * Alignement de l'IA
     * Chambre chinoise
     * Conscience artificielle
     * ContrÃ´le des capacitÃ©s de l'IA
     * Ã‰thique de l'IA
     * IA digne de confiance
     * Philosophie de l'IA
     * SÃ»retÃ© de l'IA

   Histoire et Ã©vÃ©nements
     * Histoire de l'intelligence artificielle
     * Logic Theorist (1955)
     * Perceptron (1957)
     * General Problem Solver (1959)
     * Prolog (1972)
     * Matchs Deep Blue contre Kasparov (1996-1997)
     * Match AlphaGo - Lee Sedol (2016)

   Science-fiction
     * Anticipation (IA)
     * IA-complet
     * IA gÃ©nÃ©rale
     * Risque de catastrophe planÃ©taire liÃ© Ã  l'intelligence artificielle
       gÃ©nÃ©rale
     * Superintelligence

       RÃ¨glementation
     * LÃ©gislation sur l'IA
     * RÃ©glementation de l'IA

   Organisations
     * Agence francophone pour l'IA
     * Google DeepMind
     * OpenAI
     * Partenariat sur l'IA

   Ouvrages
     * DÃ©claration de MontrÃ©al pour un dÃ©veloppement responsable de
       l'intelligence artificielle
     * Lettre ouverte sur l'IA
     * Intelligence artificielle : une approche moderne
     * I.A. La Plus Grande Mutation de l'Histoire

   Ce document provient de
   Â« https://fr.wikipedia.org/w/index.php?title=Intelligence_artificielle_
   gÃ©nÃ©rative&oldid=210402889 Â».
   CatÃ©goriesâ€¯:
     * Apprentissage automatique
     * RÃ©seau de neurones artificiels
     * Intelligence artificielle
     * Culture Internet

   CatÃ©gories cachÃ©esâ€¯:
     * Article Ã  rÃ©fÃ©rence nÃ©cessaire
     * Portail:Informatique/Articles liÃ©s
     * Portail:Technologies/Articles liÃ©s
     * Portail:Sciences/Articles liÃ©s
     * Portail:Ã‰criture/Articles liÃ©s
     * Portail:AnnÃ©es 2020/Articles liÃ©s
     * Portail:XXIe siÃ¨cle/Articles liÃ©s
     * Portail:Imagerie numÃ©rique/Articles liÃ©s

     * La derniÃ¨re modification de cette page a Ã©tÃ© faite le 9 dÃ©cembre
       2023 Ã  23:33.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les mÃªmes conditions ; dâ€™autres
       conditions peuvent sâ€™appliquer. Voyez les conditions dâ€™utilisation
       pour plus de dÃ©tails, ainsi que les crÃ©dits graphiques. En cas de
       rÃ©utilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       WikipediaÂ® est une marque dÃ©posÃ©e de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance rÃ©gie par le paragraphe 501(c)(3) du
       code fiscal des Ã‰tats-Unis.

     * Politique de confidentialitÃ©
     * Ã€ propos de WikipÃ©dia
     * Avertissements
     * Contact
     * Code de conduite
     * DÃ©veloppeurs
     * Statistiques
     * DÃ©claration sur les tÃ©moins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou dÃ©sactiver la limitation de largeur du contenu
