   #alternate Modifier Wikip√©dia (fr) Flux Atom de Wikip√©dia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails th√©matiques
     * Article au hasard
     * Contact

   Contribuer
     * D√©buter sur Wikip√©dia
     * Aide
     * Communaut√©
     * Modifications r√©centes
     * Faire un don

   Langues
   Sur cette version linguistique de Wikip√©dia, les liens interlangues
   sont plac√©s en haut √† droite du titre de l‚Äôarticle.
   Aller en haut.
   Wikip√©dia l'encyclop√©die libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * Cr√©er un compte
     * Se connecter

   [ ] Outils personnels
     * Cr√©er un compte
     * Se connecter

   Pages pour les contributeurs d√©connect√©s en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
     * D√©but
     * 1Capacit√©s

     2Principes sous-jacents

     3Modalit√©s

     4Investissements financiers



   5Transparence du syst√®me d'IA ?



   6Vers une r√©gulation, une r√©glementation et une gestion des risques



   7√âl√©ments de prospective



   8R√©f√©rences



   9Articles connexes

   [ ] Basculer la table des mati√®res

Intelligence artificielle g√©n√©rative

   [ ] 17 langues
     * ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
     * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
     * English
     * Espa√±ol
     * ŸÅÿßÿ±ÿ≥€å
     * ◊¢◊ë◊®◊ô◊™
     * Italiano
     * Êó•Êú¨Ë™û
     * ÌïúÍµ≠Ïñ¥
     * Portugu√™s
     * Runa Simi
     * –†—É—Å—Å–∫–∏–π
     * T√ºrk√ße
     * –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
     * Ti·∫øng Vi·ªát
     * ‰∏≠Êñá
     * IsiZulu

   Modifier les liens

     * Article
     * Discussion

   [ ] fran√ßais

     * Lire
     * Modifier
     * Modifier le code
     * Voir l‚Äôhistorique

   [ ] Outils
   Outils
   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
   Actions
     * Lire
     * Modifier
     * Modifier le code
     * Voir l‚Äôhistorique

   G√©n√©ral
     * Pages li√©es
     * Suivi des pages li√©es
     * T√©l√©verser un fichier
     * Pages sp√©ciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * √âl√©ment Wikidata

   Imprimer‚ÄØ/‚ÄØexporter
     * Cr√©er un livre
     * T√©l√©charger comme PDF
     * Version imprimable

   Dans d‚Äôautres projets
     * Wikimedia Commons

   Un article de Wikip√©dia, l'encyclop√©die libre.
   Page d‚Äôaide sur l‚Äôhomonymie

   Ne doit pas √™tre confondu avec Intelligence artificielle g√©n√©rale.

   L'intelligence artificielle g√©n√©rative ou IA g√©n√©rative (ou GenAI) est
   un type de syst√®me d'intelligence artificielle (IA) capable de g√©n√©rer
   du texte, des images ou d'autres m√©dias en r√©ponse √† des invites (ou
   prompts en anglais)^[1]^,^[2]. Elle est dite multimodale quand elle est
   construite √† partir de plusieurs mod√®les g√©n√©ratifs, ou d'un mod√®le
   entra√Æn√© sur plusieurs types de donn√©es et qu'elle peut produire
   plusieurs types de donn√©es. Par exemple, la version GPT-4 d'OpenAI
   accepte les entr√©es sous forme de texte et/ou d'image^[3].

   Elle semble avoir des applications possibles dans presque tous les
   domaines, avec une balance des risques et des opportunit√©s encore
   discut√©e : l'IA g√©n√©rative est en effet aussi source d'inqui√©tudes et
   des d√©fis √©thiques, techniques et socio√©conomiques √† la hauteur des
   espoirs qu'elle suscite. Elle peut contribuer √† des usages abusifs,
   accidentels ou d√©tourn√©s (militaires notamment), √† une suppression
   massive d'emploi, √† une manipulation de la population via la cr√©ation
   de fausses nouvelles (fake news en anglais), de deepfakes^[4] ou de
   nudges num√©riques^[5]. Elle questionne aussi philosophiquement la
   nature de la conscience, de la cr√©ativit√©, de la paternit√©^[6], et cr√©e
   de nouvelles interactions homme-machine. L'IA est encore peu r√©gul√©e et
   la difficult√© d‚Äô√©valuer la qualit√© et la fiabilit√© des contenus g√©n√©r√©s
   ou l‚Äôimpact sur la cr√©ativit√© et la propri√©t√© intellectuelle humaines
   est croissante. Certains experts craignent que des IA g√©n√©ratives √
   venir soient capables de manipuler les humains, d'acc√©der √† des
   syst√®mes d'armes, d'exploiter des failles de cybers√©curit√©, voire
   peut-√™tre bient√¥t d'acqu√©rir une forme de conscience et/ou de devenir
   incontr√¥lable au point de menacer l'existence de l'humanit√©^[7]. Un
   premier sommet mondial en s√ªret√© de l'IA est organis√©e d√©but novembre
   2023 √† Londres, o√π la cr√©ation d'un √©quivalent du GIEC pour informer
   sur les risques li√©s √† l'IA a notamment √©t√© discut√©e^[8].

Capacit√©s[modifier | modifier le code]

   Selon une analyse d‚ÄôOpenAI en 2018 : ¬´ depuis 2012, la quantit√© de
   calcul utilis√©e dans les plus grands entra√Ænements d‚ÄôIA a augment√© de
   mani√®re exponentielle avec un temps de doublement de 3,4 mois (en
   comparaison, la loi de Moore avait une p√©riode de doublement de 2 ans).
   Depuis 2012, cette m√©trique^[9] a augment√© de plus de 300 000 fois (une
   p√©riode de doublement de 2 ans ne donnerait qu‚Äôune augmentation de 7
   fois). ¬ª^[10]. Cette augmentation de la puissance de calcul a facilit√©
   l‚Äô√©mergence d‚ÄôIA g√©n√©ratives pouvant cr√©er des choses originales comme
   des images, des tableaux, de la musique ou du texte, en s'inspirant de
   donn√©es existantes sans les copier. Elles ne se contentent pas de
   classer les donn√©es d'entr√©e qu'on leur a fourni, ni de pr√©dire des
   donn√©es statistiquement probables ; elles g√©n√®rent des contenus
   nouveaux dont les bases ne sont qu'en partie similaire aux bases issues
   de donn√©es d'apprentissage qu'on leur a fourni^[11].

   Les versions publiques de grands mod√®les d'IA g√©n√©rative disponibles en
   2022/2023 produisent des contenus modul√©s et filtr√©s de mani√®re √
   limiter leurs biais, les contenus m√©sinformant, dangereux, racistes,
   biais√©s, choquants, haineux, non sollicit√©s, les images pornographiques
   ou sexuellement explicites^[12]^,^[13]^,^[14]^,^[15]. Au d√©but des
   ann√©es 2020, la puissance de calcul de l‚ÄôIA a doubl√© tous les six √† dix
   mois, permettant aux mod√®les d‚ÄôIA de monter en capacit√©s √† un rythme
   exponentiel.

   Les anglophones parlent de ¬´ Frontier AI ¬ª pour d√©signer les mod√®les
   d'IA aux capacit√©s les plus √©lev√©es et g√©n√©rales, et qui pourraient
   pr√©senter des risques nouveaux^[16]. Ce type d'IA s'est faite connaitre
   du public par ChatGPT (et sa variante Bing Chat), un chatbot (agent
   conversationnel programmable) construit par OpenAI √† partir de ses
   grands mod√®les de langage de fondation GPT-3 et GPT-4^[17], ainsi que
   par Bard, un chatbot de Google bas√© sur LaMDA. D'autres mod√®les d'IA
   g√©n√©rative incluent des syst√®mes artistiques d'intelligence
   artificielle tels que Stable Diffusion, Midjourney et DALL-E^[18]. Ces
   IA ont un tr√®s large spectre d'applications potentielles dans des
   domaines cr√©atifs (arts plastiques, cin√©ma, musique, √©criture, design,
   m√©t√©o, architecture...), mais aussi dans les secteurs de la sant√©, de
   la finance, des jeux vid√©o et des simulateurs, dans tous les domaines
   des sciences et techniques, des sciences sociales, de l'industrie et de
   la connaissance. Elles ont r√©cemment permis un bond en avant en
   biologie mol√©culaire et en compr√©hension de ph√©nom√®nes physiques
   complexes. Elles permettent de synth√©tiser des visage et des voix
   humaines r√©alistes. Elles offrent de nouveaux modes d'exploration
   d'hypoth√®ses et de scenarii (notamment depuis peu gr√¢ce √† la production
   de donn√©es synth√©tiques sophistiqu√©es, issues du domaine de la
   recherche g√©n√©rative assist√©e par IA)^[r√©f. n√©cessaire]...

Principes sous-jacents[modifier | modifier le code]

   Les cadres technologiques et conceptuels les plus importants pour
   aborder l'IA g√©n√©rative sont en cours d‚Äô√©laboration depuis un certain
   temps^[6], mais ils n'ont vraiment abouti que dans les ann√©es 2020 √
   plusieurs types de mod√®les d'IA particuli√®rement efficaces :
     * les r√©seaux antagonistes g√©n√©ratifs (GAN), compos√©s de deux
       parties : un r√©seau g√©n√©rateur cr√©ant de nouveaux √©chantillons de
       donn√©es, et un r√©seau discriminateur qui √©value si les √©chantillons
       sont r√©els ou faux. Les deux r√©seaux sont form√©s ensemble dans le
       cadre d'un processus concurrentiel, le r√©seau g√©n√©rateur essayant
       continuellement de produire des √©chantillons de meilleure qualit√©
       et plus r√©alistes, tandis que le r√©seau discriminateur s'efforce
       d'identifier avec pr√©cision les faux √©chantillons ;
     * les auto-encodeurs variationnels (VAE) ;
     * les mod√®les de diffusion (ex. : Dall-e, Stable Diffusion)^[19] ;
     * les transformeurs g√©n√©ratifs pr√©-entra√Æn√©s (Generative Pretrained
       Transformers, ou GPT en anglais)^[20]^,^[21], qui sont des r√©seaux
       de neurones artificiels fond√©s sur l'architecture du transformeur,
       pr√©-entra√Æn√©s sur de grands ensembles de donn√©es de texte non
       √©tiquet√©, √©quip√©s d'un ¬´ m√©canisme d'attention ¬ª et capables de
       g√©n√©rer un nouveau texte de type humain^[22]^,^[23].

   L'IA g√©n√©rative est encore loin de r√©pondre ¬´ de mani√®re fiable ou
   digne de confiance, et il reste encore beaucoup de travail √† faire pour
   rendre ces sources fiables et impartiales ¬ª^[6], mais elle a des
   applications (actuelles ou potentielles) dans des domaines aussi vari√©s
   que l‚Äôart, l'industrie, le jeu vid√©o, la musique, la m√©decine, le
   d√©veloppement logiciel, le marketing, les biotechnologies, la finance,
   la mode^[24]^,^[25]...

Modalit√©s[modifier | modifier le code]

   A detailed oil painting of figures in a futuristic opera scene Th√©√¢tre
   d'Op√©ra Spatial, une image g√©n√©r√©e par Midjourney

   Un syst√®me d'IA g√©n√©rative est construit en appliquant un apprentissage
   automatique non supervis√© ou auto-supervis√© √† un ensemble de donn√©es.
   Les capacit√©s d'un syst√®me d'IA g√©n√©rative d√©pendent de la modalit√© ou
   du type d'ensemble de donn√©es utilis√©.
     * Texte : les syst√®mes d'IA g√©n√©rative form√©s sur des mots ou des
       jetons de mots (tokens) incluent GPT-3, LaMDA, LLaMA, BLOOM, GPT-4
       et d'autres. Ils sont capables de traiter du langage naturel, de
       faire de la traduction automatique et de g√©n√©rer du langage naturel
       et peuvent √™tre utilis√©s comme mod√®les de base pour d'autres
       t√¢ches. Les principaux ensembles de donn√©es sont BookCorpus,
       Wikip√©dia et d'autres.
     * Code : Outre les textes en langage naturel, de grands mod√®les de
       langage peuvent √™tre entra√Æn√©s sur du texte en langage de
       programmation, ce qui leur permet de g√©n√©rer du code source de
       nouveaux programmes informatiques.
     * Images : Les syst√®mes d'IA g√©n√©rative form√©s sur des ensembles
       d'images avec des l√©gendes textuelles comprennent Imagen, DALL-E,
       Midjourney, Stable Diffusion et autres. Ils sont couramment
       utilis√©s pour la g√©n√©ration de texte en image et le transfert de
       style neuronal^[26]. Les jeux de donn√©es sont notamment LAION-5B et
       d'autres.
     * Mol√©cules : Les syst√®mes d'IA g√©n√©rative peuvent √™tre entra√Æn√©s sur
       des s√©quences d'acides amin√©s ou des repr√©sentations mol√©culaires
       telles que SMILES repr√©sentant l'ADN ou les prot√©ines. Ces
       syst√®mes, comme AlphaFold, sont utilis√©s pour la pr√©diction de la
       structure des prot√©ines et la d√©couverte de m√©dicaments^[27]. Les
       ensembles de donn√©es comprennent divers ensembles de donn√©es
       biologiques.
     * Musique : les syst√®mes d'IA g√©n√©rative tels que MusicLM peuvent
       √™tre form√©s sur les formes d'ondes sonores de la musique
       enregistr√©e avec des annotations textuelles afin de g√©n√©rer de
       nouveaux √©chantillons musicaux fond√©s sur des descriptions de texte
       telles qu'¬´ une m√©lodie de violon apaisante soutenue par un riff de
       guitare distordu ¬ª.
     * Vid√©o : L'IA g√©n√©rative entra√Æn√©e sur une vid√©o annot√©e peut
       g√©n√©rer des clips vid√©o coh√©rents dans le temps. Des IA comme Gen1
       par RunwayML^[28] et Make-A-Video de Meta^[29] peuvent g√©n√©rer des
       vid√©os de cette mani√®re.
     * L'IA g√©n√©rative est dite ¬´ unimodale ¬ª quand elle ne peut accepter
       et cr√©er qu'un seul type de donn√©es (du texte par exemple) ; et
       ¬´ multimodale ¬ª quand elle peut traiter ou g√©n√©rer plusieurs types
       de contenus (par exemple du texte, des images et/ou du son)^[30].

Investissements financiers[modifier | modifier le code]

   L'investissement dans l'IA g√©n√©rative a bondi, √† partir du d√©but des
   ann√©es 2020, principalement avec de grandes entreprises telles que
   Microsoft, Google et Baidu, mais aussi avec de nombreuses petites
   entreprises d√©veloppant des mod√®les d'IA g√©n√©rative^[1]^,^[31]^,^[32].

Transparence du syst√®me d'IA ?[modifier | modifier le code]

   En 2023, il est reproch√© aux syst√®mes d‚Äô IA et notamment d'IA
   g√©n√©rative de ne pas √™tre transparents, autrement dit d'√™tre des
   ¬´ boites noires ¬ª dont m√™me les d√©veloppeurs de l'IA ne comprennent pas
   le fonctionnement interne. De grands concepteurs d‚ÄôIA comme OpenAI^[12]
   et Meta^[33] ont commenc√© √† publier des ¬´ Fiches Syst√®me ¬ª^[34] (ou
   ¬´ System Cards ¬ª, inspir√©es des ¬´ Model Cards ¬ª, une norme largement
   accept√©e pour la documentation des mod√®les d‚ÄôIA). Ces fiches
   contiennent des informations sur l‚Äôarchitecture et le fonctionnement de
   leurs IA : objectifs, composants, donn√©es, performances, impacts
   potentiels d‚Äôun syst√®me d‚ÄôIA et mesures d‚Äôatt√©nuation‚Ä¶ C‚Äôest une
   premi√®re √©tape vers une documentation des syst√®mes d‚ÄôIA, lesquels
   combinent souvent plusieurs mod√®les et technologies interagissant pour
   accomplir des t√¢ches sp√©cifiques.

   Une √©tude r√©cente laisse penser qu'il semble cependant possible de
   rendre plus transparente cette boite noire, gr√¢ce √† l‚Äôanalyse de
   Fourier appliqu√©e aux r√©seaux de neurones profonds. En effet, des
   chercheurs de l‚ÄôUniversit√© Rice, apr√®s avoir form√© un r√©seau de
   neurones profonds √† reconna√Ætre les flux complexes d‚Äôair ou d‚Äôeau et
   pr√©dire comment ces flux changeraient avec le temps, lui ont ensuite
   appliqu√© une analyse de Fourier (sur les √©quations r√©gissant le r√©seau
   de neurones). Cette m√©thode a r√©v√©l√© ce que le r√©seau de neurones avait
   appris, et surtout comment il √©tait parvenu √† ces connaissances^[35].

Vers une r√©gulation, une r√©glementation et une gestion des risques[modifier |
modifier le code]

   Diff√©rents tests comme HELM^[36] ou MMLU^[37] permettent d'estimer les
   capacit√©s ou les comportements ind√©sirables (r√©ponses biais√©es,
   fausses, hallucinations, reprise de contenu prot√©g√© par le droit
   d‚Äôauteur...) de grands mod√®les de langage.

   L'Union europ√©enne, les √âtats-Unis et la Chine ont commenc√© √† se doter
   de l√©gislations sur le num√©rique commen√ßant √† prendre en compte l'IA,
   mais qui s'est av√©r√©e d√©pass√©e par les progr√®s rapides de l'IA
   g√©n√©rative.

   En 2023, de nombreuses alertes ont √©t√© lanc√©es par des pionniers du
   deep learning (ex. : Geoffrey Hinton, Yoshua Bengio, Sam Altman ou
   Demis Hassabis). Notamment via une demande de moratoire de 6 mois dans
   le d√©veloppement de l‚ÄôIA (lanc√© le 28 mars par le Future of Life
   Institute qui sera sign√©e par plus de 30 000 personnes dont beaucoup de
   sommit√©s de l‚ÄôIA telles que le laur√©at du prix Turing Yoshua Bengio et
   Elon Musk). Puis, en mai 2023, une d√©claration du Center for AI Safety
   (¬´ Centre pour la s√ªret√© de l'IA ¬ª) affirmant que ¬´ l‚Äôatt√©nuation du
   risque d‚Äôextinction de l‚Äôhumanit√© li√© √† l‚ÄôIA devrait √™tre une priorit√©
   mondiale au m√™me titre que la pr√©vention des pand√©mies et des guerres
   nucl√©aires ¬ª est sign√©e par d'√©minents chercheurs ainsi que par les
   dirigeants de OpenAI, Google DeepMind et Anthropic^[38].

   Selon Heidy Khlaaf (directrice charg√©e de l‚Äôassurance de
   l‚Äôapprentissage automatique chez Trail of Bits, une soci√©t√© de
   recherche et de conseil en cybers√©curit√©), les centrales nucl√©aires ont
   des milliers de pages de documents pour prouver que le syst√®me ne cause
   de tort √† personne, et pour Melissa Heikkil√§ : ¬´ la chose la plus
   importante que la communaut√© de l‚ÄôIA pourrait apprendre du risque
   nucl√©aire est l‚Äôimportance de la tra√ßabilit√© ¬ª^[39], deux choses encore
   peu d√©velopp√©es dans le secteur de l'IA. La r√©glementation de l'IA est
   parfois compar√©e √† la r√©glementation du secteur nucl√©aire^[40]. Sam
   Altman (PDG d‚ÄôOpenAI) a sugg√©r√© la mise en place d'un syst√®me de
   licences, dans lequel l'entra√Ænement de syst√®mes d'IA ayant des
   capacit√©s √©lev√©es n√©cessiterait l'octroi d'une licence, et pour ce
   faire de se conformer √† des exigences de s√©curit√© (de m√™me que les
   op√©rateurs d‚Äôinstallations nucl√©aires sont tenus d‚Äô√™tre licenci√©s par
   un r√©gulateur nucl√©aire)^[40]. Aidan Gomez (cofondateur de Cohere) a
   jug√© cette formule excessive et d√©tournant l'attention de risques -
   selon lui plus r√©els - de l'IA mal utilis√©e dans les m√©dias sociaux et
   la m√©decine^[41], de m√™me que Yann LeCun (embauch√© comme scientifique
   en chef de l‚ÄôIA chez Meta, le groupe qui d√©tient Facebook et travaille
   √† la cr√©ation d'un M√©tavers) et Joelle Pineau (vice-pr√©sidente de la
   recherche en IA chez Meta) qui jugent ces craintes ridicules et
   d√©raisonnables, affirmant que les IAs comme ChatGPT ne sont pas encore
   conscientes et ne peuvent donc pas selon eux manipuler ou d√©truire
   l'humanit√©^[42]. Mais en 2023, des chercheurs d‚ÄôOxford, de Cambridge,
   de l‚ÄôUniversit√© de Toronto, de l‚ÄôUniversit√© de Montr√©al, de Google
   DeepMind, d‚ÄôOpenAI, d‚ÄôAnthropic, de plusieurs organismes de recherche √
   but non lucratif sur l‚ÄôIA et Yoshua Bengio (laur√©at du prix Turing)
   sugg√®rent dans un article^[43] que les cr√©ateurs des mod√®les d'IA les
   plus puissants doivent pouvoir √©valuer si leurs IAs ont des capacit√©s
   pouvant pr√©senter des risques ¬´ extr√™mes ¬ª (planification √† long terme,
   manipulation, auto-prolif√©ration, conscience de la situation, capacit√©s
   √† mener des cyberattaques ou √† acqu√©rir des armes notamment
   biologiques...). Les d√©veloppeurs doivent √©galement apprendre √† mesurer
   la propension des mod√®les √† appliquer leurs capacit√©s √† nuire (ceci
   peut se faire gr√¢ce √† des ¬´ √©valuations d‚Äôalignement ¬ª). Selon eux,
   ¬´ ces √©valuations deviendront cruciales pour informer les d√©cideurs
   politiques et les autres parties prenantes, et pour prendre des
   d√©cisions responsables concernant l‚Äôentra√Ænement, le d√©ploiement et la
   s√©curit√© des mod√®les d'IA ¬ª^[43]^,^[39].

   Aleksander MƒÖdry (professeur d‚Äôinformatique au Cadence Design Systems
   du MIT, et directeur du Center for Deployable Machine Learning du MIT)
   a √©t√© audit√© en mars 2023 par le Sous-comit√© sur la cybers√©curit√©, les
   technologies de l‚Äôinformation et l‚Äôinnovation gouvernementale lors
   d'une cession intitul√©e ¬´ Progr√®s de l‚ÄôIA : sommes-nous pr√™ts pour une
   r√©volution technologique ? ¬ª^[44]. Selon MƒÖdry, ¬´ nous sommes √† un
   point d‚Äôinflexion en ce qui concerne ce que l‚ÄôIA du futur
   apportera(...) le gouvernement devrait plut√¥t s‚Äôinterroger sur
   l‚Äôobjectif et l‚Äôexplicabilit√© des algorithmes utilis√©s par les
   entreprises, en tant que pr√©curseur √† la r√©glementation ¬ª pour
   s‚Äôassurer que l‚ÄôIA est coh√©rente avec les objectifs de la soci√©t√©. Ce
   serait une erreur selon lui de r√©glementer l‚ÄôIA comme si elle √©tait
   humaine ‚Äì par exemple en demandant √† l‚ÄôIA d‚Äôexpliquer son raisonnement
   et en supposant que les r√©ponses qui en r√©sultent sont fiables.

   Concernant le risque de suppression massive d'emplois, dans le TIME,
   Altman a annonc√© qu‚ÄôOpenAI aborderait en 2024 le sujet de la
   redistribution des richesses (¬´ OpenAI m√®ne actuellement une √©tude de
   cinq ans sur le revenu universel ¬ª, qui doit se terminer en 2024)^[45].
   Rishi Sunak (premier ministre britannique) a invit√© la communaut√©
   internationale √† Bletchey park en novembre 2023 pour un premier sommet
   mondial en s√ªret√© de l'IA, abordant notamment les risques existentiels
   li√©s √† l'IA^[46]. Sunak propose que soit cr√©√© un groupe d‚Äôexperts
   internationaux, sur le mod√®le du GIEC, qui serait dans un premier temps
   charg√© de publier un √©tat des lieux de l‚ÄôIA. Le 1^er novembre, la
   Chine, les √âtats-Unis, l‚ÄôUnion europ√©enne et une vingtaine de pays ont
   sign√© la d√©claration de Bletchley pour un d√©veloppement ¬´ s√ªr ¬ª de
   l‚Äôintelligence artificielle^[47]. La veille, trois de ces pays (France,
   Allemagne et Italie) avaient sign√© √† Rome un accord de coop√©ration sur
   l'IA ¬´ dans le prolongement des efforts globaux d√©ploy√©s en faveur de
   la transition num√©rique et √©cologique ¬ª^[48].

√âl√©ments de prospective[modifier | modifier le code]

   L'IA g√©n√©rative, telle qu'elle se d√©veloppe √† partir de 2022 pourrait
   √©voluer vers le formes suivantes d'IA :
    1. L'IA interactive, d√©j√† en cours de d√©veloppement, et capable
       d'interagir avec le monde r√©el de mani√®re plus complexe, en
       collaborant avec d'autres logiciels, des machines ou des robots.
       Pour Mustafa Suleyman (cofondateur de DeepMind et ex-
       vice-pr√©sident des produits et des politiques d‚ÄôIA de Google),
       interrog√© par la MIT Technology Review (septembre 2023) c'est
       l'√©tape qui suivra l'IA g√©n√©rative, avec les m√™mes risques et
       atouts mais plus difficile √† contr√¥ler en cas d'usage
       malveillant^[49]. Pour Demis Hassabis (autre cofondateur de
       DeepMind), elle ¬´ a le potentiel de transformer de nombreux aspects
       de nos vies".
    2. L'IA autonome, √† ses d√©buts avec par exemple le v√©hicule autonome,
       permettra √† des machines d'accomplir des t√¢ches sans intervention
       humaine. Elle semble pouvoir notamment concerner les transports, la
       sant√© et la s√©curit√©.
    3. L'IA consciente, g√©n√©ralement consid√©r√©e comme une possibilit√©
       encore lointaine, serait capable d'une forme de ressenti des
       √©motions et d'avoir une conscience de soi. C'est une technologie
       controvers√©e, qui soul√®ve des questions √©thiques et philosophiques
       complexes.

R√©f√©rences[modifier | modifier le code]

    1. ‚Üë ^a et b (en) Erin Griffith et Cade Metz, ¬´ Anthropic Said to Be
       Closing In on $300 Million in New A.I. Funding ¬ª, The New York
       Times, 27 janvier 2023 (consult√© le 14 mars 2023)
    2. ‚Üë (en) Nate Lanxon, Dina Bass et Jackie Davalos, ¬´ A Cheat Sheet to
       AI Buzzwords and Their Meanings ¬ª, Bloomberg News,‚Äé 10 mars 2023
       (lire en ligne, consult√© le 14 mars 2023)
    3. ‚Üë ¬´ Explainer: What is Generative AI, the technology behind
       OpenAI's ChatGPT? ¬ª, Reuters,‚Äé 17 mars 2023 (lire en ligne,
       consult√© le 17 mars 2023)
    4. ‚Üë Ahona Rudra, ¬´ Risques de cybers√©curit√© li√©s √† l'IA g√©n√©rative ¬ª,
       sur powerdmarc.com, 26 juillet 2023 (consult√© le 27 ao√ªt 2023)
    5. ‚Üë (en) Julia Dhar, Allison Bailey, St√©phanie Mingardon et Jennifer
       Tankersley, ¬´ The Persuasive Power of the Digital Nudge ¬ª, sur BCG
       Global, 8 janvier 2021 (consult√© le 9 novembre 2023)
    6. ‚Üë ^a b et c (en) Rachel Gordon, ¬´ MIT CSAIL (Laboratoire
       d‚ÄôInformatique et d‚ÄôIntelligence Artificielle) researchers discuss
       frontiers of generative AI ¬ª, sur MIT News, 12 avril 2023 (consult√©
       le 31 octobre 2023)
    7. ‚Üë (en) Will Douglas Heaven, ¬´ How existential risk became the
       biggest meme in AI ¬ª, MIT Technology Review,‚Äé 19 juin 2023 (lire en
       ligne, consult√© le 31 octobre 2023)
    8. ‚Üë Alexandre Piquard, ¬´ Intelligence artificielle : au sommet de
       Londres, PDG et dirigeants face au d√©fi de la r√©gulation ¬ª, Le
       Monde.fr,‚Äé 2 novembre 2023 (lire en ligne, consult√© le 9 novembre
       2023)
    9. ‚Üë En g√©n√©ral, le petaflop/jour est utilis√© comme m√©trique. Un
       petaflop-jour (pf-jour) consiste √† effectuer 10^15 op√©rations de
       r√©seau neuronal par seconde pendant une journ√©e, soit un total
       d‚Äôenviron 10^20 op√©rations. C‚Äôest une unit√© de mesure pratique,
       similaire au kW/h pour l‚Äô√©nergie. Plut√¥t que les FLOPS th√©oriques
       maximaux du mat√©riel, on cherche √† estimer le nombre r√©el
       d‚Äôop√©rations faites ; additions et multiplications sont compt√©es
       comme des op√©rations distinctes, et on ignore les mod√®les
       d‚Äôensemble. Sur cette p√©riode, le temps de doublement pour la ligne
       de meilleure ad√©quation est de 3,4 mois.
   10. ‚Üë (en) ¬´ AI and compute ¬ª, sur openai.com, 16 mai 2018 (consult√© le
       9 novembre 2023)
   11. ‚Üë (en) Adam Pasick, ¬´ Artificial Intelligence Glossary: Neural
       Networks and Other Terms Explained ¬ª, The New York Times,‚Äé 27 mars
       2023 (lire en ligne, consult√© le 22 avril 2023)
   12. ‚Üë ^a et b (en) ¬´ DALL¬∑E 3 system card ¬ª, sur openai.com, 3 octobre
       2023 (consult√© le 9 novembre 2023)
   13. ‚Üë (en) Charlotte Bird, Eddie L. Ungless et Atoosa Kasirzadeh,
       ¬´ Typology of Risks of Generative Text-to-Image Models ¬ª, AAAI/ACM
       Conference on AI, Ethics, and Society,‚Äé 2023 (arXiv 2307.05543)
   14. ‚Üë (en) Abeba Birhane, Vinay Uday Prabhu et Emmanuel Kahembwe,
       ¬´ Multimodal datasets: misogyny, pornography, and malignant
       stereotypes ¬ª, Arxiv,‚Äé 5 octobre 2021 (arXiv 2110.01963)
   15. ‚Üë (en) Jaemin Cho, Abhay Zala et Mohit Bansal, ¬´ DALL-Eval: Probing
       the Reasoning Skills and Social Biases of Text-to-Image Generation
       Models ¬ª, ICCV 2023,‚Äé 2022 (arXiv 2202.04053)
   16. ‚Üë (en) ¬´ World leaders gather at UK summit aiming to tackle
       'frontier AI' risks ¬ª, sur France 24, 1^er novembre 2023 (consult√©
       le 9 novembre 2023)
   17. ‚Üë (en) Cade Metz, ¬´ OpenAI Plans to Up the Ante in Tech‚Äôs A.I.
       Race ¬ª, The New York Times,‚Äé 14 mars 2023 (ISSN 0362-4331, lire en
       ligne, consult√© le 9 novembre 2023)
   18. ‚Üë (en) Roose, ¬´ A Coming-Out Party for Generative A.I., Silicon
       Valley's New Craze ¬ª, The New York Times, 21 octobre 2022 (consult√©
       le 14 mars 2023)
   19. ‚Üë (en) Prafulla Dhariwal et Alex Nichol, ¬´ Diffusion Models Beat
       GANs on Image Synthesis ¬ª, NeurIPS,‚Äé 2021 (arXiv 2105.05233)
   20. ‚Üë (en) Luhui Hu, ¬´ Generative AI and Future ¬ª, sur Medium, 15
       novembre 2022 (consult√© le 9 novembre 2023)
   21. ‚Üë (en) ¬´ Generative Artificial Intelligence: Trends and
       Prospects ¬ª, sur ieeexplore.ieee.org (consult√© le 9 novembre 2023)
   22. ‚Üë (en) ¬´ Generative AI: a game-changer society needs to be ready
       for ¬ª, sur World Economic Forum, 9 janvier 2023 (consult√© le 9
       novembre 2023)
   23. ‚Üë (en) Billy Perrigo, ¬´ The A to Z of Artificial Intelligence ¬ª,
       Time,‚Äé 13 avril 2023 (lire en ligne, consult√© le 2 novembre 2023).
   24. ‚Üë (en) ¬´ Don't fear an AI-induced jobs apocalypse just yet ¬ª, The
       Economist, 6 mars 2023 (consult√© le 14 mars 2023)
   25. ‚Üë (en) Holger Harreis, Theodora Koullias, Roger Roberts et Kimberly
       Te, ¬´ Generative AI: Unlocking the future of fashion ¬ª
   26. ‚Üë (en) Aditya Ramesh, Mikhail Pavlov, Gabriel Goh et Scott Gray,
       ¬´ Zero-Shot Text-to-Image Generation ¬ª, Proceedings of the 38th
       International Conference on Machine Learning, PMLR,‚Äé 1^er juillet
       2021, p. 8821‚Äì8831 (arXiv 2102.12092, lire en ligne, consult√© le 9
       novembre 2023)
   27. ‚Üë (en) Will Douglas Heaven, ¬´ AI is dreaming up drugs that no one
       has ever seen. Now we've got to see if they work ¬ª, MIT Technology
       Review, Massachusetts Institute of Technology, 15 f√©vrier 2023
       (consult√© le 15 mars 2023)
   28. ‚Üë (en) Cade Metz, ¬´ Instant Videos Could Represent the Next Leap in
       A.I. Technology ¬ª, The New York Times, 4 avril 2023
   29. ‚Üë (en) Queenie Wong, ¬´ Facebook Parent Meta's AI Tool Can Create
       Artsy Videos From Text ¬ª, cnet.com, 29 septembre 2022 (consult√© le
       4 avril 2023)
   30. ‚Üë (en) Arham Islam, ¬´ A History of Generative AI: From GAN to
       GPT-4 ¬ª, sur MarkTechPost, 21 mars 2023 (consult√© le 9 novembre
       2023)
   31. ‚Üë (en) ¬´ The race of the AI labs heats up ¬ª, The Economist, 30
       janvier 2023 (consult√© le 14 mars 2023)
   32. ‚Üë (en) June Yang et Burak Gokturk, ¬´ Google Cloud brings generative
       AI to developers, businesses, and governments ¬ª, 14 mars 2023
   33. ‚Üë ex. : (en) ¬´ System Cards, a new resource for understanding how
       AI systems work ¬ª, sur ai.meta.com (consult√© le 2 novembre 2023)
   34. ‚Üë (en) Margaret Mitchell, Simone Wu, Andrew Zaldivar et Parker
       Barnes, ¬´ Model Cards for Model Reporting ¬ª, ACM Conference on
       Fairness, Accountability, and Transparency, ACM,‚Äé 29 janvier 2019,
       p. 220‚Äì229 (ISBN 978-1-4503-6125-5, DOI 10.1145/3287560.3287596,
       arXiv 1810.03993, lire en ligne, consult√© le 2 novembre 2023)
   35. ‚Üë (en) Charles Q. Choi, ¬´ 200-Year-Old Math Opens Up AI‚Äôs
       Mysterious Black Box - IEEE Spectrum ¬ª, sur spectrum.ieee.org, 25
       f√©vrier 2023 (consult√© le 28 octobre 2023)
   36. ‚Üë (en) Sharon Goldman, ¬´ Stanford debuts first AI benchmark to help
       understand LLMs ¬ª, sur VentureBeat, 17 novembre 2022 (consult√© le 9
       d√©cembre 2023)
   37. ‚Üë (en) Matthew Sparkes, ¬´ Google says its Gemini AI outperforms
       both GPT-4 and expert humans ¬ª, sur New Scientist, 6 d√©cembre 2023
       (consult√© le 9 d√©cembre 2023)
   38. ‚Üë ¬´ L'IA pourrait poser un ¬´ risque d'extinction ¬ª pour l'humanit√©,
       affirment 350 experts ¬ª, sur Les Echos, 30 mai 2023 (consult√© le 9
       novembre 2023)
   39. ‚Üë ^a et b (en) Melissa Heikkil√§, ¬´ To avoid AI doom, learn from
       nuclear safety ¬ª, MIT Technology Review,‚Äé 6 juin 2023 (lire en
       ligne, consult√© le 31 octobre 2023)
   40. ‚Üë ^a et b (en) Heidy Khlaaf, ¬´ How AI Can Be Regulated Like Nuclear
       Energy ¬ª, sur TIME, 24 octobre 2023 (consult√© le 2 novembre 2023)
   41. ‚Üë (en) George Hammond, ¬´ Aidan Gomez: AI threat to human existence
       is ‚Äòabsurd‚Äô distraction from real risks ¬ª, sur Financial Times, 16
       juin 2023 (consult√© le 1^er novembre 2023)
   42. ‚Üë (en) Melissa Heikkil√§, ¬´ Meta‚Äôs AI leaders want you to know fears
       over AI existential risk are ‚Äúridiculous‚Äù ¬ª, sur MIT Technology
       Review, 20 juin 2023 (consult√© le 1^er novembre 2023)
   43. ‚Üë ^a et b (en) Toby Shevlane, Sebastian Farquhar, Ben Garfinkel et
       Mary Phuong, ¬´ Model evaluation for extreme risks ¬ª, Arxiv,‚Äé 2023
       (DOI 10.48550/ARXIV.2305.15324, arXiv 2305.15324)
   44. ‚Üë (en) ¬´ Advances in AI: Are We Ready For a Tech Revolution? ¬ª, sur
       United States House Committee on Oversight and Accountability, 25
       octobre 2023 (consult√© le 31 octobre 2023)
   45. ‚Üë (en) Billy Perrigo, ¬´ OpenAI Could Quit Europe Over New AI Rules,
       CEO Warns ¬ª, sur Time, 24 mai 2023 (consult√© le 2 novembre 2023)
   46. ‚Üë ¬´ Intelligence artificielle : ¬´ Des millions de personnes vont
       bient√¥t perdre leur travail ¬ª ¬ª, sur Le Point, 3 novembre 2023
       (consult√© le 9 novembre 2023)
   47. ‚Üë ¬´ Les Etats-Unis, la Chine et l'UE signent une premi√®re
       d√©claration mondiale sur les risques de l'IA ¬ª, sur BFMTV (consult√©
       le 9 novembre 2023)
   48. ‚Üë Olivier Tosseri, ¬´ L'Italie, l'Allemagne et la France renforcent
       leur coop√©ration dans l'IA ¬ª, sur Les Echos, 31 octobre 2023
       (consult√© le 9 novembre 2023)
   49. ‚Üë (en) Will Douglas Heaven, ¬´ DeepMind‚Äôs cofounder: Generative AI
       is just a phase. What‚Äôs next is interactive AI. ¬ª, MIT Technology
       Review,‚Äé 15 septembre 2023 (lire en ligne, consult√© le 1^er
       novembre 2023)

Articles connexes[modifier | modifier le code]

     * Arts de l'intelligence artificielle
     * Recherche g√©n√©rative assist√©e par intelligence artificielle
     * R√©seau antagoniste g√©n√©ratif
     * Transformateur g√©n√©ratif pr√©-entra√Æn√©
     * Grand mod√®le de langage
     * Google Gemini
     * Falcon 180B

     * ic√¥ne d√©corative Portail de l‚Äôinformatique
     * ic√¥ne d√©corative Portail de l‚Äô√©criture
     * ic√¥ne d√©corative Portail des ann√©es 2020
     * ic√¥ne d√©corative Portail de l‚Äôimagerie num√©rique

   v ¬∑ m
   Intelligence artificielle (IA)
   Concepts
     * Effet IA
     * Grand mod√®le de langage
     * Hallucination (IA)
     * IA g√©n√©rale
     * IA g√©n√©rative

   Techniques
     * Analyse pr√©dictive
     * Apprentissage automatique
     * Apprentissage non supervis√©
     * Apprentissage profond
     * Apprentissage supervis√©
     * Mod√®le de fondation
     * Mod√®le des croyances transf√©rables
     * IA symbolique
     * R√©seau bay√©sien
     * R√©seau de neurones artificiels
     * R√©seau neuronal convolutif
     * Transformeur

   Applications
     * Art cr√©√© par IA
     * ChatGPT
     * DeepL
     * Diagnostic (IA)
     * √âcriture assist√©e par IA
     * IA dans la sant√©
     * IA dans le jeu vid√©o
     * Perception artificielle
     * Planification (IA)
     * Robotique
     * Traduction automatique
     * Traitement automatique du langage naturel
     * V√©hicule autonome
     * Vision par ordinateur

   Enjeux et philosophie
     * Alignement de l'IA
     * Chambre chinoise
     * Conscience artificielle
     * Contr√¥le des capacit√©s de l'IA
     * √âthique de l'IA
     * IA digne de confiance
     * Philosophie de l'IA
     * S√ªret√© de l'IA

   Histoire et √©v√©nements
     * Histoire de l'intelligence artificielle
     * Logic Theorist (1955)
     * Perceptron (1957)
     * General Problem Solver (1959)
     * Prolog (1972)
     * Matchs Deep Blue contre Kasparov (1996-1997)
     * Match AlphaGo - Lee Sedol (2016)

   Science-fiction
     * Anticipation (IA)
     * IA-complet
     * IA g√©n√©rale
     * Risque de catastrophe plan√©taire li√© √† l'intelligence artificielle
       g√©n√©rale
     * Superintelligence

       R√®glementation
     * L√©gislation sur l'IA
     * R√©glementation de l'IA

   Organisations
     * Agence francophone pour l'IA
     * Google DeepMind
     * OpenAI
     * Partenariat sur l'IA

   Ouvrages
     * D√©claration de Montr√©al pour un d√©veloppement responsable de
       l'intelligence artificielle
     * Lettre ouverte sur l'IA
     * Intelligence artificielle : une approche moderne
     * I.A. La Plus Grande Mutation de l'Histoire

   Ce document provient de
   ¬´ https://fr.wikipedia.org/w/index.php?title=Intelligence_artificielle_
   g√©n√©rative&oldid=210402889 ¬ª.
   Cat√©gories‚ÄØ:
     * Apprentissage automatique
     * R√©seau de neurones artificiels
     * Intelligence artificielle
     * Culture Internet

   Cat√©gories cach√©es‚ÄØ:
     * Article √† r√©f√©rence n√©cessaire
     * Portail:Informatique/Articles li√©s
     * Portail:Technologies/Articles li√©s
     * Portail:Sciences/Articles li√©s
     * Portail:√âcriture/Articles li√©s
     * Portail:Ann√©es 2020/Articles li√©s
     * Portail:XXIe si√®cle/Articles li√©s
     * Portail:Imagerie num√©rique/Articles li√©s

     * La derni√®re modification de cette page a √©t√© faite le 9 d√©cembre
       2023 √† 23:33.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les m√™mes conditions ; d‚Äôautres
       conditions peuvent s‚Äôappliquer. Voyez les conditions d‚Äôutilisation
       pour plus de d√©tails, ainsi que les cr√©dits graphiques. En cas de
       r√©utilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       Wikipedia¬Æ est une marque d√©pos√©e de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance r√©gie par le paragraphe 501(c)(3) du
       code fiscal des √âtats-Unis.

     * Politique de confidentialit√©
     * √Ä propos de Wikip√©dia
     * Avertissements
     * Contact
     * Code de conduite
     * D√©veloppeurs
     * Statistiques
     * D√©claration sur les t√©moins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou d√©sactiver la limitation de largeur du contenu
