跳去內容
[ ] 主目錄
主目錄
移去側欄收埋
導覽

  • 頭版
  • 目錄
  • 正嘢
  • 時人時事
  • 是但一版
  • 關於維基百科
  • 聯絡處
  • 捐畀維基百科

交流

  • 說明書
  • 城市論壇
  • 社區大堂
  • 最近修改

語言
其他語言嘅連結喺頁頂標題側邊。
[wikip] 維基百科 [wikipedia-tag]
查嘢
[                    ]
搵嘢

  • 開戶口
  • 簽到

[ ] 個人架生

  • 開戶口
  • 簽到

未簽到編者用嘅版面知多啲

  • 貢獻
  • 同呢個互聯網地址嘅匿名人傾偈

目錄

移去側欄收埋

  •  
    文頭
  •  
    1基本定位
  •  
    2運算方法
    切換去運算方法細章節
      □  
        2.1符號 AI
          ☆  
            2.1.1啟發法
          ☆  
            2.1.2基於邏輯
          ☆  
            2.1.3基於知識
          ☆  
            2.1.4符號 AI 問題
      □  
        2.2統計方法
      □  
        2.3神經網絡
  •  
    3重要問題
    切換去重要問題細章節
      □  
        3.1推理解難
      □  
        3.2機械感知
      □  
        3.3自動計劃
      □  
        3.4應付複雜
      □  
        3.5自然語言處理
      □  
        3.6強 AI
  •  
    4機械學習
    切換去機械學習細章節
      □  
        4.1學錯嘢
      □  
        4.2知識表示
  •  
    5應用
    切換去應用細章節
      □  
        5.1電子遊戲
      □  
        5.2第啲應用
  •  
    6科幻諗頭
  •  
    7哲學思考
  •  
    8註釋
  •  
    9相關領域
  •  
    10睇埋
  •  
    11文獻
    切換去文獻細章節
      □  
        11.1教科書
      □  
        11.2研究史
      □  
        11.3其他文獻
  •  
    12攷
  •  
    13拎

[ ] 開/收內容一覽

人工智能

[ ] 146種語言

  • Afrikaans
  • Alemannisch
  • አማርኛ
  • Aragonés
  • العربية
  • الدارجة
  • مصرى
  • অসমীয়া
  • Asturianu
  • Azərbaycanca
  • تۆرکجه
  • Башҡортса
  • Boarisch
  • Žemaitėška
  • Bikol Central
  • Беларуская
  • Беларуская (тарашкевіца)
  • Български
  • বাংলা
  • བོད་ཡིག
  • Brezhoneg
  • Bosanski
  • Буряад
  • Català
  • کوردی
  • Qırımtatarca
  • Čeština
  • Чӑвашла
  • Cymraeg
  • Dansk
  • Deutsch
  • Zazaki
  • Ελληνικά
  • English
  • Esperanto
  • Español
  • Eesti
  • Euskara
  • Estremeñu
  • فارسی
  • Suomi
  • Võro
  • Fɔ̀ngbè
  • Français
  • Nordfriisk
  • Furlan
  • Gaeilge
  • 贛語
  • Kriyòl gwiyannen
  • Gàidhlig
  • Galego
  • Avañe'ẽ
  • Gaelg
  • עברית
  • हिन्दी
  • Hrvatski
  • Kreyòl ayisyen
  • Magyar
  • Հայերեն
  • Արեւմտահայերէն
  • Interlingua
  • Bahasa Indonesia
  • Interlingue
  • Igbo
  • Ilokano
  • Ido
  • Íslenska
  • Italiano
  • 日本語
  • Patois
  • La .lojban.
  • Jawa
  • ქართული
  • Қазақша
  • ಕನ್ನಡ
  • 한국어
  • Ripoarisch
  • Кыргызча
  • Latina
  • Limburgs
  • Lombard
  • Lietuvių
  • Latviešu
  • Madhurâ
  • Malagasy
  • Minangkabau
  • Македонски
  • മലയാളം
  • Монгол
  • मराठी
  • Bahasa Melayu
  • Malti
  • မြန်မာဘာသာ
  • Nedersaksies
  • नेपाली
  • नेपाल भाषा
  • Nederlands
  • Norsk nynorsk
  • Norsk bokmål
  • Occitan
  • ଓଡ଼ିଆ
  • ਪੰਜਾਬੀ
  • Polski
  • پنجابی
  • پښتو
  • Português
  • Runa Simi
  • Română
  • Русский
  • Русиньскый
  • Саха тыла
  • Scots
  • سنڌي
  • Srpskohrvatski / српскохрватски
  • සිංහල
  • Simple English
  • Slovenčina
  • Slovenščina
  • Shqip
  • Српски / srpski
  • Svenska
  • Kiswahili
  • Ślůnski
  • தமிழ்
  • తెలుగు
  • Тоҷикӣ
  • ไทย
  • Türkmençe
  • Tagalog
  • Türkçe
  • Татарча / tatarça
  • Reo tahiti
  • ئۇيغۇرچە / Uyghurche
  • Українська
  • اردو
  • Oʻzbekcha / ўзбекча
  • Vèneto
  • Tiếng Việt
  • Walon
  • Winaray
  • 吴语
  • მარგალური
  • ייִדיש
  • 中文
  • Bân-lâm-gú
  • IsiZulu

改拎

  • 文章
  • 討論

[ ] 粵語

  • 閱
  • 改
  • 睇返紀錄

[ ] 架撐
架撐
移去側欄收埋
動作

  • 閱
  • 改
  • 睇返紀錄

基本

  • 有乜連過嚟
  • 連結頁嘅更改
  • 上載檔案
  • 專門版
  • 固定連結
  • 此版明細
  • 引用呢篇文
  • 攞短網址
  • 維基數據項

打印/匯出

  • 下載PDF
  • 印得嘅版本

第啲維基項目

  • 維基同享

出自維基百科，自由嘅百科全書

    ● 搵緊同名電影嘅話，請睇「人工智能 (電影)」。

[270px-Sophia_at_the_AI_for_Good_]
2018 年喺日內瓦舉行嘅《AI for Good》峰會嗰度所展示嘅機械人蘇菲亞（Sophia）；佢
內置 AI，曉用語言同人傾偈。
《食鬼》嘅片段；啲鬼由電腦操控，但曉追捕玩家－展現簡單嘅近似有智能行為。

人工智能jan4 gung1 zi3 nang4（英文：artificial intelligence，AI；粵拼：ei1 aai1
），又有叫機械智能gei1 haai6 zi3 nang4（machine intelligence），泛指由機械展示
嘅智能，相對於人同第啲動物展示嘅自然智能。喺科學上，「人工智能」一詞亦都俾人攞
嚟指專門研究 AI 嘅認知科學同電腦科學交界領域^[1]，呢個領域嘅研究會關注點樣教機
械做推理、知識表示、計劃、學習、自然語言處理、感知以及郁同操控物體等嘅作業^[1]
，而呢啲研究其中一個終極目標就係想造出強 AI－即係能夠展現出同人無異嘅智能嘅 AI
^[2]。

AI 嘅理論基礎建基於智能體（intelligent agent）嘅概念：喺最廣義上，一嚿物體如果
有能力感知佢四圍嘅環境，並且運用所得嘅資訊嚟提升自己達到目的嘅機會率嘅話，噉佢
就算係一個智能體－包括人在內嘅動物都符合呢個定義。AI 領域嘅目標就係研究點樣人工
噉整一啲智能體出嚟，最常見嘅做法係參考心理學以及神經科學呢啲研究自然智能嘅領域
嘅研究，跟住再編寫電腦程式嚟模仿人同第啲動物所展現嘅智能^[3]^[4]。

除咗科學，AI 研究又引起咗唔少哲學同社科上嘅討論：「人可以整機械嚟模擬人類智能」
嘅宣言引起咗一連串（到咗廿一世紀初仲有人關注嘅）心靈哲學問題同埋「人工噉創造一
個有人類水平智能嘅物體係咪合乎道德」等嘅討論^[5]；亦都有唔少人覺得 AI 如果唔受
控嘅話會對人造成威脅^[6]，例子可以睇吓廿一世紀初科幻故仔常見嘅 AI 叛變橋段，或
者有人擔心 AI 會搞到有大量嘅人失業^[7]。

AI 領域誕生於廿世紀中：喺 1956 年，有班工程師宣稱，因為人類智能可以用科學理論描
述（睇認知科學），所以用運算機械模擬人類智能係有可能嘅^[8]，引起學界熱議；而自
從嗰陣開始，AI 領域有過好幾波嘅熱潮^[9]^[10]，又試過因為研究失敗等嘅原因搞到有
排冇人肯出錢資助（即係所謂嘅 AI 低谷），有過幾波唔同嘅技術革新^[11]^[12]。到咗
廿一世紀，AI 經已係一個蓬勃嘅獨立科學領域，有得按照所使用嘅技術或者想達到嘅目的
分做多個唔同嘅子領域，而且呢啲子領域好多時仲要專化到彼此之間溝通唔到^[13]^[14]
。

基本定位[編輯]

    內文：智能體同演算法
    睇埋：認知科學同埋電腦科學

智能體（intelligent agent）係 AIei1 aai1 領域上嘅基本概念。喺最抽象化嘅層面嚟講
，一個智能體可以想像成一嚿具有以下部份嘅物體：

  • 感知：感受外界資訊嘅能力，知道「世界而家係點嘅樣」，例如眼同耳仔等嘅感官，
    可以睇吓感應器（sensor）嘅概念；
  • 決策：某啲按感知到嘅資訊法則，例如「如果睇到有嘢食，就行埋去」，可以睇埋條
    件陳述式（if-then）^[註 1]；
  • 執行器（actuator）：負責實際採取行動嘅部件，例如手同腳啲肌肉會做出適當嘅動
    作，等隻動物行埋嘢食嗰度；
  • 行動會改變環境（environment）嘅狀態，而環境上嘅改變會由感應器感知到。

如是者，智能體就會一路同環境互動，一路嘗試達成自己嘅目的。唔同智能體喺複雜度上
可以有好大差異，而一個智能體有幾複雜反映到佢智能（intelligence）有幾高^[3]^[4]
。上述呢個智能體同環境之間嘅互動可以畫成以下噉嘅抽象圖解：

智能體同環境互動嘅抽象化圖解智能體同環境互動嘅抽象化圖解

呢個圖入面嘅每件物件都可以攞數值表示。例如環境嘅狀態可以想像成一個有若干個維度
嘅向量，例：

    [2.5, 3.9, 1.0,...]，

個向量當中每一個數值表示某個描述世界狀態嘅數值，例如個環境係一間房，第一個數字
表示間房嘅平均溫度、第二個數字表示間房嘅亮度... 呀噉；於是部電腦就可以透過處理
[1.2, 4.3, 6.4,...] 同 [1.1, 4.3, 6.4,...] 噉嘅陣列知道環境嘅狀態同埋由環境狀態
當中計出要採取嘅行動^[3]。

一個智能體會有某啲目的（goal）：一個智能體嘅目的可以想像成一個「個智能體想達到
嘅狀態」，可以表達成一個特定嘅環境狀態，而「現時狀態同目的之間嘅距離」可以諗做
代表現時狀態以及目的狀態嗰兩個向量之間嘅歐幾里得距離；另一方面，目的又可以用函
數嚟表達，即係用數字話俾個智能體知佢幾時做啱幾時做錯^[註 2]，簡單嘅例子有「if
自己贏咗場象棋，then output 係 1（達到目的），else output 就係 0（達唔到目的）
」^[3]。

定義上，AI 領域想做嘅，就係

「 要人工噉製造智能體，而呢啲人造智能體要展現到好似人同第啲動物噉嘅智能。例
   如係寫程式，教電腦做出好似人腦噉嘅運算。                                  」

篇文跟住落嚟嘅內容，假設讀者已經識嗮演算法、編程同埋學習等嘅基本概念。

運算方法[編輯]

    睇埋：決策、模控學同埋運算神經科學

一個 AI 程式要展示自己嘅智能，就實要（好似人類做決策噉）

  • 攞 input，用佢內部嘅演算法做運算，
  • 再俾返個 output 出嚟，

Output 嘅質素會決定個 AI 程式嘅表現。舉例說明，喺一個 AI 程式捉象棋嗰陣，個程式
會係噉收到「個棋盤係乜嘢形勢」嘅資訊（input），跟住佢會一啲運算，決定自己要行邊
一步（output），而佢所行嘅步最後就會決定佢贏定輸（表現好唔好）。喺成個過程當中
，一個 AI 程式由 input 值計 output 值，即係話 output 值係 input 值嘅函數，

    output = f ( input ) {\displaystyle {\text{output}}=f({\text{input}})} {\
    displaystyle {\text{output}}=f({\text{input}})}

－當中函數 f {\displaystyle f} {\displaystyle f} 可以有好多唔同款^[15]^[16]。

[500px-CPT_Hardware-InputOutput]

AI 史上出名嘅運算方法（可以想像成 f {\displaystyle f} {\displaystyle f} 可能嘅
款）有以下呢啲^[17]^[18]^[19]：

符號 AI[編輯]

    內文：符號 AI

符號 AI（symbolic AI），又叫老派 AI（good old-fashioned AI，GOFAI）^[20]，係最
早期（同埋俾好多人認為係最易明）嘅 AI 運算方法：喺 1950 年代 AI 領域啱啱起步嗰
陣，啲科學家好多都認為人類智能只不過係對邏輯符號嘅玩弄^[21]，而符號 AI 做法就將
所受嘅 input 值用一大柞邏輯符號計算，再按照呢啲計算俾個 output 值出嚟睇；舉例說
明，如果家吓有個設計者想教部電腦幫手睇病（input 值係「有關病人嘅資訊」，而
output 值係「診斷」），噉就要教佢

  • 「if 一個普遍健康嘅大人發燒，then 佢有可能係感冒」、
  • 「if 一個普遍健康嘅大人發燒，then 佢都有可能係肺炎」

... 等嘅若干條法則^[22]。

即係話符號 AI 嘅做法建基於三個諗頭^[22]：

  • 表示一個智能系統嘅模型可以完全明文噉定義^[註 3]；
  • 呢個模型當中嘅知識可以用邏輯符號表達；同埋
  • 認知過程（包括思考呀噉）可以描述為做喺呢啲符號身上嘅運算。

符號 AI 嘅做法可以話係比較原始，而且過咗冇幾耐啲 AI 研究者就發現有好多問題都係
符號 AI 搞唔掂嘅^[23]^[24]。

啟發法[編輯]

    內文：啟發法

廿世紀早期嘅學者好多都認為，人嘅認知功能可以用一啲相對簡單嘅啟發法（heuristics
）嚟表達^[22]：佢哋會將要解決嘅問題想像為一柞狀態（state），而解決問題嘅過程就
係個 AI 嘗試由初始嗰個狀態變到佢目的狀態嘅過程，佢哋認為人類會用某啲相對簡單－
但唔一定啱－嘅認知捷徑嚟判斷點樣由一個狀態移去下一個狀態，例如係好似「如果我將
隻棋行得太出，佢通常會俾對手食咗」呢一啲直覺同無意識嘅假設，而呢啲簡單直接、通
常啱用嘅規則就係所謂嘅啟發法。

採取呢個做法嘅研究者認為，要令 AI 做到好似人噉嘅智能，要做嘅就係用認知心理學領
域嘅實驗搵出人思考嗰陣用啲乜嘢啟發法，並且開發出一啲模擬人腦用嗰啲啟發法嘅演算
法，再用呢啲連串嘅演算法嚟模擬人所展示嘅智能。呢種做法一路去到 1980 年代中期都
仲有好多人用^[25]。

[400px-Chess-Sicilian-Physical]喺一盤國際象棋之中，行出去嘅棋（同企後排受嚴密保
護嘅棋比起嚟）好多時會比較容易俾對手食。所以「如果我想保護隻棋，就要將佢擺喺後
排」係一條簡單嘅啟發法。

基於邏輯[編輯]

    睇埋：邏輯編程

又有好多符號 AI 研究者主張，AI 唔使模擬人嘅認知功能所涉及嘅啟發法，而係應該用一
啲實啱（相對於啟發法嘅「通常啱」）嘅邏輯法則嚟指定「乜嘢係正確答案」。例如係如
果要教一部電腦點樣知道兩個人係咪彼此嘅兄弟姐妹，運用基於邏輯做法嘅 AI 研究者會
教電腦以下呢條法則^[22]：

    siblings(X,Y) :− parent(Z,X) and parent(Z,Y)

呢條法則講嘅係，「如果有一個人 Z，佢係 X 嘅父母，又係 Y 嘅父母，噉 X 同 Y 就係
兄弟姐妹嘅關係。」呢類思考嘅方式唔似人（好多時用直覺多過邏輯嘅）日常思路，但就
係一條絕對正確同合邏輯嘅思路。相比之下，用認知模擬嘅 AI 研究者會研究吓一般人類
用乜嘢（無意識、未必完全穩陣嘅）法則判斷兩個人係兄弟姐妹嘅機會率，再用演算法模
擬呢啲法則^[26]^[27]。

基於知識[編輯]

    睇埋：專家系統

由 1970 年代開始，電腦嘅記憶量開始愈嚟愈大，令到各門嘅 AI 專家都開始嘗試將「知
識」嘅成份加落去 AI 應用嗰度。呢股「知識革命」引起咗專家系統（expert system）嘅
發展^[28]。

專家系統係第一種真係成功嘅 AI 軟件，一個專家系統會建基於一個知識基礎之上，並且
運用一大柞「if... then...」嘅法則嚟做推理。例如係一個用嚟診斷病人嘅專家系統噉，
佢內部會有一大堆有關唔同嘅病同啲病嘅症狀嘅資訊，而如果俾個病人佢睇嘅話，佢會用
一大柞

  • 「如果個病人有咳，佢可能係...」
  • 「如果個病人有咳但係又唔係肺炎，噉佢又有可能係...」

等嘅法則嘗試搵出一個診斷。但要整一個專家系統就實要有個真嘅人類專家幫手，而吓吓
都逐條逐條法則都明文講嗮俾個 AI 程式知會好嘥時間－專家往往都因為有人需要佢哋嘅
服務而好唔得閒，好難請佢哋幫手整專家系統^[29]^[30]。

符號 AI 問題[編輯]

    睇埋：複雜度

符號 AI 最大問題係，呢種做法要求

「 設計者將個 AI 做判斷要用嘅法則，冚唪唥都明文噉講嗮俾部電腦知。 」

但由 1980 年代開始，AI 學界開始留意到，呢種做法喺好多情況之下根本行唔通^[20]：
首先，噉嘅 AI 學起嘢上嚟好撈絞－如果個設計者想教一條新法則俾個程式聽，佢就要人
手噉由（閒閒地成幾萬行長嘅）源碼當中搵嗮所有同條新法則衝突嘅法則出嚟，再攞走呢
啲舊法則，非常嘥時間^[31]；而且符號 AI 根本唔能夠模擬到自然智能－認知心理學等領
域嘅研究清楚噉表明咗，人類智能好多時都會依賴直覺等無意識、難以明文噉講出嚟嘅法
則（第一型過程）。所以廿一世紀初嘅 AI 好少可會真係齋靠用符號性嘅方法，而好多時
啲新嘅 AI 做起運算上嚟都起碼會用啲混合型方法－即係結合符號同非符號嘅 AI 做法^
[32]^[33]。

統計方法[編輯]

[300px-SimpleBayesNetNodes]一個簡單嘅貝葉斯網絡

    內文：貝葉斯網絡
    睇埋：統計模型同埋運算複雜度

AI 解問題嗰陣成日都要面對不確定性（uncertainty）－意思即係話，個程式成日都焗住
要喺唔完全知道嗮所需嘅資訊嘅情況之下行事。於是 AI 專家就運用概率論同經濟學等領
域嘅知識，諗咗一柞工具出嚟去應付呢啲問題^[34]：

貝葉斯網絡（Bayesian network）係一種可以用嚟教電腦做推理^[35]、學習^[36]同計劃^
[37]等工作嘅工具。一個貝葉斯網絡會考慮大量變數，並且用一柞基於貝葉斯定理（
Bayes' Theorem）嘅方程模擬唔同變數之間嘅關係。舉個簡單例子，假想家吓有一個貝葉
斯網絡，佢會睇某啲變數（包括咗「有冇落雨」同埋「啲灌溉花灑有冇開著」等）嘅數值
，並且計出「啲草係濕嘅」呢個狀態係「真」嘅機會率，途中會用到（例如）以下呢條式^
[38]^[39]：

    Pr ( G , S , R ) = Pr ( G | S , R ) Pr ( S | R ) Pr ( R ) {\displaystyle \
    Pr(G,S,R)=\Pr(G|S,R)\Pr(S|R)\Pr(R)} {\displaystyle \Pr(G,S,R)=\Pr(G|S,R)\Pr
    (S|R)\Pr(R)}；

當中 G {\displaystyle G} {\displaystyle G} 係指「啲草濕咗」呢個狀態， S {\
displaystyle S} {\displaystyle S} 係指「啲灌溉花灑著咗」呢個狀態，而 R {\
displaystyle R} {\displaystyle R} 係指「有落雨」呢個狀態。成條式用日常用語講嘅
話係噉嘅：「嗰三個狀態都係真嘅機會率」（ Pr ( G , S , R ) {\displaystyle \Pr
(G,S,R)} {\displaystyle \Pr(G,S,R)}）等如「如果有落雨（ R {\displaystyle R} {\
displaystyle R}）而且啲灌溉花灑著咗（ S {\displaystyle S} {\displaystyle S}），
啲草濕咗（ G {\displaystyle G} {\displaystyle G}）嘅機會率」（ Pr ( G | S , R )
{\displaystyle \Pr(G|S,R)} {\displaystyle \Pr(G|S,R)}）乘以「如果有落雨（ R {\
displaystyle R} {\displaystyle R}），啲灌溉花灑著咗（ S {\displaystyle S} {\
displaystyle S}）嘅機會率」（ Pr ( S | R ) {\displaystyle \Pr(S|R)} {\
displaystyle \Pr(S|R)}）乘以「有落雨嘅機會率」（ Pr ( R ) {\displaystyle \Pr
(R)} {\displaystyle \Pr(R)}）。

個設計者寫好程式之後，可以（例如）搵一大柞有關呢幾個變數之間嘅關係嘅數據俾個程
式睇，跟住叫個程式用呢啲過往嘅數據，計出變數同變數之間嘅關係係點，而個程式就可
以攞嚟預測未來^[38]。貝葉斯式 AI 有相當廣泛嘅用途，例如 Xbox Live 噉，喺幫啲打
緊網上遊戲嘅玩家搵比賽加入嗰陣，就會用到考慮嗰個玩家嘅贏率嘅貝葉斯網路^[40]：一
種做法係整個人工神經網絡（睇下面），用每一個玩家喺先前嗰啲比賽嗰度「幾常成功殺
敵」同埋「幾常俾敵人殺」等嘅資訊做個網絡嘅 input，而呢個網絡嘅 output 就係「如
果個分隊係噉嘅話，A 隊贏嘅機會率係幾多」，並且寫個演算法搵出令到呢個機會率最接
近 50% 嘅分隊法（即係盡可能令場比賽勢均力敵）^[40]。

同符號 AI 比起上嚟，好似貝葉斯網路啲噉嘅貝葉斯式 AI 都有唔好處：佢哋內部要計大
量嘅機會率，搞到佢哋喺運算上撈絞好多（computationally expensive－做起運算上嚟要
嘥多好多時間同記憶體），好多時為咗慳啲時間同記憶體，啲設計者焗住要簡化佢哋啲模
型，例如係如果個設計者用嘅電腦冇返咁上下運算能力，佢可能就冇得用涉及打圈結構嘅
貝葉斯網路－即係話模型嘅可能複雜度受制於運算能力上嘅局限，而唔係個模型模擬現實
嘅能力^[40]。

神經網絡[編輯]

[270px-Artificial_neural_network]一個典型嘅人工神經網絡有三大層：input 層負責由
外界接收訊號，隱藏（hidden）層負責計由 input 層攞到嘅訊號，而 output 層俾嘅數值
就會係 output。

    內文：人工神經網絡同神經進化
    睇埋：解釋得嘅 AI同埋黑盒

人工神經網絡（artificial neural network，ANN）係建基於人腦入面嘅神經細胞嘅結構
嘅：一個動物嘅腦會由好多神經細胞組成，一個成年男人嘅腦有成差唔多 860 億粒神經細
胞，每粒神經細胞會由第啲神經細胞嗰度接收電同化學訊號，而當一粒神經細胞受到啲訊
號刺激嗰陣，佢就可能會射自己嘅電同化學訊號，呢個訊號跟手就可能會刺激第啲神經細
胞，於是乎訊號就噉喺個網絡嗰度傳開去^[41]。人工神經網絡運用嘅係同一道理。喺整人
工神經網絡嗰陣，個設計者會

  • 設下一大柞人工神經細胞（artificial neuron），
  • 每粒神經細胞有一個變數代表佢嘅「活躍程度」，而且
  • 有某啲方式（通常係一個矩陣）表示人工神經細胞之間嘅連結。

舉例說明，每粒人工神經細胞嘅活躍程度可以用以下呢條式代表^[42]^[43]：

    t = W 1 A 1 + W 2 A 2 . . . {\displaystyle t=W_{1}A_{1}+W_{2}A_{2}...} {\
    displaystyle t=W_{1}A_{1}+W_{2}A_{2}...}；呢個就係所謂嘅啟動函數（
    activation function）。

當中， t {\displaystyle t} {\displaystyle t} 代表粒神經細胞嘅啟動程度， A n {\
displaystyle A_{n}} {\displaystyle A_{n}} 代表前一層神經細胞當中第 n {\
displaystyle n} {\displaystyle n} 粒嘅啟動程度，而 W n {\displaystyle W_{n}} {\
displaystyle W_{n}} 就係其他神經細胞當中第 n {\displaystyle n} {\displaystyle
n} 粒嘅權重（指嗰粒神經細胞有幾影響到 t {\displaystyle t} {\displaystyle t}）。

如果個設計者人手噉俾某一啲 input 落去個神經網絡 input 層當中嗰啲神經細胞，噉跟
住嗰啲層嘅神經細胞就會受到 input 層嗰啲嘅刺激，並且改變佢哋嘅活躍程度，而最後嗰
層嘅神經細胞（output 層）就會負責表示個 output。跟住落嚟，一種可能做法係運用反
向傳播算法（back-propagation）訓練個人工神經網絡^[44]^[45]－個設計者會將個網絡
俾嘅 output 同佢想個網絡俾嘅 output 比較，計個誤差值，再用個誤差值嚟計吓應該點
樣調較啲神經細胞之間嘅權重。如果一切順利，個網絡就慢慢變到愈嚟愈俾到正確嘅答案^
[46]^[47]。

除咗反向傳播算法之外，廿一世紀初仲有咗所謂嘅遺傳演算法（GA）方法嚟訓練人工神經
網絡^[48]：用呢種做法嘅設計者運用進化論當中物競天擇原理；根據物競天擇，大自然嘅
每一種生物物種嘅內部都有個體差異，而呢啲個體差異令到一個族群嘅個體當中有啲比較
擅長生存同繁殖後代，呢啲個體就比較有機會將自己嘅基因傳俾下一代；同一道理，用 GA
整 AI 嘅過程係一開始嗰陣複製一大柞彼此之間相似，但彼此之間（喺權重值等方面）有
少少差異嘅神經網絡出嚟，再俾啲神經網絡各自噉做幾次個設計者想佢哋做嗰樣作業，表
現最好嗰啲網絡就會俾個設計者複製，生產下一代（似表現好嗰啲網絡）嘅子代網絡，表
現唔好嗰啲網絡就會被淘汰－於是乎個設計者手上有嘅神經網絡就會變到愈嚟愈勁^[48]^
[49]。

    Info：神經網絡嘅黑盒問題

    有好多神經網絡相關領域嘅學者批評神經網絡係「黑盒」（black box）^[50]。

    人喺用個腦諗完嘢解決完問題之後，曉將自己嘅思考過程口頭報告返出嚟。但一個神
    經網絡唔會識做呢樣嘢，唔會話到俾研究者聽佢經過啲乜嘢思考過程先能夠達到佢所
    俾嘅 output。所以有人將神經網絡比喻做一個黑盒－就算佢嘅 output 係準確嘅都好
    ，個研究者都淨係知個神經網絡嘅 input 同 output，冇辦法知道當中嘅思考過程。
    即係話對於「個神經網絡俾嘅答案點解係啱」呢條問題，目前唯一嘅答覆係「因為一
    部醒過人類嘅系統俾咗個答案出嚟」，雖然呢點唔損害神經網絡喺實用上預測現象嘅
    能力，但噉表示神經網絡嘅可解釋度（explainability）低得好交關，令好多學者都
    覺得難以接受^[51]。因為噉，有好多科學家都致力研究點樣先可以拆解一個經歷咗訓
    練、做緊準確預測嘅神經網絡^[52]。

    [540px-Blackbox3D-withGraphs]喺科學同工程學上，一個黑盒系統嘅 input 同
    output 之間有已知嘅關係，問題係研究者唔知佢內部點樣運作，點樣由 input 產生
    output ^[53]。

重要問題[編輯]

[300px-Sudoku_Puzzle_by_L2G-20050714_]數獨係一個典型嘅解謎遊戲；一個數獨難題可
以用演繹推理嚟解，但現實世界嘅問題好少可係有得齋靠推理嚟解嘅。

    睇埋：認知心理學、自然智能、機械人學同埋人工情感智能

AI 研究其中一個分類法係按「想解啲乜嘢問題」嚟分：原則上，AI 嘅終極目標係要創造
出能夠令電腦同第啲機械展示出智能；最大嗰個問題－模擬自然智能－有得分類做一大柞
子問題，包括係學習同解難等嘅能力都係先進嘅自然智能嘅必要部件，所以 AI 領域就要
將呢啲能力逐個逐個噉創造出嚟。以下係廿一世紀初 AI 領域當中多人關注嘅問題。

推理解難[編輯]

    內文：自動推理
    睇埋：推理同埋解難

AI 其中一個最基本嘅課題係點樣教機械解難（solve problem）。

早期嘅 AI 研究興集中於整一啲演算法嚟模仿人類玩解謎遊戲嗰陣用嘅逐步演繹推理（
deductive reasoning）^[54]，呢啲演算法會涉及一大柞嘅「如果... 就做...」（if...
then...）指令（睇返上面符號 AI）；但呢種做法有個問題－因為組合爆發等嘅問題，實
際應用上要處理嘅問題好多時都閒閒地有成幾千幾萬個可能性要考慮，冇可能吓吓都靠設
計者講明俾部電腦聽要做乜^[55]。所以到咗 1980 年代晚期同 1990 年代，AI 研究開始
運用嚟自概率論同經濟學等領域嘅概念（睇返上面貝葉斯網絡），並且發展出用嚟應付不
確定性嘅方法^[56]^[57]。事實係，認知科學領域嘅研究顯示咗，人腦好少可會真係用逐
步嘅推理嚟解決問題嘅^[58]。

舉例說明，數獨呢個解謎遊戲可以用相對簡單、而且具有決定性嘅「如果... 成立，就
做...」法則嚟搵到答案，而第啲解謎遊戲都可以用類似嘅演繹推理方法解決。但人類喺日
常生活當中解難嗰陣唔會點用呢種推理方式，好似係「要買啲乜嘢禮物氹女朋友」呢個難
題噉，會涉及（例如）估吓個女朋友想要乜，呢類問題好難齋靠「如果... 成立，就做...
」嘅明文邏輯嚟解決^[59]。

機械感知[編輯]

    內文：機械感知
    睇埋：電腦視覺

機械感知（machine perception）旨在教一部機械由感應器（包括鏡頭、咪高峰同雷達呀
噉）嗰度感應外界嘅資訊並且了解佢四圍嘅環境－而唔係吓吓都靠設計員話俾佢聽：生物
型嘅智能體－人同第啲動物－冚唪唥都曉自己用眼耳口鼻等嘅感官嚟接收有關佢哋周圍環
境嘅資訊同埋處理分析呢啲資訊，所以如果 AI 要做到好似人噉嘅智能，就一定要識做同
樣嘅嘢^[60]。

[270px-20100317203257]
[270px-Webcam000c1]
左：眼珠；右：網絡攝影機；呢兩樣嘢都內置會對光有反應嘅結構，而反應嘅特性係光嘅
特性嘅函數，所以兩者都能夠做到「感應光」嘅效果－廣義上可以算係感應光嘅感應器。

好似係電腦視覺（computer vision）噉，就係指教 AI 處理視覺資訊嘅領域^[61]，個設
計者可以（例如）寫一個會由部電腦嘅鏡頭攞數據嘅程式，而且個程式內置一個之前事先
訓練咗，曉（例如）辨認圖入面邊忽係人面乜嘢唔係－跟住佢就會有一個能夠靠部電腦個
鏡頭知道自己面前有冇人面嘅程式。除此之外，機械感知呢樣嘢仲可以攞嚟做語音辨識^
[62]同認人樣^[63]。

[630px-]邊緣檢測（edge detection）演算法曉搵出一幅圖像當中邊一忽係物件嘅邊緣－
簡單講就係亮度數值突然改變嘅位置。

自動計劃[編輯]

    內文：自動計劃

一個有返咁上下智能嘅智能體一定要識得幫自己設目的並且嘗試達到呢啲目的^[64]。要做
到呢樣嘢，一個 AI 就要有能力想像未來－用某啲方式（好似係電腦數據）嚟向自己表達
周圍環境嘅狀態以及預測自己同第啲智能體嘅行動會點樣改變周圍環境嘅狀態，仲要曉計
每種可能狀態對佢自身嘅效益（utility；簡單啲講就係有幾能夠幫到佢達到目的）以及按
佢嘅運算結果做決策^[65]^[66]。

古典嘅自動計劃研究會用一個理想化（唔多現實）嘅模型：將做緊計劃嗰個智能體想像成
好似係世上唯一一個做緊計劃嘅系統噉，喺呢種模型入面，個智能體可以完美噉預測佢嘅
行動嘅結果^[67]。但現實存在嘅智能體係唔會噉嘅，無論人定 AI 都好，佢哋喺計劃嗰陣
梗係要受制於身邊其他智能體嘅行動，所以實會有不確定性。噉即係表示，一個曉好似人
噉計劃嘅 AI 實要識得處理不確定性以及按自己行動嘅結果評估自己嘅進度^[68]。

喺 2000 年代中，電子遊戲業界出現咗好似噉嘅自動計劃演算法，用嚟控制一隻遊戲嘅
NPC^[69]：

 Start # 初始化
   個 AI 內部有若干個目的（goal）同若干個行動（action）；

 Foreach 時間點
   計每個目的有幾高 priority；
   按現時世界嘅狀態等資訊，搵出可能行動之中邊個最能夠幫手達到目的；
   模擬吓個行動係咪真係能夠幫手達到目的；
   採取行動。

應付複雜[編輯]

    內文：複雜性

喺對 AI 嘅研究當中，要點樣應付複雜（complexity）係一個重要嘅課題^[55]^[70]：

  • 某啲曉學習嘅 AI 程式係理論上如果有無限咁多嘅數據、時間同記憶嘅話，係會有能
    力完美噉接近任何嘅函數，包括任何可以準確噉描述成個現實世界嘅函數－用日常用
    語講，即係話只要有足夠嘅數據、時間同記憶，呢啲 AI 程式就能夠學識預測任何嘢
    。呢啲程式理論上能夠將可能嘅假說（hypothesis）冚唪唥考慮嗮佢，再將啲假說逐
    個逐個睇吓同數據吻唔吻合，最後推導嗮成個宇宙嘅知識出嚟。不過，
  • 因為組合爆發（combinatorial explosion；指「可能性嘅數量」隨問題嘅複雜性而有
    爆發性嘅增長）嘅問題，「考慮嗮所有可能嘅情況」通常喺實際應用上都係冇可能做
    到嘅，例如係教個 AI 程式捉棋噉，國際象棋喺兩個棋手都行咗第一步之後個棋盤會
    有 400 個可能嘅形勢，喺兩個棋手都行咗第二步之後個棋盤會有 197,742 個可能嘅
    形勢，而喺兩個都行咗第三步之後呢個數字會超過 100 萬（「可能性嘅數量」隨「行
    咗嘅步嘅數量」增長得好犀利），就算用先進嘅電腦行都要嘥極大量嘅時間先至能夠
    考慮嗮所有嘅可能性；而圍棋仲複雜，有成 10^170 個可能情況^[註 4]－部電腦運算
    能力再勁都唔會喺限定時間之內計得嗮。

[390px-Opening_chess_position_from_black_side]
                                 一盤國際象棋

因為組合爆發嘅問題，AI 研究當中有好多都集中於思考點樣喺有限嘅數據同時間之內盡可
能令 AI 程式學最多嘅嘢，其中一個方向係思考^[55]

「 點由所有可能嘅情況當中，揀一小部份最有可能啱用嘅情況出嚟考慮。 」

  • 舉個例說明，假想而家有一架內置咗 AI 程式嘅自駕車，佢主人叫佢搵由香港去廣州
    嘅最短駕駛路線，喺絕大多數情況之下，個 AI 程式喺做運算嗰陣都大可以安心噉略
    過（例如）嗰啲由香港經哈爾濱去廣州嘅駕駛路線（因為呢啲路線基本上冇可能會係
    最短路線）－於是個程式唔使嘥精神時間去考慮呢啲路線，可以喺可能嘅路線當中淨
    係揀一小部份出嚟考慮^[71]；
  • 又例如因為喺 2016 年打低咗九段（即係最高等級）圍棋棋手李世石而出名嘅 AI 程
    式 AlphaGo 噉，就用咗蒙地卡羅樹搜索（Monte Carlo Tree Search）嘅做法，噉講
    意思係指，foreach 棋步，AlphaGo 會用一啲特殊演算法估計邊一啲可能棋步嘅後果
    最有需要睇，再做若干次嘅模擬，想像每一個呢啲可能棋步行完之後自己嘅贏面會點
    變，然後就按模擬結果揀要行邊步^[72]。

自然語言處理[編輯]

[300px-ParseTree]語言學上有所謂嘅形式文法嚟分析字嘅詞性，可以攞嚟幫手做 NLP。

    內文：自然語言處理

自然語言處理（natural language processing，NLP）係指研究教 AI 理解人類語言嘅領
域^[73]。一個夠勁嘅 NLP 程式會令人類可以就噉用把口講或者用筆寫嚟同機械溝通，唔
使用（好多時都唔係咁易用）嘅程式語言，而且仲可以攞嚟由人寫嘅書以及網頁等嘅來源
提取有用嘅資訊^[74]或者做機械翻譯等嘅作業^[75]。

NLP 好常用。拼寫檢查（spell checking）就係一個比較簡單嘅例子，好似 Microsoft
Word 同埋 Google 搜尋器都有用到。拼寫檢查會做嘅嘢係檢查吓一段用字母寫嘅字有冇串
錯^[76]，拼寫檢查嘅一種可能步驟係噉嘅^[77]：

 1. 成立一個字庫，內有「邊啲字母串係真嘅字」同埋「每個字有幾常出現」等等嘅資訊
    ；
 2. 當檢查緊嗰份文件當中包含一個字庫冇嘅字嗰陣，顯示一條紅線喺個字下面；
 3. 如果個用家想嘅話，由個字庫當中揀返個字提議嚟代替紅線咗嗰個字－由個字庫嗰度
    揀出一個同紅線咗嗰個字最相近嘅字，如果有多過一個字係同嗰個字最相近嘅，揀佢
    哋當中最常見嗰個。

2010 年代嘅 NLP 程式好多時會用多種策略，能夠喺頁數或者段數嘅層次嗰度有可接受嘅
準確度，但依然缺乏理解文章內容嘅能力，仲未曉將獨立嘅句子分類，而且呢啲程式通常
都因為時間成本問題而冇辦法攞嚟喺商業上應用^[78]。

強 AI[編輯]

    內文：強 AI
    睇埋：圖靈測試

強人工智能（strong AI）可以話係 AI 領域嘅終極目標：強 AI 係指^[79]

「 能夠展現出所有自然智能有嘅特性嘅 AI，會完美噉通過圖靈測試（Turing test；
   睇下面）。                                                                」

廿世紀嘅學界作出咗多次創造強 AI 嘅嘗試，但次次都衰收尾，遠遠噉低估咗呢個作業嘅
難度，而到咗廿一世紀，一個典型嘅 AI 專家多數都會集中於解決一至兩個問題，而唔會
大想頭到諗住創造出能夠好似人類噉普遍解決問題嘅 AI 程式^[80]^[81]。有好多 AI 專
家都相信，呢啲淨係曉解決一至兩個問題嘅 AI 程式終有一日會俾人砌埋一齊做一個強 AI
^[82]^[83]。

廿一世紀初嘅 AI 領域有「AI 欠缺常識」嘅問題^[84]：同廿一世紀初嘅 AI 比起上嚟，
人好擅長喺冇受訓嘅情況之下對物理或者心理現象做判斷，

  • 例如就算係一個好細個嘅細路都識做「如果我將支筆碌過張枱嘅表面，支筆最係會跌
    落地」噉嘅推論；
  • 又例如人能夠易如反掌噉理解「市議員拒絕俾啲請願者攞允許，因為佢哋主張用暴力
    」噉嘅句子，但一個廿一世紀初嘅 AI 程式好多時會唔明呢句嘢係話市議員主張暴力
    定係請願者主張暴力^[85]。

廿一世紀初嘅 AI 喺常識上嘅缺乏表示咗佢哋成日都會犯一啲人唔會犯嘅錯，而且犯錯嘅
方式對人嚟講好匪夷所思，例如 AlphaGo 可以喺圍棋比賽嗰度鍊贏人類嘅圍棋國際冠軍，
而 Deepmind 仲喺 2010 年代成功發展出曉玩唔同 Atari 2600 遊戲嘅 AI ^[82]^[86]，
不過呢啲程式答唔到好似「點樣知一杯牛奶滿唔滿」呢啲（對人嚟講）簡單得好交關嘅問
題^[87]^[88]。

機械學習[編輯]

呢段片顯示一班機械人慢慢噉學識一齊合作推郁物件。

    內文：機械學習
    睇埋：人工神經網絡

機械學習（machine learning）專研究點樣令 AI 程式隨經驗自動改善自己^[56]^[89]。

最廣義上，學習可以定義為指一個智能體吸收知識、技能同埋行為嘅過程，包括獲取新知
識、新技能或者新行為，又可以係改變舊有嘅知識、技能同行為；數學化啲噉睇嘅話，一
個智能體可以想像成一個刺激-反應模型（S-R model）^[90]^[91]，最簡單嗰條式如下^
[92]：

    r ( t ) ≈ f ( s ( t ) ) {\displaystyle r(t)\approx f(\mathbf {s} (t))} {\
    displaystyle r(t)\approx f(\mathbf {s} (t))}；

當中

    r ( t ) {\displaystyle r(t)} {\displaystyle r(t)} 係個時間點 t {\
    displaystyle t} {\displaystyle t} 嘅反應（例如「郁手接波」）；
    s ( t ) {\displaystyle \mathbf {s} (t)} {\displaystyle \mathbf {s} (t)} 係
    一個向量，包括個反應嘅相關刺激（例如「見到個波向自己飛緊埋嚟」）嘅數值；

個模型講嘅係「一個智能體嘅反應係佢感知到嘅刺激嘅函數（ f {\displaystyle f} {\
displaystyle f}）」，即係「刺激決定反應」，而學習就可以想像成 f {\displaystyle
f} {\displaystyle f} 呢個函數改變嘅過程－個智能體做咗一次反應，然後 f {\
displaystyle f} {\displaystyle f} 改變，喺下次再感知到個刺激嗰陣反應就可能會唔
同咗。機械學習係 AI 嘅一個重要子領域，指教人造智能體學習嘅研究^[93]^[94]。

喺理想嘅情況下，能夠學習嘅程式會按自己所經歷嘅嘢改變佢內部嘅參數（parameter），
等自己下次做嘢嗰陣能夠更加成功。舉個簡單例子：想像而家有架內置 AI 程式嘅自駕車
，佢個程式嘅設定係佢會喺同前面架車距離 2 米或者以下嗰陣先耷逼力，呢個「2 米」嘅
數值就係個程式內部嘅一個參數；而跟住有一次架自駕車喺離前面架車 3 米嗰陣，前面架
車突然間耷逼力，架自駕車差少少撞埋去，一個識學習嘅程式就應該要考慮吓係咪要根據
呢個經驗將個參數變做「4 米」或者「5 米」，以求降低日後撞車嘅機會率^[95]^[96]。
佢內部嘅源碼應該會包含類似以下噉嘅內容：

float brake_distance; // 有個變數表示「要喺邊個距離耷逼力」。

if distance_from_front_car <= brake_distance {
    brake; // 如果離前面架車近得滯，就耷逼力；假設個程式經已有方法知道離前面架車有幾近。
}
... // 而跟住要有某啲演算法界定乜嘢為止「差少少撞車」，而 if「差少少撞車」呢個情況發生，噉個 brake_distance 嘅數值要永久提升，同埋提升幾多等等。

機械學習有得分做監督式學習（supervised）同非監督式學習（unsupervised）兩大種：
前者指個設計者會特登俾一啲數據個程式睇，同埋明文噉話俾佢知乜嘢為止啱嘅答案乜嘢
為止錯嘅答案^[96]；而後者指個設計者唔會噉樣做^[97]，例如係教 AI 程式將啲嘢分類
噉，用監督式學習定非監督式學習都有可能做得到：用監督式學習嘅話，個設計員一般會
先攞一大柞樣本返嚟，並且逐個逐個樣本將個樣本嘅類別列明，再俾個程式睇啲數據同教
佢要睇邊啲部份嚟分，順利嘅話，個程式會慢慢變到識得將未來撞到嘅樣本分類；而用非
監督式學習嘅例子就有聚類分析等^[98]。

學錯嘢[編輯]

    內文：奥坎剃刀
    睇埋：過適

奥坎剃刀（Occam's razor）係機械學習上嘅一個重要概念。奥坎剃刀意思係「假設第啲因
素不變，一個學習者會偏好比較簡單啲嘅理論同假說，除非比較複雜啲嗰個模型（例如）
解釋同預測現實嘅能力勁好多」。當一個 AI（通常因為設計得唔好）喺學習嗰陣為咗要令
自己心目中嗰個「描述世界點運作」嘅數學模型完美符合過去數據，而選擇一個太複雜嘅
模型，個 AI 就有過適（overfitting）嘅問題：雖然話過度複雜嘅模型解釋過去數據嘅能
力比較勁，但統計學上嘅研究表明，呢啲模型解釋將來數據嘅能力通常會渣啲。為咗防止
過適，設計 AI 嘅人好多時都會想鼓勵個程式學一啲能夠充分解釋數據得嚟又唔係太複雜
嘅模型^[99]。

例如想像下圖：

過適嘅展示過適嘅展示

家陣有一個智能體，佢要學習兩個變數（圖中嘅 X 軸同 Y 軸）之間成乜嘢關係，等自己
將來能夠由 X 嘅數值預測 Y 嘅數值；佢要做嘅係，嘗試搵一條有返咁上下合乎過去數據
（每個黑點係一個個案）嘅線，用條線做佢心目「兩個變數之間成乜嘢關係」嘅模型；藍
色嗰條線有過適嘅問題－藍色線完美噉符合過去嘅數據，但藍色線條式會複雜過直線嘅好
多，而實證研究顯示，通常呢啲咁複雜嘅線解釋將來數據嘅能力（以「將來用條線做預測
嗰陣嘅誤差」衡量）會比較渣。

「建立能夠用嚟做預測嘅數學模型」呢一點喺 AI 設計上相當重要：比較複雜嘅智能體會
具有「描述世界嘅內部模型」（internal model of the world），意思係個智能體對「世
界係點運作」嘅理解，可以想像成一大柞 Pr ( A ∣ B ) {\displaystyle \Pr(A\mid B)} 
{\displaystyle \Pr(A\mid B)} 數值^[註 5]，而呢點對於個智能體做決策嚟講不可或缺
－例：個智能體憑過往數據估計出條線，可以用變數 X 嘅數值預測變數 Y 嘅數值，而呢
個模型能夠幫個智能體做「如果我採取咗行動 B {\displaystyle B} {\displaystyle B}
令變數 X 嘅值變成噉噉噉，環境變數 Y 會變成 A {\displaystyle A} {\displaystyle
A} 嘅機會率會最大化，而我嘅目的係想要環境變數 Y 變成 A {\displaystyle A} {\
displaystyle A}，所以我要作出 B {\displaystyle B} {\displaystyle B} 呢個行動」
等嘅判斷^[100]。

除此，一個學習緊嘅智能體仲可以有「學錯嘢」嘅問題。舉個例說明，假想而家有個設計
者想訓練一個 AI 程式學識分辨馬同貓嘅圖片，佢搵一大柞啡色嘅馬同黑貓嘅圖片返嚟，
再入落去個程式嗰度訓練個程式；喺呢個情況之下，個程式可能會學錯嘢，諗住啡色嘅物
體就係「馬」，黑色嘅物體就係「貓」^[101]^[102]。「要點樣防止 AI 學錯嘢」喺圖形
辨識（pattern recognition）－專門研究點樣教機器分辨圖像嘅 AI 子領域－上係一個相
當受關注嘅課題^[103]^[104]。

[270px-WelshPonySectionD]
[270px-065-Barcelona-Cat-1_]
想像有一個人，佢從來未見過馬同貓；家陣有個老師攞住呢兩幅相，同佢講「嗱，左手邊
嘅係馬，右手邊嘅係貓」，佢好有可能會以為「色水」係一種可以攞嚟分辨馬同貓嘅特性
。

知識表示[編輯]

    內文：知識表示
    睇埋：本體 (資訊科學)

知識表示（knowledge representation）係古典 AI 研究上重要嘅一環，研究點樣教一個
AI 程式組織手上嘅知識，並且用呢啲知識解決一啲複雜嘅作業。舉個例說明，家吓有個設
計者想寫個 AI 程式嚟幫手做地理學助教，佢想個程式曉解答一啲簡單嘅地理問題，想個
程式了解北美洲喺 2020 年有邊幾多個國家，於是佢喺寫個程式嗰陣，可以用以下呢段碼^
[105]^[106]：

    NorthAmericanCountries = ("The United States", "Canada", "Mexico")

呢段源碼教個程式話「北美洲國家」呢個類別包括咗「美國」、「加拿大」同「墨西哥」
三個內容。當有個學生問個程式「北美洲喺 2020 年有邊幾個國家」嗰陣，個 AI 程式會
耖嗮佢手上有嘅資訊，搵出「北美洲國家」呢個類別包含嘅內容，再將嗰三個名俾出嚟做
output。同一道理，呢種做法可以用嚟教任何 AI 程式將啲嘢－例如係將動物或者語言－
分類。除咗呢種分類性嘅手法，知識表示研究仲有好多方法教 AI 程式組織自己手頭上嘅
知識^[107]^[108]。

上述呢個等級式嘅知識組織方法有唔少局限^[109]^[110]^[111]：

  • 首先，呢種做法假設咗類別之間有遞移關係（transitivity），噉講即係話，佢假設
    咗「如果（分類上）A 屬於 B 而 B 屬於 C，噉 A 屬於 C」，但研究顯示，人嘅心靈
    所用嘅認知機制唔係噉嘅，例如「凳」會屬「傢俬」呢個類別，「一張爛爛地嘅凳」
    呢個物體屬「凳」，但喺現實好難說服人喺答「傢俬呢個類別包含啲乜」嗰陣答「一
    張爛爛地嘅凳」－所以喺最少一方面，純等級式嘅知識組織法唔似人類智能^[112]；
  • 除此之外，如果要一個 AI 程式做到人做到嘅智能，齋靠分類係唔夠嘅－除咗將物件
    分類，人仲會識得描述物件嘅特性（「美國有 200 年歷史左右，國旗有紅、藍、同白
    三隻色...」）同物件彼此之間嘅關係（「美國同加拿大友好，同俄羅斯唔友好...」
    ）。

    Info：內隱知識

    「要點樣令 AI 展示內隱知識（tacit knowledge）」係另一個受注目嘅課題。

    內隠知識係指嗰啲難以言喻嘅知識，好似係一個象棋大師可能會直覺噉覺得某一步「
    太危險」所以唔行，但如果問返佢，佢唔會講得出點解佢覺得嗰步太危險^[113]－認
    知心理學嘅研究顯示，人有能力用直覺做判斷（第一型過程），喺呢啲情況之下，做
    判斷嘅人唔識用言語形容佢嘅思考過程，但實驗結果係，好多時用直覺做判斷估中嘅
    機會率大過純粹隨機斷估。噉即係話喺人用直覺做判斷嘅過程當中個腦實係處理咗啲
    用言語形容唔到嘅知識－呢啲知識就係所謂嘅內隱知識^[114]。

    內隱知識對人嘅日常生活好緊要，因為人冇可能吓吓做決定（例如決定行路嗰陣邊隻
    腳踩出去先）都要有意識噉諗過度過先做。所以要做出好似人噉嘅 AI，噉就實要能夠
    令 AI 具有好似內隱知識噉嘅行為^[115]。

應用[編輯]

    內文：人工智能嘅應用

AI 對於任何嘅智能作業嚟講都好有用^[116]。比較廣為人知嘅 AI 應用例子包括咗識揸自
己嘅交通工具（包括咗車同埋無人飛機呀噉）、醫療診斷、數學定理證明、藝術創作、玩
遊戲、搜尋器、認相入面嘅影像以及係網上廣告... 等等^[117]^[118]^[119]。

電子遊戲[編輯]

[300px-The_Art_of_Video_Games_2012_]一班人喺度玩《食鬼》；啲鬼由電腦操控，但曉
追捕玩家－展現咗簡單嘅智能。

    內文：電子遊戲 AI
    睇埋：瓣瓣掂玩遊戲

電子遊戲 AI 係指電子遊戲用嘅 AI：電子遊戲係能夠同玩家互動、以娛樂玩家為目的嘅電
腦程式；而電子遊戲入面好多時會涉及由電腦控制，同玩家進行對局嘅角色（NPC）^[120]
，遊戲開發者為咗想玩家得到樂趣，通常會想呢啲由電腦控制嘅角色有返咁上下聰明，能
夠為玩家提供一定嘅挑戰（睇埋心流體驗）^[121]；噉即係話佢哋會想 NPC 展現一定程度
嘅智能，而「教電腦程式做出類似有智能噉嘅行為」正正就係 AI 呢個領域嘅重心^[122]^
[123]。

舉個簡單例子，《食鬼》入面嘅敵人由電腦控制，一個教電腦控制啲敵人嘅可能演算法如
下^[124]：

Pac-Man.pos
clyde_target = random_tiles // 將 clyde_target 設做隨機一格

while game == in_play: // 當隻遊戲進行嘅每一個時間點，
    case player of:
      Blinky:  move 1 tile toward Pac-Man.pos // 第一隻鬼要向主角位置（Pac-Man.pos）行一步。
      Inky:    move 1 tile toward (Pac-Man.pos + 4) // 第二隻鬼要向主角位置前四格行一步。
      Clyde:   if Clyde.pos == clyde_target: // Clyde 呢隻鬼要向佢嘅目標位置前進，如果到咗目標位置，揀個新嘅目標位置。
                   clyde_target = (clyde_target + 1) % 10 
               else:
                   move 1 tile toward clyde_target

上述嘅碼會令啲敵人曉追趕主角－有少少似有智能嘅噉^[125]。

早期－廿世紀中－嘅電子遊戲經已有喺度用相對簡單嘅 AI，而廿一世紀初及後，電子遊戲
AI 仲成為咗遊戲製作上嘅一個大課題。遊戲製作專家會研究「用乜嘢演算法整一隻遊戲嘅
AI 先最可以令玩家過癮」，而且 AI 仲有俾人運用嚟做控制 NPC 以外嘅工作，例如係做
遊戲測試（喺隻遊戲出街前測試隻遊戲玩起上嚟點）同遊戲分析（對玩家嘅行為作出分析
）等都有用到 AI 相關嘅技術^[40]^[126]。

第啲應用[編輯]

一架自駕車行嘅片

    睇埋：自駕車同埋運算創意

  • 自駕車（driverless car）：直至 2016 年為止，總共有 30 間主要公司都有喺度用
    AI 整自駕車，而「AI 可以點樣幫助自駕車技術」係 AI 領域當中好受關注嘅一環^
    [127]^[128]^[129]－
      □ 自駕車 AI 其中一個最緊要嘅部份係教架車了解佢周圍環境嘅佈局。一般嚟講，
        一架自駕車會內置咗佢會行駛嘅地區嘅地圖，會包括咗交通燈同埋行人路嘅位置
        等嘅資訊，亦都有一啲研究嘗試令到自駕車唔使內置地圖都曉自己按照經驗學識
        佢周圍環境係乜嘢樣^[130]。
      □ 喺自駕車設計上，「要點樣確保乘客嘅安全」係一個重要嘅議題。一架自駕車嘅
        程式實會內置一啲教架車點樣處理危險情況嘅演算法，但係好似「當架車實炒、
        一係撞到路人一係令乘客受傷嗰陣，架車應該揀保護個路人定保護個乘客」呢啲
        問題都仲係好難搞^[131]... 等等。
  • 劑量：AI 程式可以幫手評估落藥嗰陣要落幾重；喺醫療上，落藥要落幾多係一條關乎
    人命嘅問題，例如手術麻醉噉，如果落嘅麻醉藥劑量大得滯會搞出人命，而喺 2016
    年，有份喺加州做嘅研究就發現，有一條多得 AI 先搵到嘅數學方程式可以用嚟評定
    要落幾大劑量嘅免疫抑制劑落去病人身上。喺醫療上，評估劑量不嬲都係一個好嘥時
    間精神嘅程序，所以呢種 AI 程式幫醫療界慳到唔少錢^[132]。
      □ 癌症研究：AI 程式可以幫手決定點樣醫癌症；可以用嚟醫癌症嘅藥同疫苗有成多
        個 800 種，所以對於醫生嚟講，要決定點樣醫一個癌症病人絕非易事。微軟發展
        咗一個叫 Hanover 嘅 AI 程式，呢個程式曉記住嗮所以同癌症有關嘅研究論文，
        知道每一種醫療方法喺邊種情況之下最有效，並且用攞到嘅資訊決定某一個特定
        病人應該用乜嘢方法醫^[133]^[134]。有研究指呢種程式喺診斷癌症嘅表現同真
        人醫生一樣咁好^[134]。
  • 數碼藝術：AI 甚至仲可以攞嚟整藝術品；人工神經網絡嘅 input 層嘅每粒神經細胞
    可以設做幅 input 圖像嘅一粒像素^[135]，而 output 層嘅每一粒神經細胞同一道理
    可以作為 output 圖像嘅像素。而中間嘅隱藏層做嗰啲運算會令到幅 output 圖像同
    input 圖像有少少似，但又唔同。舉個例子說明，有研究者成功噉整出能夠將是但一
    幅相變做印象派作品嘅人工神經網絡^[135]。
  • 金融：廿一世紀嘅金融界會用 AI 程式嚟監察買家同賣家嘅活動。呢啲程式喺見到某
    啲異常活動嗰陣會通報俾銀行等嘅機構聽，等做起探測詐騙等嘅罪行嗰陣容易好多^
    [136]。
  • 數碼營銷：有啲 AI 程式曉睇一個人上啲乜嘢網站，並且靠呢啲資訊嚟賣幫手賣廣告
    ：例如如果個程式探測到某個用家零舍鍾意搜尋有關打機嘅資訊嘅話，個程式就會俾
    個用家多啲睇到同打機相關嘅廣告^[137]。

... 等等。

科幻諗頭[編輯]

[240px-Frankenstein]一個演員扮成科學怪人嘅樣

    內文：AI 叛變、友好嘅 AI同機械人三定律
    睇埋：人工智能 (電影)、Cyberpunk同埋心靈哲學

AI 早喺 19 世紀初經已喺 sci-fi 或者類似體裁嘅創作當中出現：由英國作家瑪莉雪萊（
Mary Shelley）寫嘅經典 sci-fi 小說《科學怪人》講及一個人類科學家創造咗一隻有血
有肉、有智能嘅生命體（喺廣義上算係 AI），而呢隻生命體仲有自己嘅意志，仇視佢嘅創
造者同埋對佢嘅創造者造成威脅，可以算係早期用咗 AI 橋段嘅 sci-fi 作品^[138]。

  • 一方面，AI 叛變（AI takeover）呢條橋喺 sci-fi 創作（尤其係反烏托邦嘅
    cyberpunk）當中成日出現^[註 6]，廿世紀尾嘅《未來戰士》（Terminator）故仔講
    能夠控制全世界嘅電腦系統嘅人工神經網絡程式「天網」為咗唔想俾人閂佢而嘗試消
    滅人類、《廿二世紀殺人網絡》（The Matrix）故仔就係講機械同人類打仗，而且仲
    將人嘅精神韞喺虛擬世界入面嚟攞佢哋嘅身體做能源、廿一世紀初嘅作品《智能叛侶
    》（Ex Machina）嘅其中一個主要角色就係一個為咗唔想俾人韞住而呃人謀殺人嘅 AI
    機械人；
  • 另一方面，又有一啲作品描繪一啲對人好忠心好友善嘅 AI ^[註 7]，好似係日本嘅《
    叮噹》同《小飛俠阿童木》噉，都係以對人友好嘅 AI 機械人做主角^[139]^[140]。
  • 機械人三定律（the Three Laws of Robotics）係由著名美國 sci-fi 作家阿西莫夫
    （Isaac Asimov）喺佢多份作品當中提出嘅諗頭。根據佢嘅見解，AI 機械人必需遵守
    三條法則：
     1. 唔准傷害人類或者透過唔採取行動令到人類受傷害；
     2. 要服從人類俾嘅指令，除非嗰個指令違反咗法則一；
     3. 要保護自己，除非呢一點違反咗法則一或者法則二。
      □ 呢三條定律確保咗啲機械人會聽話，肯為咗服務人類而犧牲自己得嚟，又唔會俾
        某啲人類利用嚟做一啲傷害他人嘅嘢^[141]。機械人三定律喺西方社會係一個社
        會大眾喺有關機械人道德嘅討論上常見嘅話題，常見到俾人當咗係橋段嘅一種^
        [註 8]，但專業嘅 AI 研究者多數都嫌呢三條定律有歧義等嘅問題，好少可會認
        真噉看待佢哋^[142]。

... 等等。

哲學思考[編輯]

    內文：AI 哲學
    睇埋：圖靈測試

AI 哲學（philosophy of AI）係對 AI 嘅哲學探討：AI 同哲學－尤其係心靈哲學－相當
有關，因為兩個領域都關注智能、心靈、意識以至自由意志等嘅概念。再加上 AI 嘅技術
理論上可以引致人造心靈嘅出現，而噉做會引起唔少道德上嘅問題，所以道德哲學等嘅領
域都對 AI 嘅相關討論有興趣^[143]。

AI 哲學上嘅思考會試圖回答以下嘅問題^[144]：

  • 機械有冇可能展現智能？佢哋有冇可能解決嗮所有人曉透過思考處理嘅問題？
  • 人類智能同 AI 本質上係咪一樣？人腦同電腦有乜異同？
  • 機械有冇可能好似人類噉，擁有自己嘅精神、意識同心理狀態？

... 等等。

    Info：圖靈測試

    圖靈測試（Turing test，簡稱 TT）係 AI 哲學上一個出名嘅議題。圖靈測試係由英
    格蘭數學家亞倫圖靈（Alan Turing）喺 1950 年諗出嚟嘅一個測試，用嚟檢驗一部機
    械係咪展現到好似人噉嘅有智能行為。最基本嗰種圖靈測試步驟如下：

      □ 一次測試會有一個人類負責做評判（下圖嘅 C），
      □ 跟住又有一個人類（下圖嘅 B）同部受試嘅機械（下圖嘅 A），兩者分別噉同個
        評判講嘢；
      □ 個評判唔會見得到個人類同個受試者，淨係有得用鍵盤同熒幕等嘅方法同受試者
        傾偈，
      □ 最後個評判就要答，兩個受試者當中邊個係人邊個係機械

    －而如果搵咗一班評判返嚟之後，發現班評判嘅判斷嘅準確性唔明顯好過隨機靠撞（
    答中率等如 50%）嘅話，嗰部受試機械就算得上係通過咗圖靈測試，展現出同人類無
    異嘅智能^[145]^[146]。

    [500px-Turing_test_diagram]

    圖靈測試喺 AI 哲學上引起咗廣泛討論。例如有學者批評圖靈測試指出，嚴格嚟講，
    就算一部機械通過咗圖靈測試，都只係表示佢曉喺一個人工環境下做某啲工作，但有
    智能嘅行為要求嘅係能夠喺自然環境下生存，所以圖靈測試喺測試機械智能上嘅功用
    有限^[145]^[147]。因為噉，有學者諗出咗新版嘅圖靈測試，好似係所謂嘅真正完整
    圖靈測試（Truly Total Turing Test，TRTTT）噉，就認為一部機械要算得上展現人
    類智能，佢就需要能夠喺自然環境下達成人類能夠達成嘅重大成就，包括係－好似人
    類噉樣－創作出藝術品、音樂、遊戲以及語言等嘅文化產物^[148]。

註釋[編輯]

 1. ↑ 喺呢度，設計者好多時都會加啲演算法教個 AI 預測未來。
 2. ↑ 睇埋強化同懲罰。
 3. ↑ 即係忽略咗內隱知識。
 4. ↑ 可以睇吓 AlphaGo。
 5. ↑ 喺數學上，「 Pr ( A ∣ B ) {\displaystyle \Pr(A\mid B)} {\displaystyle \Pr
    (A\mid B)}」係指「事件 B {\displaystyle B} {\displaystyle B} 發生咗嘅話，事
    件 A {\displaystyle A} {\displaystyle A} 發生嘅機會率」。可以睇吓概率論。
 6. ↑ 可以睇吓 TV Tropes 嘅 A.I. Is a Crapshoot。
 7. ↑ 可以睇吓 TV Tropes 嘅 Benevolent A.I.。
 8. ↑ 可以睇吓 TV Tropes 嘅 Three Laws Compliant。

相關領域[編輯]

搵更多有關
Artificial intelligence
喺維基媒體兄弟計劃嘅嘢
搵維基辭典 維基辭典嘅字詞解釋
搵同享     維基同享嘅媒體
搵維基新聞 維基新聞嘅新聞故事
搵維基語錄 維基語錄嘅名言
搵維基文庫 維基文庫嘅原始文獻
搵維基書本 維基書本嘅教科書
搵維基學府 維基學府嘅學習資源

  • 哲學（心靈哲學）
  • 數學（統計學、控制理論）
  • 認知科學（心理學、腦神經學、語言學）
  • 電腦科學
  • 機械人學
  • 經濟學
  • 進化論

睇埋[編輯]

  • AI 詞彙表
  • OpenAI
  • AI 史
  • 智能放大
  • 恐怖谷理論
  • 唔確定原理
  • 意識同心靈
  • Ghost in the machine

文獻[編輯]

教科書[編輯]

  • Hutter, Marcus (2005). Universal Artificial Intelligence. Berlin: Springer.
  • Jackson, Philip (1985). Introduction to Artificial Intelligence (2nd ed.).
    Dover.
  • Luger, George; Stubblefield, William (2004). Artificial Intelligence:
    Structures and Strategies for Complex Problem Solving (5th ed.). Benjamin/
    Cummings.
  • Neapolitan, Richard; Jiang, Xia (2018). Artificial Intelligence: With an
    Introduction to Machine Learning. Chapman & Hall/CRC.
  • Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan
    Kaufmann. ISBN 978-1-55860-467-4.
  • Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern
    Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall.
  • Russell, Stuart J.; Norvig, Peter (2009). Artificial Intelligence: A Modern
    Approach (3rd ed.). Upper Saddle River, New Jersey: Prentice Hall.
  • Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational
    Intelligence: A Logical Approach. New York: Oxford University Press.
  • Winston, Patrick Henry (1984). Artificial Intelligence. Reading, MA:
    Addison-Wesley.
  • Rich, Elaine (1983). Artificial Intelligence. McGraw-Hill.
  • Bundy, Alan (1980). Artificial Intelligence: An Introductory Course (2nd
    ed.). Edinburgh University Press.
  • Poole, David; Mackworth, Alan (2017). Artificial Intelligence: Foundations
    of Computational Agents (2nd ed.). Cambridge University Press.

研究史[編輯]

  • Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial
    Intelligence, New York, NY: BasicBooks.
  • McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K.
    Peters, Ltd..
  • Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest
    For Machines That Think. New York: Macmillan/SAMS.
  • Nilsson, Nils (2009). The Quest for Artificial Intelligence: A History of
    Ideas and Achievements. New York: Cambridge University Press.

其他文獻[編輯]

  • D. H. Autor, "Why Are There Still So Many Jobs? The History and Future of
    Workplace Automation" (2015). 29(3), Journal of Economic Perspectives, 3.
  • TechCast Article Series, John Sagi, "Framing Consciousness".
  • Billings, J. J., McCaskey, A. J., Vallee, G., & Watson, G. (2017). Will
    humans even write code in 2040 and what would that mean for extreme
    heterogeneity in computing? (PDF). arXiv preprint arXiv:1712.00676.
  • Boden, Margaret, Mind As Machine, Oxford University Press, 2006
  • Domingos, Pedro, "Our Digital Doubles: AI will serve our species, not
    control it", Scientific American, vol. 319, no. 3 (September 2018), pp.
    88–93.
  • Gopnik, Alison, "Making AI More Human: Artificial intelligence has staged a
    revival by starting to incorporate what we know about how children learn",
    Scientific American, vol. 316, no. 6 (June 2017), pp. 60–65.
  • Jacovi, A., Marasović, A., Miller, T., & Goldberg, Y. (2021, March).
    Formalizing trust in artificial intelligence: Prerequisites, causes and
    goals of human trust in ai (PDF). In Proceedings of the 2021 ACM conference
    on fairness, accountability, and transparency (pp. 624-635)，呢篇文討論人點
    樣對 AI 產生信任。
  • Johnston, John (2008). The Allure of Machinic Life: Cybernetics, Artificial
    Life, and the New AI, MIT Press.
  • Kurzweil, R. (2013). How to create a mind: The secret of human thought
    revealed. Penguin.
  • Marcus, Gary, "Am I Human?: Researchers need new ways to distinguish
    artificial intelligence from the natural kind", Scientific American, vol.
    316, no. 3 (March 2017), pp. 58–63. Multiple tests of
    artificial-intelligence efficacy are needed because, "just as there is no
    single test of athletic prowess, there cannot be one ultimate test of
    intelligence." One such test, a "Construction Challenge", would test
    perception and physical action—"two important elements of intelligent
    behavior that were entirely absent from the original Turing test." Another
    proposal has been to give machines the same standardized tests of science
    and other disciplines that schoolchildren take. A so far insuperable
    stumbling block to artificial intelligence is an incapacity for reliable
    disambiguation. "[V]irtually every sentence [that people generate] is
    ambiguous, often in multiple ways." A prominent example is known as the
    "pronoun disambiguation problem": a machine has no way of determining to
    whom or what a pronoun in a sentence—such as "he", "she" or "it"—refers.
  • E. McGaughey, "Will Robots Automate Your Job Away? Full Employment, Basic
    Income, and Economic Democracy" (2018). SSRN, part 2(3).
  • Myers, Courtney Boyd ed. (2009). "The AI Report". Forbes, June 2009.
  • Raphael, Bertram (1976). The Thinking Computer. W.H. Freeman and Company.
  • Serenko, Alexander (2010). "The development of an AI journal ranking based
    on the revealed preference approach" (PDF). Journal of Informetrics. 4 (4):
    447–459.
  • Serenko, Alexander; Michael Dohan (2011). "Comparing the expert survey and
    citation impact journal ranking methods: Example from the field of
    Artificial Intelligence" (PDF). Journal of Informetrics. 5 (4): 629–649.
  • Sun, R. & Bookman, L. (eds.), Computational Architectures: Integrating
    Neural and Symbolic Processes. Kluwer Academic Publishers, Needham, MA.
    1994.
  • Tom Simonite (29 December 2014). "2014 in Computing: Breakthroughs in
    Artificial Intelligence". MIT Technology Review.

攷[編輯]

 1. ↑ ^1.0 ^1.1 This list of intelligent traits is based on the topics covered
    by the major AI textbooks, including:
      □ Russell & Norvig 2003.
      □ Luger & Stubblefield 2004.
      □ Poole, Mackworth & Goebel 1998.
      □ Nilsson 1998.
 2. ↑ General intelligence (strong AI) is discussed in popular introductions to
    AI:
      □ Kurzweil 1999 and Kurzweil 2005.
 3. ↑ ^3.0 ^3.1 ^3.2 ^3.3 Definition of AI as the study of intelligent agents:
      □ Poole, Mackworth & Goebel 1998, p. 1, which provides the version that
        is used in this article. Note that they use the term "computational
        intelligence" as a synonym for artificial intelligence.
      □ Russell & Norvig (2003). (who prefer the term "rational agent") and
        write "The whole-agent view is now widely accepted in the field"
        (Russell & Norvig 2003, p. 55).
      □ Nilsson 1998.
      □ Legg & Hutter 2007.
 4. ↑ ^4.0 ^4.1 Russell & Norvig 2009, Ch. 2.
 5. ↑ This is a central idea of Pamela McCorduck's Machines Who Think. She
    writes: "I like to think of artificial intelligence as the scientific
    apotheosis of a venerable cultural tradition." (McCorduck 2004, p. 34)
    "Artificial intelligence in one form or another is an idea that has
    pervaded Western intellectual history, a dream in urgent need of being
    realized." (McCorduck 2004, p. xviii) "Our history is full of
    attempts—nutty, eerie, comical, earnest, legendary and real—to make
    artificial intelligences, to reproduce what is the essential us—bypassing
    the ordinary means. Back and forth between myth and reality, our
    imaginations supplying what our workshops couldn't, we have engaged for a
    long time in this odd form of self-reproduction." (McCorduck 2004, p. 3)
    She traces the desire back to its Hellenistic roots and calls it the urge
    to "forge the Gods." (McCorduck 2004, pp. 340–400).
 6. ↑ "Stephen Hawking believes AI could be mankind's last accomplishment".
    BetaNews.
 7. ↑ Ford, Martin; Colvin, Geoff (6 September 2015). "Will robots create more
    jobs than they destroy?". The Guardian.
 8. ↑ Solomonoff, R. J. (1985). The Time Scale of Artificial Intelligence;
    Reflections on Social Effects, Human Systems Management, Vol 5, P. 149-153.
 9. ↑ Optimism of early AI:
      □ Herbert Simon quote: Simon 1965, p. 96 quoted in Crevier 1993, p. 109.
      □ Marvin Minsky quote: Minsky 1967, p. 2 quoted in Crevier 1993, p. 109.
10. ↑ Boom of the 1980s: rise of expert systems, Fifth Generation Project,
    Alvey, MCC, SCI:
      □ McCorduck 2004, pp. 426–441.
      □ Crevier 1993, pp. 161–162,197–203, 211, 240.
      □ Russell & Norvig 2003, p. 24.
      □ NRC 1999, pp. 210–211.
11. ↑ First AI Winter, Mansfield Amendment, Lighthill report
      □ Crevier 1993, pp. 115–117.
      □ Russell & Norvig 2003, p. 22.
      □ NRC 1999, pp. 212–213.
      □ Howe 1994.
12. ↑ Second AI winter:
      □ McCorduck 2004, pp. 430–435.
      □ Crevier 1993, pp. 209–210.
      □ NRC 1999, pp. 214–216.
13. ↑ Pamela McCorduck (2004, pp. 424) writes of "the rough shattering of AI in
    subfields—vision, natural language, decision theory, genetic algorithms,
    robotics ... and these with own sub-subfield—that would hardly have
    anything to say to each other."
14. ↑ AI applications widely used behind the scenes:
      □ Russell & Norvig 2003, p. 28.
      □ Kurzweil 2005, p. 265.
      □ NRC 1999, pp. 216–222.
15. ↑ Artificial Intelligence. Do you know what AI can do for your business?.
    Medium.
16. ↑ AI's immediate precursors:
      □ McCorduck 2004, pp. 51–107.
      □ Crevier 1993, pp. 27–32.
      □ Russell & Norvig 2003, pp. 15, 940.
      □ Moravec 1988, p. 3.
17. ↑ Domingos 2015, Chapter 2, Chapter 4, Chapter 6.
18. ↑ "Can neural network computers learn from experience, and if so, could
    they ever become what we would call 'smart'?". Scientific American. 2018.
19. ↑ "Algorithm in Artificial Intelligence 互聯網檔案館嘅歸檔，歸檔日期2022年3
    月3號，..".
20. ↑ ^20.0 ^20.1 Understanding the difference between Symbolic AI & Non
    Symbolic AI. 互聯網檔案館嘅歸檔，歸檔日期2018年12月5號，.. Analytics India.
21. ↑ Haugeland, John (1985), Artificial Intelligence: The Very Idea,
    Cambridge, Mass: MIT Press.
22. ↑ ^22.0 ^22.1 ^22.2 ^22.3 Flasiński, M. (2016). Symbolic Artificial
    Intelligence. In Introduction to Artificial Intelligence (pp. 15-22).
    Springer, Cham.
23. ↑ Haugeland 1985, pp. 112-117.
24. ↑ The most dramatic case of sub-symbolic AI being pushed into the
    background was the devastating critique of perceptrons by Marvin Minsky and
    Seymour Papert in 1969. See History of AI, AI winter, or Frank Rosenblatt.
25. ↑ What are heuristics? 互聯網檔案館嘅歸檔，歸檔日期2019年8月20號，..
    Conceptually.
26. ↑ McCarthy and AI research at SAIL and SRI International:
      □ McCorduck 2004, pp. 251-259.
      □ Crevier 1993.
27. ↑ AI research at Edinburgh and in France, birth of Prolog:
      □ Crevier 1993, pp. 193-196.
      □ Howe 1994.
28. ↑ Knowledge revolution:
      □ McCorduck 2004, pp. 266-276, 298-300, 314, 421.
      □ Russell & Norvig 2003, pp. 22-23.
29. ↑ Giarratano, J. C., & Riley, G. (1989). Expert systems: principles and
    programming. Brooks/Cole Publishing Co..
30. ↑ Kendal, S.L.; Creen, M. (2007), An introduction to knowledge engineering,
    London: Springer.
31. ↑ Domingos 2015, chapter 6.
32. ↑ Revival of connectionism:
      □ Crevier 1993, pp. 214–215.
      □ Russell & Norvig 2003, p. 25.
33. ↑ Computational intelligence
      □ IEEE Computational Intelligence Society Archived 9 May 2008 at the
        Wayback Machine.
34. ↑ Stochastic methods for uncertain reasoning:
      □ ACM 1998, ~I.2.3,
      □ Russell & Norvig 2003, pp. 462–644,
      □ Poole, Mackworth & Goebel 1998, pp. 345–395,
      □ Luger & Stubblefield 2004, pp. 165–191, 333–381,
      □ Nilsson 1998, chpt. 19.
35. ↑ Bayesian inference algorithm:
      □ Russell & Norvig 2003, pp. 504–519,
      □ Poole, Mackworth & Goebel 1998, pp. 361–381,
      □ Luger & Stubblefield 2004, pp. ~363–379,
      □ Nilsson 1998, chpt. 19.4 & 7.
36. ↑ Bayesian learning and the expectation-maximization algorithm:
      □ Russell & Norvig 2003, pp. 712–724,
      □ Poole, Mackworth & Goebel 1998, pp. 424–433,
      □ Nilsson 1998, chpt. 20.
37. ↑ Bayesian decision theory and Bayesian decision networks:
      □ Russell & Norvig 2003, pp. 597–600.
38. ↑ ^38.0 ^38.1 Bayesian Networks 互聯網檔案館嘅歸檔，歸檔日期2019年7月9號
    ，.. Bayesialab.
39. ↑ Bayesian networks:
      □ Russell & Norvig 2003, pp. 492–523,
      □ Poole, Mackworth & Goebel 1998, pp. 361–381,
      □ Luger & Stubblefield 2004, pp. ~182–190, ≈363–379,
      □ Nilsson 1998, chpt. 19.3–4.
40. ↑ ^40.0 ^40.1 ^40.2 ^40.3 Delalleau, O., Contal, E., Thibodeau-Laufer, E.,
    Ferrari, R. C., Bengio, Y., & Zhang, F. (2012). Beyond skill rating:
    Advanced matchmaking in ghost recon online. IEEE Transactions on
    Computational Intelligence and AI in Games, 4(3), 167-177.
41. ↑ Domingos 2015, Chapter 4.
42. ↑ "Why Deep Learning Is Suddenly Changing Your Life 互聯網檔案館嘅歸檔，歸
    檔日期2018年4月14號，.". Fortune. 2016.
43. ↑ "Google leads in the race to dominate artificial intelligence". The
    Economist.
44. ↑ Seppo Linnainmaa (1970). The representation of the cumulative rounding
    error of an algorithm as a Taylor expansion of the local rounding errors.
    Master's Thesis (in Finnish), Univ. Helsinki, 6–7.
45. ↑ Griewank, Andreas (2012). Who Invented the Reverse Mode of
    Differentiation?. Optimization Stories, Documenta Matematica, Extra Volume
    ISMP (2012), 389–400.
46. ↑ Paul Werbos (1982). Applications of advances in nonlinear sensitivity
    analysis. In System modeling and optimization (pp. 762–770). Springer
    Berlin Heidelberg.
47. ↑ Backpropagation:
      □ Russell & Norvig 2003, pp. 744–748,
      □ Luger & Stubblefield 2004, pp. 467–474,
      □ Nilsson 1998, chpt. 3.3.
48. ↑ ^48.0 ^48.1 "Artificial intelligence can 'evolve' to solve problems".
    Science | AAAS.
49. ↑ Welcoming the Era of Deep Neuroevolution. 互聯網檔案館嘅歸檔，歸檔日期
    2018年11月17號，.. Uber Engineering.
50. ↑ THE BLACK BOX PROBLEM CLOSES IN ON NEURAL NETWORKS. 互聯網檔案館嘅歸檔，
    歸檔日期2018年6月22號，.. The Next Platform.
51. ↑ Trust, and don't verify: the AI black box problem 互聯網檔案館嘅歸檔，歸
    檔日期2018年7月30號，.. Medium.
52. ↑ Dewdney, A. K. (1 April 1997). Yes, we have no neutrons: an eye-opening
    tour through the twists and turns of bad science. Wiley. p. 82.
53. ↑ Holzinger, Andreas; Plass, Markus; Holzinger, Katharina; Crisan, Gloria
    Cerasela; Pintea, Camelia-M.; Palade, Vasile (3 August 2017). "A glass-box
    interactive machine learning approach for solving NP-hard problems with the
    human-in-the-loop". arXiv:1708.01104
54. ↑ Problem solving, puzzle solving, game playing and deduction:
      □ Russell & Norvig 2003, chpt. 3–9,
      □ Poole, Mackworth & Goebel 1998, chpt. 2,3,7,9,
      □ Luger & Stubblefield 2004, chpt. 3,4,6,8,
      □ Nilsson 1998, chpt. 7–12.
55. ↑ ^55.0 ^55.1 ^55.2 Intractability and efficiency and the combinatorial
    explosion:
      □ Russell & Norvig 2003, pp. 9, 21–22.
56. ↑ ^56.0 ^56.1 Jordan, M. I.; Mitchell, T. M. (16 July 2015). "Machine
    learning: Trends, perspectives, and prospects". Science. 349 (6245):
    255–260.
57. ↑ Uncertain reasoning:
      □ Russell & Norvig 2003, pp. 452–644,
      □ Poole, Mackworth & Goebel 1998, pp. 345–395,
      □ Luger & Stubblefield 2004, pp. 333–381,
      □ Nilsson 1998, chpt. 19.
58. ↑ Dane, E., Baer, M., Pratt, M. G., & Oldham, G. R. (2011). Rational versus
    intuitive problem solving: How thinking "off the beaten path" can stimulate
    creativity. Psychology of Aesthetics, Creativity, and the Arts, 5(1), 3.
59. ↑ Sherin, B. (2006). Common sense clarified: The role of intuitive
    knowledge in physics problem solving. Journal of Research in Science
    Teaching: The Official Journal of the National Association for Research in
    Science Teaching, 43(6), 535-555.
60. ↑ Machine perception:
      □ Russell & Norvig 2003, pp. 537–581, 863–898
      □ Nilsson 1998, ~chpt. 6.
61. ↑ Computer vision:
      □ ACM 1998, I.2.10
      □ Russell & Norvig 2003, pp. 863–898.
      □ Nilsson 1998, chpt. 6.
62. ↑ Speech recognition:
      □ ACM 1998, ~I.2.7
      □ Russell & Norvig 2003, pp. 568–578.
63. ↑ Object recognition:
      □ Russell & Norvig 2003, pp. 885–892.
64. ↑ Planning:
      □ ACM 1998, ~I.2.8,
      □ Russell & Norvig 2003, pp. 375–459,
      □ Poole, Mackworth & Goebel 1998, pp. 281–316,
      □ Luger & Stubblefield 2004, pp. 314–329,
      □ Nilsson 1998, chpt. 10.1–2, 22.
65. ↑ Information value theory:
      □ Russell & Norvig 2003, pp. 600–604.
66. ↑ Multi-agent planning and emergent behavior:
      □ Russell & Norvig 2003, pp. 449–455.
67. ↑ Classical planning:
      □ Russell & Norvig 2003, pp. 375–430,
      □ Poole, Mackworth & Goebel 1998, pp. 281–315,
      □ Luger & Stubblefield 2004, pp. 314–329,
      □ Nilsson 1998, chpt. 10.1–2, 22.
68. ↑ Planning and acting in non-deterministic domains: conditional planning,
    execution monitoring, replanning and continuous planning:
      □ Russell & Norvig 2003, pp. 430–449.
69. ↑ Building the AI of F.E.A.R. with Goal Oriented Action Planning. Gamasutra
    .
70. ↑ Domingos 2015, Chapter 2, Chapter 3.
71. ↑ Hart, P. E.; Nilsson, N. J.; Raphael, B. (1972). "Correction to "A Formal
    Basis for the Heuristic Determination of Minimum Cost Paths"". SIGART
    Newsletter, (37): 28–29.
72. ↑ Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den
    Driessche, G., ... & Dieleman, S. (2016). Mastering the game of Go with
    deep neural networks and tree search. Nature, 529(7587), 484.
73. ↑ Natural language processing:
      □ ACM 1998, I.2.7
      □ Russell & Norvig 2003, pp. 790–831
      □ Poole, Mackworth & Goebel 1998, pp. 91–104
      □ Luger & Stubblefield 2004, pp. 591–632.
74. ↑ "Versatile question answering systems: seeing in synthesis" Archived 1
    February 2016 at the Wayback Machine., Mittal et al., IJIIDS, 5(2),
    119–142, 2011.
75. ↑ Applications of natural language processing, including information
    retrieval (i.e. text mining) and machine translation:
      □ Russell & Norvig 2003, pp. 840–857,
      □ Luger & Stubblefield 2004, pp. 623–630.
76. ↑ U.S. Patent 6618697, Method for rule-based correction of spelling and
    grammar errors.
77. ↑ Implementing spelling correction. Stanford NLP.
78. ↑ Cambria, Erik; White, Bebo (May 2014). "Jumping NLP Curves: A Review of
    Natural Language Processing Research [Review Article]". IEEE Computational
    Intelligence Magazine. 9 (2): 48–57.
79. ↑ Sample, Ian (14 March 2017). "Google's DeepMind makes AI program that can
    learn like a human". the Guardian. Retrieved 26 April 2018.
80. ↑ Pennachin, C.; Goertzel, B. (2007). "Contemporary Approaches to
    Artificial General Intelligence". Artificial General Intelligence.
    Cognitive Technologies. Berlin, Heidelberg: Springer.
81. ↑ Roberts, Jacob (2016). "Thinking Machines: The Search for Artificial
    Intelligence. 互聯網檔案館嘅歸檔，歸檔日期2018年8月19號，.". Distillations.
    Vol. 2 no. 2. pp. 14–23. Retrieved 20 March 2018.
82. ↑ ^82.0 ^82.1 Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu,
    Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller,
    Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie,
    Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan;
    Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015).
    "Human-level control through deep reinforcement learning". Nature. 518
    (7540): 529–533.
83. ↑ Goertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo
    (December 2010). "A world survey of artificial brain projects, Part II:
    Biologically inspired cognitive architectures". Neurocomputing. 74 (1–3):
    30–49.
84. ↑ Davis, Ernest; Marcus, Gary (24 August 2015). "Commonsense reasoning and
    commonsense knowledge in artificial intelligence". Communications of the
    ACM. 58 (9): 92–103.
85. ↑ Winograd, Terry (January 1972). "Understanding natural language".
    Cognitive Psychology. 3 (1): 1–191.
86. ↑ "The superhero of artificial intelligence: can this genius keep it in
    check?". The Guardian. 16 February 2016. Retrieved 26 April 2018.
87. ↑ It's Really Hard to Give AI "Common Sense". Futurism.
88. ↑ "Cultivating Common Sense | DiscoverMagazine.com". Discover Magazine.
89. ↑ Alan Turing discussed the centrality of learning as early as 1950, in his
    classic paper "Computing Machinery and Intelligence".(Turing 1950) In 1956,
    at the original Dartmouth AI summer conference, Ray Solomonoff wrote a
    report on unsupervised probabilistic machine learning: "An Inductive
    Inference Machine".(Solomonoff 1956).
90. ↑ Greg Cashman. (2000). "International Interaction: Stimulus–Response
    Theory and Arms Races". What causes war?: an introduction to theories of
    international conflict. Lexington Books. pp. 160–192.
91. ↑ Kostal, L., Lansky, P., & McDonnell, M. D. (2013). Metabolic cost of
    neuronal information in an empirical stimulus-response model. Biological
    cybernetics, 107(3), 355-365.
92. ↑ Meyer, A. F., Williamson, R. S., Linden, J. F., & Sahani, M. (2017).
    Models of neuronal stimulus-response functions: elaboration, estimation,
    and evaluation. Frontiers in systems neuroscience, 10, 109.
93. ↑ Evolutionary algorithms are the living, breathing AI of the future. VB.
94. ↑ Domingos 2015, Chapter 5.
95. ↑ This is a form of Tom Mitchell's widely quoted definition of machine
    learning: "A computer program is set to learn from an experience E with
    respect to some task T and some performance measure P if its performance on
    T as measured by P improves with experience E."
96. ↑ ^96.0 ^96.1 Learning:
      □ ACM 1998, I.2.6,
      □ Russell & Norvig 2003, pp. 649–788,
      □ Poole, Mackworth & Goebel 1998, pp. 397–438,
      □ Luger & Stubblefield 2004, pp. 385–542,
      □ Nilsson 1998, chpt. 3.3, 10.3, 17.5, 20.
97. ↑ "What is Unsupervised Learning? 互聯網檔案館嘅歸檔，歸檔日期2018年9月30號
    ，.". deepai.org.
98. ↑ Dostál, P., & Pokorný, P. (2009). Cluster analysis and neural network. In
    17th Annual Conference Proceedings on Technical Computing Prague (pp.
    131-57).
99. ↑ Domingos 2015, Chapter 6, Chapter 7.
100. ↑ Coletti, G., & Scozzafava, R. (2004). Conditional probability, fuzzy
    sets, and possibility: a unifying view. Fuzzy sets and systems, 144(1),
    227-249.
101. ↑ Domingos 2015, p. 286.
102. ↑ "Single pixel change fools AI programs". BBC News. 3 November 2017.
103. ↑ "AI Has a Hallucination Problem That's Proving Tough to Fix". WIRED.
    2018
104. ↑ Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. "Explaining
    and harnessing adversarial examples." arXiv preprint arXiv:1412.6572
    (2014).
105. ↑ Knowledge representation:
      □ ACM 1998, I.2.4,
      □ Russell & Norvig 2003, pp. 320–363,
      □ Poole, Mackworth & Goebel 1998, pp. 23–46, 69–81, 169–196, 235–277,
        281–298, 319–345,
      □ Luger & Stubblefield 2004, pp. 227–243,
      □ Nilsson 1998, chpt. 18.
106. ↑ Knowledge engineering:
      □ Russell & Norvig 2003, pp. 260–266,
      □ Poole, Mackworth & Goebel 1998, pp. 199–233,
      □ Nilsson 1998, chpt. ≈17.1–17.4.
107. ↑ Limitations of Knowledge Representation Models. 互聯網檔案館嘅歸檔，歸檔
    日期2018年8月13號，..
108. ↑ Kwasnik, B. H. (1999). The role of classification in knowledge
    representation and discovery.
109. ↑ Representing events and time: Situation calculus, event calculus, fluent
    calculus (including solving the frame problem):
      □ Russell & Norvig 2003, pp. 328–341,
      □ Poole, Mackworth & Goebel 1998, pp. 281–298,
      □ Nilsson 1998, chpt. 18.2
110. ↑ Causal calculus:
      □ Poole, Mackworth & Goebel 1998, pp. 335–337.
111. ↑ Representing knowledge about knowledge: Belief calculus, modal logics:
      □ Russell & Norvig 2003, pp. 341–344,
      □ Poole, Mackworth & Goebel 1998, pp. 275–277
112. ↑ Representing categories and relations: Semantic networks, description
    logics, inheritance (including frames and scripts):
      □ Russell & Norvig 2003, pp. 349–354,
      □ Poole, Mackworth & Goebel 1998, pp. 174–177,
      □ Luger & Stubblefield 2004, pp. 248–258,
      □ Nilsson 1998, chpt. 18.3.
113. ↑ Dreyfus & Dreyfus 1986.
114. ↑ Lufityanto, G., Donkin, C., & Pearson, J. (2016). Measuring intuition:
    nonconscious emotional information boosts decision accuracy and confidence.
    Psychological science, 27(5), 622-634.
115. ↑ Expert knowledge as embodied intuition:
      □ Dreyfus & Dreyfus 1986 (Hubert Dreyfus is a philosopher and critic of
        AI who was among the first to argue that most useful human knowledge
        was encoded sub-symbolically. See Dreyfus' critique of AI)
      □ Gladwell 2005 (Gladwell's Blink is a popular introduction to
        sub-symbolic reasoning and knowledge.)
      □ Hawkins & Blakeslee 2005 (Hawkins argues that sub-symbolic knowledge
        should be the primary focus of AI research.)
116. ↑ Russell & Norvig 2009, p. 1.
117. ↑ N. Aletras; D. Tsarapatsanis; D. Preotiuc-Pietro; V. Lampos (2016).
    "Predicting judicial decisions of the European Court of Human Rights: a
    Natural Language Processing perspective". PeerJ Computer Science.
118. ↑ Russell & Norvig 2009, p. 1.
119. ↑ "The Economist Explains: Why firms are piling into artificial
    intelligence". The Economist. 31 March 2016.
120. ↑ "The Next Generation 1996 Lexicon A to Z: NPC (Nonplayer Character)".
    Next Generation. No. 15. Imagine Media. March 1996. p. 38.
121. ↑ Yannakakis, G. N., & Hallam, J. (2007). Towards optimizing entertainment
    in computer games. Applied Artificial Intelligence, 21(10), 933-971.
122. ↑ Yannakakis, Geogios N (2012). "Game AI revisited" (PDF). Proceedings of
    the 9th Conference on Computing Frontiers: 285–292.
123. ↑ Stanley, K. O., Bryant, B. D., & Miikkulainen, R. (2005). Evolving
    neural network agents in the NERO video game. Proceedings of the IEEE,
    182-189.
124. ↑ Pac-Man 互聯網檔案館嘅歸檔，歸檔日期2021年2月11號，..
125. ↑ Bogost, Ian (March 2017). ""Artificial Intelligence" Has Become
    Meaningless". Retrieved 22 July 2017.
126. ↑ Lu, F., Yamamoto, K., Nomura, L. H., Mizuno, S., Lee, Y., & Thawonmas,
    R. (2013, October). Fighting game artificial intelligence competition
    platform. In 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)
    (pp. 320-323). IEEE.
127. ↑ "33 Corporations Working On Autonomous Vehicles". CB Insights. N.p., 11
    August 2016.
128. ↑ West, Darrell M. "Moving forward: Self-driving vehicles in China,
    Europe, Japan, Korea, and the United States". Center for Technology
    Innovation at Brookings. N.p., September 2016. 12 November 2016.
129. ↑ Teaching AI to Predict Pedestrian Behavior. Machine Design.
130. ↑ McFarland, Matt. "Google's artificial intelligence breakthrough may have
    a huge impact on self-driving cars and much more". The Washington Post 25
    February 2015. Infotrac Newsstand. 24 October 2016.
131. ↑ ArXiv, E. T. (26 October 2015). Why Self-Driving Cars Must Be Programmed
    to Kill. Retrieved 17 November 2017.
132. ↑ "10 Promising AI Applications in Health Care 互聯網檔案館嘅歸檔，歸檔日
    期2018年12月15號，.". Harvard Business Review. 2018-05-10.
133. ↑ Dina Bass (20 September 2016). "Microsoft Develops AI to Help Cancer
    Doctors Find the Right Treatments". Bloomberg.
134. ↑ ^134.0 ^134.1 Gallagher, James (26 January 2017). "Artificial
    intelligence 'as good as cancer doctors'". BBC News.
135. ↑ ^135.0 ^135.1 Neural Style Transfer: Creating Art with Deep Learning
    using tf.keras and eager execution 互聯網檔案館嘅歸檔，歸檔日期2019年1月6號
    ，.. Medium.
136. ↑ "CTO Corner: Artificial Intelligence Use in Financial Services –
    Financial Services Roundtable^[失咗效嘅鏈]". Financial Services Roundtable.
    2 April 2015.
137. ↑ Matz, S. C., et al. "Psychological targeting as an effective approach to
    digital mass persuasion." Proceedings of the National Academy of Sciences
    (2017): 201710966.
138. ↑ What Frankenstein's creature can really tell us about AI.
139. ↑ Buttazzo, G. (July 2001). "Artificial consciousness: Utopia or real
    possibility?". Computer (IEEE). 34 (7): 24–30.
140. ↑ Galvan, Jill (1 January 1997). "Entering the Posthuman Collective in
    Philip K. Dick's "Do Androids Dream of Electric Sheep?"". Science Fiction
    Studies. 24 (3): 413–429.
141. ↑ Anderson, Susan Leigh. "Asimov's "three laws of robotics" and machine
    metaethics." AI & Society 22.4 (2008): 477–493.
142. ↑ McCauley, Lee (2007). "AI armageddon and the three laws of robotics".
    Ethics and Information Technology. 9 (2): 153–164.
143. ↑ Haugeland, J. (Ed.). (1997). Mind design II: philosophy, psychology,
    artificial intelligence. MIT press.
144. ↑ Russell & Norvig 2003，p. 947, define the philosophy of AI as consisting
    of the first two questions, and the additional question of the ethics of
    artificial intelligence. Fearn 2007，p. 55, writes "In the current
    literature, philosophy has two chief roles: to determine whether or not
    such machines would be conscious, and, second, to predict whether or not
    such machines are possible." The last question bears on the first two.
145. ↑ ^145.0 ^145.1 Saygin, A. P., Cicekli, I., & Akman, V. (2000). Turing
    test: 50 years later. Minds and machines, 10(4), 463-518.
146. ↑ French, R. M. (1990). Subcognition and the limits of the Turing test.
    Mind, 99(393), 53-65.
147. ↑ Russell, Stuart J.; Norvig, Peter (2010), Artificial Intelligence: A
    Modern Approach (3rd ed.), Upper Saddle River, NJ: Prentice Hall, p. 2 - 3.
148. ↑ Schweizer, P. (1998), The Truly Total Turing Test, Minds and Machines,
    8, pp. 263–272.

拎[編輯]

  • 研學論壇－關於人工智能、模式識別、科學交流嘅學術論壇。
  • ChinaAI.org －中國人工智能網－人工智能、模式識別、數字圖像處理。
  • AI Depot － community discussion, news, and articles.
  • Loebner Prize website.
  • GameAI －關於電子遊戲方面嘅 AI 資源。
  • Kurzweil CyberArt Technologies －關於用人工智能整藝術嘅網站，有人工智能畫畫
    程式「AARON」。
  • 關於人工智能，專家系統 prolog 語言全介紹嘅 wiki 網站。
  • 中華民國人工智慧學會－為咗促進中華民國台灣地區人工智能同相關領域嘅研究、發
    展、應用同交流為宗旨嘅民間組織。
  • MostAI －關於人工智能網站，AI Fans 交流平台。

                                       • 睇
                                       • 傾
                                       • 改

                                 人工智能（AI）
研究「點樣人工噉創造智能體」嘅學問
基本 智能體 · 智能（超智能） · 演算法同電腦程式編寫 · 
概念 複雜 · 基於規則嘅系統 · AI 完全 · AI 詞彙表
運算 符號 AI · 貝葉斯網絡 · 神經網絡 · 進化演算法（遺傳
方法 演算法） · 解釋得嘅 AI
     自動推理 · 行動選擇同自動計劃 · 運動規劃 · 群體智
     能 · 情感運算同性格運算 · 瓣瓣掂玩遊戲

重要 機械感知（電腦視覺 · 邊緣檢測 · 手寫辨識 · 物體檢
問題 測） · 機械學習（知識表示 · 深度學習）
     
     NLP（語音識別 · 機械翻譯） · 運算創意 · 強 AI · 協
     作智能 · 自動資料收集
                                                         [180px-Anatomy-1751201]
 AI  遊戲 AI · 專家系統 · 自駕車 · 傾偈機械人 · 認人樣
應用 系統 · 虛擬助理 · 聰明玩具 · 智能感應器 · 環境智能
 AI  圖靈測試 · 中文房間 · AI 箱 · AI 叛變 · 友好嘅 AI
哲學 · 機械人三定律
 AI  圖靈 · AI 低谷 · DeepMind · OpenAI · ChatGPT
 史
     認知  動物行為學同認知心理學 · 神經科學（運算神經
相關 科學  科學） · 語言學 · 人機互動
領域 電腦科學（軟件工程） · 應用數學（統計學） · 控制理
     論 · 機械人學 · 經濟學

拉雜 認知 · 意識 · 智能放大 · 機械人（人形機械人） · 元
相關 宇宙 · Cyberpunk · 科技奇異點 · 通用心理測量
AI 類

                                       • 睇
                                       • 傾
                                       • 改

                                    電腦科學
研究運算嘅科學工程領域
重要 運算 · I/O · 電腦 · 運算邏輯 · 數論 · 二進制 · 數學邏
概念 輯 · 離散數學（圖論） · 抽象化 · 電腦科學詞彙表
     運算理 自動機理論 · 可運算度理論 · 運算複雜度理論 · 圖
電腦   論   靈機 · 量子運算
理論 資訊理論（資訊 · 訊號 · 資訊熵 · 編碼理論） · 資料類型
     ‎同數據結構 · 系統資源 · 演算法（分析） · 形式化方法

電腦 電腦架構（邏輯門 · 指令集架構 · 微架構 · 多元處理 · 作
系統 業系統） · 並行、平行同分散運算 · 性能 · 超級電腦
     電腦網 網絡傳輸協議 · 網絡拓樸 · 數據傳輸 · 互聯網 · 
電腦   絡   網頁設計
通訊 電腦保 網絡保安 · 漏洞 · 公共漏洞同暴露 · 網絡攻擊 · 
       安   電腦病毒 · 密碼學

程式 程式語言（程式語言理論 · 低級同高級程式語言 · 控制流程
編寫 ） · 程式執行 · 編譯器 · 程式編寫範式
     數碼  電腦圖像（2D · 3D · 電腦動畫 · 資訊可視化 · VR ·  [150px-Binario_cro]
     藝術  AR · 電腦圖像學） · 電腦音樂
     軟件  電腦軟件 · 軟件開發 · 軟件需求 · 軟件項目管理 · 
     工程  電子遊戲製作
電腦       用家 · 易用度 · 用家介面（設計 · 圖像 · 命令行 ·
應用  HCI  腦機）

     其他  資訊系統（數據庫） · 科學運算（電腦模擬） · 運算
     應用  數論 · 電腦代數

 AI  AI 哲學 · 知識表示 · 自動計劃 · 電腦視覺 · NLP · 機械
     學習（ANN · 監督式學習 · 非監督式學習 · 強化學習）
     　工程 電子工程（電訊） · 電腦工程 · 資訊科技 · 機械人
相關   學   學 · 機電工程
領域 邏輯學 · 數學（統計學 · 博弈論） · 認知科學 · 模控學 ·
     資訊科學 · 系統科學

電腦科學類

                                • 睇
                                • 傾
                                • 改

                           科學嘅各領域
科學哲學 · 科學教育 · 科學文獻 · 科學史
           • 邏輯
           • 數學（應用數學 · 統計學）
形式科學   • 理論電腦科學
           • 系統科學

                    • 物理科學（物理學 · 化學 · 地球科學 · 天文學）
         自然科學   • 生命科學（生物學）

                    • 語言學
                    • 人類學
         認知科學   • 神經科學
                    • 心理學
 純科學
                    • 地理學
                    • 考古學
         社會科學   • 社會學
                    • 經濟學
                    • 資訊科學
                    • 政治學

           • 計量學
           • 農學同農業科學
           • 工程學
應用科學   • 醫學
           • 運動科學
           • 法證科學
           • 電腦科學（AI）

           • 精密科學
           • 硬同軟科學
           • 跨學科
拉雜相關   • 假科學
           • 科技同科幻
           • 科學論
           • 開放科學

睇埋
知識論（經驗主義） · 商學 · 人文學 · 學術同學術出版

                                     • 睇
                                     • 傾
                                     • 改

                                   工程學
架生 · 科技 · 發明 · 工程師 · 工程學詞彙表
           • 設計過程（工程圖）
           • 工程數學
           • 工程物理（工程力學）
方法基礎   • 工程經濟
           • 運算工程學
           • 倫理

           • 土力
           • 水利
           • 結構
           • 建築
土木工程   • 建造
           • 交通
           • 環境
           • 地震
           • 礦業

                    • 汽車
                    • 鐵路
         機械工程   • 航海（船舶）
                    • 航空太空（航空 · 太空）
                    • 熱力

                    • 電力
                    • 電子（無線電 · 電訊）
機電領域 電機工程   • 訊號處理
                    • 電腦
                    • 微波

                    • IT（資訊 · 資訊系統 · 軟件 · 保安）
           其他     • 電動機械學
                    • 機械電子工程
                    • 機械人學

                     • 生化
                     • 分子
         化學工程    • 化學反應
                     • 石油

                     • 材料物理學
                     • 材料化學                           [150px-Opfindelser]
         材料科學    • 陶瓷
                     • 冶金學
                     • 聚合物科學

                     • 能源
                     • 農業
拉雜領域             • 食品
                     • 防火
         按用途分    • 工業
                     • 軍事
                     • 衛生
                     • 人因

           • 聲音
           • 核子
           • 光學
           • 光子學
           • 生物（基因 · 生物醫學）
           • 納米科技

           • 系統（複雜系統 · 動態系統）
系統概念   • 控制（控制理論）
           • 系統設計

           • Archi
           • 城市設計（城市規劃）
           • 廢物管理
相關領域   • 電腦科學
           • 人工智能
           • 製造業
           • 市場學

           • 科學（應用數學 · 物理學）
           • 科幻
           • 工藝
拉雜相關   • 自動化技術
           • 產品設計
           • 科技研究
           • 技術決定論

工程學類

*
由「https://zh-yue.wikipedia.org/w/index.php?title=人工智能&oldid=2060002」收
屬於2類：

  • Pages using div col with small parameter
  • 人工智能

屬於5隱類：

  • Webarchive模wayback連結
  • 有失效鏈嘅頁
  • 有英文嘅文章
  • 有拉丁文嘅文章
  • 用緊ISBN魔術鏈嘅版

  • 呢版上次改係2023年12月8號 (禮拜五) 04:47 嘅事。
  • 呢度嘅所有文字係根據Creative Commons Attribution-ShareAlike 牌照 4.0 嘅條款
    發佈；可能會有附加嘅條款。利用呢個網站，你同意利用條款同埋私隱政策。
    Wikipedia® 係Wikimedia Foundation, Inc. 嘅註冊商標，一個非牟利機構。

  • 私隱政策
  • 關於維基百科
  • 免責聲明
  • 行為準則
  • 開發人員
  • 統計
  • Cookie聲明
  • 手提版

  • Wikimedia Foundation
  • Powered by MediaWiki

  • 切換限制內容闊度

