   #alternate Modifier WikipÃ©dia (fr) Flux Atom de WikipÃ©dia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails thÃ©matiques
     * Article au hasard
     * Contact

   Contribuer
     * DÃ©buter sur WikipÃ©dia
     * Aide
     * CommunautÃ©
     * Modifications rÃ©centes
     * Faire un don

   Langues
   Sur cette version linguistique de WikipÃ©dia, les liens interlangues
   sont placÃ©s en haut Ã  droite du titre de lâ€™article.
   Aller en haut.
   WikipÃ©dia l'encyclopÃ©die libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * CrÃ©er un compte
     * Se connecter

   [ ] Outils personnels
     * CrÃ©er un compte
     * Se connecter

   Pages pour les contributeurs dÃ©connectÃ©s en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
     * DÃ©but
     * 1Terminologie

     2Histoire

     3CaractÃ©ristiques
   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section CaractÃ©ristiques
     * 3.1Sentience

     3.2Explosion d'intelligence



   4FaisabilitÃ©



   5BÃ©nÃ©fices



   6Risques

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Risques
     * 6.1Perte de contrÃ´le



   6.2ChÃ´mage de masse



   6.3DÃ©sinformation et manipulation



   6.4Cyberattaques et prolifÃ©ration



   7RÃ©fÃ©rences



   8Voir aussi

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Voir aussi
     * 8.1Articles connexes



   8.2Liens externes



   8.3Bibliographie

   [ ] Basculer la table des matiÃ¨res

Intelligence artificielle gÃ©nÃ©rale

   [ ] 35 langues
     * Afrikaans
     * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
     * Bosanski
     * CatalÃ
     * Ú©ÙˆØ±Ø¯ÛŒ
     * ÄŒeÅ¡tina
     * Deutsch
     * English
     * EspaÃ±ol
     * Euskara
     * ÙØ§Ø±Ø³ÛŒ
     * Suomi
     * ×¢×‘×¨×™×ª
     * Hrvatski
     * Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶
     * Bahasa Indonesia
     * Italiano
     * æ—¥æœ¬èª
     * í•œêµ­ì–´
     * Nederlands
     * à¬“à¬¡à¬¼à¬¿à¬†
     * Polski
     * Ù¾ÚšØªÙˆ
     * PortuguÃªs
     * Runa Simi
     * RomÃ¢nÄƒ
     * Ğ ÑƒÑÑĞºĞ¸Ğ¹
     * SlovenÅ¡Äina
     * Svenska
     * à¹„à¸—à¸¢
     * TÃ¼rkÃ§e
     * Ø¦Û‡ÙŠØºÛ‡Ø±Ú†Û• / Uyghurche
     * Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°
     * ä¸­æ–‡
     * ç²µèª

   Modifier les liens

     * Article
     * Discussion

   [ ] franÃ§ais

     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   [ ] Outils
   Outils
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Actions
     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   GÃ©nÃ©ral
     * Pages liÃ©es
     * Suivi des pages liÃ©es
     * TÃ©lÃ©verser un fichier
     * Pages spÃ©ciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * Ã‰lÃ©ment Wikidata

   Imprimerâ€¯/â€¯exporter
     * CrÃ©er un livre
     * TÃ©lÃ©charger comme PDF
     * Version imprimable

   Un article de WikipÃ©dia, l'encyclopÃ©die libre.
   Page dâ€™aide sur lâ€™homonymie

   Ne doit pas Ãªtre confondu avec Intelligence artificielle gÃ©nÃ©rative.
   [220px-Artificial_intelligence_prompt_completion_by_dalle_mini.jpg]
   Image gÃ©nÃ©rÃ©e en juin 2022 par le modÃ¨le de gÃ©nÃ©ration d'images
   DALL-E-mini, Ã  partir de la consigne Â« Intelligence artificielle Â».

   Une intelligence artificielle gÃ©nÃ©rale (IAG) est une intelligence
   artificielle capable d'effectuer ou d'apprendre pratiquement n'importe
   quelle tÃ¢che cognitive propre aux humains ou autres animaux^[1]^,^[2].
   La crÃ©ation d'intelligences artificielles gÃ©nÃ©rales est un des
   principaux objectifs de certaines entreprises comme OpenAI, DeepMind et
   Anthropic. C'est aussi un thÃ¨me majeur de la science-fiction et de la
   futurologie. MÃªme si GPT-4 a Ã©tÃ© dÃ©crit comme ayant des Â« Ã©tincelles
   d'intelligence artificielle gÃ©nÃ©rale Â», il n'existe pas en 2023 d'IA
   consensuellement considÃ©rÃ©e comme gÃ©nÃ©rale^[3].

   Bien que l'intelligence artificielle gÃ©nÃ©rale puisse Ãªtre trÃ¨s utile
   dans de nombreux domaines, des Ã©tudes en cours Ã©valuent les risques
   potentiels de cette technologie en voie de dÃ©veloppement^[4]^,^[5].
   Notamment les risques de dÃ©sinformation et de chÃ´mage de masse. Selon
   des experts en IA comme Stuart Russell^[6], Yoshua Bengio^[7] ou
   Geoffrey Hinton^[8] et d'autres chercheurs en IA^[9], une perte de
   contrÃ´le pourrait Ã©galement causer des risques existentiels tels que la
   fin de l'humanitÃ©^[9].

Terminologie[modifier | modifier le code]

   Selon la plupart des spÃ©cialistes, l'IAG (Artificial general
   intelligence ou AGI en anglais), ou IA de niveau humain, se rÃ©fÃ¨re Ã  la
   capacitÃ© d'une machine autonome Ã  effectuer lâ€™ensemble des tÃ¢ches
   intellectuelles qu'un Ãªtre humain peut effectuer^[1]. Cette dÃ©finition
   assez restrictive fait qu'une IA peut gÃ©nÃ©rer du texte de haute qualitÃ©
   et Ãªtre bien plus rapide que l'humain sans Ãªtre qualifiÃ©e de
   Â« gÃ©nÃ©rale Â», s'il reste des tÃ¢ches qu'elle n'effectue pas aussi bien
   que l'humain. OpenAI dÃ©finit plutÃ´t l'IAG comme un systÃ¨me hautement
   autonome capable de surpasser l'humain dans la plupart des tÃ¢ches ayant
   un intÃ©rÃªt Ã©conomique^[10].

   Un systÃ¨me expert, ou IA Â« Ã©troite Â» est un systÃ¨me informatique
   potentiellement trÃ¨s compÃ©tent, mais qui n'opÃ¨re que dans un contexte
   restreint, souvent focalisÃ© sur une tÃ¢che prÃ©cise^[11].

   Le terme d'IA forte fait quant Ã  lui plus souvent intervenir une notion
   philosophique de conscience, ce qui fait que les capacitÃ©s de l'IA ne
   suffisent pas Ã  dire si elle est Â« forte Â». Une IA peut donc Ãªtre
   parfois qualifiÃ©e de Â« faible Â» dans ce sens, indÃ©pendamment de ses
   compÃ©tences, si elle n'est pas Â« consciente Â». Ces notions font
   rÃ©fÃ©rence Ã  l'hypothÃ¨se de l'IA forte et de l'IA faible dans
   l'expÃ©rience de pensÃ©e de la chambre chinoise^[12].

   Le terme de superintelligence artificielle dÃ©crit une IA aux capacitÃ©s
   intellectuelles bien supÃ©rieures Ã  celles de l'humain dans pratiquement
   tous les domaines^[13]. Les experts affichent une large incertitude sur
   le temps que cela prendrait de passer d'une IAG Ã  une superintelligence
   artificielle, les estimations pouvant aller de moins d'une heure Ã
   plusieurs dÃ©cennies, en supposant que ce soit possible^[14].

   Cela dit, ces termes peuvent avoir des dÃ©finitions diffÃ©rentes, et ces
   dÃ©finitions sont suffisamment vagues pour qu'il puisse parfois Ãªtre
   difficile de catÃ©goriser une IA.

Histoire[modifier | modifier le code]

   Dans les annÃ©es 1950, la premiÃ¨re gÃ©nÃ©ration de chercheurs en
   intelligence artificielle Ã©tait convaincue que l'IAG est possible et
   existerait au bout de quelques dÃ©cennies. Le pionnier Herbert Simon a
   Ã©crit en 1965 : Â« les machines seront capables, dans moins de 20 ans,
   d'accomplir n'importe quelle tÃ¢che qu'un homme peut accomplir Â»^[15].

   Cependant, dans les annÃ©es 1970, il devint Ã©vident qu'ils avaient
   grossiÃ¨rement sous-estimÃ© la difficultÃ© du projet. Les fonds
   d'investissement devinrent sceptiques de l'IAG, et mirent davantage de
   pression sur les chercheurs pour obtenir des applications plus
   concrÃ¨tes^[16]. AprÃ¨s un bref regain d'intÃ©rÃªt dans les annÃ©es 1980, la
   confiance gÃ©nÃ©rale dans l'IA rechute. Jusqu'aux annÃ©es 1990, les
   chercheurs en IA Ã©taient rÃ©putÃ©s pour faire des promesses vaines, et
   devinrent rÃ©ticents Ã  faire la moindre prÃ©diction^[17].

   Dans les annÃ©es 1990 et au dÃ©but du XXI^e siÃ¨cle, la recherche en IA a
   atteint un certain succÃ¨s commercial et une respectabilitÃ© acadÃ©mique
   en se concentrant sur des applications commerciales ou des
   sous-problÃ¨mes auxquels l'IA peut fournir des rÃ©sultats vÃ©rifiables.
   Notamment via des rÃ©seaux de neurones artificiels ou des techniques
   d'apprentissage statistique. Ces techniques sont maintenant largement
   appliquÃ©es dans l'industrie^[18].

   Le terme d'Â« intelligence artificielle gÃ©nÃ©rale Â» a Ã©tÃ© utilisÃ© dÃ¨s
   1997 par Mark Gubrud dans une discussion sur les implications de
   l'automatisation de la production et des opÃ©rations militaires^[19].

   En 2016, DeepMind a conÃ§u AlphaGo, un programme d'apprentissage par
   renforcement qui s'est avÃ©rÃ© capable de vaincre le champion du monde de
   Go Lee Sedol. Ce programme nÃ©cessitait cependant une connaissance
   spÃ©cifique du jeu de Go et des donnÃ©es humaines, ainsi que des rÃ¨gles
   du jeu. En 2020, Google DeepMind crÃ©e MuZero, qui n'a plus ces
   limitations et peut Ãªtre entraÃ®nÃ© sur d'autres types de jeux comme les
   jeux Atari^[20]. En 2022, Google DeepMind dÃ©veloppe Gato, un systÃ¨me
   d'IA gÃ©nÃ©raliste capable d'exÃ©cuter plus de 600 tÃ¢ches^[21].

   En 2023, Microsoft Research a publiÃ© une Ã©tude sur une version prÃ©coce
   de GPT-4, affirmant que GPT-4 manifestait une intelligence plus
   gÃ©nÃ©rale que les prÃ©cÃ©dents modÃ¨les d'IA, et affichait des performances
   de niveau humain dans de multiples domaines tels que les mathÃ©matiques,
   la programmation et le judiciaire^[22]. Une autre Ã©tude en 2023
   rapporte que GPT-4 surpasse 99 % des humains aux tests de crÃ©ativitÃ© de
   Torrance^[23].

CaractÃ©ristiques[modifier | modifier le code]

   Une IAG doit notamment pouvoir :
     * Planifier
     * Comprendre des concepts abstraits
     * RÃ©soudre des problÃ¨mes
     * Prendre des dÃ©cisions en tenant compte de l'incertitude
     * Apprendre
     * Communiquer en langage naturel
     * Faire preuve de crÃ©ativitÃ©

Sentience[modifier | modifier le code]

   Article dÃ©taillÃ© : Conscience artificielle.

   La sentience n'est en gÃ©nÃ©ral pas considÃ©rÃ©e comme un critÃ¨re
   nÃ©cessaire pour l'IAG. Une machine pourrait probablement en effet Ãªtre
   trÃ¨s compÃ©tente pour accomplir des objectifs sans nÃ©cessairement Ãªtre
   sentiente^[24].

   La question de savoir si les machines peuvent en principe Ãªtre
   sentientes est controversÃ©e^[25]. Il n'existe actuellement pas de
   mesure fiable de la sentience, ni mÃªme de thÃ©orie qui fasse largement
   consensus^[26]. Selon les fonctionnalistes, la sentience est causÃ©e par
   certains types de traitement de l'information. Il n'y a dans ce cas pas
   de barriÃ¨re thÃ©orique au fait que la sentience puisse se manifester sur
   un support autre que biologique^[27]. Le fait qu'une machine soit
   sentiente n'implique pas nÃ©cessairement qu'elle soit plus puissante ou
   plus dangereuse, mais plutÃ´t qu'elle pourrait avoir une dimension
   morale. Si c'est le cas, il pourrait, de mÃªme que pour les animaux,
   Ãªtre pertinent d'accorder des droits Ã  ces IAs ou de se soucier de leur
   bien-Ãªtre^[28].

Explosion d'intelligence[modifier | modifier le code]

   C'est lÃ  aussi controversÃ©, mais une IAG serait en principe capable de
   remplacer le poste de chercheur en intelligence artificielle.
   Cependant, les machines sont en gÃ©nÃ©ral plus rapides que le cerveau
   humain, certains chercheurs estiment donc qu'il pourrait survenir une
   Â« explosion d'intelligence Â», faisant rapidement de l'IAG une
   superintelligence.

   Le concept n'est pas nouveau. En 1965, Irving John Good Ã©crivait^[29] :

     Â« Supposons une machine ultra-intelligente dÃ©finie comme une machine
     pouvant surpasser toutes les activitÃ©s intellectuelles de n'importe
     quel homme quelle que soit son intelligence. La conception de telles
     machines Ã©tant lâ€™une de ces activitÃ©s intellectuelles, une machine
     ultra-intelligente pourrait concevoir des machines encore
     meilleures ; il y aurait alors incontestablement une Â« explosion
     dâ€™intelligence Â», et lâ€™intelligence humaine serait trÃ¨s vite laissÃ©e
     loin derriÃ¨re. Ainsi, lâ€™invention de la premiÃ¨re machine
     ultra-intelligente est la derniÃ¨re invention que lâ€™humanitÃ© ait
     besoin de rÃ©aliser, Ã  condition que la machine soit suffisamment
     docile pour nous dire comment la garder sous contrÃ´le. Â»

   â€” Irving John Good, Speculations Concerning the First Ultraintelligent
   Machine

   Ce scÃ©nario est dÃ©battu. D'autres pensent que cette amÃ©lioration
   rÃ©cursive se ferait de faÃ§on plus dÃ©centralisÃ©e ou progressive,
   s'Ã©talant sur des annÃ©es voire des dÃ©cennies. L'Ã©conomiste Robin Hanson
   estime par exemple que pour dÃ©clencher une explosion d'intelligence,
   une machine devrait avoir une meilleure capacitÃ© d'innovation que le
   reste du monde combinÃ©, ce qui lui semble peu plausible^[30].

FaisabilitÃ©[modifier | modifier le code]

   Cette capacitÃ© nÃ©cessite notamment une gÃ©nÃ©ralisation et une
   abstraction de l'apprentissage sur un ensemble de fonctions cognitives.
   Pour l'instant, le transfert autonome et agile de l'apprentissage d'un
   domaine Ã  un autre n'en est qu'Ã  ses balbutiements^[31].

   LÃ  oÃ¹ l'approche de Google DeepMind avec AlphaGo, Muzero et Gato
   consistait Ã  partir de systÃ¨mes d'apprentissage par renforcement
   puissants mais spÃ©cifiques et Ã  tenter de les gÃ©nÃ©raliser Ã  des
   situations de plus en plus complexes (avec un certain
   succÃ¨s)^[20]^,^[32], les grands modÃ¨les de langage ont rÃ©cemment
   fournit une approche diffÃ©rente. Initialement, les modÃ¨les d'IA
   disposent d'un grand nombre de paramÃ¨tres ajustables (par exemple, 175
   milliards dans le cas de GPT-3^[33]). La premiÃ¨re Ã©tape de
   l'entraÃ®nement des grands modÃ¨les de langage consiste Ã  prÃ©dire, pour
   un trÃ¨s grand nombre de textes issus d'internet, le mot suivant (ou
   plus exactement le token suivant, un token Ã©tant une sÃ©quence
   d'octets). Au fur et Ã  mesure de cet apprentissage, le modÃ¨le ajuste
   ses paramÃ¨tres internes. Cette tÃ¢che Ã©tonnamment simple, rÃ©pÃ©tÃ©e un
   grand nombre de fois, permet au modÃ¨le de langage d'acquÃ©rir une
   connaissance non seulement du langage, mais aussi de nombreux autres
   domaines tels que l'arithmÃ©tique, le raisonnement, la physique,
   l'humour, la traduction^[34]...

   Une procÃ©dure d'entraÃ®nement relativement simple est ainsi capable de
   faire Ã©merger des connaissances et des capacitÃ©s complexes. L'IAG
   pourrait peut-Ãªtre ainsi Ãªtre principalement une question de quantitÃ©
   de ressources consacrÃ©es Ã  l'entraÃ®nement. Il semble en effet que pour
   un modÃ¨le de taille suffisante, les performances augmentent
   rÃ©guliÃ¨rement avec^[35] :
     * La quantitÃ© de donnÃ©es ayant servi Ã  entraÃ®ner du modÃ¨le.
     * Les capacitÃ©s de calcul ayant servi Ã  entraÃ®ner le modÃ¨le, ou
       autrement dit le nombre d'itÃ©rations.

   Il y a quelques annÃ©es, l'intelligence artificielle gÃ©nÃ©rale Ã©tait
   perÃ§u comme un sujet spÃ©culatif et lointain. En 2015, Le vice-prÃ©sident
   de Baidu, Andrew Ng, que s'inquiÃ©ter des risques existentiels liÃ©s Ã
   l'IAG est Â« comme s'inquiÃ©ter de la surpopulation sur Mars alors que
   nous n'avons mÃªme pas encore mis le pied sur la planÃ¨te Â»^[36].

   Les spectaculaires progrÃ¨s rÃ©cents suggÃ¨rent cependant que l'IAG soit
   moins difficile Ã  rÃ©aliser que prÃ©vu^[37]. Selon l'informaticien
   Geoffrey Hinton^[38] :

     Â« L'idÃ©e que Ã§a pourrait devenir plus intelligent que l'humain â€”
     quelques gens y croyaient, [...]. Mais la plupart pensaient que ce
     Ã§a n'arriverait pas avant longtemps. Et je pensais que Ã§a
     n'arriverait pas avant longtemps. Je pensais que Ã§a prendrait entre
     30 et 50 ans. Ã‰videmment, ce n'est plus ce que je pense Â»

   â€” Geoffrey Hinton

   Certains estiment que GPT-5, le successeur Ã  venir de
   GPT-4^[39]^,^[40], sera probablement une intelligence artificielle
   gÃ©nÃ©rale^[41]. La dÃ©finition d'intelligence artificielle gÃ©nÃ©rale reste
   cependant suffisamment floue pour qu'il puisse Ãªtre difficile ou
   subjectif d'Ã©valuer si un modÃ¨le est une IAG.

BÃ©nÃ©fices[modifier | modifier le code]

   L'IAG pourrait avoir des applications trÃ¨s variÃ©es. Si elle est
   orientÃ©e vers ce but, l'IAG, et plus encore la superintelligence
   artificielle, pourrait aider Ã  combattre divers problÃ¨mes dans le monde
   tels la faim, la pauvretÃ© et les problÃ¨mes de santÃ©^[42].

   L'IAG pourrait augmenter la productivitÃ© et l'efficacitÃ© dans la
   plupart des travaux. Par exemple, dans le secteur de la santÃ©, l'IAG
   pourrait accÃ©lÃ©rer la recherche, notamment contre le cancer^[43]. Elle
   pourrait s'occuper des personnes Ã¢gÃ©es^[44], ou encore dÃ©mocratiser
   l'accÃ¨s Ã  des diagnostiques mÃ©dicaux rapides et de qualitÃ©^[45]. De
   mÃªme dans le secteur de l'Ã©ducation, oÃ¹ elle pourrait offrir une
   Ã©ducation ludique, personnalisÃ©e et Ã  faible coÃ»t^[44]. Pour
   pratiquement n'importe quel travail bÃ©nÃ©ficiant Ã  la sociÃ©tÃ© s'il est
   bien accompli, il serait probablement tÃ´t ou tard prÃ©fÃ©rable de le
   laisser Ã  une IAG. Le besoin de travailler pour subsister pourrait
   devenir obsolÃ¨te, si les richesses produites sont adÃ©quatement
   redistribuÃ©es^[46]^,^[44]. Cela pose donc aussi la question de la place
   de l'humain dans une sociÃ©tÃ© radicalement automatisÃ©e.

   L'IAG pourrait aussi aider Ã  prendre des dÃ©cisions rationnelles,
   anticiper et empÃªcher des catastrophes. Si une IAG avait pour objectif
   premier d'empÃªcher des catastrophes planÃ©taires telles que l'extinction
   de l'humanitÃ© (ce qui pourrait Ãªtre difficile si l'HypothÃ¨se du Monde
   VulnÃ©rable s'avÃ¨re fondÃ©e^[47]), elle pourrait ainsi prendre des
   mesures rÃ©duisant drastiquement les risques^[48] tout en minimisant
   l'impact de ces mesures sur notre qualitÃ© de vie. Elle pourrait aussi
   aider Ã  tirer les bÃ©nÃ©fices de technologies potentiellement
   catastrophiques telles que les nanotechnologies ou l'ingÃ©nierie
   climatique tout en Ã©vitant les risques associÃ©s^[48].

Risques[modifier | modifier le code]

   Les risques associÃ©s Ã  l'IAG sont divers et peuvent provenir de l'IAG
   elle-mÃªme, ou du comportement humain face Ã  celle-ci^[49]. Certains
   risques sont dÃ©jÃ  un problÃ¨me aujourd'hui, comme le chÃ´mage, la
   dÃ©sinformation ou les armes lÃ©tales autonomes, mais pourraient Ãªtre
   exacerbÃ©s par l'IAG. En outre, la capacitÃ© de la sociÃ©tÃ© humaine Ã
   prÃ©dire et Ã  contrÃ´ler le dÃ©veloppement de l'IAG, ainsi que sa capacitÃ©
   Ã  faire face aux risques potentiels font l'objet d'Ã©tudes^[49].

   Voici une liste non-exhaustive de risques importants.

Perte de contrÃ´le[modifier | modifier le code]

   Un risque particuliÃ¨rement dÃ©battu est celui d'une catastrophe
   existentielle liÃ©e l'IAG. Cela implique en gÃ©nÃ©ral une perte
   irrÃ©versible de contrÃ´le d'une IAG qui aurait un objectif diffÃ©rent de
   celui des humains^[50].

   Le sort de l'humanitÃ© face Ã  l'IAG a parfois Ã©tÃ© comparÃ© Ã  celui du
   gorille, menacÃ© par les activitÃ©s humaines. Le supplÃ©ment
   d'intelligence de l'humanitÃ© l'a mise dans une position de domination,
   et le gorille est devenu vulnÃ©rable de faÃ§ons qu'il n'aurait pas pu
   anticiper. Le gorille est devenu une espÃ¨ce menacÃ©e, pas par
   malveillance, mais simplement comme un dommage collatÃ©ral des activitÃ©s
   humaines^[51].

   Le fait d'assigner les objectifs souhaitÃ©s Ã  des intelligences
   artificielles gÃ©nÃ©rales est encore un sujet actif de recherche, baptisÃ©
   le problÃ¨me de l'alignement. Selon OpenAI, l'IAG pose un risque
   existentiel^[52]^,^[53], et Â« rÃ©soudre le problÃ¨me de l'alignement des
   IAG pourrait s'avÃ©rer si difficile que cela nÃ©cessiterait que toute
   l'humanitÃ© y travaille ensemble Â»^[52]. Une des difficultÃ©s vient du
   fait que si l'IAG est capable de manipuler des humains, il est trÃ¨s
   difficile de vÃ©rifier si ses intentions sont vraiment celles que l'on
   souhaite^[54]. Une approche nommÃ©e l'Â« interprÃ©tabilitÃ© Â» consiste Ã
   tenter de comprendre le fonctionnement interne de ces modÃ¨les d'IA,
   notamment afin de pouvoir dÃ©tecter des signes de manipulation, une
   tÃ¢che difficile vu la complexitÃ© et le nombre de paramÃ¨tres de ces
   modÃ¨les d'IA^[55].

   Des sceptiques comme Yann Le Cun estiment que les intelligences
   artificielles gÃ©nÃ©rales n'auront pas de raison de vouloir dominer
   l'humanitÃ©, et qu'il faut Ãªtre prudent de ne pas les anthropomorphiser
   et leur accorder des intentions humaines^[56]. Il considÃ¨re que les
   humains ne seraient pas Â« suffisamment intelligents pour concevoir des
   machines superintelligentes, et pourtant ridiculement stupides au point
   de leur donner des objectifs idiots sans avoir de garde-fous Â»^[57].

   Le principe de convergence instrumentale suggÃ¨re Ã  l'inverse que
   presque quel que soit les objectifs d'un agent intelligent, celui-ci a
   des raisons de chercher Ã  survivre et accumuler davantage de ressources
   et d'influence, car cela l'aide Ã  accomplir ces objectifs. Et que cela
   ne nÃ©cessite pas que l'IA ait des Ã©motions^[58]. Le philosophe Nick
   Bostrom donne l'exemple du maximiseur de trombones pour illustrer
   comment l'optimisation d'un objectif quelconque pourrait avoir des
   consÃ©quences catastrophiques :

     Â« Supposons que nous ayons une IA dont l'unique but soit de faire
     autant de trombones que possible. L'IA se rendra vite compte que ce
     serait bien mieux s'il n'y avait pas d'humains, parce que les
     humains pourraient dÃ©cider de l'Ã©teindre. Parce que si les humains
     le faisaient, il y aurait moins de trombones. De plus, le corps
     humain contient beaucoup d'atomes qui pourraient Ãªtre transformÃ©s en
     trombones. L'avenir vers lequel l'IA essaierait de se diriger serait
     un futur avec beaucoup de trombones mais aucun humain. Â»

   â€” Nick Bostrom^[59]

   Beaucoup de sceptiques estiment que l'IAG n'est pas pour bientÃ´t ou
   n'aura pas lieu, ou que ces risques contre-intuitifs dÃ©tournent
   l'attention de problÃ¨mes plus concrets et immÃ©diats^[60].

   En 2023, Max Tegmark dresse une analogie entre la superintelligence non
   alignÃ©e et la comÃ¨te qui s'apprÃªte Ã  heurter la Terre dans le film Ã
   succÃ¨s Don't Look Up^[61].

ChÃ´mage de masse[modifier | modifier le code]

   Les modÃ¨les de langage actuels pourraient dÃ©jÃ  toucher le marchÃ© de
   l'emploi. Selon OpenAI, Â« 80 % de la main-d'Å“uvre amÃ©ricaine pourrait
   voir au moins 10 % de ses tÃ¢ches affectÃ©es, tandis qu'environ 19 % des
   travailleurs pourraient voir au moins 50 % de leurs tÃ¢ches affectÃ©es
   par l'introduction d'outils tels que ChatGPT Â»^[62]. Les travailleurs
   de bureau semblent Ãªtre les plus concernÃ©s, par exemple les
   mathÃ©maticiens, comptables ou concepteurs de sites Web^[62].

   L'IAG pourrait augmenter l'autonomie de ces systÃ¨mes, leur capacitÃ© Ã
   prendre des dÃ©cisions, Ã  s'interfacer avec d'autres outils
   informatiques, mais aussi Ã  contrÃ´ler des corps robotisÃ©s.

   Cette automatisation est parfois considÃ©rÃ©e comme une aubaine, crÃ©ant
   davantage de richesses tout en travaillant moins. Larry Page,
   cofondateur de Google, estime que cela nous permettra de Â« vivre
   mieux Â» en nous Â« libÃ©rant du temps Â»^[63]. Selon Stephen Hawking, le
   rÃ©sultat dÃ©pendra notamment de la faÃ§on dont les richesses seront
   redistribuÃ©es^[46] :

     Â« Chacun pourra vivre une voluptueuse existence de loisirs si les
     richesses produites par les machines sont rÃ©parties, ou bien la
     majoritÃ© des gens vivront dans la misÃ¨re si les propriÃ©taires de ces
     machines parviennent Ã  nullifier la redistribution des richesses.
     Jusquâ€™ici, la tendance semble Ãªtre la seconde option, et la
     technologie creuse toujours plus les inÃ©galitÃ©s. Â»

   â€” Stephen Hawking

   D'aprÃ¨s Elon Musk, cette automatisation gÃ©nÃ©rale des tÃ¢ches dans la
   sociÃ©tÃ© nÃ©cessitera l'adoption par les gouvernements d'un revenu
   universel^[63].

DÃ©sinformation et manipulation[modifier | modifier le code]

   La gÃ©nÃ©ration automatique d'images ou de textes crÃ©dibles est dÃ©jÃ
   possible. Par exemple, une fausse image d'une explosion du Pentagone le
   22 mai 2023, partagÃ©e par des comptes financiers ainsi que par des
   mÃ©dias russes, a entraÃ®nÃ© une baisse momentanÃ©e de 0,3 % des cours
   boursiers aux Ã‰tats-Unis^[64]. L'IAG pourrait nÃ©anmoins acquÃ©rir une
   meilleure comprÃ©hension du contexte, interagir avec d'autres outils et
   se montrer plus convaincante, stratÃ©gique, personnalisÃ©e et autonome.

   La capacitÃ© des modÃ¨les d'IA Ã  produire du contenu trÃ¨s rapidement et Ã
   faible coÃ»t pourrait inonder internet de texte, d'images ou de vidÃ©os
   gÃ©nÃ©rÃ©es automatiquement^[65]^,^[66]. Ce contrÃ´le de l'information
   pourrait Ãªtre Ã©galement exploitÃ© par des rÃ©gimes autoritaires Ã  des
   fins de surveillance et de contrÃ´le. Cela pourrait ainsi intensifier la
   diffusion de dÃ©sinformation et de propagande. Une solution proposÃ©e
   serait l'adoption Ã  grande Ã©chelle de systÃ¨mes numÃ©riques permettant de
   prouver anonymement sur internet que l'on est un humain, ce qui
   permettrait notamment de filtrer efficacement les faux-comptes^[67].

Cyberattaques et prolifÃ©ration[modifier | modifier le code]

   L'IAG pourrait aussi automatiser les cyberattaques ou les escroqueries
   reposant sur l'ingÃ©nierie sociale^[68]. Que ce soit l'intention du
   concepteur ou non, il se pourrait que l'IAG soit en mesure d'exploiter
   les faiblesses de systÃ¨mes informatiques pour dÃ©jouer des protections,
   obtenir de l'argent ou se reproduire^[69].

RÃ©fÃ©rences[modifier | modifier le code]

    1. â†‘ ^a et b Pitpitt, Â« Intelligence artificielle gÃ©nÃ©rale â€”
       DataFranca Â», sur datafranca.org (consultÃ© le 24 mai 2023)
    2. â†‘ Â« The original goal of Artificial Intelligence (AI) was to build
       â€˜thinking machinesâ€™, but mainstream AI research has turned toward
       domain-dependent and problem-specific solutions; therefore it has
       become necessary to use a new name to indicate research that still
       pursues the â€œGrand AI Dreamâ€. Similar labels for this kind of
       research include â€œStrong AIâ€, â€œHuman-level AIâ€, etc. Â» Artificial
       General Intelligence (AGI) (AGI Society)
    3. â†‘ (en) Â« What is Artificial General Intelligence? - TechTarget Â»,
       sur Enterprise AI (consultÃ© le 26 mai 2023)
    4. â†‘ Â« Intelligence artificielle : opportunitÃ©s et risques Â»,
       ActualitÃ©, Parlement europÃ©en, 30 septembre 2020 (consultÃ© le 24
       mai 2023).
    5. â†‘ Source AFP, Â« Lâ€™IA prÃ©sente Â« des risques majeurs pour
       lâ€™humanitÃ© Â», selon Elon Musk et des experts Â», sur Le Point, 29
       mars 2023 (consultÃ© le 24 mai 2023).
    6. â†‘ (en) Â« Yes, We Are Worried About the Existential Risk of
       Artificial Intelligence Â», sur MIT Technology Review (consultÃ© le
       26 mai 2023).
    7. â†‘ (en) Â« AI guru Yoshua Bengio says regulation too slow, warns of
       'existential' threats Â», sur Vancouver Is Awesome, 24 mai 2023
       (consultÃ© le 26 mai 2023).
    8. â†‘ (en) Craig S. Smith, Â« Geoff Hinton, AIâ€™s Most Famous Researcher,
       Warns Of â€˜Existential Threatâ€™ From AI Â», sur Forbes (consultÃ© le 26
       mai 2023)
    9. â†‘ ^a et b (en-US) https://aiimpacts.org/author/katja, Â« 2022 Expert
       Survey on Progress in AI Â», sur AI Impacts, 4 aoÃ»t 2022 (consultÃ©
       le 25 mai 2023).
   10. â†‘ (en-US) Â« OpenAI Charter Â», sur openai.com (consultÃ© le 19 juin
       2023) : Â« OpenAIâ€™s mission is to ensure that artificial general
       intelligence (AGI)â€”by which we mean highly autonomous systems that
       outperform humans at most economically valuable workâ€”benefits all
       of humanity. Â»
   11. â†‘ Team rÃ©dac, Â« Intelligence Artificielle : dÃ©finition, histoire,
       utilisations, dangers Â», sur DataScientest.com, 20 novembre 2020
       (consultÃ© le 26 mai 2023)
   12. â†‘ (en) John Searle, Â« Minds, brains, and programs Â», 1980
   13. â†‘ Pitpitt, Â« Superintelligence â€” DataFranca Â», sur datafranca.org
       (consultÃ© le 26 mai 2023)
   14. â†‘ (en) Owen Cotton-Barratt et Toby Ord, Â« Strategic considerations
       about different speeds of AI takeoff Â», sur The Future of Humanity
       Institute, 12 aoÃ»t 2014 (consultÃ© le 25 mai 2023)
   15. â†‘ (en) Anthony M. Zador, Â« A critique of pure learning and what
       artificial neural networks can learn from animal brains Â», Nature
       Communications, vol. 10, n^o 1,â€ 21 aoÃ»t 2019, p. 3770
       (ISSN 2041-1723, DOI 10.1038/s41467-019-11786-6, lire en ligne,
       consultÃ© le 25 mai 2023)
   16. â†‘ Diana Sisu, Â« School of Informatics: History of Artificial
       Intelligence at Edinburgh Â», sur inf.ed.ac.uk (consultÃ© le 25 mai
       2023)
   17. â†‘ Â« Review of Artificial Intelligence: A General Survey Â», sur
       formal.stanford.edu (consultÃ© le 25 mai 2023) : Â« it would be a
       great relief to the rest of the workers in AI if the inventors of
       new general formalisms would express their hopes in a more guarded
       form than has sometimes been the case. Â»
   18. â†‘ Stuart J. Russell et Peter Norvig, Artificial intelligence: a
       modern approach ; [the intelligent agent book], Prentice Hall,
       coll. Â« Prentice Hall series in artificial intelligence Â», 2003,
       2^e Ã©d. (ISBN 978-0-13-790395-5), p. 25-26
   19. â†‘ (en) Mark Gubrud, Â« Fifth Foresight Conference on Molecular
       Nanotechnology Â», novembre 1997
   20. â†‘ ^a et b (en) Â« MuZero: Mastering Go, chess, shogi and Atari
       without rules Â», sur deepmind.com (consultÃ© le 26 mai 2023)
   21. â†‘ Â« L'intelligence artificielle "Gato" peut-elle surpasser
       l'intelligence humaine ? Â», sur Les NumÃ©riques, 3 juin 2022
       (consultÃ© le 26 mai 2023)
   22. â†‘ Â« Microsoft prÃ©tend que GPT-4 montre des Â« Ã©tincelles Â»
       d'intelligence artificielle gÃ©nÃ©rale, Â« nous pensons que
       l'intelligence de GPT-4 signale un vÃ©ritable changement de
       paradigme Â» Â», Developpez.com,â€ 27 mars 2023 (lire en ligne,
       consultÃ© le 26 mai 2023)
   23. â†‘ Elina S., Â« ChatGPT est-il vraiment plus crÃ©atif que 99% des
       humains ? Â», sur lebigdata.fr, 20 juillet 2023 (consultÃ© le 6
       novembre 2023).
   24. â†‘ (en-US) Kumar Gandharv, Â« Is Artificial General Intelligence
       Enhancing AI Consciousness Â», sur Datatechvibe, 10 aoÃ»t 2022
       (consultÃ© le 26 mai 2023)
   25. â†‘ (en) Â« AI could have 20% chance of sentience in 10 years, says
       philosopher David Chalmers Â», sur ZDNET (consultÃ© le 26 mai 2023)
   26. â†‘ (en) Rob Toews, Â« Reflecting On â€˜Artificial General Intelligenceâ€™
       And AI Sentience Â», sur Forbes (consultÃ© le 26 mai 2023)
   27. â†‘ Riccardo Manzotti et Antonio Chella, Â« Good Old-Fashioned
       Artificial Consciousness and the Intermediate Level Fallacy Â»,
       Frontiers in Robotics and AI, vol. 5,â€ 2018 (ISSN 2296-9144,
       DOI 10.3389/frobt.2018.00039/full, lire en ligne, consultÃ© le 26
       mai 2023)
   28. â†‘ (en-US) Dustin Crummett, Â« AI Sentience and Moral Risk Â», sur
       Prindle Institute, 22 juin 2022 (consultÃ© le 26 mai 2023)
   29. â†‘ (en) Santa Clara University, Â« Good Machine, Nice Machine,
       Superintelligent Machine Â», sur scu.edu (consultÃ© le 26 mai 2023) :
       Â« Let an ultraintelligent machine be defined as a machine that can
       far surpass all the intellectual activities of any man however
       clever. Since the design of machines is one of these intellectual
       activities, an ultraintelligent machine could design even better
       machines; there would then unquestionably be an 'intelligence
       explosion,' and the intelligence of man would be left far behind.
       Thus the first ultraintelligent machine is the last invention that
       man need ever make provided that the machine is docile enough to
       tell us how to keep it under control. Â»
   30. â†‘ (en) Robin Hanson, Â« I Still Donâ€™t Get Foom Â», sur
       overcomingbias.com (consultÃ© le 26 mai 2023)
   31. â†‘ Nicolas Miailhe, Cyrus Hodes. La troisiÃ¨me Ã¨re de l'intelligence
       artificielle. OpenEdition Journals
   32. â†‘ (en) Â« A Generalist Agent Â», sur deepmind.com (consultÃ© le 26 mai
       2023)
   33. â†‘ (en-US) Â« OpenAI Presents GPT-3, a 175 Billion Parameters
       Language Model Â», sur NVIDIA Technical Blog, 7 juillet 2020
       (consultÃ© le 26 mai 2023)
   34. â†‘ (en) Â« Pathways Language Model (PaLM): Scaling to 540 Billion
       Parameters for Breakthrough Performance Â», sur ai.googleblog.com, 4
       avril 2022 (consultÃ© le 26 mai 2023)
   35. â†‘ (en) Â« Scaling Laws - AI Alignment Forum Â», sur
       alignmentforum.org (consultÃ© le 26 mai 2023)
   36. â†‘ (en) Michael Shermer, Â« Artificial Intelligence Is Not a
       Threatâ€”Yet Â», sur Scientific American (consultÃ© le 26 mai 2023) :
       Â« like worrying about overpopulation on Mars when we have not even
       set foot on the planet yet. Â»
   37. â†‘ Â« L'intelligence artificielle gÃ©nÃ©rale, prochaine rÃ©volution pour
       l'humanitÃ© ? Â», sur L'Ã‰claireur Fnac, 22 avril 2023 (consultÃ© le 26
       mai 2023)
   38. â†‘ (en-US) Cade Metz, Â« â€˜The Godfather of A.I.â€™ Leaves Google and
       Warns of Danger Ahead Â», The New York Times,â€ 1^er mai 2023
       (ISSN 0362-4331, lire en ligne, consultÃ© le 26 mai 2023) :

     Â« The idea that this stuff could actually get smarter than people â€”
     a few people believed that, [...]. But most people thought it was
     way off. And I thought it was way off. I thought it was 30 to 50
     years or even longer away. Obviously, I no longer think that. Â»
   39. â†‘ Edward Back, Â« ChatGPT-5 devrait sortir en fin dâ€™annÃ©e et
       atteindre le graal de lâ€™intelligence artificielle gÃ©nÃ©rale ! Â», sur
       Futura (consultÃ© le 26 mai 2023)
   40. â†‘ (en) Â« Will There Be a GPT-5? When Will GPT-5 Launch? Â», sur
       makeuseof.com, 18 avril 2023 (consultÃ© le 7 juin 2023).
   41. â†‘ (en-US) Arjun Sha, Â« OpenAI GPT-5: Release Date, Features, AGI
       Rumors, Speculations, and More Â», sur Beebom, 19 mai 2023 (consultÃ©
       le 7 juin 2023).
   42. â†‘ (en-US) Â« Artificial General Intelligence â€“ Do the cost outweigh
       benefits? Â», 23 aoÃ»t 2021 (consultÃ© le 26 mai 2023)
   43. â†‘ Â« How we can Benefit from Advancing Artificial General
       Intelligence (AGI) - Unite.AI Â», sur unite.ai (consultÃ© le 26 mai
       2023)
   44. â†‘ ^a b et c (en) Smithsonian Magazine et Jules Julien,Stephan
       Talty, Â« What Will Our Society Look Like When Artificial
       Intelligence Is Everywhere? Â», sur Smithsonian Magazine (consultÃ©
       le 26 mai 2023)
   45. â†‘ Setra, Â« Selon Sam Altman, lâ€™IA donnera des conseils mÃ©dicaux
       (aux pauvres) Â», sur Presse-citron, 23 fÃ©vrier 2023 (consultÃ© le 26
       mai 2023)
   46. â†‘ ^a et b Maxime VendÃ©, Â« Pour Stephen Hawking, la robotisation
       accroÃ®t les inÃ©galitÃ©s Â», sur Mouvement FranÃ§ais pour un Revenu de
       Base, 13 octobre 2015 (consultÃ© le 25 mai 2023) : Â« Everyone can
       enjoy a life of luxurious leisure if the machine-produced wealth is
       shared, or most people can end up miserably poor if the
       machine-owners successfully lobby against wealth redistribution. So
       far, the trend seems to be toward the second option, with
       technology driving ever-increasing inequality. Â»
   47. â†‘ Â« La surveillance totale est le seul moyen de sauver
       l'humanitÃ© Â», sur Intelligence Artificielle et Transhumanisme, 22
       avril 2019 (consultÃ© le 26 mai 2023)
   48. â†‘ ^a et b Nick Bostrom, Superintelligence: paths, dangers,
       strategies, Oxford University Press, 2017 (ISBN 978-0-19-967811-2),
       Â§ Preferred order of arrival
   49. â†‘ ^a et b Ali GÃ¼ndoÄŸar, Saulius Niauronis. An Overview of Potential
       Risks of Artificial General Intelligence Robots. Applied Scientific
       Research, Vol. 2, No. 1, 2023).
   50. â†‘ (en) Wim NaudÃ© et Otto Barten, Â« Artificial General Intelligence:
       can we avoid the ultimate existential threat? Â»
   51. â†‘ (en-US) Mario Herger, Â« The Gorilla Problem â€“ Enterprise Garage Â»
       (consultÃ© le 26 mai 2023)
   52. â†‘ ^a et b (en-US) Â« Our approach to alignment research Â», sur
       openai.com (consultÃ© le 26 mai 2023) : Â« Â« Unaligned AGI could pose
       substantial risks to humanity and solving the AGI alignment problem
       could be so difficult that it will require all of humanity to work
       together. Â» Â»
   53. â†‘ (en-US) Â« Governance of superintelligence Â», sur openai.com
       (consultÃ© le 26 mai 2023)
   54. â†‘ (en) Â« Why AI alignment could be hard with modern deep
       learning Â», sur Cold Takes, 21 septembre 2021 (consultÃ© le 26 mai
       2023)
   55. â†‘ (en) Â« 19 - Mechanistic Interpretability with Neel Nanda Â», sur
       AXRP - the AI X-risk Research Podcast, 4 fÃ©vrier 2023 (consultÃ© le
       26 mai 2023)
   56. â†‘ (en) Anthony Zador,Yann LeCun, Â« Donâ€™t Fear the Terminator Â», sur
       Scientific American Blog Network (consultÃ© le 26 mai 2023)
   57. â†‘ Â« The fascinating Facebook debate between Yann LeCun, Stuart
       Russel and Yoshua Bengio about the risks of strong AI Â», sur The
       fascinating Facebook debate between Yann LeCun, Stuart Russel and
       Yoshua Bengio about the risks of strong AI (consultÃ© le 26 mai
       2023) : Â« I think it would only be relevant in a fantasy world in
       which people would be smart enough to design super-intelligent
       machines, yet ridiculously stupid to the point of giving it moronic
       objectives with no safeguards. Â»
   58. â†‘ Â« The fascinating Facebook debate between Yann LeCun, Stuart
       Russel and Yoshua Bengio about the risks of strong AI Â», sur The
       fascinating Facebook debate between Yann LeCun, Stuart Russel and
       Yoshua Bengio about the risks of strong AI (consultÃ© le 26 mai
       2023) : Â« It is trivial to construct a toy MDP in which the agent's
       only reward comes from fetching the coffee. If, in that MDP, there
       is another "human" who has some probability, however small, of
       switching the agent off, and if the agent has available a button
       that switches off that human, the agent will necessarily press that
       button as part of the optimal solution for fetching the coffee. No
       hatred, no desire for power, no built-in emotions, no built-in
       survival instinct, nothing except the desire to fetch the coffee
       successfully. This point cannot be addressed because it's a simple
       mathematical observation Â»
   59. â†‘ Kathleen Miles, Â« Artificial Intelligence May Doom The Human Race
       Within A Century, Oxford Professor Says Â», Huffington Post,â€ 22
       aoÃ»t 2014 (lire en ligne) : Â« Suppose we have an AI whose only goal
       is to make as many paper clips as possible. The AI will realize
       quickly that it would be much better if there were no humans
       because humans might decide to switch it off. Because if humans do
       so, there would be fewer paper clips. Also, human bodies contain a
       lot of atoms that could be made into paper clips. The future that
       the AI would be trying to gear towards would be one in which there
       were a lot of paper clips but no humans. Â»
   60. â†‘ (en) Â« Expert Comment: No need to wait for the future, the danger
       of AI is already here Â», University of Oxford, 15 mai 2023
       (consultÃ© le 26 mai 2023).
   61. â†‘ (en) Â« The 'Don't Look Up' Thinking That Could Doom Us With AI Â»,
       sur Time, 25 avril 2023 (consultÃ© le 26 mai 2023)
   62. â†‘ ^a et b Â« ChatGPT : quels sont les mÃ©tiers menacÃ©s par les
       intelligences artificielles ? Â», sur Capital.fr, 29 mars 2023
       (consultÃ© le 25 mai 2023)
   63. â†‘ ^a et b Fabien Soyez, Â« Revenu universel : une solution pour
       contrer les robots et la destruction du travail ? Â», sur cnet, 10
       novembre 2016 (consultÃ© le 25 mars 2023)
   64. â†‘ Â« La fausse image dâ€™une explosion au Pentagone fait briÃ¨vement
       douter les marchÃ©s Â», Le Monde,â€ 24 mai 2023 (lire en ligne,
       consultÃ© le 25 mai 2023).
   65. â†‘ Â« Lâ€™intelligence artificielle permet dÃ©sormais dâ€™inonder le Web
       de fake news Â», sur 01net.com, 5 aoÃ»t 2021 (consultÃ© le 26 mai
       2023)
   66. â†‘ Â« Midjourney, ChatGPTâ€¦ Quel rÃ´le lâ€™intelligence artificielle
       joue-t-elle sur la dÃ©sinformation ? Â», sur Ouest-France.fr, 28 mars
       2023 (consultÃ© le 26 mai 2023)
   67. â†‘ (en) Â« Proof of personhood: What it is and why itâ€™s needed Â», sur
       worldcoin.org (consultÃ© le 26 mai 2023)
   68. â†‘ (en) Jeffrey Laddish et Lennart Heim, Â« Information security
       considerations for AI and the long term future Â», sur LessWrong, 2
       mai 2022.
   69. â†‘ (en) Zach Stein-Perlman, Â« DeepMind: Model evaluation for extreme
       risks Â», LessWrong,â€ 25 mai 2023 (lire en ligne, consultÃ© le 26 mai
       2023)

Voir aussi[modifier | modifier le code]

Articles connexes[modifier | modifier le code]

     * Alignement des intelligences artificielles
     * ChatGPT
     * Grand modÃ¨le de langage
     * Risque de catastrophe planÃ©taire liÃ© Ã  l'intelligence artificielle
       gÃ©nÃ©rale
     * Superintelligence
     * Association for the Advancement of Artificial Intelligence
     * Ben Goertzel
     * OpenCog

Liens externes[modifier | modifier le code]

     * Site officiel de l'AGI Society

Bibliographie[modifier | modifier le code]

     * Cette section est vide, insuffisamment dÃ©taillÃ©e ou incomplÃ¨te.
       Votre aide est la bienvenue ! Comment faire ?

     * icÃ´ne dÃ©corative Portail de lâ€™informatique
     * icÃ´ne dÃ©corative Portail de la psychologie

   v Â· m
   Intelligence artificielle (IA)
   Concepts
     * Effet IA
     * Grand modÃ¨le de langage
     * Hallucination (IA)
     * IA gÃ©nÃ©rale
     * IA gÃ©nÃ©rative

   Techniques
     * Analyse prÃ©dictive
     * Apprentissage automatique
     * Apprentissage non supervisÃ©
     * Apprentissage profond
     * Apprentissage supervisÃ©
     * ModÃ¨le de fondation
     * ModÃ¨le des croyances transfÃ©rables
     * IA symbolique
     * RÃ©seau bayÃ©sien
     * RÃ©seau de neurones artificiels
     * RÃ©seau neuronal convolutif
     * Transformeur

   Applications
     * Art crÃ©Ã© par IA
     * ChatGPT
     * DeepL
     * Diagnostic (IA)
     * Ã‰criture assistÃ©e par IA
     * IA dans la santÃ©
     * IA dans le jeu vidÃ©o
     * Perception artificielle
     * Planification (IA)
     * Robotique
     * Traduction automatique
     * Traitement automatique du langage naturel
     * VÃ©hicule autonome
     * Vision par ordinateur

   Enjeux et philosophie
     * Alignement de l'IA
     * Chambre chinoise
     * Conscience artificielle
     * ContrÃ´le des capacitÃ©s de l'IA
     * Ã‰thique de l'IA
     * IA digne de confiance
     * Philosophie de l'IA
     * SÃ»retÃ© de l'IA

   Histoire et Ã©vÃ©nements
     * Histoire de l'intelligence artificielle
     * Logic Theorist (1955)
     * Perceptron (1957)
     * General Problem Solver (1959)
     * Prolog (1972)
     * Matchs Deep Blue contre Kasparov (1996-1997)
     * Match AlphaGo - Lee Sedol (2016)

   Science-fiction
     * Anticipation (IA)
     * IA-complet
     * IA gÃ©nÃ©rale
     * Risque de catastrophe planÃ©taire liÃ© Ã  l'intelligence artificielle
       gÃ©nÃ©rale
     * Superintelligence

       RÃ¨glementation
     * LÃ©gislation sur l'IA
     * RÃ©glementation de l'IA

   Organisations
     * Agence francophone pour l'IA
     * Google DeepMind
     * OpenAI
     * Partenariat sur l'IA

   Ouvrages
     * DÃ©claration de MontrÃ©al pour un dÃ©veloppement responsable de
       l'intelligence artificielle
     * Lettre ouverte sur l'IA
     * Intelligence artificielle : une approche moderne
     * I.A. La Plus Grande Mutation de l'Histoire

   Ce document provient de
   Â« https://fr.wikipedia.org/w/index.php?title=Intelligence_artificielle_
   gÃ©nÃ©rale&oldid=210201469 Â».
   CatÃ©goriesâ€¯:
     * Apprentissage automatique
     * RÃ©seau de neurones artificiels
     * Intelligence artificielle
     * Culture Internet
     * Risque de catastrophe planÃ©taire liÃ© Ã  l'intelligence artificielle
       gÃ©nÃ©rale

   CatÃ©gories cachÃ©esâ€¯:
     * Page utilisant des arguments dupliquÃ©s dans les appels de modÃ¨le
     * Article avec une section vide ou incomplÃ¨te
     * Portail:Informatique/Articles liÃ©s
     * Portail:Technologies/Articles liÃ©s
     * Portail:Sciences/Articles liÃ©s
     * Portail:Psychologie/Articles liÃ©s
     * Portail:Sciences humaines et sociales/Articles liÃ©s

     * La derniÃ¨re modification de cette page a Ã©tÃ© faite le 2 dÃ©cembre
       2023 Ã  17:33.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les mÃªmes conditions ; dâ€™autres
       conditions peuvent sâ€™appliquer. Voyez les conditions dâ€™utilisation
       pour plus de dÃ©tails, ainsi que les crÃ©dits graphiques. En cas de
       rÃ©utilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       WikipediaÂ® est une marque dÃ©posÃ©e de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance rÃ©gie par le paragraphe 501(c)(3) du
       code fiscal des Ã‰tats-Unis.

     * Politique de confidentialitÃ©
     * Ã€ propos de WikipÃ©dia
     * Avertissements
     * Contact
     * Code de conduite
     * DÃ©veloppeurs
     * Statistiques
     * DÃ©claration sur les tÃ©moins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou dÃ©sactiver la limitation de largeur du contenu
