   #alternate Modifier Wikip√©dia (fr) Flux Atom de Wikip√©dia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails th√©matiques
     * Article au hasard
     * Contact

   Contribuer
     * D√©buter sur Wikip√©dia
     * Aide
     * Communaut√©
     * Modifications r√©centes
     * Faire un don

   Langues
   Sur cette version linguistique de Wikip√©dia, les liens interlangues
   sont plac√©s en haut √† droite du titre de l‚Äôarticle.
   Aller en haut.
   Wikip√©dia l'encyclop√©die libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * Cr√©er un compte
     * Se connecter

   [ ] Outils personnels
     * Cr√©er un compte
     * Se connecter

   Pages pour les contributeurs d√©connect√©s en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
     * D√©but
     * 1Introduction

     2Quelques pr√©curseurs
   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section Quelques pr√©curseurs
     * 2.1L'intelligence artificielle : mythes, fiction et sp√©culation

     2.2Automates

     2.3Raisonnement formel



   2.4Intelligence artificielle et premiers ordinateurs



   3Naissance: 1943‚àí1956

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section Naissance: 1943‚àí1956
     * 3.1Cybern√©tique et premiers r√©seaux neuronaux



   3.2L'intelligence artificielle dans les jeux



   3.3Test de Turing



   3.4Raisonnement symbolique et le th√©oricien logique



   3.5La traduction automatique des langages



   3.6Conf√©rence de Dartmouth de 1956 : naissance de l'intelligence
   artificielle



   4L'√¢ge d'or 1956‚àí1974

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section L'√¢ge d'or 1956‚àí1974
     * 4.1Les perc√©es

     * 4.1.1Raisonnement par t√¢tonnements



   4.1.2Langage naturel



   4.1.3Micro-mondes



   4.2L'optimisme



   4.3Le financement



   5La premi√®re hibernation de l'intelligence artificielle (1974‚àí1980)

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section La premi√®re hibernation de
   l'intelligence artificielle (1974‚àí1980)
     * 5.1Les probl√®mes

     * 5.1.1Limites de la puissance de calcul



   5.1.2Limites inh√©rentes : la compl√©tude NP



   5.1.3Raisonnement et base de connaissance de culture g√©n√©rale



   5.1.4Le paradoxe de Moravec



   5.1.5Le cadre et les probl√®mes de qualification



   5.2La fin des investissements



   5.3Critiques universitaires



   5.4Perceptrons et la p√©riode sombre du connexionnisme



   5.5Les √©l√©gants : calcul des pr√©dicats, Prolog et syst√®mes experts



   5.6Les brouillons : cadres et scripts



   6Le boom 1980‚Äì1987

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section Le boom 1980‚Äì1987
     * 6.1La mont√©e des syst√®mes experts



   6.2La r√©volution de la connaissance



   6.3L'argent est de retour : projets de la cinqui√®me g√©n√©ration



   6.4La renaissance du connexionnisme



   7La crise : le second hiver de l'IA 1987‚àí1993

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section La crise : le second hiver
   de l'IA 1987‚àí1993
     * 7.1Une seconde hibernation



   7.2L'importance du corps : Nouvelle intelligence artificielle et
   embodiment



   81993-2000

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section 1993-2000
     * 8.1Verrous qui sautent et loi de Moore



   8.2Agents intelligents



   8.3¬´ Victoire des √©l√©gants ¬ª



   8.4L'IA, travailleur de l'ombre



   92001 et HAL 9000



   102000 - 2010



   112009 - 2019



   12Red√©finition dans les ann√©es 2020



   13La recherche en intelligence artificielle en France



   14Notes et r√©f√©rences



   15R√©f√©rences



   16Annexes

   (BUTTON) Afficher‚ÄØ/‚ÄØmasquer la sous-section Annexes
     * 16.1Bibliographie



   16.2Articles connexes

   [ ] Basculer la table des mati√®res

Histoire de l'intelligence artificielle

   [ ] 26 langues
     * Afrikaans
     * ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
     * Az…ôrbaycanca
     * ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
     * Catal√
     * ⁄©Ÿàÿ±ÿØ€å
     * Deutsch
     * ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨
     * English
     * Espa√±ol
     * Euskara
     * ŸÅÿßÿ±ÿ≥€å
     * ’Ä’°’µ’•÷Ä’•’∂
     * Bahasa Indonesia
     * √çslenska
     * Êó•Êú¨Ë™û
     * ÌïúÍµ≠Ïñ¥
     * Ÿæ⁄öÿ™Ÿà
     * Portugu√™s
     * –†—É—Å—Å–∫–∏–π
     * ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç
     * –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
     * Ti·∫øng Vi·ªát
     * ‰∏≠Êñá
     * Á≤µË™û
     * IsiZulu

   Modifier les liens

     * Article
     * Discussion

   [ ] fran√ßais

     * Lire
     * Modifier
     * Modifier le code
     * Voir l‚Äôhistorique

   [ ] Outils
   Outils
   (BUTTON) d√©placer vers la barre lat√©rale (BUTTON) masquer
   Actions
     * Lire
     * Modifier
     * Modifier le code
     * Voir l‚Äôhistorique

   G√©n√©ral
     * Pages li√©es
     * Suivi des pages li√©es
     * T√©l√©verser un fichier
     * Pages sp√©ciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * √âl√©ment Wikidata

   Imprimer‚ÄØ/‚ÄØexporter
     * Cr√©er un livre
     * T√©l√©charger comme PDF
     * Version imprimable

   Un article de Wikip√©dia, l'encyclop√©die libre.

   L'intelligence artificielle plonge ses racines dans l'Antiquit√©, mais
   c'est surtout dans la deuxi√®me partie du XX^e si√®cle qu'elle prit son
   essor, et qu'une lecture historique devient envisageable. On parle d'un
   essor apr√®s la seconde guerre mondiale, puis d'un premier hiver, puis
   d'un retour dans les ann√©es 1980, puis d'un second hiver, interrompu
   par l'arriv√©e des IA g√©n√©ratives.

Introduction[modifier | modifier le code]

   Les premiers jalons historiques de l'intelligence artificielle (ou IA)
   datent de la Protohistoire, o√π mythes, l√©gendes et rumeurs dotent des
   √™tres artificiels, r√©alis√©s par des ma√Ætres-artisans, d'une
   intelligence ou d'une conscience ; comme l'√©crit Pamela McCorduck (en),
   l'intelligence artificielle commence avec ¬´ le vieux souhait de jouer √
   Dieu^[1] ¬ª.

   L'intelligence artificielle comme nous l'entendons aujourd'hui a √©t√©
   initi√©e par les philosophes classiques, dont Gottfried Wilhelm Leibniz
   avec son calculus ratiocinator, qui essaient de d√©crire le processus de
   la pens√©e humaine comme la manipulation m√©canique de symboles, sans
   pour autant vouloir fabriquer des sp√©cimens. Cette r√©flexion s'est
   concr√©tis√©e avec l'invention de l'ordinateur programmable dans les
   ann√©es 1940. Cet instrument et les id√©es qu'il sous-tend ont inspir√©
   les scientifiques qui ont commenc√© √† √©voquer s√©rieusement la
   faisabilit√© d'un ¬´ cerveau √©lectronique ¬ª.

   La recherche en intelligence artificielle a vraiment commenc√© apr√®s une
   conf√©rence tenue sur le campus de Dartmouth College pendant l'√©t√© 1956.
   √Ä la suite de cette r√©union, certains participants se sont investis
   dans une recherche sur l'intelligence artificielle. Certains utopistes
   ont pronostiqu√© qu'une machine aussi intelligente qu'un √™tre humain
   existerait en moins d'une g√©n√©ration et des millions de dollars ont
   alors √©t√© investis pour r√©ifier cette pr√©diction. Avec le temps, il est
   apparu que les difficult√©s inh√©rentes √† cette annonce avaient √©t√©
   grossi√®rement sous-estim√©es. En 1973, en r√©ponse aux critiques des
   scientifiques, notamment de James Lighthill et aux pressions
   continuelles des parlementaires, les gouvernements britannique et
   am√©ricain stoppent les subventions √† la recherche en intelligence
   artificielle sans orientation. Sept ans plus tard, √† la suite de
   l'initiative proph√©tique du Cabinet du Japon, les gouvernements et
   l'industrie r√©investissent dans l'intelligence artificielle, mais √† la
   fin des ann√©es 1980 les d√©cideurs d√©sabus√©s retirent √† nouveau leurs
   fonds. On peut donc dire que ce cycle en dents de scie, o√π alternent
   p√©riodes de gel et de d√©gel, caract√©rise le soutien √† l'intelligence
   artificielle. Mais il reste toujours des id√©alistes pour faire des
   pr√©dictions os√©es^[2].

   Malgr√© des hauts et des bas et en d√©pit de certaines r√©ticences de
   d√©cideurs et investisseurs, l'intelligence artificielle progresse. Les
   progr√®s de l'algorithmique ont permis de r√©soudre des probl√®mes que les
   heuristiques ne pouvaient traiter et jug√©s inaccessibles en 1970 ; et
   ces solutions sont comercialis√©es. Mais aucune machine dot√©e d'une
   intelligence artificielle forte n'a encore √©t√© construite,
   contrairement aux pr√©visions optimistes de la premi√®re g√©n√©ration de
   chercheurs. ¬´ Nous ne pouvons qu'entrevoir le court terme ¬ª a conc√©d√©
   Alan Turing, dans un article c√©l√®bre de 1950 pr√©figurant la recherche
   moderne sur les machines pensantes. ¬´ Mais, ¬ª ajoute-t-il, ¬´ nous ne
   pouvons pas envisager l'ampleur du travail qui reste √† accomplir^[3] ¬ª.

   Au d√©part, deux approches se confrontent : d'une part l'approche
   logiciste ou symbolique, qui vise √† recr√©er les ¬´ lois universelles ¬ª
   de la pens√©e et s'inspirent du concept de machine de Turing, et d'autre
   part l'approche neuronale, incarn√©e par Frank Rosenblatt, qui essaie
   d'imiter les processus biologiques c√©r√©braux. Si l'approche logiciste,
   inspir√©e des travaux de Russell, Frege, du cercle de Vienne, de logique
   math√©matique, etc., l'emporte √† la DARPA, principal organisme finan√ßant
   les recherches en intelligence artificielle, l'approche neuronale
   refait surface dans les ann√©es 1980, inspirant les travaux sur le
   connexionnisme.

   L'intelligence artificielle ayant, √† ses d√©buts, surtout √©merg√© aux
   √âtats-Unis, cet article se focalisera essentiellement sur ce pays.

Quelques pr√©curseurs[modifier | modifier le code]

   McCorduck 2004 √©crit en 2004 que ¬´ l'intelligence artificielle sous une
   forme ou une autre est une id√©e qui s'est r√©pandue dans l'histoire de
   la pens√©e occidentale, un r√™ve au besoin pressant d'√™tre r√©alis√©, ¬ª que
   l'on retrouve dans les mythes, l√©gendes, histoires, sp√©culations et
   automates anthropomorphes de l'humanit√©^[4].

L'intelligence artificielle : mythes, fiction et sp√©culation[modifier |
modifier le code]

   Les hommes m√©caniques et les √™tres artificiels sont pr√©sents dans la
   mythologie grecque, ainsi les robots dor√©s d'H√©pha√Østos, Pygmalion et
   Galat√©e^[5].

   Tandis qu'au Moyen √Çge, circulent des rumeurs de secrets mystiques ou
   de techniques alchimiques pour impr√©gner des esprits, tels que le
   Takwin de Geber, les homoncules de Paracelse et le Golem de
   MaHaRaL^[6].

   Au XIX^e si√®cle, l'id√©e d'hommes artificiels et de machines pensantes
   prend corps dans des ≈ìuvres de fiction, telles que Frankenstein de Mary
   Shelley ou encore R. U. R. (Rossum's Universal Robots) de Karel
   ƒåapek^[7], et des essais de sp√©culation, comme Darwin among the
   Machines de Samuel Butler^[8].

   L'IA est un √©l√©ment important de la science-fiction.

Automates[modifier | modifier le code]

   Article d√©taill√© : Automate anthropomorphe.
   [250px-Al-jazari_robots.jpg] L'automate programmable d'Al-Djazari (1206
   apr. J.-C.)

   Des automates anthropomorphes r√©alistes ont √©t√© construits par des
   artisans de toutes les civilisations, dont Yan Shi qui travaillait pour
   Ji Man^[9], H√©ron d'Alexandrie^[10], Al-Djazari^[11] et Wolfgang von
   Kempelen^[12]. Les plus vieux automates sont les statues sacr√©es
   d'ancienne √âgypte et de Gr√®ce antique. Les croyants √©taient persuad√©s
   que les artisans avaient impr√©gn√© ces statues avec des esprits r√©els,
   capables de sagesse et d'√©motion ‚Äî Herm√®s Trism√©giste a √©crit qu'¬´ en
   d√©couvrant la vraie nature des dieux, l'homme a √©t√© capable de le
   reproduire^[13]^,^[14] ¬ª. L'automate de Vaucanson du XVIII^e si√®cle qui
   repr√©sente un canard est une mise en ≈ìuvre saisissante d'un √™tre
   artificiel r√©alisant certaines fonctions du vivant, tandis que le turc
   joueur d'√©chec de Johann Wolfgang von Kempelen est une supercherie.

Raisonnement formel[modifier | modifier le code]

   L'intelligence artificielle se fonde sur l'hypoth√®se que le processus
   de pens√©e humaine peut √™tre m√©canis√©. L'√©tude du raisonnement m√©canique
   ‚Äî ou ¬´ formel ¬ª ‚Äî a un long historique. Les philosophes chinois,
   indiens et grecs ont tous d√©velopp√© des m√©thodes structur√©es de
   d√©duction formelle au cours du premier mill√©naire apr. J.-C. Leurs
   id√©es ont √©t√© d√©velopp√©es √† travers les si√®cles par des philosophes
   comme Aristote (qui a donn√© une analyse formelle du syllogisme),
   Euclide (dont les √âl√©ments ont √©t√© un mod√®le de raisonnement formel),
   Al-Khawarizmi (auquel on doit l'alg√®bre et dont le nom a donn√©
   ¬´ algorithme ¬ª) et les philosophes scolastiques europ√©ens comme
   Guillaume d'Ockham et Duns Scot^[15].

   Le philosophe majorquin Raymond Lulle (1232‚Äì1315) a con√ßu plusieurs
   machines logiques destin√©es √† la production de connaissance par des
   moyens logiques^[16] ; Lulle d√©crit ses machines en tant qu'entit√©s
   m√©caniques qui pouvaient combiner des v√©rit√©s fondamentales et
   ind√©niables via de simples op√©rations logiques, g√©n√©r√©es par la machine
   gr√¢ce √† des m√©canismes, de mani√®re √† produire tout le savoir
   possible^[17]. Le travail de Lulle a une grande influence sur Leibniz,
   qui a red√©velopp√© ses id√©es^[18].
   [220px-Gottfried_Wilhelm_von_Leibniz.jpg] Gottfried Wilhelm Leibniz,
   qui sp√©culait qu'on pouvait r√©duire la raison humaine √† des calculs
   m√©caniques

   Au XVII^e si√®cle, Gottfried Wilhelm Leibniz, Thomas Hobbes et Ren√©
   Descartes ont explor√© la possibilit√© que toute la pens√©e rationnelle
   puisse √™tre aussi syst√©matique que l'alg√®bre ou la g√©om√©trie^[19]. Dans
   le L√©viathan de Hobbes, on retrouve la c√©l√®bre phrase : ¬´ la raison
   [...] n'est rien d'autre que le fait de calculer^[20] ¬ª. Leibniz
   imaginait un langage universel du raisonnement (sa characteristica
   universalis) qui assimilerait l'argumentation √† un calcul, afin qu'¬´ il
   n'y a[it] pas plus de besoin de se disputer entre deux philosophes
   qu'entre deux comptables. Car il leur suffirait de prendre leur crayon
   et leur ardoise en main, et de se dire l'un l'autre (avec un ami en
   t√©moin, au besoin) : Calculons !^[21] ¬ª. Ces philosophes ont commenc√© √
   articuler les hypoth√®ses d'un syst√®me de symboles physiques qui
   deviendra par la suite l'un des dogmes de la recherche en IA.

   Au XX^e si√®cle, l'√©tude de la logique math√©matique a fourni l'essentiel
   des avanc√©es qui ont rendu plausible l'intelligence artificielle. Les
   bases ont √©t√© mises en place avec des ≈ìuvres telles que Les Lois de la
   Pens√©e de Boole et Id√©ographie de Frege. S'appuyant sur le syst√®me de
   Frege, Russell et Whitehead ont pr√©sent√© un traitement formel des
   fondements des math√©matiques dans leur chef-d'≈ìuvre Principia
   Mathematica en 1913. Inspir√© par le succ√®s de Russell, David Hilbert a
   d√©fi√© les math√©maticiens des ann√©es 1920-1930 de r√©pondre √† cette
   question fondamentale : ¬´ Le raisonnement math√©matique peut-il √™tre
   enti√®rement formalis√©^[15] ? ¬ª On r√©pondit √† sa question par les
   th√©or√®mes d'incompl√©tude de G√∂del, la machine de Turing et le
   lambda-calcul de Church^[15]^,^[22]. Leur r√©ponse √©tait surprenante √
   plusieurs titres. Tout d'abord, ils prouv√®rent qu'il y avait, en fait,
   des limitations dans ce que la logique math√©matique pouvait accomplir.
   [250px-Classic_shot_of_the_ENIAC.jpg] L'ENIAC, √† la Moore School of
   Electrical Engineering.

   Mais aussi (et plus important encore pour l'IA) leurs travaux ont
   sugg√©r√© que, sous ces conditions, toute forme de raisonnement
   math√©matique pouvait √™tre m√©canis√©e. La th√®se de Church impliquait
   qu'un appareil m√©canique, manipulant des symboles aussi simples que des
   0 et des 1, pouvait imiter tout processus concevable de d√©duction
   math√©matique. Cette notion-cl√© se traduisit par la machine de Turing ‚Äî
   une simple construction th√©orique qui capturait l'essence de la
   manipulation de symboles abstraits. Cette invention inspira une poign√©e
   de scientifiques qui commenc√®rent alors √† discuter de la possibilit√© de
   machines pensantes^[15]^,^[23].

Intelligence artificielle et premiers ordinateurs[modifier | modifier le
code]

   Les machines √† calculer sont apparues d√®s l'Antiquit√©^[Note 1] et ont
   √©t√© am√©lior√©es tout au long de l'histoire par de nombreux
   math√©maticiens et ing√©nieurs, dont Leibniz. Au d√©but du XIX^e si√®cle,
   Charles Babbage con√ßoit la machine √† calculer programmable (la Machine
   analytique), sans jamais la construire. √Ä sa suite, Ada Lovelace
   sp√©cule que la machine ¬´ peut composer des pi√®ces de musique √©labor√©es
   et scientifiques de toutes complexit√© et longueur^[24]^,^[Note 2] ¬ª.

   Les premiers ordinateurs modernes sont les machines massives de
   cryptanalyse de la Seconde Guerre mondiale (telles que le Z3, l'ENIAC
   et le Colossus)^[25], con√ßues, en ce qui concerne les deux derni√®res, √
   partir des fondements th√©oriques √©tablis par Alan Turing et d√©velopp√©s
   par John von Neumann^[26].

Naissance: 1943‚àí1956[modifier | modifier le code]

   [420px-BRL61-IBM_702.jpg] L'IBM 702 : un ordinateur utilis√© par la
   premi√®re g√©n√©ration de chercheurs en IA.

   Une note sur les sections de cet article^[27].

   Dans les ann√©es 1940 et 1950, une poign√©e de scientifiques d'une large
   gamme de domaines (math√©matiques, psychologie, ing√©nierie, √©conomie et
   science politique) ont commenc√© √† discuter de la possibilit√© de cr√©er
   un cerveau artificiel. Ce domaine de recherche de l'intelligence
   artificielle a √©t√© fond√© en tant que discipline acad√©mique en
   1956^[28].

Cybern√©tique et premiers r√©seaux neuronaux[modifier | modifier le code]

   Les toutes premi√®res recherches dans le domaine des machines pensantes
   ont √©t√© inspir√©es par une convergence d'id√©es qui se sont
   progressivement r√©pandues de la fin des ann√©es 1930 au d√©but des ann√©es
   1950. De r√©centes recherches en neurologie ont montr√© que le cerveau
   √©tait un r√©seau √©lectrique de neurones qui envoyaient des impulsions de
   type tout-ou-rien. La cybern√©tique de Norbert Wiener a d√©crit les
   contr√¥les et la stabilit√© dans les r√©seaux √©lectriques. La th√©orie de
   l'information de Claude Shannon d√©taille des signaux num√©riques (i.e.,
   signaux tout-ou-rien). La th√©orie du calcul d'Alan Turing montre que
   toute forme de calcul peut √™tre repr√©sent√©e num√©riquement. Les
   relations √©troites entre ces id√©es sugg√®rent la possibilit√© de
   construire un cerveau artificiel^[29].

   On peut citer comme exemples de travaux de cette veine les robots tels
   que les Tortues de Bristol de William Grey Walter et la B√™te de Johns
   Hopkins (en). Ces machines n'utilisent pas d'ordinateurs,
   d'√©lectronique num√©rique ni de raisonnement symbolique ; elles √©taient
   enti√®rement contr√¥l√©es par des circuits analogiques^[30].

   Walter Pitts et Warren McCulloch ont analys√© des r√©seaux de neurones
   artificiels id√©aux et ont montr√© comment ils pourraient effectuer de
   simples op√©rations logiques. Ils ont √©t√© les premiers √† √©voquer ce que
   des chercheurs plus tard appelleraient un r√©seau neuronal^[31].

   Un des √©tudiants inspir√©s par Pitts et McCulloch √©tait Marvin Minsky, √
   l'√©poque jeune √©tudiant de 24 ans. En 1951 (avec Dean Edmonds), il
   construisit la premi√®re machine √† r√©seau neuronal, le SNARC^[32].
   Minsky allait devenir l'un des plus importants leaders et innovateurs
   en IA des cinquante ann√©es suivantes.

L'intelligence artificielle dans les jeux[modifier | modifier le code]

   En 1951, en utilisant la machine Ferranti Mark I de l'universit√© de
   Manchester, Christopher Strachey a √©crit un programme de jeu de dames
   et Dietrich Prinz un programme de jeu d'√©checs^[33]. Le jeu de dames
   d'Arthur Samuel, d√©velopp√© au milieu des ann√©es 1950 et au d√©but des
   ann√©es 1960, a fini par acqu√©rir un niveau suffisant pour d√©fier un bon
   amateur^[34]. De fait, l'intelligence artificielle dans les jeux sert
   d'√©talon des avanc√©es de l'intelligence artificielle.

Test de Turing[modifier | modifier le code]

   En 1950 Alan Turing publie un article m√©morable dans lequel il sp√©cule
   sur la possibilit√© de cr√©er des machines dot√©es d'une v√©ritable
   intelligence^[35]. Il remarque qu'il est difficile de d√©finir
   l'¬´ intelligence ¬ª et imagine son c√©l√®bre test de Turing. Si une
   machine peut mener une conversation (par t√©l√©scripteur interpos√©) qu'on
   ne puisse diff√©rencier d'une conversation avec un √™tre humain, alors la
   machine pouvait √™tre qualifi√©e d'¬´ intelligente ¬ª. Cette version
   simplifi√©e du probl√®me a permis √† Turing d'argumenter de mani√®re
   convaincante qu'une ¬´ machine pensante ¬ª √©tait au-moins plausible, cet
   article r√©pondant √† toutes les objections classiques √† cette
   proposition^[36]. Le test de Turing a √©t√© la premi√®re hypoth√®se
   s√©rieuse dans le domaine de la philosophie de l'intelligence
   artificielle.

Raisonnement symbolique et le th√©oricien logique[modifier | modifier le code]

   Quand l'acc√®s aux ordinateurs est devenu possible au milieu des ann√©es
   1950, des scientifiques, en petit nombre au d√©but, ont compris qu'une
   machine qui pouvait manipuler des nombres pouvait aussi manipuler des
   symboles et que cette manipulation de symboles pouvait potentiellement
   √™tre l'essence-m√™me de la pens√©e humaine. Cela a conduit √
   l'√©laboration des premi√®res machines pensantes^[37].

   En 1955, Allen Newell et le futur prix Nobel d'√©conomie, Herbert Simon,
   avec l'aide de Cliff Shaw, ont cr√©√© le ¬´ Th√©oricien logique ¬ª. Le
   programme finira par d√©montrer 38 des 52 premiers th√©or√®mes des
   Principia Mathematica de Russell et Whitehead, et a m√™me trouv√© des
   d√©monstrations in√©dites et √©l√©gantes^[38]. Simon raconte qu'ils ont
   ¬´ r√©solu le v√©n√©rable probl√®me corps-esprit, expliquant comment un
   syst√®me compos√© de mati√®re peut avoir des propri√©t√©s de
   l'esprit^[39] ¬ª. C'est l'une des premi√®res formulations d'un mouvement
   philosophique que John Searle appellera plus tard ¬´ intelligence
   artificielle forte ¬ª : comme les humains, les machines peuvent poss√©der
   un esprit^[40].

La traduction automatique des langages[modifier | modifier le code]

   En 1949, Warren Weaver publie son memorandum sur la traduction
   automatique des langues naturelles^[41] qui est √† la fois visionnaire
   et optimiste sur le futur de ce probl√®me fondamental de l'intelligence
   artificielle.

Conf√©rence de Dartmouth de 1956 : naissance de l'intelligence
artificielle[modifier | modifier le code]

   Article d√©taill√© : conf√©rence de Dartmouth.

   La conf√©rence de Dartmouth de 1956^[42] a √©t√© organis√©e par Marvin
   Minsky, John McCarthy et deux scientifiques seniors : Claude Shannon et
   Nathan Rochester (en) d'IBM. La th√®se de la conf√©rence incluait cette
   assertion : ¬´ chaque aspect de l'apprentissage ou toute autre
   caract√©ristique de l'intelligence peut √™tre si pr√©cis√©ment d√©crit
   qu'une machine peut √™tre con√ßue pour le simuler^[43] ¬ª. Parmi les
   participants on retrouve Ray Solomonoff, Oliver Selfridge, Trenchard
   More, Arthur Samuel, Allen Newell et Herbert Simon, qui vont tous cr√©er
   des programmes importants durant les premi√®res d√©cennies de la
   recherche en IA^[44]. √Ä la conf√©rence, Newell et Simon ont
   d√©but√©^[incompr√©hensible] le ¬´ Th√©oricien Logique ¬ª (logic theorist) et
   McCarthy a convaincu l'auditoire d'accepter l'expression ¬´ Intelligence
   Artificielle ¬ª comme intitul√© du domaine^[45]. La conf√©rence de
   Dartmouth de 1956 a √©t√© le moment-cl√© o√π l'intelligence artificielle a
   √©t√© appel√©e comme telle, a d√©fini ses objectifs, a concr√©tis√© ses
   premi√®res r√©ussites et a r√©uni ses acteurs importants. Cette conf√©rence
   est largement consid√©r√©e, dans le monde occidental, comme le moment
   fondateur de l'intelligence artificielle en tant que discipline
   th√©orique ind√©pendante (de l'informatique)^[r√©f. n√©cessaire]^[46].

L'√¢ge d'or 1956‚àí1974[modifier | modifier le code]

   Les ann√©es qui suivent la conf√©rence de Dartmouth sont une √®re de
   d√©couverte, de conqu√™tes effr√©n√©es de nouvelles contr√©es du savoir. Les
   programmes d√©velopp√©s √† l'√©poque sont consid√©r√©s par la plupart des
   gens comme simplement ¬´ extraordinaires^[47] ¬ª : des ordinateurs
   r√©solvent des probl√®mes alg√©briques de mots, d√©montrent des th√©or√®mes
   en g√©om√©trie et apprennent √† parler anglais. √Ä cette √©poque, peu
   croient que de tels comportements ¬´ intelligents ¬ª soient possibles
   pour des machines^[48]. Les chercheurs font preuve alors d'un optimisme
   intense dans le priv√© comme dans leurs articles, ils pr√©disent qu'une
   machine compl√®tement intelligente sera construite dans les 20 ans √
   venir^[49]. Les agences gouvernementales comme la DARPA investissent
   massivement dans ce nouveau domaine^[50].

Les perc√©es[modifier | modifier le code]

   Beaucoup de programmes sont couronn√©s de succ√®s.

Raisonnement par t√¢tonnements[modifier | modifier le code]

   Ils sont nombreux parmi les premiers programmes d'intelligence
   artificielle √† utiliser le m√™me algorithme fondamental. Pour remplir
   certains objectifs (comme gagner un jeu ou d√©montrer un th√©or√®me), ils
   proc√®dent pas √† pas vers la solution (en effectuant un mouvement ou une
   d√©duction √† la fois) comme s'ils naviguent dans un labyrinthe, revenant
   en arri√®re d√®s qu'ils se heurtent √† une impasse. Ce paradigme est
   appel√© ¬´ raisonnement par t√¢tonnements^[51] ¬ª ou retour sur trace.

   La principale difficult√© r√©side dans le fait que, pour beaucoup de
   probl√®mes, le nombre de chemins possibles vers la solution est
   astronomique, c'est la fameuse ¬´ explosion combinatoire ¬ª. Des
   chercheurs ont alors essay√© de r√©duire l'espace de recherche √† l'aide
   d'heuristiques ou de ¬´ r√®gles empiriques ¬ª qui √©liminent la plupart des
   chemins dont il est peu probable qu'ils m√®nent √† une solution^[52].

   Newell et Simon essaient de capturer une version g√©n√©rale de cet
   algorithme dans un programme appel√© le General Problem Solver^[53]
   (¬´ solutionneur de probl√®me g√©n√©ral ¬ª). Certains programmes de
   ¬´ recherche ¬ª sont capables d'accomplir des t√¢ches jug√©es √† l'√©poque
   impressionnantes comme la r√©solution de probl√®mes g√©om√©triques et
   alg√©briques, tels que le Geometry Theorem Prover d'Herbert Gelernter
   (1958) et le SAINT, √©crit par James Slagle, un des √©tudiants de
   Minsky^[54] (1961). D'autres programmes cherchent √† travers des
   objectifs et sous-objectifs pour planifier des actions, comme le
   syst√®me STRIPS d√©velopp√© √† Stanford pour contr√¥ler le comportement de
   leur robot, Shakey^[55].
   [400px-SemanticNetArbre_s%C3%A9mantique_fr.jpg] Un exemple de r√©seau
   s√©mantique.

Langage naturel[modifier | modifier le code]

   Un but majeur de la recherche en IA est de permettre aux ordinateurs de
   communiquer en langage naturel comme l'anglais. Un des premiers succ√®s
   √©tait le programme STUDENT de Bobrow, qui pouvait r√©soudre des
   probl√®mes alg√©briques r√©dig√©s pour lyc√©ens^[56].

   Un r√©seau s√©mantique repr√©sente des concepts (par ex. ¬´ maison ¬ª,
   ¬´ porte ¬ª) √† l'aide de n≈ìuds et les relations entre les concepts (par
   ex. ¬´ poss√®de un ¬ª) par des liaisons entre ces n≈ìuds. Le premier
   programme d'IA √† utiliser un r√©seau s√©mantique a √©t√© √©crit par Ross
   Quillian^[57] et la version la plus performante (et controvers√©e) a √©t√©
   la Conceptual dependency theory de Roger Schank^[58].

   ELIZA de Joseph Weizenbaum pouvait mener des conversations si r√©alistes
   que certains utilisateurs se sont laiss√© abuser en croyant communiquer
   avec un √™tre humain et non un programme. En r√©alit√©, ELIZA n'avait
   aucune id√©e de ce dont elle parlait. Elle donnait simplement une
   ¬´ r√©ponse-bateau ¬ª ou reformulait en r√©ponse gr√¢ce √† quelques r√®gles de
   grammaire. ELIZA √©tait le premier agent conversationnel^[59].

Micro-mondes[modifier | modifier le code]

   √Ä la fin des ann√©es 1960, Marvin Minsky et Seymour Papert du
   Laboratoire d'IA du MIT ont propos√© que la recherche d'IA se concentre
   sur des situations artificiellement simplifi√©es appel√©es aussi
   micro-mondes. Ils ont mentionn√© √† juste titre que dans les sciences
   performantes comme la physique, les principes fondamentaux √©taient
   souvent mieux compris en utilisant des mod√®les simplifi√©s tels que des
   avions sans friction, ou des corps parfaitement rigides. La majorit√© de
   la recherche s'est alors centr√©e sur un ¬´ monde-blocs ¬ª, qui consistait
   en un ensemble de blocs color√©s de formes et tailles vari√©es dispos√©s
   sur une surface plane^[60].

   Ce paradigme a permis des travaux innovants dans la vision industrielle
   de Gerald Sussman (qui dirigeait l'√©quipe), Adolfo Guzman, David Waltz
   (qui inventa la ¬´ propagation de contraintes ¬ª), et surtout Patrick
   Winston. Au m√™me moment, Minsky et Papert construisait un bras
   robotique qui empilait des blocs, insufflant la vie dans ces
   monde-blocs. La plus grande r√©ussite de ces programmes micro-mondes a
   √©t√© le SHRDLU de Terry Winograd. Ce dernier pouvait communiquer en
   anglais √† l'aide de phrases ordinaires, planifier des op√©rations et les
   ex√©cuter^[61].

L'optimisme[modifier | modifier le code]

   La premi√®re g√©n√©ration de chercheurs en IA fait les pr√©visions
   suivantes √† propos de leur travail :
     * En 1958, H. Simon et Allen Newell : ¬´ d'ici dix ans un ordinateur
       sera le champion du monde des √©checs ¬ª et ¬´ d'ici dix ans, un
       ordinateur d√©couvrira et r√©soudra un nouveau th√©or√®me math√©matique
       majeur^[62] ¬ª.
     * En 1965, H. Simon : ¬´ des machines seront capables, d'ici vingt
       ans, de faire tout travail que l'homme peut faire^[63] ¬ª.
     * En 1967, Marvin Minsky : ¬´ dans une g√©n√©ration [...] le probl√®me de
       la cr√©ation d'une 'intelligence artificielle' [sera] en grande
       partie r√©solu^[64] ¬ª.
     * En 1970, Marvin Minsky (dans le magazine Life) : ¬´ Dans trois √
       huit ans nous aurons une machine avec l'intelligence g√©n√©rale d'un
       √™tre humain ordinaire^[65] ¬ª.

Le financement[modifier | modifier le code]

   En juin 1963 le MIT re√ßoit une subvention de 2,2 millions de dollars de
   la toute jeune ARPA (¬´ Agence pour les projets de recherche avanc√©e ¬ª,
   qui deviendra plus tard la DARPA). L'argent est utilis√© pour financer
   le Projet MAC (en) qui englobe le ¬´ Groupe IA ¬ª fond√© par Minsky et
   McCarthy cinq ans plus t√¥t. L'ARPA continue √† fournir trois millions de
   dollars par an jusqu'aux ann√©es 1970^[66]. L'ARPA fait des subventions
   similaires au programme de Newell et Simon √† Carnegie-Mellon et au
   projet Stanford I.A. (fond√© par John McCarthy en 1963)^[67]. Un autre
   laboratoire important d'IA est √©tabli √† l'universit√© d'√âdimbourg par
   Donald Michie en 1965^[68]. Ces quatre institutions continuent d'√™tre
   les principaux centres de recherche en IA au niveau acad√©mique pendant
   de nombreuses ann√©es^[69].

   L'argent est distribu√© avec peu de contr√¥le. L'ancien professeur de
   Minsky √† Harvard, J. C. R. Licklider, alors √† la t√™te du ¬´ Bureau des
   Techniques de Traitement de l'Information ¬ª (IPTO) et directeur du
   Programme Command & Control de l'ARPA, pense que son organisation doit
   ¬´ financer des personnes, pas des projets ! ¬ª et autorise les
   chercheurs √† poursuivre toutes les pistes qui leur semblent
   int√©ressantes^[70]. Cela cr√©e une atmosph√®re de libert√© totale au MIT
   qui donne ainsi naissance √† la culture hacker^[71]. √Ä Licklider
   (1962-64) succ√®dent Ivan Sutherland (1964-66), Robert Taylor (1966-69)
   et Lawrence Roberts (1969-1972), tous proches du MIT et dans la
   continuit√© de Licklider vis-√†-vis de l'IA. N√©anmoins cette attitude non
   interventionniste ne dure pas.

La premi√®re hibernation de l'intelligence artificielle (1974‚àí1980)[modifier |
modifier le code]

   Dans les ann√©es 1970, l'intelligence artificielle subit critiques et
   revers budg√©taires, car les chercheurs en intelligence artificielle
   n'ont pas une vision claire des difficult√©s des probl√®mes auxquels ils
   sont confront√©s. Leur immense optimisme a engendr√© une attente
   excessive et quand les r√©sultats promis ne se mat√©rialisent pas, les
   investissements consacr√©s √† l'intelligence artificielle
   s'√©tiolent^[72]. Dans la m√™me p√©riode, le connexionisme a √©t√© presque
   compl√©tement mis sous le boisseau pour 10 ans par la critique
   d√©vastatrice de Marvin Minsky sur les perceptrons^[73]. Malgr√© l'image
   n√©gative de l'intelligence artificielle dans le grand public √† la fin
   des ann√©es 1970, de nouvelles id√©es sont explor√©es en programmation
   logique, raisonnement de bon sens^[Note 3] et dans d'autres
   directions^[74].

Les probl√®mes[modifier | modifier le code]

   Au d√©but des ann√©es 1970, les capacit√©s des programmes d'IA sont
   limit√©es. Les plus performants peinent √† manipuler des versions
   simplistes des probl√®mes qu'ils sont suppos√©s r√©soudre et tous les
   probl√®mes sont, d'une certaine mani√®re, des ¬´ broutilles^[75] ¬ª. De
   fait, les chercheurs en IA font face √† plusieurs limites fondamentales
   insurmontables et bien que certaines limites soient d√©pass√©es depuis,
   d'autres demeurent de vrais obstacles^[76].

Limites de la puissance de calcul[modifier | modifier le code]

   La puissance et la m√©moire de l'√©poque √©taient consid√©r√©es √† juste
   titre comme un v√©ritable frein √† des applications pratiques ; elles
   suffisaient √† peine pour d√©montrer des mod√®les simplistes.

   Ainsi, le travail de Ross Quillian sur le langage naturel est limit√© √
   un vocabulaire de vingt mots, car la m√©moire ne peut pas en contenir
   plus^[77].

   En outre, Hans Moravec se plaint en 1976 du fait que les ordinateurs
   soient des millions de fois trop faibles pour faire montre d'une
   quelconque intelligence, qu'ils sont loin d'atteindre le seuil critique
   minimal. Pour mieux faire comprendre ce qu'il entend par seuil, il
   utilise l'analogie suivante : ¬´ En dessous d'un certain niveau de
   puissance, un avion reste plaqu√© au sol et ne peut pas d√©coller du
   tout, c'est juste impossible ¬ª. N√©anmoins comme la puissance
   informatique augmente, √ßa finira par devenir possible^[78]^,^[Note 4].

   Quant √† la vision par ordinateur, Moravec estime que le simple fait
   d'√©galer les capacit√©s de la r√©tine humaine √† d√©tecter les mouvements
   et les contours en temps r√©el (probl√®me simple de nos jours)
   n√©cessiterait un ordinateur g√©n√©rique capable de 10^9 op√©rations par
   seconde (1 000 MIPS^[79]). Par comparaison, l'ordinateur le plus rapide
   en 1976, le Cray-1 (vendu entre 5 et 8 000 000 $), est seulement
   capable d'environ 80 √† 130 MIPS, et un ordinateur de bureau typique de
   l'√©poque n'atteint m√™me pas 1 MIPS. En fait, son estimation,
   impressionnante pour l'√©poque, s'est av√©r√©e trop optimiste : en 2011,
   les applications de vision par ordinateur concr√®tes ont besoin de dix √
   mille fois plus de puissance, se situant plut√¥t entre 10 000 √
   1 000 000 MIPS.

Limites inh√©rentes : la compl√©tude NP[modifier | modifier le code]

   En 1972, √† la suite du th√©or√®me de Cook, Richard Karp a montr√© qu'il y
   avait de nombreux probl√®mes tr√®s difficiles, pour lesquels trouver des
   solutions optimales √©tait impensable, avec comme cons√©quence que les
   probl√®mes fondamentaux de l'intelligence artificielle ne passeront pas
   √† l'√©chelle^[80].

Raisonnement et base de connaissance de culture g√©n√©rale[modifier | modifier
le code]

   De nombreuses applications majeures d'intelligence artificielle comme
   la vision par ordinateur ou le traitement automatique du langage
   naturel ont besoin d'√©normes quantit√©s d'information du monde r√©el pour
   mettre en place des programmes capable de ¬´ comprendre ¬ª ce qu'il voit
   ou de discuter. D√®s les ann√©es 1970, les chercheurs dans ces domaines
   d√©couvrent que la quantit√© d'information correspondante est tr√®s
   grande, bien qu'un enfant l'acquiert tr√®s rapidement. √Ä cette √©poque,
   il n'√©tait pas envisageable de construire une telle base de donn√©es ni
   un programme capable de g√©rer autant d'information^[81]^,^[82]^,^[83].

Le paradoxe de Moravec[modifier | modifier le code]

   Article d√©taill√© : paradoxe de Moravec.

   Les chercheurs en intelligence artificielle et en robotique Hans
   Moravec, Rodney Brooks et Marvin Minsky mirent en √©vidence que le
   raisonnement de haut niveau est souvent plus facile √† reproduire et
   simuler par un programme informatique que les aptitudes sensorimotrices
   humaines. Ceci peut sembler contre-intuitif du fait qu'un humain n'a
   pas de difficult√© particuli√®re √† effectuer des t√¢ches relevant de cette
   derni√®re cat√©gorie, contrairement √† la premi√®re.

   Par exemple, d√©montrer des th√©or√®mes ou r√©soudre des probl√®mes
   g√©om√©triques est relativement faisable par les ordinateurs, mais une
   t√¢che plus simple pour un humain, comme reconna√Ætre un visage ou
   traverser une pi√®ce sans collision, a longtemps √©t√© tr√®s compliqu√© pour
   les machines. Ainsi, la recherche en vision par ordinateur et en
   robotique a fait peu de progr√®s au milieu des ann√©es 1970^[84]^,^[85].

Le cadre et les probl√®mes de qualification[modifier | modifier le code]

   Les chercheurs en IA (comme John McCarthy) qui se sont servis de la
   logique ont d√©couvert qu'ils ne pouvaient pas repr√©senter des
   d√©ductions ordinaires qui impliquaient de la planification ou des
   raisonnements par d√©faut sans avoir √† modifier la structure de la
   logique elle-m√™me. Ils ont d√ª d√©velopper de nouvelles logiques (comme
   les logiques non monotones et modales) pour essayer de r√©soudre ces
   probl√®mes^[86].

La fin des investissements[modifier | modifier le code]

   Les agences qui ont investi dans la recherche en IA (comme le
   gouvernement britannique, la DARPA et le NRC, Conseil am√©ricain de la
   recherche) deviennent frustr√©es par le manque de progr√®s et finissent
   par couper pratiquement tous les fonds de recherche fondamentale en IA.
   Ce comportement commence d√®s 1966 quand un rapport de l'ALPAC^[Note 5]
   para√Æt critiquer les efforts de traduction automatis√©e. Apr√®s avoir
   d√©pens√© 20 millions de dollars, le NRC d√©cide de tout arr√™ter^[87]. En
   1973, le Rapport Lighthill (en) sur l'√©tat de la recherche en IA en
   Angleterre a critiqu√© l'√©chec lamentable de l'IA √† atteindre ses
   ¬´ ambitieux objectifs ¬ª et a conduit au d√©mant√®lement de la recherche
   en IA dans ce pays^[88] (Ce rapport mentionne en particulier le
   probl√®me d'explosion combinatoire comme une des raisons des √©checs de
   l'IA^[89]). Quant √† la DARPA, elle a √©t√© extr√™mement d√©√ßue par les
   chercheurs travaillant dans le programme Speech Understanding Research
   √† Carnegie-Mellon et a annul√© une subvention annuelle de trois millions
   de dollars^[90]. Vers 1974, trouver des financements pour des projets
   d'IA √©tait donc chose rare.

   Hans Moravec a attribu√© la crise aux pr√©dictions irr√©alistes de ses
   coll√®gues. ¬´ Beaucoup de chercheurs se sont retrouv√©s pi√©g√©s dans un
   entrelacs d'exag√©rations croissantes^[91]. ¬ª Un autre probl√®me est
   apparu : le vote de l'amendement Mansfield en 1969, a mis la DARPA sous
   une pression croissante pour qu'elle ne finance que des ¬´ recherches
   directement applicables, plut√¥t que des recherches exploratoires
   fondamentales ¬ª. Un financement pour de l'exploration cr√©ative, en roue
   libre, tel qu'il avait cours dans les ann√©es soixante ne viendrait plus
   de la DARPA. Au lieu de cela, l'argent √©tait redirig√© vers des projets
   sp√©cifiques avec des objectifs pr√©cis, comme des chars de combat
   autonomes ou des syst√®mes de gestion de batailles^[92].

Critiques universitaires[modifier | modifier le code]

   Plusieurs philosophes √©mettent de fortes objections aux affirmations
   des chercheurs en IA. Un des premiers opposants est John Lucas, qui
   s'appuie sur le th√©or√®me d'incompl√©tude de G√∂del pour contester
   l'aptitude des d√©monstrateurs automatiques de th√©or√®mes √† d√©montrer
   certaines affirmations^[93]. Hubert Dreyfus ridiculise les promesses
   non tenues des ann√©es soixante et critique les hypoth√®ses de l'IA,
   argumentant que le raisonnement humain avait en fait besoin de tr√®s peu
   de ¬´ traitement symbolique ¬ª mais surtout de sentiment d‚Äôembodiment,
   d'instinct, d'un ¬´ savoir-faire ¬ª inconscient^[94]^,^[95]. L'argument
   de la chambre chinoise avanc√© par John Searle en 1980, tente de montrer
   qu'on ne peut pas dire qu'un programme ¬´ comprend ¬ª les symboles qu'il
   utilise (une qualit√© appel√©e ¬´ intentionnalit√© ¬ª). Si les symboles
   n'ont aucun sens pour la machine, on ne peut, dixit Searle, qualifier
   la machine de ¬´ pensante^[96] ¬ª.

   Ces critiques ne sont pas vraiment prises en consid√©ration par les
   chercheurs en IA, tant certaines ne visent pas l'essence du probl√®me.
   Les questions telles que l'ind√©cidabilit√©, la complexit√© inh√©rente ou
   la d√©finition de la culture g√©n√©rale semblent beaucoup plus imm√©diates
   et graves. Ils pensent que la diff√©rence entre le ¬´ savoir-faire ¬ª et
   l'¬´ intentionnalit√© ¬ª n'apporte presque rien √† un programme
   informatique. Minsky dit de Dreyfus et Searle qu'¬´ ils ont mal compris
   la question et on devrait les ignorer^[97] ¬ª. Les critiques de Dreyfus,
   qui enseigne au MIT, sont accueillies fra√Æchement : il a plus tard
   avou√© que les chercheurs en IA ¬´ n'osaient pas manger avec moi de peur
   que nous soyons vus ensemble^[98] ¬ª. Joseph Weizenbaum, l'auteur
   d'ELIZA, consid√®re, lui, que le comportement de ses coll√®gues √† l'√©gard
   de Dreyfus est non professionnel et infantile. Bien qu'il critique
   ouvertement les positions de Dreyfus, il fait clairement comprendre que
   ce n'est pas [comme cela] qu'il faut traiter quelqu'un^[99].

   Weizenbaum commence √† avoir de s√©rieux doutes √©thiques √† propos de l'IA
   quand Kenneth Colby √©crit DOCTOR, un agent conversationnel th√©rapeute.
   Weizenbaum est g√™n√© par le fait que Colby voit en son programme sans
   esprit un outil th√©rapeutique s√©rieux. Une querelle √©clate alors, et la
   situation empire quand Colby omet de mentionner la contribution de
   Weizenbaum au programme. En 1976, Weizenbaum publie Puissance
   informatique et raison humaine (en) qui explique que le mauvais usage
   de l'intelligence artificielle peut potentiellement conduire √
   d√©valoriser la vie humaine^[100].

Perceptrons et la p√©riode sombre du connexionnisme[modifier | modifier le
code]

   Un perceptron est un type de r√©seaux neuronaux introduit en 1958 par
   Frank Rosenblatt^[101]. Comme la plupart des chercheurs en IA de
   l'√©poque, il est optimiste, pr√©disant qu'¬´ un perceptron pourra √™tre
   capable d'apprendre, de prendre des d√©cisions, et de traduire les
   langues ¬ª. Un programme de recherche dynamique sur ces concepts est
   men√© dans les ann√©es soixante, mais il s'arr√™te brutalement apr√®s la
   publication du livre de Minsky et Papert en 1969 intitul√© Perceptrons.
   Ce livre constate plusieurs limites √† ce que les perceptrons peuvent
   faire et note plusieurs exag√©rations dans les pr√©dictions de Frank
   Rosenblatt. L'effet du livre est d√©vastateur : aucune recherche dans le
   domaine du connexionnisme ne se fait pendant dix ans. Ce n'est qu'apr√®s
   une d√©cennie, qu'une nouvelle g√©n√©ration de chercheurs se r√©attaque au
   probl√®me, notamment en France, Guy Perennou et Serge Castan^[102].

Les √©l√©gants : calcul des pr√©dicats, Prolog et syst√®mes experts[modifier |
modifier le code]

   John McCarthy introduit l'usage de la logique en IA d√®s 1958, dans son
   Advice Taker^[Note 6]^,^[103]. En 1963, J. Alan Robinson d√©couvre une
   m√©thode relativement simple pour impl√©menter la d√©duction. Pour cela il
   invente les concepts de r√©solution et d'unification. En effet, des
   impl√©mentations plus directes, comme celles essay√©es par McCarthy et
   ses √©tudiants √† la fin des ann√©es soixante, se sont r√©v√©l√©es
   particuli√®rement inefficaces, car les algorithmes requi√®rent un nombre
   astronomique d'√©tapes pour d√©montrer des th√©or√®mes tr√®s simples^[104].
   Une utilisation plus fructueuse de la logique a √©t√© d√©velopp√©e dans les
   ann√©es 1970 par Alain Colmerauer et Philippe Roussel √† l'universit√© de
   Marseille-Luminy et Robert Kowalski (en) √† l'universit√© d'√âdimbourg qui
   ont cr√©√© le langage de programmation Prolog^[105]. Prolog utilise un
   sous-ensemble du calcul des pr√©dicats, les clauses de Horn, qui permet
   des calculs plus efficaces. D'autres chercheurs utilisent des r√®gles de
   production, notamment les syst√®mes experts d'Edward Feigenbaum et les
   logiciels d'Allen Newell et Herbert Simon qui conduit √† Soar et la
   Th√©ory unifi√©e de la cognition [¬´ Unified Theory of Cognition ¬ª],
   1990^[106].

   L'approche logique a √©t√© critiqu√©e d√®s son apparition. Ainsi Hubert
   Dreyfus note que les √™tres humains se servent rarement de logique quand
   ils r√©solvent des probl√®mes. Les exp√©riences de psychologues tels que
   Peter Wason, Eleanor Rosch, Amos Tversky, Daniel Kahneman et d'autres
   corroborent plus ou moins cet avis^[107]. McCarthy a r√©torqu√© que ce
   que les humains font n'est pas pertinent, expliquant que le but est
   d'avoir des machines qui peuvent r√©soudre des probl√®mes, pas des
   machines qui pensent comme des humains^[108]. Mais la critique la plus
   s√©v√®re de l'approche fond√©e sur la d√©duction automatique vient du
   th√©oricien de l'informatique Stephen Cook qui montre dans son c√©l√®bre
   article The Complexity of Theorem-Proving Procedures (¬´ La complexit√©
   des proc√©dures de d√©monstration de th√©or√®mes ¬ª) qu'il n'y a pas de
   proc√©dures automatiques efficaces de d√©monstration de th√©or√®mes sauf si
   P = NP.

Les brouillons : cadres et scripts[modifier | modifier le code]

   Parmi les critiques de l'approche de McCarthy on trouve ses coll√®gues √
   travers le pays au MIT Marvin Minsky, Seymour Papert et Roger Schank
   ont essay√© de r√©soudre des probl√®mes comme la ¬´ compr√©hension d'une
   histoire ¬ª et la ¬´ reconnaissance d'objets ¬ª qui requi√®rent d'une
   machine de penser comme une personne. Pour manipuler des concepts
   ordinaires comme une ¬´ chaise ¬ª ou un ¬´ restaurant ¬ª, elles doivent
   faire toutes les m√™mes hypoth√®ses plus ou moins logiques que les gens
   font habituellement. Malheureusement, de tels concepts impr√©cis sont
   difficiles √† repr√©senter en logique. Gerald Sussman observe
   qu'¬´ utiliser un langage pr√©cis pour d√©crire des concepts impr√©cis ne
   rend pas ces derniers plus pr√©cis^[109] ¬ª. Schank d√©crit ces approches
   alogiques comme ¬´ brouillonnes (en) ¬ª, qu'il oppose aux paradigmes
   ¬´ √©l√©gants (en) ¬ª utilis√©s par McCarthy, Kowalski, Feigenbaum, Newell
   et Simon^[110].

   En 1975, Minsky remarque que beaucoup de ses pairs ¬´ brouillons ¬ª
   utilisent la m√™me approche, √† savoir un cadre de travail qui englobe
   toutes les hypoth√®ses de culture g√©n√©rale (en) d'un th√®me donn√©. Par
   exemple, si on manipule le concept ¬´ oiseau ¬ª, une multitude de faits
   viennent √† l'esprit, ainsi on peut pr√©tendre qu'il vole, qu'il mange
   des vers, etc.. On sait que ces faits ne sont pas toujours vrais et que
   les d√©ductions √† partir de ces faits ne sont pas toutes ¬´ logiques ¬ª,
   mais ces ensembles structur√©s d'hypoth√®ses font partie du contexte de
   nos discussions ou de nos pens√©es. Minsky appelle ces structures des
   ¬´ cadres ¬ª. Schank, quant √† lui, introduit une variante des cadres
   qu'il appelle des ¬´ scripts ¬ª afin de r√©pondre √† des questions sur des
   romans anglophones^[111]. Certains affirment que quelques ann√©es plus
   tard la programmation orient√©e objet empruntera aux cadres de
   l'intelligence artificielle la notion d'¬´ h√©ritage ¬ª.

Le boom 1980‚Äì1987[modifier | modifier le code]

   Dans les ann√©es 1980, des programmes d'IA appel√©s ¬´ syst√®mes experts ¬ª
   sont adopt√©s par les entreprises et la connaissance devient le sujet
   central de la recherche en IA. Au m√™me moment, le gouvernement japonais
   finance massivement l'IA √† travers son initiative ¬´ ordinateurs de
   cinqui√®me g√©n√©ration (en) ¬ª. Un autre √©v√®nement est la renaissance du
   connexionnisme √† travers les travaux de John Hopfield et David
   Rumelhart.

La mont√©e des syst√®mes experts[modifier | modifier le code]

   Un syst√®me expert est un programme qui r√©pond √† des questions ou r√©sout
   des probl√®mes dans un domaine de connaissance donn√©, √† l'aide de r√®gles
   logiques d√©riv√©es de la connaissance des experts humains de ce domaine.
   Les tout premiers exemplaires sont d√©velopp√©s par Edward Feigenbaum et
   ses √©tudiants. Dendral, commenc√© en 1965, identifie des composants
   chimiques √† partir de relev√©s spectrom√©triques. Mycin, d√©velopp√© en
   1972, permet de diagnostiquer des maladies infectieuses du sang. Ces
   programmes confirment la viabilit√© de l'approche^[112].

   Les syst√®mes experts se limitent volontairement √† un petit domaine de
   connaissance sp√©cifique (esquivant ainsi le probl√®me de culture
   g√©n√©rale) et leur conception simple permet de construire ces logiciels
   relativement facilement et de les am√©liorer une fois d√©ploy√©s.
   Finalement, ces programmes se r√©v√®lent utiles, car c'est la premi√®re
   fois que l'intelligence artificielle trouve une application
   pratique^[113].

   En 1980, un syst√®me expert appel√© Xcon, dont l'objectif est d'optimiser
   la configuration des ordinateurs VAX √† livrer aux clients, est r√©alis√©
   par Carnegie-Mellon pour DEC. Le succ√®s est √©norme, car l'entreprise
   peut √©conomiser d√®s 1986 jusqu'√† 40 millions de dollars par an^[114].
   D√®s lors, les soci√©t√©s de par le monde commencent √† d√©velopper et √
   d√©ployer leurs syst√®mes experts et vers 1985 plus d'un milliard de
   dollars est d√©pens√© en intelligence artificielle, majoritairement dans
   les centres industriels de recherche et d√©veloppement. Tout un secteur
   industriel se cr√©e autour des syst√®mes experts, dont des constructeurs
   de mat√©riel informatique comme Symbolics et LMI (Lisp Machines, Inc.)
   et des √©diteurs de logiciels tels que IntelliCorp et Aion^[115].

La r√©volution de la connaissance[modifier | modifier le code]

   La puissance des syst√®mes experts vient de l'expertise qu'ils
   contiennent. Ils font partie d'une nouvelle direction de recherche en
   IA qui a gagn√© du terrain dans les ann√©es 1970. ¬´ Les chercheurs en IA
   commen√ßaient √† soup√ßonner ‚Äî avec r√©ticence, car √ßa allait contre le
   canon scientifique de parcimonie ‚Äî que l'intelligence puisse tr√®s bien
   √™tre bas√©e sur la capacit√© √† utiliser une large quantit√© de savoirs
   divers de diff√©rentes mani√®res^[116] ¬ª remarque Pamela McCorduck. ¬´ La
   grande le√ßon des ann√©es soixante-dix a √©t√© que les comportements
   intelligents d√©pendaient √©norm√©ment du traitement de la connaissance,
   parfois d'une connaissance tr√®s avanc√©e dans le domaine d'une t√¢che
   donn√©e^[117]. ¬ª Les syst√®mes de bases de connaissance et l'ing√©nierie
   des connaissances sont devenus centraux dans la recherche en
   intelligence artificielle des ann√©es 1980^[118].

   Les ann√©es 1980 ont aussi vu la naissance de Cyc, la premi√®re tentative
   d'attaque frontale du probl√®me de culture g√©n√©rale : une base de
   donn√©es gigantesque a √©t√© cr√©√©e dans le but de contenir tous les faits
   triviaux qu'une personne moyenne conna√Æt. Douglas Lenat, qui a d√©marr√©
   et dirig√© le projet, argumente qu'il n'y a aucun raccourci ‚Äï le seul
   moyen pour des machines de conna√Ætre la signification de concepts
   humains √©tait de leur apprendre, un concept √† la fois, et manuellement.
   On s'attend bien s√ªr √† ce que le projet se d√©roule sur plusieurs
   d√©cennies^[119].

L'argent est de retour : projets de la cinqui√®me g√©n√©ration[modifier |
modifier le code]

   En 1981, le minist√®re japonais de l'√âconomie, du Commerce et de
   l'Industrie r√©serve 850 millions de dollars pour le projet des
   ordinateurs de cinqui√®me g√©n√©ration (en). Leur objectif est d'√©crire
   des programmes et de construire des machines qui peuvent tenir des
   conversations, traduire, interpr√©ter des images et raisonner comme des
   √™tres humains^[120]. Au grand dam des tenants de l'approche
   brouillonne (en), ils choisissent Prolog comme langage informatique
   principal de leur projet^[121], qu'ils modifient d'ailleurs assez
   profond√©ment pour qu'il s'adapte √† leur besoin.

   D'autres pays r√©pondent avec de nouveaux programmes √©quivalents. Le
   Royaume-Uni d√©marre le projet Alvey (en) de 350 millions de livres. Un
   consortium d'entreprises am√©ricaines forment la Microelectronics and
   Computer Technology Corporation (ou MCC) pour financer des projets en
   informatique et en intelligence artificielle √† grande
   √©chelle^[122]^,^[123]. La DARPA a aussi r√©agi en fondant la Strategic
   Computing Initiative (Initiative Informatique Strat√©gique) et en
   triplant ses investissements en IA entre 1984 et 1988^[124].
   [220px-Hopfield-net-vector.svg.png] Un r√©seau d'Hopfield √† quatre
   n≈ìuds.

La renaissance du connexionnisme[modifier | modifier le code]

   En 1982, le physicien John Hopfield a d√©montr√© qu'un certain type de
   r√©seau neuronal (d√©sormais appel√© un ¬´ r√©seau de Hopfield ¬ª) pouvait
   apprendre et traiter de l'information d'une mani√®re totalement in√©dite.
   Au cours de la m√™me p√©riode, David Rumelhart a rendu populaire une
   nouvelle m√©thode de formation des r√©seaux neuronaux appel√©e
   ¬´ r√©tropropagation du gradient ¬ª (d√©couverte quelques ann√©es avant par
   Paul Werbos). Ces deux nouvelles d√©couvertes ont fait rena√Ætre le champ
   du connexionnisme qui avait √©t√© largement abandonn√© depuis
   1970^[123]^,^[125].

   Le tout jeune domaine a √©t√© unifi√© et inspir√© par l'apparence du
   Traitement Parall√®le Distribu√© de 1986 ‚Äî une collection d'articles en
   deux volumes √©dit√©e par Rumelhart et le psychologue McClelland. Les
   r√©seaux neuronaux deviendront un succ√®s commercial dans les ann√©es
   1990, quand on commencera √† les utiliser comme moteurs d'applications
   telles que la reconnaissance optique de caract√®res et la reconnaissance
   vocale^[123]^,^[126].

La crise : le second hiver de l'IA 1987‚àí1993[modifier | modifier le code]

   La fascination de la communaut√© √©conomique pour l'intelligence
   artificielle a gonfl√© puis chut√© dans les ann√©es 1980 en suivant le
   sch√©ma classique d'une bulle √©conomique. L'effondrement de l'IA a eu
   lieu au niveau de la perception que les investisseurs et les agences
   gouvernementales en avaient ‚Äî le domaine scientifique continue ses
   avanc√©es malgr√© les critiques. Rodney Brooks et Hans Moravec,
   chercheurs dans le domaine voisin de la robotique, plaident pour une
   approche enti√®rement neuve de l'intelligence artificielle.

Une seconde hibernation[modifier | modifier le code]

   L'expression ¬´ hiver de l'IA ¬ª a circul√© parmi les chercheurs qui,
   ayant d√©j√† v√©cu les coupes de budget de 1974, r√©alisent avec inqui√©tude
   que l'excitation autour des syst√®mes experts est hors de contr√¥le et
   qu'il y aurait s√ªrement de la d√©ception derri√®re^[127]. Leurs craintes
   sont effectivement fond√©es : entre la fin des ann√©es 1980 et le d√©but
   des ann√©es 1990, l'intelligence artificielle a subi une s√©rie de coupes
   budg√©taires.

   Les premiers indices d'une temp√™te √† venir ont √©t√© le brusque
   effondrement du march√© du mat√©riel informatique sp√©cialiste de
   l'intelligence artificielle en 1987. Les ordinateurs de bureau d'Apple
   et IBM ont progressivement am√©lior√© leur vitesse et leur puissance et
   en 1987 ils deviennent plus performants que les fleurons du march√©,
   tels que la meilleure machine Lisp de Symbolics. Il n'y a donc plus
   aucune raison de les acheter. Du jour au lendemain, une industrie d'un
   demi-milliard de dollars dispara√Æt totalement^[128].

   Finalement, les premiers syst√®mes experts √† succ√®s comme le Xcon ont un
   co√ªt de maintenance trop √©lev√©. Ils sont difficiles √† mettre √† jour,
   ils ne peuvent pas apprendre, ils sont trop ¬´ fragiles (en) ¬ª (ainsi,
   ils peuvent faire des erreurs grotesques quand les param√®tres sortent
   des valeurs habituelles), et s'emp√™trent dans des probl√®mes (tels que
   le probl√®me de qualification). Les syst√®mes experts se sont r√©v√©l√©s
   utiles, mais uniquement dans des contextes tr√®s sp√©cifiques^[129].

   √Ä la fin des ann√©es 1980, la Strategic Computing Initiative^[Note 7] de
   la DARPA a compl√©tement et abruptement coup√© ses subsides √
   l'intelligence artificielle. Une nouvelle direction de la DARPA ayant
   conclu que l'intelligence artificielle n'est plus de ¬´ derni√®re mode ¬ª,
   elle a redirig√© les subventions vers des projets plus propices √† des
   r√©sultats rapides^[130].

   Vers 1991, les objectifs impressionnants list√©s en 1981 par le Japon
   pour ses Ordinateurs de cinqui√®me g√©n√©ration n'ont pas √©t√© atteints.
   D'ailleurs certains d'entre eux, comme le fait de ¬´ mener une
   conversation ordinaire ¬ª ne l'ont toujours pas √©t√© vingt ans plus
   tard^[131]. Comme pour d'autres projets en intelligence artificielle,
   la barre a √©t√© plac√©e beaucoup trop haut^[131].

L'importance du corps : Nouvelle intelligence artificielle et
embodiment[modifier | modifier le code]

   √Ä la fin des ann√©es 1980, plusieurs chercheurs plaident pour une
   approche de l'intelligence artificielle compl√©tement in√©dite, centr√©e
   sur la robotique^[132]. Ils pensent que pour mettre en √©vidence une
   vraie intelligence, une machine doit avoir conscience de son corps ‚Äî
   elle doit percevoir, bouger, survivre et √©voluer dans le monde. Ils
   expliquent que ces capacit√©s senso-motrices sont essentielles aux
   capacit√©s de plus haut niveau telles que le raisonnement de culture
   g√©n√©rale et que le raisonnement abstrait est en fait la capacit√©
   humaine la moins int√©ressante ou importante (cf. le paradoxe de
   Moravec). Ils d√©fendent une intelligence ¬´ par la base^[133]. ¬ª

   L'approche ravive des concepts n√©s de la cybern√©tique et de la
   r√©gulation qui ont perdu de leur impact depuis les ann√©es soixante. Un
   des pr√©curseurs, David Marr, est arriv√© au MIT √† la fin des ann√©es 1970
   fort de r√©ussites pass√©es en neuroscience th√©orique afin d'y diriger le
   groupe √©tudiant la vision. Il r√©fute toutes les approches symboliques
   (√† la fois la logique de McCarthy et les cadres de Minsky), arguant que
   l'intelligence artificielle a besoin de comprendre la machinerie
   physique de la vision par le bas avant qu'un traitement symbolique
   puisse √™tre mis en place. Son travail a √©t√© brusquement interrompu par
   la leuc√©mie qui l'a frapp√© en 1980^[134].

   Dans un article de 1990 intitul√© Elephants Don't Play Chess^[135]
   (¬´ Les √©l√©phants ne jouent pas aux √©checs ¬ª), le chercheur en robotique
   Rodney Brooks vise directement l'hypoth√®se de syst√®me symbolique
   physique, expliquant que les symboles ne sont pas toujours n√©cessaires
   car ¬´ le monde est son propre mod√®le et c'est le meilleur. Il est
   toujours parfaitement √† jour. Il contient toujours tous les d√©tails
   n√©cessaires. Ce qu'il faut, c'est le mesurer correctement de mani√®re
   r√©p√©t√©e^[136] ¬ª. Dans les ann√©es 1980 et 1990, beaucoup de cogniticiens
   rejettent √©galement le mod√®le de traitement symbolique de l'esprit en
   expliquant que le corps est essentiel dans le raisonnement, une th√®se
   appel√©e embodiment^[137].

1993-2000[modifier | modifier le code]

   Le champ de l'intelligence artificielle, avec plus d'un demi-si√®cle
   derri√®re lui, a finalement r√©ussi √† atteindre certains de ses plus
   anciens objectifs. On a commenc√© √† s'en servir avec succ√®s dans le
   secteur technologique, m√™me sans avoir vraiment √©t√© mise en avant.
   Quelques r√©ussites sont venues avec la mont√©e en puissance des
   ordinateurs et d'autres ont √©t√© obtenues en se concentrant sur des
   probl√®mes isol√©s sp√©cifiques et en les approfondissant avec les plus
   hauts standards d'int√©grit√© scientifique. N√©anmoins, la r√©putation de
   l'IA, dans le monde des affaires au-moins, est loin d'√™tre parfaite. En
   interne, on n'arrive pas √† vraiment expliquer les raisons de l'√©chec de
   l'intelligence artificielle √† r√©pondre au r√™ve d'un niveau
   d'intelligence √©quivalent √† l'Homme qui a captiv√© l'imagination du
   monde dans les ann√©es 1960. Tous ces facteurs expliquent la
   fragmentation de l'IA en de nombreux sous-domaines concurrents
   consacr√©s √† une probl√©matique ou une voie pr√©cise, allant m√™me parfois
   jusqu'√† choisir un nom qui √©vite l'expression d√©sormais souill√©e
   d'¬´ intelligence artificielle^[138] ¬ª. L'IA a du coup √©t√© √† la fois
   plus prudente mais aussi plus fructueuse que jamais.
   [210px-Deep_Blue.jpg] Deep Blue, un ordinateur semblable √† celui-ci a
   battu Garry Kasparov en mai 1997. C'est la premi√®re machine √† remporter
   une partie d'√©checs contre un champion du monde en titre.

Verrous qui sautent et loi de Moore[modifier | modifier le code]

   Le 11 mai 1997, Deep Blue est devenu le premier syst√®me informatique de
   jeu d'√©checs √† battre le champion du monde en titre, Garry
   Kasparov^[139]. En 2005, un robot de Stanford a remport√© le DARPA Grand
   Challenge en conduisant de mani√®re autonome pendant 131 milles sur une
   piste de d√©sert sans avoir fait de reconnaissance pr√©alable^[140]. Deux
   ans plus tard, une √©quipe de Carnegie-Mellon remporte le DARPA Urban
   Challenge, cette fois en naviguant en autonome pendant 55 milles dans
   un environnement urbain tout en respectant les conditions de trafic et
   le code de la route^[141]. En f√©vrier 2011, dans un match de
   d√©monstration du jeu t√©l√©vis√© Jeopardy!, les deux plus grands champions
   de Jeopardy!, Brad Rutter et Ken Jennings ont √©t√© battus avec une marge
   confortable par le syst√®me de questions-r√©ponses con√ßu par IBM, au
   centre de recherche Watson^[142].

   Ces succ√®s ne reposent pas sur de nouveaux paradigmes r√©volutionnaires,
   mais sur une application minutieuse des techniques d'ing√©nierie et sur
   la puissance ph√©nom√©nale des ordinateurs^[143]. En effet, la machine
   Deep Blue est 10 millions de fois plus rapide que la Ferranti Mark I √
   qui Christopher Strachey a appris √† jouer aux √©checs en 1951^[Note 8].
   Cette augmentation spectaculaire suit la loi de Moore, qui pr√©dit que
   la vitesse et la capacit√© de m√©moire des ordinateurs doublent tous les
   deux ans. N'est-on pas en train de faire sauter le verrou de la
   ¬´ puissance informatique ¬ª ?

Agents intelligents[modifier | modifier le code]

   Un nouveau paradigme, les ¬´ agents intelligents ¬ª, s'est
   progressivement impos√© au cours des ann√©es 1990^[144]. Bien que les
   premiers chercheurs aient propos√© des approches modulaires de type
   ¬´ diviser pour r√©gner ¬ª en intelligence artificielle^[145], l'agent
   intelligent n'a pas atteint sa forme moderne avant que Judea Pearl,
   Allen Newell et d'autres n'y am√®nent des concepts de th√©orie de la
   d√©cision et d'√©conomie^[146]. Quand la d√©finition √©conomique de l'agent
   rationnel s'est combin√©e √† la d√©finition informatique de l'objet ou
   encore du module, le paradigme de l'agent intelligent s'installe.

   Un agent intelligent est un syst√®me qui per√ßoit son environnement et
   entreprend des actions qui maximisent ses chances de r√©ussite. Gr√¢ce √
   cette d√©finition, de simple programmes qui r√©solvent des probl√®mes
   sp√©cifiques sont des ¬´ agents intelligents ¬ª, tout comme le sont des
   √™tres humains et des organisations d'√™tres humains comme les
   entreprises. Le paradigme de l'agent intelligent d√©finit l'intelligence
   artificielle comme l'¬´ √©tude des agents intelligents ¬ª. C'est une
   g√©n√©ralisation de certaines des premi√®res d√©finitions de l'IA : elle va
   au-del√† de l'√©tude de l'intelligence humaine ; elle √©tudie tout type
   d'intelligence^[147].

   Ce paradigme a ouvert aux chercheurs la voie vers l'√©tude de probl√®mes
   isol√©s ; les solutions trouv√©es sont √† la fois v√©rifiables et utiles.
   Un langage commun permet de d√©crire les probl√®mes et partager leurs
   solutions entre les uns et les autres, et d'autres domaines ont
   √©galement utilis√© ce concept d'agents abstraits, comme l'√©conomie et la
   r√©gulation. On pense qu'une ¬´ architecture agent ¬ª (comme la Soar de
   Newell) permettrait un jour √† des chercheurs de construire des syst√®mes
   plus polyvalents et intelligents √† base d'agents
   intelligents^[146]^,^[148].

¬´ Victoire des √©l√©gants ¬ª[modifier | modifier le code]

   Les chercheurs en intelligence artificielle d√©veloppent et utilisent
   des outils math√©matiques sophistiqu√©s comme jamais auparavant^[149].
   Ils prennent conscience que de nombreux probl√®mes que l'intelligence
   artificielle doit r√©soudre ont d√©j√† √©t√© trait√©s dans d'autres domaines
   comme les math√©matiques, l'√©conomie ou la recherche op√©rationnelle. En
   particulier, les math√©matiques permettent √† la fois d'am√©liorer la
   collaboration avec des disciplines plus solidement fond√©es et
   conduisent √† des fertilisations crois√©es et √† la collecte de donn√©es
   mesurables et d√©montrables ; l'intelligence artificielle progresse vers
   l'¬´ orthodoxie scientifique ¬ª. Russell et Norvig 2003 qualifie cela de
   rien de moins qu'une ¬´ r√©volution ¬ª et de la ¬´ victoire des
   √©l√©gants (en)^[150]^,^[151] ¬ª.

   Le livre-charni√®re de 1988 de Judea Pearl^[152] int√®gre les
   probabilit√©s et la th√©orie de la d√©cision avec les r√©seaux bay√©siens,
   les mod√®les de Markov cach√©s, la th√©orie de l'information, le calcul
   stochastique et plus g√©n√©ralement l'optimisation math√©matique. Des
   descriptions math√©matiques s'appliquent aux paradigmes primordiaux de
   l'¬´ intelligence computationnelle ¬ª comme les r√©seaux neuronaux et les
   algorithmes √©volutionnistes^[150].

L'IA, travailleur de l'ombre[modifier | modifier le code]

   Des algorithmes initialement d√©velopp√©s par des chercheurs en
   intelligence artificielle commencent √† faire partie de syst√®mes plus
   larges. L'IA a r√©solu beaucoup de probl√®mes tr√®s complexes^[153] et
   leurs solutions ont servi √† travers tout le secteur
   technologique^[154], tels que l'exploration de donn√©es, la robotique
   industrielle, la logistique^[155], la reconnaissance vocale^[156], des
   applications bancaires^[157], des diagnostics m√©dicaux^[157], la
   reconnaissance de formes, et le moteur de recherche de Google^[158].

   Le domaine de l'intelligence artificielle n'a quasiment re√ßu aucun
   cr√©dit pour ces r√©ussites. Certaines de ses plus grandes innovations
   ont √©t√© r√©duites au statut d'un √©ni√®me item dans la bo√Æte √† outils de
   l'informatique^[159]. Nick Bostrom explique : ¬´ Beaucoup d'IA de pointe
   a filtr√© dans des applications g√©n√©rales, sans y √™tre officiellement
   rattach√©e car d√®s que quelque chose devient suffisamment utile et
   commun, on lui retire l'√©tiquette d'IA^[160]. ¬ª

   Beaucoup de chercheurs en intelligence artificielle dans les ann√©es
   quatre-vingt-dix ont volontairement appel√© leurs √©tudes par d'autres
   noms, tels que l'informatique, les syst√®mes √† base de connaissances,
   les syst√®mes cognitifs ou l'intelligence computationnelle. Cela peut
   √™tre partiellement car ils consid√®rent leur domaine comme
   fondamentalement diff√©rent de l'IA, mais aussi car ces nouveaux noms
   facilitent les financements. Dans le secteur commercial au-moins, les
   promesses non tenues de l'hiver de l'IA continuent de hanter la
   recherche en intelligence artificielle, comme le New York Times le
   rapporte en 2005 : ¬´ Les scientifiques en informatique et les
   ing√©nieurs logiciel ont √©vit√© l'expression 'intelligence artificielle'
   par crainte d'√™tre consid√©r√©s comme de doux illumin√©s
   r√™veurs^[161]^,^[162]^,^[163]. ¬ª

2001 et HAL 9000[modifier | modifier le code]

   La science-fiction avait imagin√© pour 2001 l'arriv√© de HAL 9000, une
   machine ayant une intelligence comparable, voire exc√©dant les capacit√©s
   des √™tres humains.

   En 1968, Arthur C. Clarke et Stanley Kubrick imaginent que d√®s l'ann√©e
   2001, une machine aura une intelligence comparable, voire exc√©dant les
   capacit√©s des √™tres humains. Le personnage qu'ils cr√©ent, HAL 9000,
   s'appuie sur une opinion r√©pandue chez nombre de chercheurs en
   intelligence artificielle √† savoir qu'une telle machine existera en
   2001^[164].

   Marvin Minsky s'interroge : ¬´ pourquoi n'avons-nous pas eu HAL en
   2001^[165] ? ¬ª et pense que des probl√®mes centraux comme le
   raisonnement de culture g√©n√©rale, sont n√©glig√©s, car la plupart des
   chercheurs se concentrent sur des aspects tels que des applications
   commerciales des r√©seaux neuronaux ou des algorithmes g√©n√©tiques. John
   McCarthy, d'un autre c√¥t√©, bl√¢me encore le probl√®me de
   qualification^[166]. Pour Ray Kurzweil, le probl√®me r√©side dans le
   manque de puissance de calcul et, en s'appuyant sur la loi de Moore, il
   pr√©dit que les machines avec une intelligence comparable √† l'humain
   arriveront vers 2030^[167]. Pour d'autres chercheurs, une intelligence
   artificielle forte (ou intelligence artificielle g√©n√©rale) ne serait
   possible que dans plusieurs d√©cennies, voire plusieurs si√®cles^[168].

2000 - 2010[modifier | modifier le code]

   Dans les ann√©es 2000 et 2010, on constate l'arriv√©e de plusieurs
   assistants personnels ¬´ intelligents ¬ª : Apple Siri en 2007, Google Now
   en 2012 (Google Assistant depuis 2018), Microsoft Cortana et Amazon
   Alexa en 2014. En 2022, ChatGPT devient la premi√®re IA g√©n√©rative grand
   public.

2009 - 2019[modifier | modifier le code]

   La d√©cennie 2009 - 2019 connait un d√©veloppement sans pr√©c√©dent du deep
   learning sur des sujets comme la reconnaissance vocale, la
   reconnaissance d'images ou la traduction^[169]:

   En 2010, au Royaume-Uni, le neuro-scientifique, Demis Hassabis cherche
   un capital pour d√©marrer la fondation d'une intelligence artificielle
   g√©n√©rale qui serait capable de faire tout ce que le cerveau d'un √™tre
   humain pourrait faire^[170].

   En 2012, un r√©seau de neurones utilisant 16 000 Microprocesseur c≈ìurs
   de processeur de 1000 processeurs d'ordinateur apr√®s avoir √©t√© entrain√©
   est capable de reconna√Ætre un chat sans qu'il lui ait √©t√© appris √
   reconna√Ætre un chat^[171].

   Le capital-risqueur Reid Hoffman ancien dirigeant de PayPal et
   fondateur de LinkedIn est devenu capital-risqueur et est avec Elon Musk
   et Thiel dans le groupe qui investit un milliard de dollars dans
   OpenAI^[172].

   En 2012, Google ach√®te le travail de Geoffrey Hinton, professeur de
   l'Universit√© de Toronto qui travaillaient sur des r√©seaux de
   neurones^[172].

   En 2015, Sam Altman g√®re "Y Combinator", un incubateur de start-up de
   la Silicon Valley (vall√©e du silicium). Il s'entretient avec Elon Musk
   au sujet de l'intelligence artificielle et d√©marre OpenAI^[172].

   Elon Musk quitte OpenAI en 2018.

   Demis Hassabis, neuro-scientifique, a fond√© DeepMind avec un
   fincancement obtenu aupr√®s de Peter Thiel. L'entreprise a produit le
   service AlphaGo qui en 2016 a battu le meilleur joueur du monde du jeu
   de plateau Go^[172].

   Dario Amodei a quitt√© OpenAI en 2021 pour se concenter sur une start-up
   d'intelligence sure, Anthropic^[172].

   Bill Gates a √©t√© convaincu en 2022 du potentiel de l'intelligence
   artificielle et a conduite Microsoft √† capitaliser sur l'intelligence
   artificielle g√©n√©rative^[172].

Red√©finition dans les ann√©es 2020[modifier | modifier le code]

   Le mardi 12 f√©vrier 2019, √† Strasbourg, une politique industrielle
   europ√©enne globale sur l‚Äôintelligence artificielle et la robotique,
   conduit √† la R√©solution du Parlement europ√©en du 12 f√©vrier 2019 sur
   une politique industrielle europ√©enne globale sur l‚Äôintelligence
   artificielle et la robotique^[173].

   L‚Äôintelligence artificielle est red√©finie √† la vue des progr√®s
   technologiques.

   Pour la CNIL, l‚Äôintelligence artificielle n‚Äôest pas une technique
   sp√©cifique mais un ensemble de domaines auxquels appartiennent les
   outils qui entrent dans ces crit√®res^[174].

   L'intelligence artificielle est une technique automatis√©e suivant une
   logique ou un algorithme d√©di√© √† des t√¢ches sp√©cifiques^[174].

   Le Parlement europ√©en associe l'intelligence artificielle √† la
   reproduction ¬´ des comportements li√©s aux humains, tels que le
   raisonnement, la planification et la cr√©ativit√© ¬ª^[175].

   La Commission europ√©enne consid√®re l'intelligence artificielle comme un
   ensemble de diverses approches^[175]:
     * apprentissage automatique ;
     * logique et connaissances ; et
     * statistiques, estimation bay√©sienne, et m√©thodes de recherche et
       d‚Äôoptimisation.

   L'intelligence artificielle peut √©galement d√©passer les capacit√©s
   humaines^[175].

La recherche en intelligence artificielle en France[modifier | modifier le
code]

   Cette section est vide, insuffisamment d√©taill√©e ou incompl√®te. Votre
   aide est la bienvenue ! Comment faire ?

   La recherche en intelligence artificielle en France d√©bute vers la fin
   des ann√©es soixante-dix, avec notamment le GR 22 (appel√© aussi groupe
   de recherche Claude-Fran√ßois Picard o√π travaillent Jacques Pitrat et
   Jean-Louis Lauri√®re) √† Paris, le GIA (sic) (autour d'Alain Colmerauer)
   √† Marseille, le LIMSI √† Orsay, le CRIN √† Nancy, le CERFIA √† Toulouse et
   le Laboria (autour de G√©rard Huet et dans un domaine tr√®s fondamental)
   √† Rocquencourt.

   Un congr√®s national annuel Reconnaissance de formes et intelligence
   artificielle est cr√©√© en 1979 √† Toulouse^[Note 9]. En lien avec
   l'organisation de la conf√©rence International Joint Conference on
   Artificial Intelligence √† Chamb√©ry en 1993, et la cr√©ation d'un
   GRECO-PRC^[Note 10] intelligence artificielle, en 1983, il donne
   naissance √† une soci√©t√© savante, l'AFIA en 1989, qui, entre autres,
   organise des conf√©rences nationales en intelligence artificielle^[176].
   C'est de cette √©cole fran√ßaise qu'est issu Yann Le Cun.

Notes et r√©f√©rences[modifier | modifier le code]

    1. ‚Üë Par exemple la machine d'Anticyth√®re.
    2. ‚Üë Ada Lovelace est g√©n√©ralement consid√©r√©e comme le premier
       programmeur gr√¢ce aux notes qu'elle a √©crites qui d√©taillent
       compl√©tement une m√©thode pour calculer les nombres de Bernoulli
       avec la Machine.
    3. ‚Üë Le raisonnement de bon sens est la branche de l'intelligence
       artificielle qui tente de r√©pliquer la pens√©e humaine. Dans ce
       domaine, il y a :
          + les bases de connaissance de culture g√©n√©rale,
          + les m√©thodes de raisonnement imitant la pens√©e humaine
            (raisonnement √† base de connaissances par d√©faut, raisonnement
            rapide dans un large √©ventail de domaines, tol√©rance √
            l'incertitude, prise de d√©cisions sous connaissance incompl√®te
            et correction a posteriori quand les connaissances
            s'am√©liorent),
          + le d√©veloppement de nouveaux types d'architectures cognitives
            compatibles avec plusieurs m√©thodes et repr√©sentations de
            raisonnement.
    4. ‚Üë Cette condition de puissance est bien n√©cessaire ici, mais pas
       suffisante, car les probl√®mes d'IA sont intrins√®quement difficiles
       et complexes.
    5. ‚Üë L'ALPAC (Automatic Language Processing Advisory Committee) est le
       comit√© am√©ricain de sept scientifiques charg√© de surveiller les
       progr√®s en mati√®re de traitement du langage.
    6. ‚Üë Advice Taker (¬´ Preneur de conseils ¬ª en fran√ßais) est un
       programme informatique hypoth√©tique d√©crit par MacCarthy dans son
       Programs with Common Sense, 1958. C'est le premier programme √
       utiliser la logique en tant qu'outil de repr√©sentation et non en
       tant que mati√®re d'√©tude.
    7. ‚Üë La Strategic Computing Initiative (¬´ Initiative Informatique
       Strat√©gique ¬ª) de la DARPA finance pour plus d'1 milliard de $ de
       projets de recherche en mat√©riel informatique de pointe et en
       intelligence artificielle sur la d√©cennie 1983-1993, depuis la
       conception et fabrication de puces √† des logiciels d'intelligence
       artificielle.
    8. ‚Üë La dur√©e d'un cycle de Ferranti Mark I √©tait de 1,2 ms, ce qui
       correspond grossi√®rement √† environ 833 flops. Deep Blue
       fournissait, lui, 11,38 gigaflops (sans m√™me prendre en compte le
       mat√©riel sp√©cialement con√ßu pour les √©checs qui √©quipait Deep
       Blue). √Ä la louche, ces deux grandeurs diff√®rent d'un facteur 10^7.
    9. ‚Üë Reconnaissance des formes et intelligence artificielle, congr√®s
       AFCET-IRIA, Toulouse 12, 13, 14 septembre 1979. Il est intitul√©
       ¬´ 2^e congr√®s ¬ª et prend la suite du congr√®s AFCET-IRIA
       Reconnaissance des formes et traitement des images en 1978 √
       Chatenay-Malabry.
   10. ‚Üë Un GRECO est un anc√™tre des actuels GDR du CNRS et un PRC est un
       programme de recherche concert√©e

R√©f√©rences[modifier | modifier le code]

     * (en) Cet article est partiellement ou en totalit√© issu de l‚Äôarticle
       de Wikip√©dia en anglais intitul√© ¬´ History of artificial
       intelligence ¬ª (voir la liste des auteurs).

    1. ‚Üë McCorduck 2004
    2. ‚Üë Par exemple Kurzweil 2005 maintient que des machines ayant une
       intelligence comparable √† celle de l'homme existeront en 2029.
    3. ‚Üë Turing 1950, p. 460
    4. ‚Üë McCorduck 2004, p. 5‚Äì35
    5. ‚Üë McCorduck 2004, p. 5 ; Russell et Norvig 2003, p. 939
    6. ‚Üë McCorduck 2004, p. 15‚Äì16 ; Buchanan 2005, p. 50 (Golem) ;
       McCorduck 2004, p. 13‚Äì14 (Paracelse) ; O'Connor 1994 (Takwin)
    7. ‚Üë McCorduck 2004, p. 17‚Äì25
    8. ‚Üë Butler 1863
    9. ‚Üë Needham 1986, p. 53
   10. ‚Üë McCorduck 2004, p. 6
   11. ‚Üë Nick 2005
   12. ‚Üë McCorduck 2004, p. 17 ; Levitt 2000
   13. ‚Üë Cit√© dans McCorduck 2004, p. 8. Crevier 1993, p. 1 et McCorduck
       2004, p. 6‚Äì9 traitent des statues sacr√©es.
   14. ‚Üë D'autres automates importants ont √©t√© construits par H√¢roun
       ar-Rach√Æd (McCorduck 2004), Jacques de Vaucanson (McCorduck 2004)
       et Leonardo Torres Quevedo (McCorduck 2004), sans oublier la
       compagnie de th√©√¢tre contemporaine Royal de luxe.
   15. ‚Üë ^a b c et d Berlinski 2000
   16. ‚Üë (es) Carreras Artau et Tom√°s y Joaqu√≠n, Historia de la filosof√≠a
       espa√±ola. Filosof√≠a cristiana de los siglos XIII al XV, vol. I,
       Madrid, 1939
   17. ‚Üë (en) Anthony Bonner, The Art and Logic of Ram√≥n Llull : A User's
       Guide, Brill, 2007
   18. ‚Üë (en) Anthony Bonner (√©d.), Doctor Illuminatus. A Ramon Llull
       Reader, Llull's Influence: The History of Lullism, Princeton
       University, 1985, p. 57-71
   19. ‚Üë IA et m√©canisme du XVII^e si√®cle :
          + McCorduck 2004, p. 37‚Äì46
          + Russell et Norvig 2003, p. 6
          + Haugeland 1985, chap. 2
          + Buchanan 2005, p. 53
   20. ‚Üë Hobbes et l'I.A. :
          + McCorduck 2004, p. 42
          + Hobbes 1651, chap. 5
   21. ‚Üë Leibniz et l'I.A. :
          + McCorduck 2004, p. 41
          + Russell et Norvig 2003, p. 6
          + Berlinski 2000, p. 12
          + Buchanan 2005, p. 53
   22. ‚Üë Le lambda-calcul est particuli√®rement important en IA, car il a
       inspir√© le langage Lisp (le principal langage utilis√© en IA).
       Crevier 1993, p. 190-196,61
   23. ‚Üë La machine de Turing :McCorduck 2004, p. 63‚Äì64, Crevier 1993,
       p. 22‚Äì24, Russell et Norvig 2003, p. 8 et √©galement Turing 1936
   24. ‚Üë Menabrea 1843
   25. ‚Üë McCorduck 2004, p. 61‚Äì62, 64‚Äì66, Russell et Norvig 2003, p. 14‚Äì15
   26. ‚Üë Von Neumann : McCorduck 2004, p. 76‚Äì80
   27. ‚Üë Les dates de d√©but et de fin des sections de cet article
       correspondent √† Crevier 1993 et Russell et Norvig 2003, p. 16‚àí27.
       Les th√®mes, tendances et projets sont trait√©s dans la p√©riode o√π le
       gros du travail a √©t√© effectu√©.
   28. ‚Üë ¬´ Andreas Kaplan (2022) Artificial Intelligence, Business and
       Civilization - Our Fate Made in Machines, Routledge, ISBN
       9781032155319 ¬ª
   29. ‚Üë McCorduck 2004, p. 51‚Äì57, 80‚Äì107, Crevier 1993, p. 27‚Äì32, Russell
       et Norvig 2003, p. 15, 940, Moravec 1988, p. 3, Cordeschi 2002,
       Chap. 5.
   30. ‚Üë McCorduck 2004, p. 98, Crevier 1993, p. 27‚àí28, Russell et Norvig
       2003, p. 15, 940, Moravec 1988, p. 3, Cordeschi 2002, Chap. 5.
   31. ‚Üë McCorduck 2004, p. 51‚Äì57, 88‚Äì94, Crevier 1993, p. 30, Russell et
       Norvig 2003, p. 15‚àí16, Cordeschi 2002, Chap. 5 et voir aussi
       McCulloch et Pitts 1943
   32. ‚Üë McCorduck 2004, p. 102, Crevier 1993, p. 34‚àí35 et Russell et
       Norvig 2003, p. 17
   33. ‚Üë cf. (en)A Brief History of Computing sur AlanTuring.net.
   34. ‚Üë Jonathan Schaeffer, One Jump Ahead : Challenging Human Supremacy
       in Checkers, Springer, 1997, 585 p. (ISBN 978-0-387-76575-4),
       chap. 6. Aujourd'hui les programmes de jeux dames sont complets au
       sens o√π ils gagnent contre toute d√©fense.
   35. ‚Üë McCorduck 2004, p. 70‚àí72, Crevier 1993, p. 22‚àí25, Russell et
       Norvig 2003, p. 2‚àí3,948, Haugeland 1985, p. 6‚àí9, Cordeschi 2002,
       p. 170‚Äì176. Voir aussi Turing 1950
   36. ‚Üë Russell et Norvig 2003, p. 948 d√©clare que Turing r√©pond √† toutes
       les objections majeures √† l'IA qui sont apparues dans les ann√©es
       qui suivirent la publication de cet article.
   37. ‚Üë McCorduck 2004, p. 137‚Äì170, Crevier 1993, p. 44‚Äì47
   38. ‚Üë McCorduck 2004, p. 123‚Äì125, Crevier 1993, p. 44‚àí46 et Russell et
       Norvig 2003, p. 17
   39. ‚Üë Cit√© dans Crevier 1993, p. 46 et Russell et Norvig 2003, p. 17
   40. ‚Üë Russell et Norvig 2003, p. 947,952
   41. ‚Üë La premi√®re version de ce memorandum a √©t√© publi√© √† Carlsbad
       (Nouveau Mexique) en juillet 1949. Il a √©t√© reproduit dans Machine
       Translation of Languages, Cambridge, Massachusetts, MIT Press,
       1955, 15‚Äì23 p. (ISBN 0-8371-8434-7, lire en ligne), ¬´ Translation ¬ª
   42. ‚Üë McCorduck 2004, p. 111‚Äì136, Crevier 1993, p. 49‚Äì51 et Russell et
       Norvig 2003, p. 17
   43. ‚Üë Voir McCarthy et al. 1955. Voir √©galement Crevier 1993, p. 48 o√π
       Crevier d√©clare que ¬´ [cette th√®se] est devenue plus tard connue
       comme l‚Äô'hypoth√®se des syst√®mes de symbole physique' ¬ª. L'hypoth√®se
       de syst√®me de symbole physique a √©t√© d√©velopp√©e et nomm√©e par
       Newell et Simon dans leur article sur le General Problem Solver.
       Newell et al. 1963 Cela comporte une d√©finition plus sp√©cifique de
       la ¬´ machine ¬ª en tant qu'agent qui manipule des symboles (voir
       aussi la philosophie de l'intelligence artificielle).
   44. ‚Üë McCorduck 2004, p. 129‚Äì130 raconte comment les anciens de la
       conf√©rence de Dartmouth ont domin√© les deux premi√®res d√©cennies de
       la recherche en IA, les surnommant la ¬´ facult√© invisible ¬ª.
   45. ‚Üë ¬´ Je ne jurerai pas et je ne l'avais pas encore vu avant ¬ª,
       McCarthy indique √† Pamela McCorduck en 1979. McCorduck 2004, p. 114
       Cependant, McCarthy a aussi d√©clar√© sans √©quivoque ¬´ J'ai invent√©
       le terme ¬ª dans une interview du CNET. (Skillings 2006)
   46. ‚Üë Crevier 1993, p. 49 √©crit que ¬´ la conf√©rence est g√©n√©ralement
       reconnue comme la date de naissance officielle de cette nouvelle
       science. ¬ª
   47. ‚Üë Russell et Norvig ont √©crit que ¬´ c'√©tait extraordinaire d√®s
       qu'un ordinateur faisait quoi que ce soit de vaguement malin. ¬ª
       Russell et Norvig 2003, p. 18
   48. ‚Üë Crevier 1993, p. 52‚àí107, Moravec 1988, p. 9 et Russell et Norvig
       2003, p. 18‚àí21
   49. ‚Üë McCorduck 2004, p. 218, Crevier 1993, p. 108‚àí109 et Russell et
       Norvig 2003, p. 21
   50. ‚Üë Crevier 1993, p. 52‚àí107, Moravec 1988, p. 9
   51. ‚Üë Le raisonnement par t√¢tonnements : McCorduck 2004, p. 247‚Äì248,
       Russell et Norvig 2003, p. 59‚àí61
   52. ‚Üë Heuristique : McCorduck 2004, p. 246, Russell et Norvig 2003,
       p. 21‚àí22
   53. ‚Üë GPS: McCorduck 2004, p. 245‚Äì250, Crevier 1993, p. GPS?, Russell
       et Norvig 2003, p. GPS?
   54. ‚Üë Crevier 1993, p. 51‚àí58,65‚àí66 et Russell et Norvig 2003, p. 18‚àí19
   55. ‚Üë McCorduck 2004, p. 268‚Äì271, Crevier 1993, p. 95‚àí96, Moravec 1988,
       p. 14‚àí15
   56. ‚Üë McCorduck 2004, p. 286, Crevier 1993, p. 76‚àí79, Russell et Norvig
       2003, p. 19
   57. ‚Üë Crevier 1993, p. 79‚àí83
   58. ‚Üë Crevier 1993, p. 164‚àí172
   59. ‚Üë McCorduck 2004, p. 291‚Äì296, Crevier 1993, p. 134‚àí139
   60. ‚Üë McCorduck 2004, p. 299‚Äì305, Crevier 1993, p. 83‚àí102, Russell et
       Norvig 2003, p. 19 et Copeland 2000
   61. ‚Üë McCorduck 2004, p. 300‚Äì305, Crevier 1993, p. 84‚àí102, Russell et
       Norvig 2003, p. 19
   62. ‚Üë Simon et Newell 1958, p. 7‚àí8 quoted in Crevier 1993, p. 108. Voir
       aussi Russell et Norvig 2003, p. 21
   63. ‚Üë Simon 1965, p. 96 quoted in Crevier 1993, p. 109
   64. ‚Üë Minsky 1967, p. 2 cit√© dans Crevier 1993, p. 109
   65. ‚Üë Minsky croit fermement qu'on l'a mal cit√©. Voir McCorduck 2004,
       p. 272‚Äì274, Crevier 1993, p. 96 et Darrach 1970.
   66. ‚Üë Crevier 1993, p. 64‚àí65
   67. ‚Üë Crevier 1993, p. 94
   68. ‚Üë Howe 1994
   69. ‚Üë McCorduck 2004, p. 131, Crevier 1993, p. 51. McCorduck remarque
       √©galement que les financements est pour la majeure partie focilis√©
       sur les anciens de la conf√©rence de Dartmouth de 1956.
   70. ‚Üë Crevier 1993, p. 65
   71. ‚Üë Crevier 1993, p. 68‚àí71, et Turkle 1984
   72. ‚Üë Crevier 1993, p. 100‚àí144 et Russell et Norvig 2003, p. 21‚àí22
   73. ‚Üë McCorduck 2004, p. 104‚àí107, Crevier 1993, p. 102‚àí105, Russell et
       Norvig 2003, p. 22
   74. ‚Üë Crevier 1993, p. 163‚àí196
   75. ‚Üë Crevier 1993, p. 146
   76. ‚Üë Russell et Norvig 2003, p. 20‚àí21
   77. ‚Üë Crevier 1993, p. 146‚àí148, voir aussi Buchanan 2005, p. 56:(en)
       ¬´ Early programs were necessarily limited in scope by the size and
       speed of memory ¬ª
   78. ‚Üë Moravec 1976. McCarthy a toujours √©t√© oppos√© √† Moravec l√†-dessus,
       d√®s leurs premiers jours ensemble au Laboratoire d'IA de Stanford.
       Il a d√©clar√© : ¬´ Je dirais qu'il y a cinquante ans, les capacit√©s
       des machines √©taient trop faibles, mais il y a trente ans, les
       capacit√©s des machines n'√©taient plus le vrai probl√®me ¬ª dans une
       interview sur CNET. (Skillings 2006)
   79. ‚Üë (en)¬´ ROBOT: Mere Machine to Transcendent Mind ¬ª
   80. ‚Üë Russell et Norvig 2003, p. 9,21‚àí22 et Lighthill 1973
   81. ‚Üë McCorduck 2004, p. 300,421, Crevier 1993, p. 113‚àí114, Moravec
       1988, p. 13
   82. ‚Üë Lenat et Guha 1989, (Introduction)
   83. ‚Üë Russell et Norvig 2003, p. 21
   84. ‚Üë McCorduck 2004, p. 456
   85. ‚Üë Moravec 1988, p. 15‚àí16
   86. ‚Üë McCarthy et al. 1969, Crevier 1993, p. 117‚àí119
   87. ‚Üë McCorduck 2004, p. 280‚Äì281, Crevier 1993, p. 110, Russell et
       Norvig 2003, p. 21 et NRC 1999 dans Success in Speech Recognition
       (reconnaissance en reconnaissance de la parole).
   88. ‚Üë Crevier 1993, p. 117, Russell et Norvig 2003, p. 22, Howe 1994 et
       voir aussi Lighthill 1973.
   89. ‚Üë Russell et Norvig 2003, p. 22, Lighthill 1973, John McCarthy a
       r√©pondu que ¬´ le probl√®me de l'explosion combinatoire √©tait connu
       en IA depuis le d√©part ¬ª dans (en) Review of Lighthill report
   90. ‚Üë Crevier 1993, p. 115‚àí116 (o√π ce constat appara√Æt). D'autres
       points de vue sont expos√©s dans McCorduck 2004, p. 306‚Äì313 et NRC
       1999 dans Success in Speech Recognition.
   91. ‚Üë Crevier 1993, p. 115. Moravec explique que ¬´ leurs promesses
       initiales √† la DARPA ont √©t√© bien trop optimistes. Bien s√ªr, ce
       qu'ils livraient derri√®re √©tait bien loin du compte. Mais ils
       sentaient qu'ils ne pouvaient promettre moins pour leur prochain
       objectif, et donc ils promirent davantage ¬ª.
   92. ‚Üë NRC 1999 dans Shift to Applied Research Increases Investment.
       Bien que le tank autonome fut un √©chec, le syst√®me de gestion de
       batailles (appel√© ¬´ Dynamic Analysis and Replanning Tool ¬ª) a √©t√©
       un √©norme succ√®s, √©conomisant des milliards dans la premi√®re guerre
       du Golfe, remboursant les investissements et justifiant la
       politique pragmatique de la DARPA, au-moins √† son niveau.
   93. ‚Üë Critique de l'IA de Lucas et Penrose : Crevier 1993, p. 22,
       Russell et Norvig 2003, p. 949‚àí950, Hofstadter 1979, p. 471‚àí477 et
       aussi Lucas 1961
   94. ‚Üë ¬´ Savoir-faire ¬ª est une expression de Dreyfus. Il distingue le
       ¬´ savoir-faire ¬ª de la ¬´ connaissance ¬ª (classique), une version
       moderne de la distinction d'Heidegger entre l'¬´ √©tant disponible ¬ª
       (readiness-to-hand en anglais, Zuhandenheit en allemand) et
       l'¬´ √©tant subsistant ¬ª (respectivement presence-at-hand et
       Vorhandenheit). (Dreyfus et Dreyfus 1986)
   95. ‚Üë Critiques d'Hubert Dreyfus sur l'intelligence artificielle (en) :
       McCorduck 2004, p. 211‚àí239, Crevier 1993, p. 120‚àí132, Russell et
       Norvig 2003, p. 950‚àí952 et √©galement Dreyfus 1965, Dreyfus 1972,
       Dreyfus et Dreyfus 1986
   96. ‚Üë Critique de l'IA de Searle : McCorduck 2004, p. 443‚àí445, Crevier
       1993, p. 269‚àí271, Russell et Norvig 2003, p. 958‚àí960 ainsi que
       Searle 1980
   97. ‚Üë Cit√© dans Crevier 1993, p. 143
   98. ‚Üë Cit√© dans Crevier 1993, p. 122
   99. ‚Üë ¬´ J'√©tais alors le seul membre de la communaut√© d'IA qu'on
       pouvait voir d√©jeuner avec Dreyfus. Et j'ai clairement fait
       comprendre qu'on ne traitait pas ainsi un autre √™tre humain. ¬ª
       Joseph Weizenbaum, cit√© dans Crevier 1993, p. 123.
   100. ‚Üë Critique de l'IA de Weizenbaum : McCorduck 2004, p. 356‚àí373,
       Crevier 1993, p. 132‚àí144, Russell et Norvig 2003, p. 961 et aussi
       Weizenbaum 1976
   101. ‚Üë Frank Rosenblatt a √©t√© un condisciple de Marvin Minsky √† la
       Bronx High School of Science
   102. ‚Üë Mounier-Kuhn 2010, p. 266.
   103. ‚Üë McCorduck 2004, p. 51, Russell et Norvig 2003, p. 19, 23
   104. ‚Üë McCorduck 2004, p. 51, Crevier 1993, p. 190‚àí192
   105. ‚Üë Crevier 1993, p. 193‚àí196
   106. ‚Üë Crevier 1993, p. 145‚àí149,258‚àí63
   107. ‚Üë Wason 1966 a montr√© que les humains √©prouvent des difficult√©s
       sur des probl√®mes compl√©tement abstraits, mais quand le probl√®me
       est reformul√© pour permettre l'utilisation de l'intelligence
       sociale plus intuitive, leurs performances augmentent
       consid√©rablement. (Voir la t√¢che de s√©lection de Wason) Tversky,
       Slovic et Kahneman 1982 ont montr√©, eux, que les humains sont
       m√©diocres sur des probl√®mes √©l√©mentaires qui impliquent un
       raisonnement incertain. (Voir la liste de biais cognitifs pour
       plusieurs exemples). Le travail d'Eleanor Rosch est d√©crit dans
       Lakoff 1987
   108. ‚Üë Une premi√®re occurrence de l'opinion de McCathy appara√Æt dans le
       journal Science : ¬´ C'est de l'IA, donc peu importe que ce soit
       psychologiquement correct ¬ª (Kolata 1982), et il a confirm√© 20 ans
       plus tard son opinion √† la conf√©rence AI@50 (Dartmouth Artificial
       Intelligence Conference: The Next Fifty Years) de 2006 o√π il
       explique que ¬´ l'Intelligence artificielle n'est pas, par
       d√©finition, la simulation de l'intelligence humaine ¬ª (Maker 2006).
   109. ‚Üë Crevier 1993, p. 175
   110. ‚Üë ¬´ Brouillons contre √âl√©gants ¬ª (Neat vs. scruffy) : McCorduck
       2004, p. 421‚Äì424 (qui d√©crit l'√©tat du d√©bat en 1984). Crevier
       1993, p. 168 (qui documente l'usage initial du terme par Schank).
       Un autre aspect du conflit est intitul√© ¬´ la distinction
       proc√©dural/d√©claratif ¬ª mais ne s'est pas r√©v√©l√© important dans les
       recherches en IA ult√©rieures.
   111. ‚Üë McCorduck 2004, p. 305‚Äì306, Crevier 1993, p. 170‚àí173, 246 et
       Russell et Norvig 2003, p. 24. L'article de Minsky sur les cadres :
       Minsky 1974.
   112. ‚Üë McCorduck 2004, p. 327‚Äì335 (Dendral), Crevier 1993, p. 148‚àí159,
       Russell et Norvig 2003, p. 22‚àí23
   113. ‚Üë Crevier 1993, p. 158‚àí159 et Russell et Norvig 2003, p. 23‚àí24
   114. ‚Üë Crevier 1993, p. 198
   115. ‚Üë McCorduck 2004, p. 434‚Äì435, Crevier 1993, p. 161‚àí162,197‚àí203 et
       Russell et Norvig 2003, p. 24
   116. ‚Üë McCorduck 2004, p. 299
   117. ‚Üë McCorduck 2004, p. 421
   118. ‚Üë R√©volution de la connaissance : McCorduck 2004, p. 266‚Äì276,
       298‚Äì300, 314, 421, Russell et Norvig 2003, p. 22‚Äì23
   119. ‚Üë Cyc : McCorduck 2004, p. 489, Crevier 1993, p. 239‚àí243, Russell
       et Norvig 2003, p. 363‚àí365 et Lenat et Guha 1989
   120. ‚Üë McCorduck 2004, p. 436‚Äì441, Crevier 1993, p. 211, Russell et
       Norvig 2003, p. 24 et voir √©galement Feigenbaum et McCorduck 1983
   121. ‚Üë Crevier 1993, p. 195
   122. ‚Üë Crevier 1993, p. 240.
   123. ‚Üë ^a b et c Russell et Norvig 2003, p. 25
   124. ‚Üë McCorduck 2004, p. 426‚Äì432, NRC 1999 dans Shift to Applied
       Research Increases Investment
   125. ‚Üë Crevier 1993, p. 214‚àí215.
   126. ‚Üë Crevier 1993, p. 215‚àí216.
   127. ‚Üë Crevier 1993, p. 203. L‚Äôhiver de l'IA est apparu pour la
       premi√®re fois dans le nom d'un s√©minaire sur le sujet de
       l‚ÄôAssociation for the Advancement of Artificial Intelligence.
   128. ‚Üë McCorduck 2004, p. 435, Crevier 1993, p. 209‚àí210
   129. ‚Üë McCorduck 2004, p. 435 (qui cite des raisons institutionnelles
       pour leur ultime √©chec), Crevier 1993, p. 204‚àí208 (qui cite ici la
       difficult√© de la maintenance du savoir, c'est-√†-dire apprentissage
       et mise √† jour continus), Lenat et Guha 1989, Introduction (qui met
       l'accent sur l'extr√™me sensibilit√© et l'incapacit√© √† manipuler des
       qualifications limites)
   130. ‚Üë McCorduck 2004, p. 430‚Äì431
   131. ‚Üë ^a et b McCorduck 2004, p. 441, Crevier 1993, p. 212. McCorduck
       √©crit √† ce sujet : ¬´ Deux d√©cennies et demie plus tard, nous avons
       pu observer que le Japon n'a pas r√©ussi √† remplir tous ses
       objectifs ambitieux. ¬ª
   132. ‚Üë McCorduck 2004, p. 454‚Äì462
   133. ‚Üë Moravec 1988, p. 20 a √©crit : ¬´ Je suis s√ªr que la direction de
       bas en haut de la recherche en IA rencontrera un jour la plus
       classique voie de haut en bas, et ce, apr√®s avoir parcouru la
       majorit√© du chemin, pr√™te √† livrer au monde r√©el la comp√©tence et
       le savoir de culture g√©n√©rale qui ont √©chapp√© jusqu'ici aux
       programmes de raisonnement de mani√®re si frustrante. Des machines
       compl√©tement intelligentes couronneront la r√©union de ces deux
       efforts. ¬ª
   134. ‚Üë Crevier 1993, p. 183‚àí190.
   135. ‚Üë (en)Elephants Don't Play Chess (PDF)
   136. ‚Üë Brooks 1990, p. 3
   137. ‚Üë Voir, par exemple, Lakoff et Turner 1989
   138. ‚Üë McCorduck 2004, p. 424 discute cet √©clatement et la mise au ban
       des objectifs initiaux de l'IA.
   139. ‚Üë McCorduck 2004, p. 480‚Äì483.
   140. ‚Üë (en) Page d'accueil de DARPA Grand Challenge ¬´ Copie archiv√©e ¬ª
       (version du 23 juillet 2018 sur Internet Archive).
   141. ‚Üë (en)Archive du DARPA Grand Challenge.
   142. ‚Üë (en) John Markoff, ¬´ On 'Jeopardy!' Watson Win Is All but
       Trivial ¬ª, The New York Times,‚Äé 16 f√©vrier 2011 (lire en ligne).
   143. ‚Üë Kurzweil 2005, p. 274 √©crit que les am√©liorations du jeu
       d'√©checs en informatique, ¬´ d'apr√®s la sagesse populaire, sont
       uniquement dues √† l'accroissement de la force brute du mat√©riel
       informatique ¬ª.
   144. ‚Üë McCorduck 2004, p. 471‚Äì478, Russell et Norvig 2003, p. 55, o√π
       ils √©crivent : ¬´ La notion d'agent-entier est d√©sormais largement
       accept√©e dans le domaine. ¬ª On discute du paradigme de l'agent
       intelligent dans les textes majeurs de l'IA, comme Russell et
       Norvig 2003, p. 32‚àí58, 968‚àí972, Poole, Mackworth et Goebel 1998,
       p. 7‚àí21 et Luger et Stubblefield 2004, p. 235‚àí240
   145. ‚Üë Le mod√®le d'acteur de Carl Hewitt est le pr√©curseur de la
       d√©finition moderne des agents intelligents. (Hewitt, Bishop et
       Steiger 1973) John Doyle (Doyle 1983) et le classique The Society
       of Mind de Marvin Minsky (Minsky 1986) ont tous les deux utilis√©s
       le terme ¬´ agent ¬ª. Parmi d'autres propositions ¬´ modulaires ¬ª, on
       trouve l'¬´ architecture par pr√©misses ¬ª de Rodney Brook, la
       programmation orient√©e objet, etc..
   146. ‚Üë ^a et b Russell et Norvig 2003, p. 27, 55
   147. ‚Üë C'est cette d√©finition de l'intelligence artificielle qui est
       globalement accept√©e par tous les textes du xxi^e si√®cle, cf.
       Russell et Norvig 2003, p. 32 et Poole, Mackworth et Goebel 1998,
       p. 1.
   148. ‚Üë McCorduck 2004, p. 478
   149. ‚Üë McCorduck 2004, p. 486‚Äì487, Russell et Norvig 2003, p. 25‚Äì26
   150. ‚Üë ^a et b Russell et Norvig 2003, p. 25‚àí26
   151. ‚Üë McCorduck 2004, p. 487: ¬´ Au moment o√π j'√©cris ces lignes,
       l'intelligence artificielle b√©n√©ficie d'une h√©g√©monie √©l√©gante. ¬ª
   152. ‚Üë Pearl 1988
   153. ‚Üë Voir certaines applications de l'intelligence artificielle (en).
   154. ‚Üë NRC 1999 dans ¬´ Artificial Intelligence in the 90s ¬ª, et
       Kurzweil 2005, p. 264
   155. ‚Üë Russell et Norvig 2003, p. 28
   156. ‚Üë Pour un √©tat de l'art de l'intelligence artificielle sur la
       reconnaissance vocale en 2007, lire The Economist 2007
   157. ‚Üë ^a et b ¬´ Des syst√®mes inspir√©es par l'IA faisaient d√©j√† partie
       de nombreuses technologies de tous les jours telles que les moteurs
       de recherche Internet, les applications bancaires de traitement de
       transactions et les diagnostics m√©dicaux. ¬ª Nick Bostrom, cit√© dans
       CNN 2006
   158. ‚Üë Olsen 2004,Olsen 2006
   159. ‚Üë McCorduck 2004, p. 423, Kurzweil 2005, p. 265, Hofstadter 1979,
       p. 601
   160. ‚Üë CNN 2006
   161. ‚Üë Markoff 2005
   162. ‚Üë The Economist 2007
   163. ‚Üë Tascarella 2006
   164. ‚Üë Crevier 1993, p. 108‚àí109
   165. ‚Üë Il continue ainsi : ¬´ La r√©ponse est, Je crois que l'on aurait
       pu‚Ä¶ J'ai assist√© une fois √† une conf√©rence internationale sur le[s]
       r√©seau[x] neurona[ux]. Il y avait quarante mille inscrits‚Ä¶ mais‚Ä¶ si
       vous faisiez une conf√©rence internationale sur, par exemple, les
       repr√©sentations multiples du raisonnement de culture g√©n√©rale, je
       n'ai r√©ussi √† trouver que 6 ou 7 personnes dans le monde entier. ¬ª
       Minsky 2001
   166. ‚Üë Maker 2006
   167. ‚Üë Kurzweil 2005
   168. ‚Üë IA faible / IA forte : on en est o√π au fait ?
   169. ‚Üë Intelligence artificielle : de quoi parle-t-on ? Beno√Æt Georges,
       Constructif 2019/3 (N¬∞ 54), pages 5 √† 10
       https://www.cairn.info/revue-constructif-2019-3-page-5.htm
   170. ‚Üë Ego, Fear and Money: How the A.I. Fuse Was Lit, Cade Metz, Karen
       Weise, Nico Grant and Mike Isaac, San Francisco, 3 D√©cembre 2023
       https://www.nytimes.com/2023/12/03/technology/ai-openai-musk-page-a
       ltman.html
   171. ‚Üë A Massive Google Network Learns To Identify ‚Äî Cats, 26 Juin
       2012, All Things Considered, Audie Cornish et sous-traitant,
       https://www.npr.org/2012/06/26/155792609/a-massive-google-network-l
       earns-to-identify
   172. ‚Üë ^a b c d e et f The Who‚Äôs Who Behind the Modern Artificial
       Intelligence Movement, J. Edward Moreno, 3 d√©cembre 2023, The New
       York Times
       https://www.nytimes.com/2023/12/03/technology/whos-who-modern-artif
       icial-intelligence-movement.html
   173. ‚Üë R√©solution du Parlement europ√©en du 12 f√©vrier 2019 sur une
       politique industrielle europ√©enne globale sur l‚Äôintelligence
       artificielle et la robotique (2018/2088(INI))
       https://www.europarl.europa.eu/doceo/document/TA-8-2019-0081_FR.htm
       l
   174. ‚Üë ^a et b Intelligence artificielle, de quoi parle-t-on ? 25 mars
       2022
       https://www.cnil.fr/fr/intelligence-artificielle/intelligence-artif
       icielle-de-quoi-parle-t-on
   175. ‚Üë ^a b et c Intelligence artificielle
       https://www.cnil.fr/fr/definition/intelligence-artificielle
   176. ‚Üë ¬´ AFIA - Association Fran√ßaise pour l'Intelligence
       Artificielle ¬ª, sur AFIA (consult√© le 19 d√©cembre 2017)

Annexes[modifier | modifier le code]

Bibliographie[modifier | modifier le code]

     * (en) David Berlinski, The Advent of the Algorithm : The 300-Year
       Journey from an Idea to the Computer, Harcourt Books, 2000, 345 p.
       (ISBN 0-15-601391-6, OCLC 46890682)
     * (en) Rodney Brooks, ¬´ Elephants Don't Play Chess ¬ª, Robotics and
       Autonomous Systems, vol. 6,‚Äé 1990, p. 3‚àí15
       (DOI 10.1016/S0921-8890(05)80025-9, lire en ligne, consult√© le 30
       ao√ªt 2007)
     * (en) Bruce G. Buchanan, A (Very) Brief History of Artificial
       Intelligence, AI Magazine, 2005 (lire en ligne [archive du 26
       septembre 2007]), p. 53‚àí60
     * (en) Samuel Butler, Darwin Among the Machines, Christchurch, the
       Press, juin 1863 (lire en ligne)
     * (en) CNN, ¬´ AI set to exceed human brain power ¬ª, CNN.com,‚Äé 26
       juillet 2006 (lire en ligne, consult√© le 16 octobre 2007).
     * (en) Jack Copeland, Micro-World AI, 2000 (lire en ligne).
     * (en) Roberto Cordeschi, The Discovery of the Artificial, Dordrecht,
       Kluwer, 2002
     * (en) Daniel Crevier, AI : The Tumultuous Search for Artificial
       Intelligence, New York, BasicBooks, 1993, 386 p.
       (ISBN 0-465-02997-3)
     * (en) Brad Darrach, ¬´ Meet Shakey, the First Electronic Person ¬ª,
       Life Magazine,‚Äé 20 novembre 1970, p. 58‚àí68
     * (en) J. Doyle, ¬´ What is rational psychology? Toward a modern
       mental philosophy ¬ª, AI Magazine, vol. 4, n^o 3,‚Äé 1983, p. 50‚àí53
     * (en) Hubert Dreyfus, Alchemy and AI, RAND Corporation Memo, 1965
     * (en) Hubert Dreyfus, What Computers Can't Do : The Limits of
       Artificial Intelligence, New York, MIT Press, 1972, 354 p.
       (ISBN 0-06-090613-8, OCLC 5056816)
     * (en) Hubert Dreyfus, Stuart Dreyfus et Paul Anthanasiou, Mind Over
       Machine : The Power of Human Intuition and Expertise in the Era of
       the Computer, Free Press, 1986 (ISBN 0-7432-0551-0)
     * (en) The Economist, ¬´ Are You Talking to Me? ¬ª, The Economist,‚Äé 7
       juin 2007 (lire en ligne, consult√© le 16 octobre 2008)
     * (en) Edward A. Feigenbaum et Pamela McCorduck, The Fifth
       Generation : Artificial Intelligence and Japan's Computer Challenge
       to the World, Michael Joseph, 1983 (ISBN 0-7181-2401-4)
     * (en) Michael Haenlein et Andreas Kaplan, ¬´ A Brief History of
       Artificial Intelligence: On the Past, Present, and Future of
       Artificial Intelligence ¬ª, California Management Journal,‚Äé 2019
       (lire en ligne)
     * (en) Jeff Hawkins et Sandra Blakeslee, On Intelligence, New York,
       Owl Books, 2004, 272 p. (ISBN 0-8050-7853-3, OCLC 61273290)
     * (en) D.O. Hebb, The Organization of Behavior : a neuropsychological
       theory, New York, Wiley, 1949, 335 p. (ISBN 0-8058-4300-0,
       OCLC 48871099)
     * (en) Carl Hewitt, Peter Bishop et Richard Steiger, A Universal
       Modular Actor Formalism for Artificial Intelligence, IJCAI, 1973,
       PDF (lire en ligne)
     * (en) Thomas Hobbes, Leviathan, 1651
     * (en) Douglas Hofstadter, G√∂del, Escher, Bach : an Eternal Golden
       Braid, Basic Books, 1979, 824 p. (ISBN 0-465-02656-7,
       OCLC 225590743)
     * (en) J. Howe, Artificial Intelligence at Edinburgh University : a
       Perspective, 1994 (lire en ligne)
     * (en) G. Kolata, ¬´ How can computers get common sense? ¬ª, Science,
       vol. 217, n^o 4566,‚Äé 1982, p. 1237‚Äì1238 (PMID 17837639,
       DOI 10.1126/science.217.4566.1237, Bibcode 1982Sci...217.1237K)
     * (en) Ray Kurzweil, The Singularity is Near : When Humans Transcend
       Biology, New York, Penguin, 2005, 652 p. (ISBN 0-14-303788-9 et
       978-0-14-303788-0, OCLC 71826177)
     * (en) George Lakoff, Women, Fire, and Dangerous Things : What
       Categories Reveal About the Mind, Chicago/London, University of
       Chicago Press., 1987, 614 p. (ISBN 0-226-46804-6)
     * (en) Douglas Lenat et R. V. Guha, Building Large Knowledge-Based
       Systems : representation and inference in the Cyc project,
       Addison-Wesley, 1989, 372 p. (ISBN 0-201-51752-3, OCLC 19981533)
     * (en) Gerald M. Levitt, The Turk, Chess Automaton, Jefferson,
       McFarland, 2000, 258 p. (ISBN 0-7864-0778-6)
     * (en) Professor Sir James Lighthill, Artificial Intelligence : a
       paper symposium : Artificial Intelligence: A General Survey,
       Science Research Council, 1973
     * (en) John Lucas, ¬´ Minds, Machines and G√∂del ¬ª, Philosophy,
       vol. 36, n^o XXXVI,‚Äé 1961, p. 112‚Äì127
       (DOI 10.1017/S0031819100057983, lire en ligne, consult√© le 15
       octobre 2008)
     * (en) Meg Houston Maker, AI@50 : AI Past, Present, Future, Dartmouth
       College, 2006 (lire en ligne [archive du 8 octobre 2008])
     * (en) John Markoff, ¬´ Behind Artificial Intelligence, a Squadron of
       Bright Real People ¬ª, The New York Times,‚Äé 14 octobre 2005 (lire en
       ligne, consult√© le 16 octobre 2008)
     * (en) John McCarthy, Marvin Minsky, Nathan Rochester et Claude
       Shannon, A Proposal for the Dartmouth Summer Research Project on
       Artificial Intelligence, ao√ªt 1955 (lire en ligne)
     * (en) John McCarthy, P. J. Hayes, B. J. Meltzer (√©diteur) et Donald
       Mitchie (√©diteur), Machine Intelligence 4 : Some philosophical
       problems from the standpoint of artificial intelligence, Edinburgh
       University Press, 1969 (lire en ligne), p. 463‚àí502
     * (en) Pamela McCorduck, Machines Who Think, Natick, A. K. Peters,
       Ltd., 2004, 2^e √©d., 565 p. (ISBN 1-56881-205-1)
     * (en) Warren Sturgis McCulloch et W. Pitts, A logical calculus of
       the ideas immanent in nervous activity, vol. 5, Bulletin of
       Mathematical Biophysics, 1943 (DOI 10.1007/BF02478259), chap. 4,
       p. 115‚àí127
     * (en) Luigi Federico Menabrea et Ada Lovelace, Sketch of the
       Analytical Engine Invented by Charles Babbage, vol. 3, Scientific
       Memoirs, 1843 (lire en ligne) avec des notes du traducteur sur le
       m√©moire
     * (en) Marvin Minsky, Computation : Finite and Infinite Machines,
       Englewood Cliffs, N.J., Prentice-Hall, 1967
     * (en) Marvin Minsky et Seymour Papert, Perceptrons : An Introduction
       to Computational Geometry, The MIT Press, 1969 (ISBN 0-262-63111-3,
       OCLC 16924756)
     * (en) Marvin Minsky, A Framework for Representing Knowledge, 1974
       (lire en ligne)
     * (en) Marvin Minsky, The Society of Mind, New-York, Simon and
       Schuster, 1986, 339 p. (ISBN 0-671-65713-5, OCLC 223353010, lire en
       ligne)
     * (en) Marvin Minsky, It's 2001. Where Is HAL?, D^r Dobb's
       Technetcast, 2001 (lire en ligne)
     * (en) Hans Moravec, The Role of Raw Power in Intelligence, 1976
       (lire en ligne)
     * (en) Hans Moravec, Mind Children : The Future of Robot and Human
       Intelligence, Harvard University Press, 1988, 214 p.
       (ISBN 0-674-57618-7, OCLC 245755104, lire en ligne)
     * Pierre-√âric Mounier-Kuhn, L'informatique en France de la Seconde
       Guerre mondiale au Plan Calcul : l'√©mergence d'une science, Paris,
       Presses universitaires de Paris-Sorbonne, coll. ¬´ Centre Roland
       Mousnier ¬ª, 2010, 718 p. (ISBN 978-2-84050-654-6 et 2840506548)
     * (en) Allen Newell, H. A. Simon, E.A. Feigenbaum (√©diteur) et J.
       Feldman (√©diteur), Computers and Thought : GPS: A Program that
       Simulates Human Thought, New York, McGraw-Hill, 1963, 535 p.
       (ISBN 0-262-56092-5, OCLC 246968117)
     * (en) Martin Nick, Al Jazari : The Ingenious 13th Century Muslin
       Mechanic, Al Shindagah, 2005 (lire en ligne)
     * (en) NRC, Funding a Revolution : Government Support for Computing
       Research, National Academy Press, 1999 (ISBN 0-309-06278-0,
       OCLC 246584055), ¬´ Developments in Artificial Intelligence ¬ª
     * (en) Kathleen Malone O'Connor, The alchemical creation of life
       (takwin) and other concepts of Genesis in medieval Islam,
       University of Pennsylvania, 1994 (lire en ligne)
     * (en) Stefanie Olsen, ¬´ Newsmaker: Google's man behind the
       curtain ¬ª, CNET,‚Äé 10 mai 2004 (lire en ligne, consult√© le 17
       octobre 2008)
     * (en) Stefanie Olsen, ¬´ Spying an intelligent search engine ¬ª,
       CNET,‚Äé 18 ao√ªt 2006 (lire en ligne, consult√© le 17 octobre 2008)
     * (en) J. Pearl, Probabilistic Reasoning in Intelligent Systems :
       Networks of Plausible Inference, San Mateo (Californie), Morgan
       Kaufmann, 1988 (ISBN 1-55860-479-0, OCLC 249625842)
     * (en) David Poole, Alan Mackworth et Randy Goebel, Computational
       Intelligence : A Logical Approach, New York, Oxford University
       Press., 1998, 558 p. (ISBN 0-19-510270-3, lire en ligne)
     * (en) Stuart J. Russell et Peter Norvig, Artificial Intelligence : A
       Modern Approach, Upper Saddle River, Prentice Hall, 2003, 2^e √©d.
       (ISBN 0-13-790395-2, lire en ligne)
     * (en) Arthur L. Samuel, ¬´ Some studies in machine learning using the
       game of checkers ¬ª, IBM Journal of Research and Development,
       vol. 3, n^o 3,‚Äé juillet 1959, p. 210‚àí219 (DOI 10.1147/rd.33.0210,
       lire en ligne, consult√© le 20 ao√ªt 2007)
     * (en) John Searle, ¬´ Minds, Brains and Programs ¬ª, Behavioral and
       Brain Sciences, vol. 3, n^o 3,‚Äé 1980, p. 417‚Äì457
       (DOI 10.1017/S0140525X00005756, lire en ligne, consult√© le 13 mai
       2009)
     * (en) H. A. Simon et Allen Newell, Heuristic Problem Solving : The
       Next Advance in Operations Research, vol. 6, Operations Research,
       1958 (DOI 10.1287/opre.6.1.1)
     * (en) H. A. Simon, The Shape of Automation for Men and Management,
       New York, Harper & Row, 1965
     * (en) Jonathan Skillings, ¬´ Newsmaker: Getting machines to think
       like us ¬ª, CNET,‚Äé 2006 (lire en ligne, consult√© le 8 octobre 2008)
     * (en) Patty Tascarella, ¬´ Robotics firms find fundraising struggle,
       with venture capital shy ¬ª, Pittsburgh Business Times,‚Äé 11 ao√ªt
       2006 (lire en ligne, consult√© le 8 octobre 2008).
     * (en) Alan Turing, On Computable Numbers, with an Application to the
       Entscheidungsproblem, Proceedings of the London Mathematical
       Society, 1936 (DOI 10.1112/plms/s2-42.1.230, lire en ligne),
       chap. 42, p. 230‚Äì265
     * (en) Alan Turing, ¬´ Computing Machinery and Intelligence ¬ª, Mind,
       vol. LIX, n^o 236,‚Äé octobre 1950, p. 433‚Äì460 (ISSN 0026-4423, lire
       en ligne [archive du 2 juillet 2008])
     * (en) Joseph Weizenbaum, Computer Power and Human Reason, W.H.
       Freeman & Company, 1976 (ISBN 0-14-022535-8, OCLC 10952283)
     * (en) Joseph Needham, Science and Civilization in China : Volume 2,
       Taipei, Caves Books Ltd, 1986
     * (en) John Haugeland, Artificial Intelligence : The Very Idea,
       Cambridge, MIT Press, 1985 (ISBN 0-262-08153-9)
     * (en) George Lakoff et Mark Turner, More than cool reason : a field
       guide to poetic metaphor, 1989
     * (en) George Luger et William Stubblefield, Artificial
       intelligence : structures and strategies for complex problem
       solving, Redwood City (Calif.)/Menlo Park (Calif.)/Reading (Mass.)
       etc., The Benjamin/Cummings Publishing Company, Inc., 2004,
       5^e √©d., 740 p. (ISBN 0-8053-4780-1, lire en ligne)
     * (en) Sherry Turkle, The second self : computers and the human
       spirit, New York, Simon & Schuster, Inc., 1984, 386 p.
       (ISBN 978-0-262-70111-2)
     * (en) Peter Cathcart Wason et Shapiro, New horizons in psychology,
       Harmondsworth, Penguin, 1966
     * (en) A. Tversky, P. Slovic et D. Kahneman, Judgment Under
       Uncertainty : Heuristics and Biases, New York, Cambridge University
       Press, 1982

Articles connexes[modifier | modifier le code]

     * Cerveau artificiel
     * Histoire des ordinateurs
     * Histoire de l'informatique
     * Intelligence artificielle
     * Intelligence artificielle amicale
     * Philosophie de l'intelligence artificielle
     * Principaux projets et r√©alisations en intelligence artificielle
     * R√©volution num√©rique

   v ¬∑ m
   Histoire des sciences
   Chronologie
     * Alg√®bre
     * Astronomie
          + Stellaire
          + Syst√®me solaire
     * Biologie
     * Botanique
     * Chimie
     * Entomologie
     * Informatique
     * M√©canique classique
     * Optique
     * Ornithologie
     * Pathologie v√©g√©tale
     * Place des femmes en science
     * Sant√© et m√©decine
     * Techniques

   Sciences et techniques par civilisation
     * √âgypte
     * Gr√®ce
     * Rome
     * Chine
     * Inde
     * Byzance
     * Monde arabe
     * Moyen √Çge
     * Empire ottoman
     * Europe des Lumi√®res
     * Renaissance

   Histoires des disciplines
     * Anthropologie
     * Arch√©ologie
     * Astronomie
          + Gravitation
     * Biologie
          + Biologie marine
          + Biologie mol√©culaire
          + √âvolution
     * Botanique
     * Chimie
          + √âlectrochimie
          + √âl√©ments
     * Cryptologie
     * √âcologie
     * √âconomie
     * √âlectrophysiologie
     * G√©n√©tique
     * G√©ographie
     * G√©ologie
     * Histoire naturelle
     * Ichtyologie
     * Informatique
     * Intelligence artificielle
     * Linguistique
     * Logique
     * Math√©matiques
          + Alg√®bre
          + Analyse
          + Calcul infinit√©simal
          + Analyse fonctionnelle
          + G√©om√©trie
          + Probabilit√©
          + Statistique
          + Trigonom√©trie
     * M√©decine
     * M√©t√©orologie
     * M√©thode scientifique
     * Min√©ralogie
     * Pal√©oanthropologie
     * Pal√©ontologie
     * Phycologie
     * Physique
          + √âlectricit√©
          + M√©canique
          + M√©canique quantique
          + Magn√©tisme
          + Optique
          + Relativit√© g√©n√©rale
          + Relativit√© restreinte Article de qualit√©
          + Th√©orie des champs
     * Psychologie
          + Psychologie cognitive
          + Psychologie analytique
          + Psychanalyse
     * Techniques
     * Volcanologie
     * Zoologie
          + Primatologie

   v ¬∑ m
   Intelligence artificielle (IA)
   Concepts
     * Histoire de l'IA
     * S√ªret√© des IA(s)
     * Intelligence artificielle : une approche moderne
     * Hallucination (IA)
     * Analyse pr√©dictive

           Organisation
     * Agence francophone pour l'IA
     * Partenariat sur l'IA

   Capacit√©s
     * Perception artificielle
     * Mod√®le de fondation
     * Mod√®le des croyances transf√©rables
     * Grand mod√®le de langage
     * IA symbolique
     * IA g√©n√©rative
     * R√©seau neuronal convolutif
     * Apprentissage automatique
     * Apprentissage profond

   Applications de l'IA
     * Planification (IA)
     * IA dans le jeu vid√©o
     * IA dans la sant√©
     * √âcriture assist√©e par IA
     * Art cr√©√© par IA
     * V√©hicule autonome
     * Diagnostic (IA)
     * DeepL
     * Traduction automatique
     * ChatGPT

   Philosophie morale et √©thique
     * Philosophie de l'IA
     * Lettre ouverte sur l'IA
     * √âthique de l'IA
     * IA faible
     * IA digne de confiance
     * I.A. La Plus Grande Mutation de l'Histoire
     * Effet IA
     * D√©claration de Montr√©al pour un d√©veloppement responsable de
       l'intelligence artificielle
     * Contr√¥le des capacit√©s de l'IA
     * Chambre chinoise

   Histoire et √©v√©nements
     * Histoire de l'intelligence artificielle
     * Logic Theorist (1955)
     * Perceptron (1957)
     * General Problem Solver (1959)
     * Prolog (1972)
     * Matchs Deep Blue contre Kasparov (1996-1997)
     * Match AlphaGo - Lee Sedol (2016)

   Science-fiction
     * IA g√©n√©rale
     * Risque de catastrophe plan√©taire li√© √† l'intelligence artificielle
       g√©n√©rale
     * IA-complet
     * Superintelligence
     * Anticipation (IA)

          R√®glementation
     * L√©gislation sur l'IA
     * R√©glementation de l'IA

     * ic√¥ne d√©corative Portail de la robotique
     * ic√¥ne d√©corative Portail de l‚Äôinformatique
     * ic√¥ne d√©corative Portail de la psychologie
     * ic√¥ne d√©corative Portail du Web s√©mantique
     * ic√¥ne d√©corative Portail de l‚Äôhistoire des sciences

   Ce document provient de
   ¬´ https://fr.wikipedia.org/w/index.php?title=Histoire_de_l%27intelligen
   ce_artificielle&oldid=210357398 ¬ª.
   Cat√©gories‚ÄØ:
     * Intelligence artificielle
     * Histoire par domaine scientifique

   Cat√©gories cach√©es‚ÄØ:
     * Article contenant un appel √† traduction en anglais
     * Article √† r√©f√©rence n√©cessaire
     * Article avec une section vide ou incompl√®te
     * Portail:Robotique/Articles li√©s
     * Portail:√âlectricit√© et √©lectronique/Articles li√©s
     * Portail:G√©nie m√©canique/Articles li√©s
     * Portail:Technologies/Articles li√©s
     * Portail:Informatique/Articles li√©s
     * Portail:Sciences/Articles li√©s
     * Portail:Psychologie/Articles li√©s
     * Portail:Sciences humaines et sociales/Articles li√©s
     * Portail:Web s√©mantique/Articles li√©s
     * Portail:Histoire des sciences/Articles li√©s
     * Portail:Histoire/Articles li√©s

     * La derni√®re modification de cette page a √©t√© faite le 8 d√©cembre
       2023 √† 10:08.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les m√™mes conditions ; d‚Äôautres
       conditions peuvent s‚Äôappliquer. Voyez les conditions d‚Äôutilisation
       pour plus de d√©tails, ainsi que les cr√©dits graphiques. En cas de
       r√©utilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       Wikipedia¬Æ est une marque d√©pos√©e de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance r√©gie par le paragraphe 501(c)(3) du
       code fiscal des √âtats-Unis.

     * Politique de confidentialit√©
     * √Ä propos de Wikip√©dia
     * Avertissements
     * Contact
     * Code de conduite
     * D√©veloppeurs
     * Statistiques
     * D√©claration sur les t√©moins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou d√©sactiver la limitation de largeur du contenu
