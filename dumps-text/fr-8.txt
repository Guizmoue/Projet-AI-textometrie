   #alternate Modifier WikipÃ©dia (fr) Flux Atom de WikipÃ©dia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails thÃ©matiques
     * Article au hasard
     * Contact

   Contribuer
     * DÃ©buter sur WikipÃ©dia
     * Aide
     * CommunautÃ©
     * Modifications rÃ©centes
     * Faire un don

   Langues
   Sur cette version linguistique de WikipÃ©dia, les liens interlangues
   sont placÃ©s en haut Ã  droite du titre de lâ€™article.
   Aller en haut.
   WikipÃ©dia l'encyclopÃ©die libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * CrÃ©er un compte
     * Se connecter

   [ ] Outils personnels
     * CrÃ©er un compte
     * Se connecter

   Pages pour les contributeurs dÃ©connectÃ©s en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
     * DÃ©but
     * 1Introduction

     2Quelques prÃ©curseurs
   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Quelques prÃ©curseurs
     * 2.1L'intelligence artificielle : mythes, fiction et spÃ©culation

     2.2Automates

     2.3Raisonnement formel



   2.4Intelligence artificielle et premiers ordinateurs



   3Naissance: 1943âˆ’1956

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Naissance: 1943âˆ’1956
     * 3.1CybernÃ©tique et premiers rÃ©seaux neuronaux



   3.2L'intelligence artificielle dans les jeux



   3.3Test de Turing



   3.4Raisonnement symbolique et le thÃ©oricien logique



   3.5La traduction automatique des langages



   3.6ConfÃ©rence de Dartmouth de 1956 : naissance de l'intelligence
   artificielle



   4L'Ã¢ge d'or 1956âˆ’1974

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section L'Ã¢ge d'or 1956âˆ’1974
     * 4.1Les percÃ©es

     * 4.1.1Raisonnement par tÃ¢tonnements



   4.1.2Langage naturel



   4.1.3Micro-mondes



   4.2L'optimisme



   4.3Le financement



   5La premiÃ¨re hibernation de l'intelligence artificielle (1974âˆ’1980)

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section La premiÃ¨re hibernation de
   l'intelligence artificielle (1974âˆ’1980)
     * 5.1Les problÃ¨mes

     * 5.1.1Limites de la puissance de calcul



   5.1.2Limites inhÃ©rentes : la complÃ©tude NP



   5.1.3Raisonnement et base de connaissance de culture gÃ©nÃ©rale



   5.1.4Le paradoxe de Moravec



   5.1.5Le cadre et les problÃ¨mes de qualification



   5.2La fin des investissements



   5.3Critiques universitaires



   5.4Perceptrons et la pÃ©riode sombre du connexionnisme



   5.5Les Ã©lÃ©gants : calcul des prÃ©dicats, Prolog et systÃ¨mes experts



   5.6Les brouillons : cadres et scripts



   6Le boom 1980â€“1987

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Le boom 1980â€“1987
     * 6.1La montÃ©e des systÃ¨mes experts



   6.2La rÃ©volution de la connaissance



   6.3L'argent est de retour : projets de la cinquiÃ¨me gÃ©nÃ©ration



   6.4La renaissance du connexionnisme



   7La crise : le second hiver de l'IA 1987âˆ’1993

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section La crise : le second hiver
   de l'IA 1987âˆ’1993
     * 7.1Une seconde hibernation



   7.2L'importance du corps : Nouvelle intelligence artificielle et
   embodiment



   81993-2000

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section 1993-2000
     * 8.1Verrous qui sautent et loi de Moore



   8.2Agents intelligents



   8.3Â« Victoire des Ã©lÃ©gants Â»



   8.4L'IA, travailleur de l'ombre



   92001 et HAL 9000



   102000 - 2009



   11De 2009 Ã  aujourd'hui



   12RedÃ©finition dans les annÃ©es 2020



   13La recherche en intelligence artificielle en France



   14Notes et rÃ©fÃ©rences



   15RÃ©fÃ©rences



   16Annexes

   (BUTTON) Afficherâ€¯/â€¯masquer la sous-section Annexes
     * 16.1Bibliographie



   16.2Articles connexes

   [ ] Basculer la table des matiÃ¨res

Histoire de l'intelligence artificielle

   [ ] 26 langues
     * Afrikaans
     * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
     * AzÉ™rbaycanca
     * à¦¬à¦¾à¦‚à¦²à¦¾
     * CatalÃ
     * Ú©ÙˆØ±Ø¯ÛŒ
     * Deutsch
     * Î•Î»Î»Î·Î½Î¹ÎºÎ¬
     * English
     * EspaÃ±ol
     * Euskara
     * ÙØ§Ø±Ø³ÛŒ
     * Õ€Õ¡ÕµÕ¥Ö€Õ¥Õ¶
     * Bahasa Indonesia
     * Ãslenska
     * æ—¥æœ¬èª
     * í•œêµ­ì–´
     * Ù¾ÚšØªÙˆ
     * PortuguÃªs
     * Ğ ÑƒÑÑĞºĞ¸Ğ¹
     * à®¤à®®à®¿à®´à¯
     * Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°
     * Tiáº¿ng Viá»‡t
     * ä¸­æ–‡
     * ç²µèª
     * IsiZulu

   Modifier les liens

     * Article
     * Discussion

   [ ] franÃ§ais

     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   [ ] Outils
   Outils
   (BUTTON) dÃ©placer vers la barre latÃ©rale (BUTTON) masquer
   Actions
     * Lire
     * Modifier
     * Modifier le code
     * Voir lâ€™historique

   GÃ©nÃ©ral
     * Pages liÃ©es
     * Suivi des pages liÃ©es
     * TÃ©lÃ©verser un fichier
     * Pages spÃ©ciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * Ã‰lÃ©ment Wikidata

   Imprimerâ€¯/â€¯exporter
     * CrÃ©er un livre
     * TÃ©lÃ©charger comme PDF
     * Version imprimable

   Un article de WikipÃ©dia, l'encyclopÃ©die libre.

   Des prÃ©curseurs existent dÃ¨s l'AntiquitÃ©, mais c'est surtout aprÃ¨s la
   seconde guerre mondiale que l'intelligence artificielle (IA) prend son
   essor. AprÃ¨s quelques succÃ¨s, un premier Â« hiver Â» dÃ©marre en 1974,
   marquÃ© par des dÃ©sillusions et des coupes budgÃ©taires. L'IA fait son
   retour dans les annÃ©es 1980, notamment avec les systÃ¨mes experts, mais
   un second hiver s'ensuit^[1]. Au XXI^e siÃ¨cle, l'IA a suscitÃ© un
   enthousiasme grandissant, notamment avec l'avÃ¨nement de l'apprentissage
   profond, l'augmentation des donnÃ©es disponibles et l'utilisation de
   cartes graphiques pour dÃ©cupler les capacitÃ©s de calcul^[2], et
   l'introduction de l'architecture transformeur^[3].

Introduction[modifier | modifier le code]

   Les premiers jalons historiques de l'intelligence artificielle (ou IA)
   datent de la Protohistoire, oÃ¹ mythes, lÃ©gendes et rumeurs dotent des
   Ãªtres artificiels, rÃ©alisÃ©s par des maÃ®tres-artisans, d'une
   intelligence ou d'une conscience ; comme l'Ã©crit Pamela McCorduck (en),
   l'intelligence artificielle commence avec Â« le vieux souhait de jouer Ã
   Dieu^[4] Â».

   L'intelligence artificielle comme nous l'entendons aujourd'hui a Ã©tÃ©
   initiÃ©e par les philosophes classiques, dont Gottfried Wilhelm Leibniz
   avec son calculus ratiocinator, qui essaient de dÃ©crire le processus de
   la pensÃ©e humaine comme la manipulation mÃ©canique de symboles, sans
   pour autant vouloir fabriquer des spÃ©cimens. Cette rÃ©flexion s'est
   concrÃ©tisÃ©e avec l'invention de l'ordinateur programmable dans les
   annÃ©es 1940. Cet instrument et les idÃ©es qu'il sous-tend ont inspirÃ©
   les scientifiques qui ont commencÃ© Ã  Ã©voquer sÃ©rieusement la
   faisabilitÃ© d'un Â« cerveau Ã©lectronique Â».

   La recherche en intelligence artificielle a vraiment commencÃ© aprÃ¨s une
   confÃ©rence tenue sur le campus de Dartmouth College pendant l'Ã©tÃ© 1956.
   Ã€ la suite de cette rÃ©union, certains participants se sont investis
   dans une recherche sur l'intelligence artificielle. Certains utopistes
   ont pronostiquÃ© qu'une machine aussi intelligente qu'un Ãªtre humain
   existerait en moins d'une gÃ©nÃ©ration et des millions de dollars ont
   alors Ã©tÃ© investis pour rÃ©ifier cette prÃ©diction. Avec le temps, il est
   apparu que les difficultÃ©s inhÃ©rentes Ã  cette annonce avaient Ã©tÃ©
   grossiÃ¨rement sous-estimÃ©es. En 1973, en rÃ©ponse aux critiques des
   scientifiques, notamment de James Lighthill et aux pressions
   continuelles des parlementaires, les gouvernements britannique et
   amÃ©ricain stoppent les subventions Ã  la recherche en intelligence
   artificielle sans orientation. Sept ans plus tard, Ã  la suite de
   l'initiative prophÃ©tique du Cabinet du Japon, les gouvernements et
   l'industrie rÃ©investissent dans l'intelligence artificielle, mais Ã  la
   fin des annÃ©es 1980 les dÃ©cideurs dÃ©sabusÃ©s retirent Ã  nouveau leurs
   fonds. On peut donc dire que ce cycle en dents de scie, oÃ¹ alternent
   pÃ©riodes de gel et de dÃ©gel, caractÃ©rise le soutien Ã  l'intelligence
   artificielle. Mais il reste toujours des idÃ©alistes pour faire des
   prÃ©dictions osÃ©es^[5].

   MalgrÃ© des hauts et des bas et en dÃ©pit de certaines rÃ©ticences de
   dÃ©cideurs et investisseurs, l'intelligence artificielle progresse. Les
   progrÃ¨s de l'algorithmique ont permis de rÃ©soudre des problÃ¨mes que les
   heuristiques ne pouvaient traiter et jugÃ©s inaccessibles en 1970 ; et
   ces solutions sont comercialisÃ©es. Mais aucune machine dotÃ©e d'une
   intelligence artificielle forte n'a encore Ã©tÃ© construite,
   contrairement aux prÃ©visions optimistes de la premiÃ¨re gÃ©nÃ©ration de
   chercheurs. Â« Nous ne pouvons qu'entrevoir le court terme Â» a concÃ©dÃ©
   Alan Turing, dans un article cÃ©lÃ¨bre de 1950 prÃ©figurant la recherche
   moderne sur les machines pensantes. Â« Mais, Â» ajoute-t-il, Â« nous ne
   pouvons pas envisager l'ampleur du travail qui reste Ã  accomplir^[6] Â».

   Au dÃ©part, deux approches se confrontent : d'une part l'approche
   logiciste ou symbolique, qui vise Ã  recrÃ©er les Â« lois universelles Â»
   de la pensÃ©e et s'inspirent du concept de machine de Turing, et d'autre
   part l'approche neuronale, incarnÃ©e par Frank Rosenblatt, qui essaie
   d'imiter les processus biologiques cÃ©rÃ©braux. Si l'approche logiciste,
   inspirÃ©e des travaux de Russell, Frege, du cercle de Vienne, de logique
   mathÃ©matique, etc., l'emporte Ã  la DARPA, principal organisme finanÃ§ant
   les recherches en intelligence artificielle, l'approche neuronale
   refait surface dans les annÃ©es 1980, inspirant les travaux sur le
   connexionnisme.

   L'intelligence artificielle ayant, Ã  ses dÃ©buts, surtout Ã©mergÃ© aux
   Ã‰tats-Unis, cet article se focalisera essentiellement sur ce pays.

Quelques prÃ©curseurs[modifier | modifier le code]

   McCorduck 2004 Ã©crit en 2004 que Â« l'intelligence artificielle sous une
   forme ou une autre est une idÃ©e qui s'est rÃ©pandue dans l'histoire de
   la pensÃ©e occidentale, un rÃªve au besoin pressant d'Ãªtre rÃ©alisÃ©, Â» que
   l'on retrouve dans les mythes, lÃ©gendes, histoires, spÃ©culations et
   automates anthropomorphes de l'humanitÃ©^[7].

L'intelligence artificielle : mythes, fiction et spÃ©culation[modifier |
modifier le code]

   Les hommes mÃ©caniques et les Ãªtres artificiels sont prÃ©sents dans la
   mythologie grecque, ainsi les robots dorÃ©s d'HÃ©phaÃ¯stos, Pygmalion et
   GalatÃ©e^[8].

   Tandis qu'au Moyen Ã‚ge, circulent des rumeurs de secrets mystiques ou
   de techniques alchimiques pour imprÃ©gner des esprits, tels que le
   Takwin de Geber, les homoncules de Paracelse et le Golem de
   MaHaRaL^[9].

   Au XIX^e siÃ¨cle, l'idÃ©e d'hommes artificiels et de machines pensantes
   prend corps dans des Å“uvres de fiction, telles que Frankenstein de Mary
   Shelley ou encore R. U. R. (Rossum's Universal Robots) de Karel
   ÄŒapek^[10], et des essais de spÃ©culation, comme Darwin among the
   Machines de Samuel Butler^[11].

   L'IA est un Ã©lÃ©ment important de la science-fiction.

Automates[modifier | modifier le code]

   Articles dÃ©taillÃ©s : Automate et Automate anthropomorphe.
   [215px-Al-jazari_robots.jpg] L'automate programmable d'Al-Djazari (1206
   apr. J.-C.)

   Des automates anthropomorphes rÃ©alistes ont Ã©tÃ© construits par des
   artisans de toutes les civilisations, dont Yan Shi qui travaillait pour
   Ji Man^[12], HÃ©ron d'Alexandrie^[13], Al-Djazari^[14] et Wolfgang von
   Kempelen^[15]. Les plus vieux automates sont les statues sacrÃ©es
   d'ancienne Ã‰gypte et de GrÃ¨ce antique. Les croyants Ã©taient persuadÃ©s
   que les artisans avaient imprÃ©gnÃ© ces statues avec des esprits rÃ©els,
   capables de sagesse et d'Ã©motion â€” HermÃ¨s TrismÃ©giste a Ã©crit qu'Â« en
   dÃ©couvrant la vraie nature des dieux, l'homme a Ã©tÃ© capable de le
   reproduire^[16]^,^[17] Â». L'automate de Vaucanson du XVIII^e siÃ¨cle qui
   reprÃ©sente un canard est une mise en Å“uvre saisissante d'un Ãªtre
   artificiel rÃ©alisant certaines fonctions du vivant, tandis que le turc
   joueur d'Ã©chec de Johann Wolfgang von Kempelen est une supercherie.

Raisonnement formel[modifier | modifier le code]

   L'intelligence artificielle se fonde sur l'hypothÃ¨se que le processus
   de pensÃ©e humaine peut Ãªtre mÃ©canisÃ©. L'Ã©tude du raisonnement mÃ©canique
   â€” ou Â« formel Â» â€” a un long historique. Les philosophes chinois,
   indiens et grecs ont tous dÃ©veloppÃ© des mÃ©thodes structurÃ©es de
   dÃ©duction formelle au cours du premier millÃ©naire apr. J.-C. Leurs
   idÃ©es ont Ã©tÃ© dÃ©veloppÃ©es Ã  travers les siÃ¨cles par des philosophes
   comme Aristote (qui a donnÃ© une analyse formelle du syllogisme),
   Euclide (dont les Ã‰lÃ©ments ont Ã©tÃ© un modÃ¨le de raisonnement formel),
   Al-Khawarizmi (auquel on doit l'algÃ¨bre et dont le nom a donnÃ©
   Â« algorithme Â») et les philosophes scolastiques europÃ©ens comme
   Guillaume d'Ockham et Duns Scot^[18].

   Le philosophe majorquin Raymond Lulle (1232â€“1315) a conÃ§u plusieurs
   machines logiques destinÃ©es Ã  la production de connaissance par des
   moyens logiques^[19] ; Lulle dÃ©crit ses machines en tant qu'entitÃ©s
   mÃ©caniques qui pouvaient combiner des vÃ©ritÃ©s fondamentales et
   indÃ©niables via de simples opÃ©rations logiques, gÃ©nÃ©rÃ©es par la machine
   grÃ¢ce Ã  des mÃ©canismes, de maniÃ¨re Ã  produire tout le savoir
   possible^[20]. Le travail de Lulle a une grande influence sur Leibniz,
   qui a redÃ©veloppÃ© ses idÃ©es^[21].
   [220px-Gottfried_Wilhelm_von_Leibniz.jpg] Gottfried Wilhelm Leibniz,
   qui spÃ©culait qu'on pouvait rÃ©duire la raison humaine Ã  des calculs
   mÃ©caniques

   Au XVII^e siÃ¨cle, Gottfried Wilhelm Leibniz, Thomas Hobbes et RenÃ©
   Descartes ont explorÃ© la possibilitÃ© que toute la pensÃ©e rationnelle
   puisse Ãªtre aussi systÃ©matique que l'algÃ¨bre ou la gÃ©omÃ©trie^[22]. Dans
   le LÃ©viathan de Hobbes, on retrouve la cÃ©lÃ¨bre phrase : Â« la raison
   [...] n'est rien d'autre que le fait de calculer^[23] Â». Leibniz
   imaginait un langage universel du raisonnement (sa characteristica
   universalis) qui assimilerait l'argumentation Ã  un calcul, afin qu'Â« il
   n'y a[it] pas plus de besoin de se disputer entre deux philosophes
   qu'entre deux comptables. Car il leur suffirait de prendre leur crayon
   et leur ardoise en main, et de se dire l'un l'autre (avec un ami en
   tÃ©moin, au besoin) : Calculons !^[24] Â». Ces philosophes ont commencÃ© Ã
   articuler les hypothÃ¨ses d'un systÃ¨me de symboles physiques qui
   deviendra par la suite l'un des dogmes de la recherche en IA. Leibniz a
   toutefois mis en avant la difficultÃ© liÃ©e Ã  lâ€™interconnexion des les
   concepts, qui ne permet pas dâ€™isoler une idÃ©e de toutes les autres pour
   simplifier le raisonnement.

   Au XX^e siÃ¨cle, l'Ã©tude de la logique mathÃ©matique a fourni l'essentiel
   des avancÃ©es qui ont rendu plausible l'intelligence artificielle.
   George Boole a inventÃ© la formulation mathÃ©matique des processus
   fondamentaux du raisonnement, connue sous le nom dâ€™algÃ¨bre de Boole. Il
   Ã©tait conscient des liens de ses travaux avec les mÃ©canismes de
   lâ€™intelligence, comme le montre le titre de son principal ouvrage paru
   en 1854 : Les Lois de la pensÃ©e^[25] (The laws of thought), sur
   lâ€™algÃ¨bre boolÃ©enne. Gottlob Frege perfectionna le systÃ¨me de Boole en
   formalisant le concept de prÃ©dicat, qui est une entitÃ© logique soit
   vraie, soit fausse (toute maison a un propriÃ©taire), mais contenant des
   variables non logiques, nâ€™ayant en soi aucun degrÃ© de vÃ©ritÃ© (maison,
   propriÃ©taire). Cette formalisation eut une grande importance
   puisqu'elle permit de dÃ©montrer des thÃ©orÃ¨mes gÃ©nÃ©raux, simplement en
   appliquant des rÃ¨gles typographiques Ã  des ensembles de symboles. La
   rÃ©flexion en langage courant ne portait plus que sur le choix des
   rÃ¨gles Ã  appliquer. Par ailleurs, lâ€™utilisateur joue un rÃ´le important
   puisqu'il connaÃ®t le sens des symboles quâ€™il a inventÃ©s et ce sens^[a]
   n'est pas toujours formalisÃ©, ce qui ramÃ¨ne au problÃ¨me de la
   signification en intelligence artificielle, et de la subjectivitÃ© des
   utilisateurs.

   S'appuyant sur le systÃ¨me de Frege, Russell et Whitehead ont prÃ©sentÃ©
   un traitement formel des fondements des mathÃ©matiques dans leur
   chef-d'Å“uvre Principia Mathematica en 1913. InspirÃ© par le succÃ¨s de
   Russell, David Hilbert a dÃ©fiÃ© les mathÃ©maticiens des annÃ©es 1920-1930
   de rÃ©pondre Ã  cette question fondamentale : Â« Le raisonnement
   mathÃ©matique peut-il Ãªtre entiÃ¨rement formalisÃ©^[18] ? Â» On rÃ©pondit Ã
   sa question par les thÃ©orÃ¨mes d'incomplÃ©tude de GÃ¶del, la machine de
   Turing et le lambda-calcul de Church^[18]^,^[26]. Leur rÃ©ponse Ã©tait
   surprenante Ã  plusieurs titres. Tout d'abord, ils prouvÃ¨rent qu'il y
   avait, en fait, des limitations dans ce que la logique mathÃ©matique
   pouvait accomplir.
   [250px-Classic_shot_of_the_ENIAC.jpg] L'ENIAC, Ã  la Moore School of
   Electrical Engineering.

   Mais aussi (et plus important encore pour l'IA) leurs travaux ont
   suggÃ©rÃ© que, sous ces conditions, toute forme de raisonnement
   mathÃ©matique pouvait Ãªtre mÃ©canisÃ©e. La thÃ¨se de Church impliquait
   qu'un appareil mÃ©canique, manipulant des symboles aussi simples que des
   0 et des 1, pouvait imiter tout processus concevable de dÃ©duction
   mathÃ©matique. Cette notion-clÃ© se traduisit par la machine de Turing â€”
   une simple construction thÃ©orique qui capturait l'essence de la
   manipulation de symboles abstraits. Cette invention inspira une poignÃ©e
   de scientifiques qui commencÃ¨rent alors Ã  discuter de la possibilitÃ© de
   machines pensantes^[18]^,^[27].

Intelligence artificielle et premiers ordinateurs[modifier | modifier le
code]

   Les machines Ã  calculer sont apparues dÃ¨s l'AntiquitÃ©^[Note 1] et ont
   Ã©tÃ© amÃ©liorÃ©es tout au long de l'histoire par de nombreux
   mathÃ©maticiens et ingÃ©nieurs, dont Leibniz. Au dÃ©but du XIX^e siÃ¨cle,
   Charles Babbage conÃ§oit la machine Ã  calculer programmable (la Machine
   analytique), sans jamais la construire. Ã€ sa suite, Ada Lovelace
   spÃ©cule que la machine Â« peut composer des piÃ¨ces de musique Ã©laborÃ©es
   et scientifiques de toutes complexitÃ© et longueur^[28]^,^[Note 2] Â».

   Les premiers ordinateurs modernes sont les machines massives de
   cryptanalyse de la Seconde Guerre mondiale (telles que le Z3, l'ENIAC
   et le Colossus)^[29], conÃ§ues, en ce qui concerne les deux derniÃ¨res, Ã
   partir des fondements thÃ©oriques Ã©tablis par Alan Turing et dÃ©veloppÃ©s
   par John von Neumann^[30].

Naissance: 1943âˆ’1956[modifier | modifier le code]

   [420px-BRL61-IBM_702.jpg] L'IBM 702 : un ordinateur utilisÃ© par la
   premiÃ¨re gÃ©nÃ©ration de chercheurs en IA.

   Une note sur les sections de cet article^[31].

   Dans les annÃ©es 1940 et 1950, une poignÃ©e de scientifiques d'une large
   gamme de domaines (mathÃ©matiques, psychologie, ingÃ©nierie, Ã©conomie et
   science politique) ont commencÃ© Ã  discuter de la possibilitÃ© de crÃ©er
   un cerveau artificiel. Ce domaine de recherche de l'intelligence
   artificielle a Ã©tÃ© fondÃ© en tant que discipline acadÃ©mique en
   1956^[32].

CybernÃ©tique et premiers rÃ©seaux neuronaux[modifier | modifier le code]

   Les toutes premiÃ¨res recherches dans le domaine des machines pensantes
   ont Ã©tÃ© inspirÃ©es par une convergence d'idÃ©es qui se sont
   progressivement rÃ©pandues de la fin des annÃ©es 1930 au dÃ©but des annÃ©es
   1950. De rÃ©centes recherches en neurologie ont montrÃ© que le cerveau
   Ã©tait un rÃ©seau Ã©lectrique de neurones qui envoyaient des impulsions de
   type tout-ou-rien. La cybernÃ©tique de Norbert Wiener a dÃ©crit les
   contrÃ´les et la stabilitÃ© dans les rÃ©seaux Ã©lectriques. La thÃ©orie de
   l'information de Claude Shannon dÃ©taille des signaux numÃ©riques (i.e.,
   signaux tout-ou-rien). La thÃ©orie du calcul d'Alan Turing montre que
   toute forme de calcul peut Ãªtre reprÃ©sentÃ©e numÃ©riquement. Les
   relations Ã©troites entre ces idÃ©es suggÃ¨rent la possibilitÃ© de
   construire un cerveau artificiel^[33].

   On peut citer comme exemples de travaux de cette veine les robots tels
   que les Tortues de Bristol de William Grey Walter et la BÃªte de Johns
   Hopkins (en). Ces machines n'utilisent pas d'ordinateurs,
   d'Ã©lectronique numÃ©rique ni de raisonnement symbolique ; elles Ã©taient
   entiÃ¨rement contrÃ´lÃ©es par des circuits analogiques^[34].

   Walter Pitts et Warren McCulloch ont analysÃ© des rÃ©seaux de neurones
   artificiels idÃ©aux et ont montrÃ© comment ils pourraient effectuer de
   simples opÃ©rations logiques. Ils ont Ã©tÃ© les premiers Ã  Ã©voquer ce que
   des chercheurs plus tard appelleraient un rÃ©seau neuronal^[35].

   Un des Ã©tudiants inspirÃ©s par Pitts et McCulloch Ã©tait Marvin Minsky, Ã
   l'Ã©poque jeune Ã©tudiant de 24 ans. En 1951 (avec Dean Edmonds), il
   construisit la premiÃ¨re machine Ã  rÃ©seau neuronal, le SNARC^[36].
   Minsky allait devenir l'un des plus importants leaders et innovateurs
   en IA des cinquante annÃ©es suivantes.

L'intelligence artificielle dans les jeux[modifier | modifier le code]

   En 1951, en utilisant la machine Ferranti Mark I de l'universitÃ© de
   Manchester, Christopher Strachey a Ã©crit un programme de jeu de dames
   et Dietrich Prinz un programme de jeu d'Ã©checs^[37]. Le jeu de dames
   d'Arthur Samuel, dÃ©veloppÃ© au milieu des annÃ©es 1950 et au dÃ©but des
   annÃ©es 1960, a fini par acquÃ©rir un niveau suffisant pour dÃ©fier un bon
   amateur^[38]. De fait, l'intelligence artificielle dans les jeux sert
   d'Ã©talon des avancÃ©es de l'intelligence artificielle.

Test de Turing[modifier | modifier le code]

   En 1950 Alan Turing publie un article mÃ©morable dans lequel il spÃ©cule
   sur la possibilitÃ© de crÃ©er des machines dotÃ©es d'une vÃ©ritable
   intelligence^[39]. Il remarque qu'il est difficile de dÃ©finir
   l'Â« intelligence Â» et imagine son cÃ©lÃ¨bre test de Turing. Si une
   machine peut mener une conversation (par tÃ©lÃ©scripteur interposÃ©) qu'on
   ne puisse diffÃ©rencier d'une conversation avec un Ãªtre humain, alors la
   machine pouvait Ãªtre qualifiÃ©e d'Â« intelligente Â». Cette version
   simplifiÃ©e du problÃ¨me a permis Ã  Turing d'argumenter de maniÃ¨re
   convaincante qu'une Â« machine pensante Â» Ã©tait au-moins plausible, cet
   article rÃ©pondant Ã  toutes les objections classiques Ã  cette
   proposition^[40]. Le test de Turing a Ã©tÃ© la premiÃ¨re hypothÃ¨se
   sÃ©rieuse dans le domaine de la philosophie de l'intelligence
   artificielle.

Raisonnement symbolique et le thÃ©oricien logique[modifier | modifier le code]

   Quand l'accÃ¨s aux ordinateurs est devenu possible au milieu des annÃ©es
   1950, des scientifiques, en petit nombre au dÃ©but, ont compris qu'une
   machine qui pouvait manipuler des nombres pouvait aussi manipuler des
   symboles et que cette manipulation de symboles pouvait potentiellement
   Ãªtre l'essence-mÃªme de la pensÃ©e humaine. Cela a conduit Ã
   l'Ã©laboration des premiÃ¨res machines pensantes^[41].

   En 1955, Allen Newell et le futur prix Nobel d'Ã©conomie, Herbert Simon,
   avec l'aide de Cliff Shaw, ont crÃ©Ã© le Â« ThÃ©oricien logique Â». Le
   programme finira par dÃ©montrer 38 des 52 premiers thÃ©orÃ¨mes des
   Principia Mathematica de Russell et Whitehead, et a mÃªme trouvÃ© des
   dÃ©monstrations inÃ©dites et Ã©lÃ©gantes^[42]. Simon raconte qu'ils ont
   Â« rÃ©solu le vÃ©nÃ©rable problÃ¨me corps-esprit, expliquant comment un
   systÃ¨me composÃ© de matiÃ¨re peut avoir des propriÃ©tÃ©s de
   l'esprit^[43] Â». C'est l'une des premiÃ¨res formulations d'un mouvement
   philosophique que John Searle appellera plus tard Â« intelligence
   artificielle forte Â» : comme les humains, les machines peuvent possÃ©der
   un esprit^[44].

La traduction automatique des langages[modifier | modifier le code]

   En 1949, Warren Weaver publie son memorandum sur la traduction
   automatique des langues naturelles^[45] qui est Ã  la fois visionnaire
   et optimiste sur le futur de ce problÃ¨me fondamental de l'intelligence
   artificielle.

ConfÃ©rence de Dartmouth de 1956 : naissance de l'intelligence
artificielle[modifier | modifier le code]

   Article dÃ©taillÃ© : confÃ©rence de Dartmouth.

   La confÃ©rence de Dartmouth de 1956^[46] a Ã©tÃ© organisÃ©e par Marvin
   Minsky, John McCarthy et deux scientifiques seniors : Claude Shannon et
   Nathan Rochester (en) d'IBM. La thÃ¨se de la confÃ©rence incluait cette
   assertion : Â« chaque aspect de l'apprentissage ou toute autre
   caractÃ©ristique de l'intelligence peut Ãªtre si prÃ©cisÃ©ment dÃ©crit
   qu'une machine peut Ãªtre conÃ§ue pour le simuler^[47] Â». Parmi les
   participants on retrouve Ray Solomonoff, Oliver Selfridge, Trenchard
   More, Arthur Samuel, Allen Newell et Herbert Simon, qui vont chacun
   crÃ©er des programmes importants durant les premiÃ¨res dÃ©cennies de la
   recherche en IA^[48]. Newell et Simon y ont prÃ©sentÃ© le programme
   informatique Logic Theorist (Â« ThÃ©oricien logique Â»), parfois dÃ©crit
   comme le premier programme d'intelligence artificielle
   fonctionnant^[49]. Pendant la confÃ©rence, McCarthy a convaincu
   l'auditoire d'accepter l'expression Â« Intelligence Artificielle Â» comme
   intitulÃ© du domaine^[50]. La confÃ©rence de Dartmouth de 1956 a Ã©tÃ© le
   moment-clÃ© oÃ¹ l'intelligence artificielle a Ã©tÃ© appelÃ©e comme telle, a
   dÃ©fini ses objectifs, a concrÃ©tisÃ© ses premiÃ¨res rÃ©ussites et a rÃ©uni
   ses acteurs importants. Cette confÃ©rence est largement considÃ©rÃ©e, dans
   le monde occidental, comme le moment fondateur de l'intelligence
   artificielle en tant que discipline thÃ©orique indÃ©pendante (de
   l'informatique)^[rÃ©f. nÃ©cessaire]^[51].

L'Ã¢ge d'or 1956âˆ’1974[modifier | modifier le code]

   Les annÃ©es qui suivent la confÃ©rence de Dartmouth sont une Ã¨re de
   dÃ©couverte, de conquÃªtes effrÃ©nÃ©es de nouvelles contrÃ©es du savoir. Les
   programmes dÃ©veloppÃ©s Ã  l'Ã©poque sont considÃ©rÃ©s par la plupart des
   gens comme simplement Â« extraordinaires^[52] Â» : des ordinateurs
   rÃ©solvent des problÃ¨mes algÃ©briques de mots, dÃ©montrent des thÃ©orÃ¨mes
   en gÃ©omÃ©trie et apprennent Ã  parler anglais. Ã€ cette Ã©poque, peu
   croient que de tels comportements Â« intelligents Â» soient possibles
   pour des machines^[53]. Les chercheurs font preuve alors d'un optimisme
   intense dans le privÃ© comme dans leurs articles, ils prÃ©disent qu'une
   machine complÃ¨tement intelligente sera construite dans les 20 ans Ã
   venir^[54]. Les agences gouvernementales comme la DARPA investissent
   massivement dans ce nouveau domaine^[55].

Les percÃ©es[modifier | modifier le code]

   Beaucoup de programmes sont couronnÃ©s de succÃ¨s.

Raisonnement par tÃ¢tonnements[modifier | modifier le code]

   Ils sont nombreux parmi les premiers programmes d'intelligence
   artificielle Ã  utiliser le mÃªme algorithme fondamental. Pour remplir
   certains objectifs (comme gagner un jeu ou dÃ©montrer un thÃ©orÃ¨me), ils
   procÃ¨dent pas Ã  pas vers la solution (en effectuant un mouvement ou une
   dÃ©duction Ã  la fois) comme s'ils naviguent dans un labyrinthe, revenant
   en arriÃ¨re dÃ¨s qu'ils se heurtent Ã  une impasse. Ce paradigme est
   appelÃ© Â« raisonnement par tÃ¢tonnements^[56] Â» ou retour sur trace.

   La principale difficultÃ© rÃ©side dans le fait que, pour beaucoup de
   problÃ¨mes, le nombre de chemins possibles vers la solution est
   astronomique, c'est la fameuse Â« explosion combinatoire Â». Des
   chercheurs ont alors essayÃ© de rÃ©duire l'espace de recherche Ã  l'aide
   d'heuristiques ou de Â« rÃ¨gles empiriques Â» qui Ã©liminent la plupart des
   chemins dont il est peu probable qu'ils mÃ¨nent Ã  une solution^[57].

   Newell et Simon essaient de capturer une version gÃ©nÃ©rale de cet
   algorithme dans un programme appelÃ© le General Problem Solver^[58]
   (Â« solutionneur de problÃ¨me gÃ©nÃ©ral Â»). Certains programmes de
   Â« recherche Â» sont capables d'accomplir des tÃ¢ches jugÃ©es Ã  l'Ã©poque
   impressionnantes comme la rÃ©solution de problÃ¨mes gÃ©omÃ©triques et
   algÃ©briques, tels que le Geometry Theorem Prover d'Herbert Gelernter
   (1958) et le SAINT, Ã©crit par James Slagle, un des Ã©tudiants de
   Minsky^[59] (1961). D'autres programmes cherchent Ã  travers des
   objectifs et sous-objectifs pour planifier des actions, comme le
   systÃ¨me STRIPS dÃ©veloppÃ© Ã  Stanford pour contrÃ´ler le comportement de
   leur robot, Shakey^[60].
   [400px-SemanticNetArbre_s%C3%A9mantique_fr.jpg] Un exemple de rÃ©seau
   sÃ©mantique.

Langage naturel[modifier | modifier le code]

   Un but majeur de la recherche en IA est de permettre aux ordinateurs de
   communiquer en langage naturel comme l'anglais. Un des premiers succÃ¨s
   Ã©tait le programme STUDENT de Bobrow, qui pouvait rÃ©soudre des
   problÃ¨mes algÃ©briques rÃ©digÃ©s pour lycÃ©ens^[61].

   Un rÃ©seau sÃ©mantique reprÃ©sente des concepts (par ex. Â« maison Â»,
   Â« porte Â») Ã  l'aide de nÅ“uds et les relations entre les concepts (par
   ex. Â« possÃ¨de un Â») par des liaisons entre ces nÅ“uds. Le premier
   programme d'IA Ã  utiliser un rÃ©seau sÃ©mantique a Ã©tÃ© Ã©crit par Ross
   Quillian^[62] et la version la plus performante (et controversÃ©e) a Ã©tÃ©
   la Conceptual dependency theory de Roger Schank^[63].

   ELIZA de Joseph Weizenbaum pouvait mener des conversations si rÃ©alistes
   que certains utilisateurs se sont laissÃ© abuser en croyant communiquer
   avec un Ãªtre humain et non un programme. En rÃ©alitÃ©, ELIZA n'avait
   aucune idÃ©e de ce dont elle parlait. Elle donnait simplement une
   Â« rÃ©ponse-bateau Â» ou reformulait en rÃ©ponse grÃ¢ce Ã  quelques rÃ¨gles de
   grammaire. ELIZA Ã©tait le premier agent conversationnel^[64].

Micro-mondes[modifier | modifier le code]

   Ã€ la fin des annÃ©es 1960, Marvin Minsky et Seymour Papert du
   Laboratoire d'IA du MIT ont proposÃ© que la recherche d'IA se concentre
   sur des situations artificiellement simplifiÃ©es appelÃ©es aussi
   micro-mondes. Ils ont mentionnÃ© Ã  juste titre que dans les sciences
   performantes comme la physique, les principes fondamentaux Ã©taient
   souvent mieux compris en utilisant des modÃ¨les simplifiÃ©s tels que des
   avions sans friction, ou des corps parfaitement rigides. La majoritÃ© de
   la recherche s'est alors centrÃ©e sur un Â« monde-blocs Â», qui consistait
   en un ensemble de blocs colorÃ©s de formes et tailles variÃ©es disposÃ©s
   sur une surface plane^[65].

   Ce paradigme a permis des travaux innovants dans la vision industrielle
   de Gerald Sussman (qui dirigeait l'Ã©quipe), Adolfo Guzman, David Waltz
   (qui inventa la Â« propagation de contraintes Â»), et surtout Patrick
   Winston. Au mÃªme moment, Minsky et Papert construisait un bras
   robotique qui empilait des blocs, insufflant la vie dans ces
   monde-blocs. La plus grande rÃ©ussite de ces programmes micro-mondes a
   Ã©tÃ© le SHRDLU de Terry Winograd. Ce dernier pouvait communiquer en
   anglais Ã  l'aide de phrases ordinaires, planifier des opÃ©rations et les
   exÃ©cuter^[66].

L'optimisme[modifier | modifier le code]

   La premiÃ¨re gÃ©nÃ©ration de chercheurs en IA fait les prÃ©visions
   suivantes Ã  propos de leur travail :
     * En 1958, H. Simon et Allen Newell : Â« d'ici dix ans un ordinateur
       sera le champion du monde des Ã©checs Â» et Â« d'ici dix ans, un
       ordinateur dÃ©couvrira et rÃ©soudra un nouveau thÃ©orÃ¨me mathÃ©matique
       majeur^[67] Â».
     * En 1965, H. Simon : Â« des machines seront capables, d'ici vingt
       ans, de faire tout travail que l'homme peut faire^[68] Â».
     * En 1967, Marvin Minsky : Â« dans une gÃ©nÃ©ration [...] le problÃ¨me de
       la crÃ©ation d'une 'intelligence artificielle' [sera] en grande
       partie rÃ©solu^[69] Â».
     * En 1970, Marvin Minsky (dans le magazine Life) : Â« Dans trois Ã
       huit ans nous aurons une machine avec l'intelligence gÃ©nÃ©rale d'un
       Ãªtre humain ordinaire^[70] Â».

Le financement[modifier | modifier le code]

   En juin 1963 le MIT reÃ§oit une subvention de 2,2 millions de dollars de
   la toute jeune ARPA (Â« Agence pour les projets de recherche avancÃ©e Â»,
   qui deviendra plus tard la DARPA). L'argent est utilisÃ© pour financer
   le Projet MAC (en) qui englobe le Â« Groupe IA Â» fondÃ© par Minsky et
   McCarthy cinq ans plus tÃ´t. L'ARPA continue Ã  fournir trois millions de
   dollars par an jusqu'aux annÃ©es 1970^[71]. L'ARPA fait des subventions
   similaires au programme de Newell et Simon Ã  Carnegie-Mellon et au
   projet Stanford I.A. (fondÃ© par John McCarthy en 1963)^[72]. Un autre
   laboratoire important d'IA est Ã©tabli Ã  l'universitÃ© d'Ã‰dimbourg par
   Donald Michie en 1965^[73]. Ces quatre institutions continuent d'Ãªtre
   les principaux centres de recherche en IA au niveau acadÃ©mique pendant
   de nombreuses annÃ©es^[74].

   L'argent est distribuÃ© avec peu de contrÃ´le. L'ancien professeur de
   Minsky Ã  Harvard, J. C. R. Licklider, alors Ã  la tÃªte du Â« Bureau des
   Techniques de Traitement de l'Information Â» (IPTO) et directeur du
   Programme Command & Control de l'ARPA, pense que son organisation doit
   Â« financer des personnes, pas des projets ! Â» et autorise les
   chercheurs Ã  poursuivre toutes les pistes qui leur semblent
   intÃ©ressantes^[75]. Cela crÃ©e une atmosphÃ¨re de libertÃ© totale au MIT
   qui donne ainsi naissance Ã  la culture hacker^[76]. Ã€ Licklider
   (1962-64) succÃ¨dent Ivan Sutherland (1964-66), Robert Taylor (1966-69)
   et Lawrence Roberts (1969-1972), tous proches du MIT et dans la
   continuitÃ© de Licklider vis-Ã -vis de l'IA. NÃ©anmoins cette attitude non
   interventionniste ne dure pas.

La premiÃ¨re hibernation de l'intelligence artificielle (1974âˆ’1980)[modifier |
modifier le code]

   Dans les annÃ©es 1970, l'intelligence artificielle subit critiques et
   revers budgÃ©taires, car les chercheurs en intelligence artificielle
   n'ont pas une vision claire des difficultÃ©s des problÃ¨mes auxquels ils
   sont confrontÃ©s. Leur immense optimisme a engendrÃ© une attente
   excessive et quand les rÃ©sultats promis ne se matÃ©rialisent pas, les
   investissements consacrÃ©s Ã  l'intelligence artificielle
   s'Ã©tiolent^[77]. Dans la mÃªme pÃ©riode, le connexionisme a Ã©tÃ© presque
   complÃ©tement mis sous le boisseau pour 10 ans par la critique
   dÃ©vastatrice de Marvin Minsky sur les perceptrons^[78]. MalgrÃ© l'image
   nÃ©gative de l'intelligence artificielle dans le grand public Ã  la fin
   des annÃ©es 1970, de nouvelles idÃ©es sont explorÃ©es en programmation
   logique, raisonnement de bon sens^[Note 3] et dans d'autres
   directions^[79].

Les problÃ¨mes[modifier | modifier le code]

   Au dÃ©but des annÃ©es 1970, les capacitÃ©s des programmes d'IA sont
   limitÃ©es. Les plus performants peinent Ã  manipuler des versions
   simplistes des problÃ¨mes qu'ils sont supposÃ©s rÃ©soudre et tous les
   problÃ¨mes sont, d'une certaine maniÃ¨re, des Â« broutilles^[80] Â». De
   fait, les chercheurs en IA font face Ã  plusieurs limites fondamentales
   insurmontables et bien que certaines limites soient dÃ©passÃ©es depuis,
   d'autres demeurent de vrais obstacles^[81].

Limites de la puissance de calcul[modifier | modifier le code]

   La puissance et la mÃ©moire de l'Ã©poque Ã©taient considÃ©rÃ©es Ã  juste
   titre comme un vÃ©ritable frein Ã  des applications pratiques ; elles
   suffisaient Ã  peine pour dÃ©montrer des modÃ¨les simplistes.

   Ainsi, le travail de Ross Quillian sur le langage naturel est limitÃ© Ã
   un vocabulaire de vingt mots, car la mÃ©moire ne peut pas en contenir
   plus^[82].

   En outre, Hans Moravec se plaint en 1976 du fait que les ordinateurs
   soient des millions de fois trop faibles pour faire montre d'une
   quelconque intelligence, qu'ils sont loin d'atteindre le seuil critique
   minimal. Pour mieux faire comprendre ce qu'il entend par seuil, il
   utilise l'analogie suivante : Â« En dessous d'un certain niveau de
   puissance, un avion reste plaquÃ© au sol et ne peut pas dÃ©coller du
   tout, c'est juste impossible Â». NÃ©anmoins comme la puissance
   informatique augmente, Ã§a finira par devenir possible^[83]^,^[Note 4].

   Quant Ã  la vision par ordinateur, Moravec estime que le simple fait
   d'Ã©galer les capacitÃ©s de la rÃ©tine humaine Ã  dÃ©tecter les mouvements
   et les contours en temps rÃ©el (problÃ¨me simple de nos jours)
   nÃ©cessiterait un ordinateur gÃ©nÃ©rique capable de 10^9 opÃ©rations par
   seconde (1 000 MIPS^[84]). Par comparaison, l'ordinateur le plus rapide
   en 1976, le Cray-1 (vendu entre 5 et 8 000 000 $), est seulement
   capable d'environ 80 Ã  130 MIPS, et un ordinateur de bureau typique de
   l'Ã©poque n'atteint mÃªme pas 1 MIPS. En fait, son estimation,
   impressionnante pour l'Ã©poque, s'est avÃ©rÃ©e trop optimiste : en 2011,
   les applications de vision par ordinateur concrÃ¨tes ont besoin de dix Ã
   mille fois plus de puissance, se situant plutÃ´t entre 10 000 Ã
   1 000 000 MIPS.

Limites inhÃ©rentes : la complÃ©tude NP[modifier | modifier le code]

   En 1972, Ã  la suite du thÃ©orÃ¨me de Cook, Richard Karp a montrÃ© qu'il y
   avait de nombreux problÃ¨mes trÃ¨s difficiles, pour lesquels trouver des
   solutions optimales Ã©tait impensable, avec comme consÃ©quence que les
   problÃ¨mes fondamentaux de l'intelligence artificielle ne passeront pas
   Ã  l'Ã©chelle^[85].

Raisonnement et base de connaissance de culture gÃ©nÃ©rale[modifier | modifier
le code]

   De nombreuses applications majeures d'intelligence artificielle comme
   la vision par ordinateur ou le traitement automatique du langage
   naturel ont besoin d'Ã©normes quantitÃ©s d'information du monde rÃ©el pour
   mettre en place des programmes capable de Â« comprendre Â» ce qu'il voit
   ou de discuter. DÃ¨s les annÃ©es 1970, les chercheurs dans ces domaines
   dÃ©couvrent que la quantitÃ© d'information correspondante est trÃ¨s
   grande, bien qu'un enfant l'acquiert trÃ¨s rapidement. Ã€ cette Ã©poque,
   il n'Ã©tait pas envisageable de construire une telle base de donnÃ©es ni
   un programme capable de gÃ©rer autant d'information^[86]^,^[87]^,^[88].

Le paradoxe de Moravec[modifier | modifier le code]

   Article dÃ©taillÃ© : paradoxe de Moravec.

   Les chercheurs en intelligence artificielle et en robotique Hans
   Moravec, Rodney Brooks et Marvin Minsky mirent en Ã©vidence que le
   raisonnement de haut niveau est souvent plus facile Ã  reproduire et
   simuler par un programme informatique que les aptitudes sensorimotrices
   humaines. Ceci peut sembler contre-intuitif du fait qu'un humain n'a
   pas de difficultÃ© particuliÃ¨re Ã  effectuer des tÃ¢ches relevant de cette
   derniÃ¨re catÃ©gorie, contrairement Ã  la premiÃ¨re.

   Par exemple, dÃ©montrer des thÃ©orÃ¨mes ou rÃ©soudre des problÃ¨mes
   gÃ©omÃ©triques est relativement faisable par les ordinateurs, mais une
   tÃ¢che plus simple pour un humain, comme reconnaÃ®tre un visage ou
   traverser une piÃ¨ce sans collision, a longtemps Ã©tÃ© trÃ¨s compliquÃ© pour
   les machines. Ainsi, la recherche en vision par ordinateur et en
   robotique a fait peu de progrÃ¨s au milieu des annÃ©es 1970^[89]^,^[90].

Le cadre et les problÃ¨mes de qualification[modifier | modifier le code]

   Les chercheurs en IA (comme John McCarthy) qui se sont servis de la
   logique ont dÃ©couvert qu'ils ne pouvaient pas reprÃ©senter des
   dÃ©ductions ordinaires qui impliquaient de la planification ou des
   raisonnements par dÃ©faut sans avoir Ã  modifier la structure de la
   logique elle-mÃªme. Ils ont dÃ» dÃ©velopper de nouvelles logiques (comme
   les logiques non monotones et modales) pour essayer de rÃ©soudre ces
   problÃ¨mes^[91].

La fin des investissements[modifier | modifier le code]

   Les agences qui ont investi dans la recherche en IA (comme le
   gouvernement britannique, la DARPA et le NRC, Conseil amÃ©ricain de la
   recherche) deviennent frustrÃ©es par le manque de progrÃ¨s et finissent
   par couper pratiquement tous les fonds de recherche fondamentale en IA.
   Ce comportement commence dÃ¨s 1966 quand un rapport de l'ALPAC^[Note 5]
   paraÃ®t critiquer les efforts de traduction automatisÃ©e. AprÃ¨s avoir
   dÃ©pensÃ© 20 millions de dollars, le NRC dÃ©cide de tout arrÃªter^[92]. En
   1973, le Rapport Lighthill (en) sur l'Ã©tat de la recherche en IA en
   Angleterre a critiquÃ© l'Ã©chec lamentable de l'IA Ã  atteindre ses
   Â« ambitieux objectifs Â» et a conduit au dÃ©mantÃ¨lement de la recherche
   en IA dans ce pays^[93] (Ce rapport mentionne en particulier le
   problÃ¨me d'explosion combinatoire comme une des raisons des Ã©checs de
   l'IA^[94]). Quant Ã  la DARPA, elle a Ã©tÃ© extrÃªmement dÃ©Ã§ue par les
   chercheurs travaillant dans le programme Speech Understanding Research
   Ã  Carnegie-Mellon et a annulÃ© une subvention annuelle de trois millions
   de dollars^[95]. Vers 1974, trouver des financements pour des projets
   d'IA Ã©tait donc chose rare.

   Hans Moravec a attribuÃ© la crise aux prÃ©dictions irrÃ©alistes de ses
   collÃ¨gues. Â« Beaucoup de chercheurs se sont retrouvÃ©s piÃ©gÃ©s dans un
   entrelacs d'exagÃ©rations croissantes^[96]. Â» Un autre problÃ¨me est
   apparu : le vote de l'amendement Mansfield en 1969, a mis la DARPA sous
   une pression croissante pour qu'elle ne finance que des Â« recherches
   directement applicables, plutÃ´t que des recherches exploratoires
   fondamentales Â». Un financement pour de l'exploration crÃ©ative, en roue
   libre, tel qu'il avait cours dans les annÃ©es soixante ne viendrait plus
   de la DARPA. Au lieu de cela, l'argent Ã©tait redirigÃ© vers des projets
   spÃ©cifiques avec des objectifs prÃ©cis, comme des chars de combat
   autonomes ou des systÃ¨mes de gestion de batailles^[97].

Critiques universitaires[modifier | modifier le code]

   Plusieurs philosophes Ã©mettent de fortes objections aux affirmations
   des chercheurs en IA. Un des premiers opposants est John Lucas, qui
   s'appuie sur le thÃ©orÃ¨me d'incomplÃ©tude de GÃ¶del pour contester
   l'aptitude des dÃ©monstrateurs automatiques de thÃ©orÃ¨mes Ã  dÃ©montrer
   certaines affirmations^[98]. Hubert Dreyfus ridiculise les promesses
   non tenues des annÃ©es soixante et critique les hypothÃ¨ses de l'IA,
   argumentant que le raisonnement humain avait en fait besoin de trÃ¨s peu
   de Â« traitement symbolique Â» mais surtout de sentiment dâ€™embodiment,
   d'instinct, d'un Â« savoir-faire Â» inconscient^[99]^,^[100]. L'argument
   de la chambre chinoise avancÃ© par John Searle en 1980, tente de montrer
   qu'on ne peut pas dire qu'un programme Â« comprend Â» les symboles qu'il
   utilise (une qualitÃ© appelÃ©e Â« intentionnalitÃ© Â»). Si les symboles
   n'ont aucun sens pour la machine, on ne peut, dixit Searle, qualifier
   la machine de Â« pensante^[101] Â».

   Ces critiques ne sont pas vraiment prises en considÃ©ration par les
   chercheurs en IA, tant certaines ne visent pas l'essence du problÃ¨me.
   Les questions telles que l'indÃ©cidabilitÃ©, la complexitÃ© inhÃ©rente ou
   la dÃ©finition de la culture gÃ©nÃ©rale semblent beaucoup plus immÃ©diates
   et graves. Ils pensent que la diffÃ©rence entre le Â« savoir-faire Â» et
   l'Â« intentionnalitÃ© Â» n'apporte presque rien Ã  un programme
   informatique. Minsky dit de Dreyfus et Searle qu'Â« ils ont mal compris
   la question et on devrait les ignorer^[102] Â». Les critiques de
   Dreyfus, qui enseigne au MIT, sont accueillies fraÃ®chement : il a plus
   tard avouÃ© que les chercheurs en IA Â« n'osaient pas manger avec moi de
   peur que nous soyons vus ensemble^[103] Â». Joseph Weizenbaum, l'auteur
   d'ELIZA, considÃ¨re, lui, que le comportement de ses collÃ¨gues Ã  l'Ã©gard
   de Dreyfus est non professionnel et infantile. Bien qu'il critique
   ouvertement les positions de Dreyfus, il fait clairement comprendre que
   ce n'est pas [comme cela] qu'il faut traiter quelqu'un^[104].

   Weizenbaum commence Ã  avoir de sÃ©rieux doutes Ã©thiques Ã  propos de l'IA
   quand Kenneth Colby Ã©crit DOCTOR, un agent conversationnel thÃ©rapeute.
   Weizenbaum est gÃªnÃ© par le fait que Colby voit en son programme sans
   esprit un outil thÃ©rapeutique sÃ©rieux. Une querelle Ã©clate alors, et la
   situation empire quand Colby omet de mentionner la contribution de
   Weizenbaum au programme. En 1976, Weizenbaum publie Puissance
   informatique et raison humaine (en) qui explique que le mauvais usage
   de l'intelligence artificielle peut potentiellement conduire Ã
   dÃ©valoriser la vie humaine^[105].

Perceptrons et la pÃ©riode sombre du connexionnisme[modifier | modifier le
code]

   Un perceptron est un type de rÃ©seaux neuronaux introduit en 1958 par
   Frank Rosenblatt^[106]. Comme la plupart des chercheurs en IA de
   l'Ã©poque, il est optimiste, prÃ©disant qu'Â« un perceptron pourra Ãªtre
   capable d'apprendre, de prendre des dÃ©cisions, et de traduire les
   langues Â». Un programme de recherche dynamique sur ces concepts est
   menÃ© dans les annÃ©es soixante, mais il s'arrÃªte brutalement aprÃ¨s la
   publication du livre de Minsky et Papert en 1969 intitulÃ© Perceptrons.
   Ce livre constate plusieurs limites Ã  ce que les perceptrons peuvent
   faire et note plusieurs exagÃ©rations dans les prÃ©dictions de Frank
   Rosenblatt. L'effet du livre est dÃ©vastateur : aucune recherche dans le
   domaine du connexionnisme ne se fait pendant dix ans. Ce n'est qu'aprÃ¨s
   une dÃ©cennie, qu'une nouvelle gÃ©nÃ©ration de chercheurs se rÃ©attaque au
   problÃ¨me, notamment en France, Guy Perennou et Serge Castan^[107].

Les Ã©lÃ©gants : calcul des prÃ©dicats, Prolog et systÃ¨mes experts[modifier |
modifier le code]

   John McCarthy introduit l'usage de la logique en IA dÃ¨s 1958, dans son
   Advice Taker^[Note 6]^,^[108]. En 1963, J. Alan Robinson dÃ©couvre une
   mÃ©thode relativement simple pour implÃ©menter la dÃ©duction. Pour cela il
   invente les concepts de rÃ©solution et d'unification. En effet, des
   implÃ©mentations plus directes, comme celles essayÃ©es par McCarthy et
   ses Ã©tudiants Ã  la fin des annÃ©es soixante, se sont rÃ©vÃ©lÃ©es
   particuliÃ¨rement inefficaces, car les algorithmes requiÃ¨rent un nombre
   astronomique d'Ã©tapes pour dÃ©montrer des thÃ©orÃ¨mes trÃ¨s simples^[109].
   Une utilisation plus fructueuse de la logique a Ã©tÃ© dÃ©veloppÃ©e dans les
   annÃ©es 1970 par Alain Colmerauer et Philippe Roussel Ã  l'universitÃ© de
   Marseille-Luminy et Robert Kowalski (en) Ã  l'universitÃ© d'Ã‰dimbourg qui
   ont crÃ©Ã© le langage de programmation Prolog^[110]. Prolog utilise un
   sous-ensemble du calcul des prÃ©dicats, les clauses de Horn, qui permet
   des calculs plus efficaces. D'autres chercheurs utilisent des rÃ¨gles de
   production, notamment les systÃ¨mes experts d'Edward Feigenbaum et les
   logiciels d'Allen Newell et Herbert Simon qui conduit Ã  Soar et la
   ThÃ©ory unifiÃ©e de la cognition [Â« Unified Theory of Cognition Â»],
   1990^[111].

   L'approche logique a Ã©tÃ© critiquÃ©e dÃ¨s son apparition. Ainsi Hubert
   Dreyfus note que les Ãªtres humains se servent rarement de logique quand
   ils rÃ©solvent des problÃ¨mes. Les expÃ©riences de psychologues tels que
   Peter Wason, Eleanor Rosch, Amos Tversky, Daniel Kahneman et d'autres
   corroborent plus ou moins cet avis^[112]. McCarthy a rÃ©torquÃ© que ce
   que les humains font n'est pas pertinent, expliquant que le but est
   d'avoir des machines qui peuvent rÃ©soudre des problÃ¨mes, pas des
   machines qui pensent comme des humains^[113]. Mais la critique la plus
   sÃ©vÃ¨re de l'approche fondÃ©e sur la dÃ©duction automatique vient du
   thÃ©oricien de l'informatique Stephen Cook qui montre dans son cÃ©lÃ¨bre
   article The Complexity of Theorem-Proving Procedures (Â« La complexitÃ©
   des procÃ©dures de dÃ©monstration de thÃ©orÃ¨mes Â») qu'il n'y a pas de
   procÃ©dures automatiques efficaces de dÃ©monstration de thÃ©orÃ¨mes sauf si
   P = NP.

Les brouillons : cadres et scripts[modifier | modifier le code]

   Parmi les critiques de l'approche de McCarthy on trouve ses collÃ¨gues Ã
   travers le pays au MIT Marvin Minsky, Seymour Papert et Roger Schank
   ont essayÃ© de rÃ©soudre des problÃ¨mes comme la Â« comprÃ©hension d'une
   histoire Â» et la Â« reconnaissance d'objets Â» qui requiÃ¨rent d'une
   machine de penser comme une personne. Pour manipuler des concepts
   ordinaires comme une Â« chaise Â» ou un Â« restaurant Â», elles doivent
   faire toutes les mÃªmes hypothÃ¨ses plus ou moins logiques que les gens
   font habituellement. Malheureusement, de tels concepts imprÃ©cis sont
   difficiles Ã  reprÃ©senter en logique. Gerald Sussman observe
   qu'Â« utiliser un langage prÃ©cis pour dÃ©crire des concepts imprÃ©cis ne
   rend pas ces derniers plus prÃ©cis^[114] Â». Schank dÃ©crit ces approches
   alogiques comme Â« brouillonnes (en) Â», qu'il oppose aux paradigmes
   Â« Ã©lÃ©gants (en) Â» utilisÃ©s par McCarthy, Kowalski, Feigenbaum, Newell
   et Simon^[115].

   En 1975, Minsky remarque que beaucoup de ses pairs Â« brouillons Â»
   utilisent la mÃªme approche, Ã  savoir un cadre de travail qui englobe
   toutes les hypothÃ¨ses de culture gÃ©nÃ©rale (en) d'un thÃ¨me donnÃ©. Par
   exemple, si on manipule le concept Â« oiseau Â», une multitude de faits
   viennent Ã  l'esprit, ainsi on peut prÃ©tendre qu'il vole, qu'il mange
   des vers, etc.. On sait que ces faits ne sont pas toujours vrais et que
   les dÃ©ductions Ã  partir de ces faits ne sont pas toutes Â« logiques Â»,
   mais ces ensembles structurÃ©s d'hypothÃ¨ses font partie du contexte de
   nos discussions ou de nos pensÃ©es. Minsky appelle ces structures des
   Â« cadres Â». Schank, quant Ã  lui, introduit une variante des cadres
   qu'il appelle des Â« scripts Â» afin de rÃ©pondre Ã  des questions sur des
   romans anglophones^[116]. Certains affirment que quelques annÃ©es plus
   tard la programmation orientÃ©e objet empruntera aux cadres de
   l'intelligence artificielle la notion d'Â« hÃ©ritage Â».

Le boom 1980â€“1987[modifier | modifier le code]

   Dans les annÃ©es 1980, des programmes d'IA appelÃ©s Â« systÃ¨mes experts Â»
   sont adoptÃ©s par les entreprises et la connaissance devient le sujet
   central de la recherche en IA. Au mÃªme moment, le gouvernement japonais
   finance massivement l'IA Ã  travers son initiative Â« ordinateurs de
   cinquiÃ¨me gÃ©nÃ©ration (en) Â». Un autre Ã©vÃ¨nement est la renaissance du
   connexionnisme Ã  travers les travaux de John Hopfield et David
   Rumelhart.

La montÃ©e des systÃ¨mes experts[modifier | modifier le code]

   Un systÃ¨me expert est un programme qui rÃ©pond Ã  des questions ou rÃ©sout
   des problÃ¨mes dans un domaine de connaissance donnÃ©, Ã  l'aide de rÃ¨gles
   logiques dÃ©rivÃ©es de la connaissance des experts humains de ce domaine.
   Les tout premiers exemplaires sont dÃ©veloppÃ©s par Edward Feigenbaum et
   ses Ã©tudiants. Dendral, commencÃ© en 1965, identifie des composants
   chimiques Ã  partir de relevÃ©s spectromÃ©triques. Mycin, dÃ©veloppÃ© en
   1972, permet de diagnostiquer des maladies infectieuses du sang. Ces
   programmes confirment la viabilitÃ© de l'approche^[117].

   Les systÃ¨mes experts se limitent volontairement Ã  un petit domaine de
   connaissance spÃ©cifique (esquivant ainsi le problÃ¨me de culture
   gÃ©nÃ©rale) et leur conception simple permet de construire ces logiciels
   relativement facilement et de les amÃ©liorer une fois dÃ©ployÃ©s.
   Finalement, ces programmes se rÃ©vÃ¨lent utiles, car c'est la premiÃ¨re
   fois que l'intelligence artificielle trouve une application
   pratique^[118].

   En 1980, un systÃ¨me expert appelÃ© Xcon, dont l'objectif est d'optimiser
   la configuration des ordinateurs VAX Ã  livrer aux clients, est rÃ©alisÃ©
   par Carnegie-Mellon pour DEC. Le succÃ¨s est Ã©norme, car l'entreprise
   peut Ã©conomiser dÃ¨s 1986 jusqu'Ã  40 millions de dollars par an^[119].
   DÃ¨s lors, les sociÃ©tÃ©s de par le monde commencent Ã  dÃ©velopper et Ã
   dÃ©ployer leurs systÃ¨mes experts et vers 1985 plus d'un milliard de
   dollars est dÃ©pensÃ© en intelligence artificielle, majoritairement dans
   les centres industriels de recherche et dÃ©veloppement. Tout un secteur
   industriel se crÃ©e autour des systÃ¨mes experts, dont des constructeurs
   de matÃ©riel informatique comme Symbolics et LMI (Lisp Machines, Inc.)
   et des Ã©diteurs de logiciels tels que IntelliCorp et Aion^[120].

La rÃ©volution de la connaissance[modifier | modifier le code]

   La puissance des systÃ¨mes experts vient de l'expertise qu'ils
   contiennent. Ils font partie d'une nouvelle direction de recherche en
   IA qui a gagnÃ© du terrain dans les annÃ©es 1970. Â« Les chercheurs en IA
   commenÃ§aient Ã  soupÃ§onner â€” avec rÃ©ticence, car Ã§a allait contre le
   canon scientifique de parcimonie â€” que l'intelligence puisse trÃ¨s bien
   Ãªtre basÃ©e sur la capacitÃ© Ã  utiliser une large quantitÃ© de savoirs
   divers de diffÃ©rentes maniÃ¨res^[121] Â» remarque Pamela McCorduck. Â« La
   grande leÃ§on des annÃ©es soixante-dix a Ã©tÃ© que les comportements
   intelligents dÃ©pendaient Ã©normÃ©ment du traitement de la connaissance,
   parfois d'une connaissance trÃ¨s avancÃ©e dans le domaine d'une tÃ¢che
   donnÃ©e^[122]. Â» Les systÃ¨mes de bases de connaissance et l'ingÃ©nierie
   des connaissances sont devenus centraux dans la recherche en
   intelligence artificielle des annÃ©es 1980^[123].

   Les annÃ©es 1980 ont aussi vu la naissance de Cyc, la premiÃ¨re tentative
   d'attaque frontale du problÃ¨me de culture gÃ©nÃ©rale : une base de
   donnÃ©es gigantesque a Ã©tÃ© crÃ©Ã©e dans le but de contenir tous les faits
   triviaux qu'une personne moyenne connaÃ®t. Douglas Lenat, qui a dÃ©marrÃ©
   et dirigÃ© le projet, argumente qu'il n'y a aucun raccourci â€• le seul
   moyen pour des machines de connaÃ®tre la signification de concepts
   humains Ã©tait de leur apprendre, un concept Ã  la fois, et manuellement.
   On s'attend bien sÃ»r Ã  ce que le projet se dÃ©roule sur plusieurs
   dÃ©cennies^[124].

L'argent est de retour : projets de la cinquiÃ¨me gÃ©nÃ©ration[modifier |
modifier le code]

   En 1981, le ministÃ¨re japonais de l'Ã‰conomie, du Commerce et de
   l'Industrie rÃ©serve 850 millions de dollars pour le projet des
   ordinateurs de cinquiÃ¨me gÃ©nÃ©ration (en). Leur objectif est d'Ã©crire
   des programmes et de construire des machines qui peuvent tenir des
   conversations, traduire, interprÃ©ter des images et raisonner comme des
   Ãªtres humains^[125]. Au grand dam des tenants de l'approche
   brouillonne (en), ils choisissent Prolog comme langage informatique
   principal de leur projet^[126], qu'ils modifient d'ailleurs assez
   profondÃ©ment pour qu'il s'adapte Ã  leur besoin.

   D'autres pays rÃ©pondent avec de nouveaux programmes Ã©quivalents. Le
   Royaume-Uni dÃ©marre le projet Alvey (en) de 350 millions de livres. Un
   consortium d'entreprises amÃ©ricaines forment la Microelectronics and
   Computer Technology Corporation (ou MCC) pour financer des projets en
   informatique et en intelligence artificielle Ã  grande
   Ã©chelle^[127]^,^[128]. La DARPA a aussi rÃ©agi en fondant la Strategic
   Computing Initiative (Initiative Informatique StratÃ©gique) et en
   triplant ses investissements en IA entre 1984 et 1988^[129].
   [220px-Hopfield-net-vector.svg.png] Un rÃ©seau d'Hopfield Ã  quatre
   nÅ“uds.

La renaissance du connexionnisme[modifier | modifier le code]

   En 1982, le physicien John Hopfield a dÃ©montrÃ© qu'un certain type de
   rÃ©seau neuronal (dÃ©sormais appelÃ© un Â« rÃ©seau de Hopfield Â») pouvait
   apprendre et traiter de l'information d'une maniÃ¨re totalement inÃ©dite.
   Au cours de la mÃªme pÃ©riode, David Rumelhart a rendu populaire une
   nouvelle mÃ©thode de formation des rÃ©seaux neuronaux appelÃ©e
   Â« rÃ©tropropagation du gradient Â» (dÃ©couverte quelques annÃ©es avant par
   Paul Werbos). Ces deux nouvelles dÃ©couvertes ont fait renaÃ®tre le champ
   du connexionnisme qui avait Ã©tÃ© largement abandonnÃ© depuis
   1970^[128]^,^[130].

   Le tout jeune domaine a Ã©tÃ© unifiÃ© et inspirÃ© par l'apparence du
   Traitement ParallÃ¨le DistribuÃ© de 1986 â€” une collection d'articles en
   deux volumes Ã©ditÃ©e par Rumelhart et le psychologue McClelland. Les
   rÃ©seaux neuronaux deviendront un succÃ¨s commercial dans les annÃ©es
   1990, quand on commencera Ã  les utiliser comme moteurs d'applications
   telles que la reconnaissance optique de caractÃ¨res et la reconnaissance
   vocale^[128]^,^[131].

La crise : le second hiver de l'IA 1987âˆ’1993[modifier | modifier le code]

   La fascination de la communautÃ© Ã©conomique pour l'intelligence
   artificielle a gonflÃ© puis chutÃ© dans les annÃ©es 1980 en suivant le
   schÃ©ma classique d'une bulle Ã©conomique. L'effondrement de l'IA a eu
   lieu au niveau de la perception que les investisseurs et les agences
   gouvernementales en avaient â€” le domaine scientifique continue ses
   avancÃ©es malgrÃ© les critiques. Rodney Brooks et Hans Moravec,
   chercheurs dans le domaine voisin de la robotique, plaident pour une
   approche entiÃ¨rement neuve de l'intelligence artificielle.

Une seconde hibernation[modifier | modifier le code]

   L'expression Â« hiver de l'IA Â» a circulÃ© parmi les chercheurs qui,
   ayant dÃ©jÃ  vÃ©cu les coupes de budget de 1974, rÃ©alisent avec inquiÃ©tude
   que l'excitation autour des systÃ¨mes experts est hors de contrÃ´le et
   qu'il y aurait sÃ»rement de la dÃ©ception derriÃ¨re^[132]. Leurs craintes
   sont effectivement fondÃ©es : entre la fin des annÃ©es 1980 et le dÃ©but
   des annÃ©es 1990, l'intelligence artificielle a subi une sÃ©rie de coupes
   budgÃ©taires.

   Les premiers indices d'une tempÃªte Ã  venir ont Ã©tÃ© le brusque
   effondrement du marchÃ© du matÃ©riel informatique spÃ©cialiste de
   l'intelligence artificielle en 1987. Les ordinateurs de bureau d'Apple
   et IBM ont progressivement amÃ©liorÃ© leur vitesse et leur puissance et
   en 1987 ils deviennent plus performants que les fleurons du marchÃ©,
   tels que la meilleure machine Lisp de Symbolics. Il n'y a donc plus
   aucune raison de les acheter. Du jour au lendemain, une industrie d'un
   demi-milliard de dollars disparaÃ®t totalement^[133].

   Finalement, les premiers systÃ¨mes experts Ã  succÃ¨s comme le Xcon ont un
   coÃ»t de maintenance trop Ã©levÃ©. Ils sont difficiles Ã  mettre Ã  jour,
   ils ne peuvent pas apprendre, ils sont trop Â« fragiles (en) Â» (ainsi,
   ils peuvent faire des erreurs grotesques quand les paramÃ¨tres sortent
   des valeurs habituelles), et s'empÃªtrent dans des problÃ¨mes (tels que
   le problÃ¨me de qualification). Les systÃ¨mes experts se sont rÃ©vÃ©lÃ©s
   utiles, mais uniquement dans des contextes trÃ¨s spÃ©cifiques^[134].

   Ã€ la fin des annÃ©es 1980, la Strategic Computing Initiative^[Note 7] de
   la DARPA a complÃ©tement et abruptement coupÃ© ses subsides Ã
   l'intelligence artificielle. Une nouvelle direction de la DARPA ayant
   conclu que l'intelligence artificielle n'est plus de Â« derniÃ¨re mode Â»,
   elle a redirigÃ© les subventions vers des projets plus propices Ã  des
   rÃ©sultats rapides^[135].

   Vers 1991, les objectifs impressionnants listÃ©s en 1981 par le Japon
   pour ses Ordinateurs de cinquiÃ¨me gÃ©nÃ©ration n'ont pas Ã©tÃ© atteints.
   D'ailleurs certains d'entre eux, comme le fait de Â« mener une
   conversation ordinaire Â» ne l'ont toujours pas Ã©tÃ© vingt ans plus
   tard^[136]. Comme pour d'autres projets en intelligence artificielle,
   la barre a Ã©tÃ© placÃ©e beaucoup trop haut^[136].

L'importance du corps : Nouvelle intelligence artificielle et
embodiment[modifier | modifier le code]

   Ã€ la fin des annÃ©es 1980, plusieurs chercheurs plaident pour une
   approche de l'intelligence artificielle complÃ©tement inÃ©dite, centrÃ©e
   sur la robotique^[137]. Ils pensent que pour mettre en Ã©vidence une
   vraie intelligence, une machine doit avoir conscience de son corps â€”
   elle doit percevoir, bouger, survivre et Ã©voluer dans le monde. Ils
   expliquent que ces capacitÃ©s senso-motrices sont essentielles aux
   capacitÃ©s de plus haut niveau telles que le raisonnement de culture
   gÃ©nÃ©rale et que le raisonnement abstrait est en fait la capacitÃ©
   humaine la moins intÃ©ressante ou importante (cf. le paradoxe de
   Moravec). Ils dÃ©fendent une intelligence Â« par la base^[138]. Â»

   L'approche ravive des concepts nÃ©s de la cybernÃ©tique et de la
   rÃ©gulation qui ont perdu de leur impact depuis les annÃ©es soixante. Un
   des prÃ©curseurs, David Marr, est arrivÃ© au MIT Ã  la fin des annÃ©es 1970
   fort de rÃ©ussites passÃ©es en neuroscience thÃ©orique afin d'y diriger le
   groupe Ã©tudiant la vision. Il rÃ©fute toutes les approches symboliques
   (Ã  la fois la logique de McCarthy et les cadres de Minsky), arguant que
   l'intelligence artificielle a besoin de comprendre la machinerie
   physique de la vision par le bas avant qu'un traitement symbolique
   puisse Ãªtre mis en place. Son travail a Ã©tÃ© brusquement interrompu par
   la leucÃ©mie qui l'a frappÃ© en 1980^[139].

   Dans un article de 1990 intitulÃ© Elephants Don't Play Chess^[140]
   (Â« Les Ã©lÃ©phants ne jouent pas aux Ã©checs Â»), le chercheur en robotique
   Rodney Brooks vise directement l'hypothÃ¨se de systÃ¨me symbolique
   physique, expliquant que les symboles ne sont pas toujours nÃ©cessaires
   car Â« le monde est son propre modÃ¨le et c'est le meilleur. Il est
   toujours parfaitement Ã  jour. Il contient toujours tous les dÃ©tails
   nÃ©cessaires. Ce qu'il faut, c'est le mesurer correctement de maniÃ¨re
   rÃ©pÃ©tÃ©e^[141] Â». Dans les annÃ©es 1980 et 1990, beaucoup de cogniticiens
   rejettent Ã©galement le modÃ¨le de traitement symbolique de l'esprit en
   expliquant que le corps est essentiel dans le raisonnement, une thÃ¨se
   appelÃ©e embodiment^[142].

1993-2000[modifier | modifier le code]

   Le champ de l'intelligence artificielle, avec plus d'un demi-siÃ¨cle
   derriÃ¨re lui, a finalement rÃ©ussi Ã  atteindre certains de ses plus
   anciens objectifs. On a commencÃ© Ã  s'en servir avec succÃ¨s dans le
   secteur technologique, mÃªme sans avoir vraiment Ã©tÃ© mise en avant.
   Quelques rÃ©ussites sont venues avec la montÃ©e en puissance des
   ordinateurs et d'autres ont Ã©tÃ© obtenues en se concentrant sur des
   problÃ¨mes isolÃ©s spÃ©cifiques et en les approfondissant avec les plus
   hauts standards d'intÃ©gritÃ© scientifique. NÃ©anmoins, la rÃ©putation de
   l'IA, dans le monde des affaires au-moins, est loin d'Ãªtre parfaite. En
   interne, on n'arrive pas Ã  vraiment expliquer les raisons de l'Ã©chec de
   l'intelligence artificielle Ã  rÃ©pondre au rÃªve d'un niveau
   d'intelligence Ã©quivalent Ã  l'Homme qui a captivÃ© l'imagination du
   monde dans les annÃ©es 1960. Tous ces facteurs expliquent la
   fragmentation de l'IA en de nombreux sous-domaines concurrents
   consacrÃ©s Ã  une problÃ©matique ou une voie prÃ©cise, allant mÃªme parfois
   jusqu'Ã  choisir un nom qui Ã©vite l'expression dÃ©sormais souillÃ©e
   d'Â« intelligence artificielle^[143] Â». L'IA a du coup Ã©tÃ© Ã  la fois
   plus prudente mais aussi plus fructueuse que jamais.
   [210px-Deep_Blue.jpg] Deep Blue, un ordinateur semblable Ã  celui-ci a
   battu Garry Kasparov en mai 1997. C'est la premiÃ¨re machine Ã  remporter
   une partie d'Ã©checs contre un champion du monde en titre.

Verrous qui sautent et loi de Moore[modifier | modifier le code]

   Le 11 mai 1997, Deep Blue est devenu le premier systÃ¨me informatique de
   jeu d'Ã©checs Ã  battre le champion du monde en titre, Garry
   Kasparov^[144]. En 2005, un robot de Stanford a remportÃ© le DARPA Grand
   Challenge en conduisant de maniÃ¨re autonome pendant 131 milles sur une
   piste de dÃ©sert sans avoir fait de reconnaissance prÃ©alable^[145]. Deux
   ans plus tard, une Ã©quipe de Carnegie-Mellon remporte le DARPA Urban
   Challenge, cette fois en naviguant en autonome pendant 55 milles dans
   un environnement urbain tout en respectant les conditions de trafic et
   le code de la route^[146]. En fÃ©vrier 2011, dans un match de
   dÃ©monstration du jeu tÃ©lÃ©visÃ© Jeopardy!, les deux plus grands champions
   de Jeopardy!, Brad Rutter et Ken Jennings ont Ã©tÃ© battus avec une marge
   confortable par le systÃ¨me de questions-rÃ©ponses conÃ§u par IBM, au
   centre de recherche Watson^[147].

   Ces succÃ¨s ne reposent pas sur de nouveaux paradigmes rÃ©volutionnaires,
   mais sur une application minutieuse des techniques d'ingÃ©nierie et sur
   la puissance phÃ©nomÃ©nale des ordinateurs^[148]. En effet, la machine
   Deep Blue est 10 millions de fois plus rapide que la Ferranti Mark I Ã
   qui Christopher Strachey a appris Ã  jouer aux Ã©checs en 1951^[Note 8].
   Cette augmentation spectaculaire suit la loi de Moore, qui prÃ©dit que
   la vitesse et la capacitÃ© de mÃ©moire des ordinateurs doublent tous les
   deux ans. N'est-on pas en train de faire sauter le verrou de la
   Â« puissance informatique Â» ?

Agents intelligents[modifier | modifier le code]

   Un nouveau paradigme, les Â« agents intelligents Â», s'est
   progressivement imposÃ© au cours des annÃ©es 1990^[149]. Bien que les
   premiers chercheurs aient proposÃ© des approches modulaires de type
   Â« diviser pour rÃ©gner Â» en intelligence artificielle^[150], l'agent
   intelligent n'a pas atteint sa forme moderne avant que Judea Pearl,
   Allen Newell et d'autres n'y amÃ¨nent des concepts de thÃ©orie de la
   dÃ©cision et d'Ã©conomie^[151]. Quand la dÃ©finition Ã©conomique de l'agent
   rationnel s'est combinÃ©e Ã  la dÃ©finition informatique de l'objet ou
   encore du module, le paradigme de l'agent intelligent s'installe.

   Un agent intelligent est un systÃ¨me qui perÃ§oit son environnement et
   entreprend des actions qui maximisent ses chances de rÃ©ussite. GrÃ¢ce Ã
   cette dÃ©finition, de simple programmes qui rÃ©solvent des problÃ¨mes
   spÃ©cifiques sont des Â« agents intelligents Â», tout comme le sont des
   Ãªtres humains et des organisations d'Ãªtres humains comme les
   entreprises. Le paradigme de l'agent intelligent dÃ©finit l'intelligence
   artificielle comme l'Â« Ã©tude des agents intelligents Â». C'est une
   gÃ©nÃ©ralisation de certaines des premiÃ¨res dÃ©finitions de l'IA : elle va
   au-delÃ  de l'Ã©tude de l'intelligence humaine ; elle Ã©tudie tout type
   d'intelligence^[152].

   Ce paradigme a ouvert aux chercheurs la voie vers l'Ã©tude de problÃ¨mes
   isolÃ©s ; les solutions trouvÃ©es sont Ã  la fois vÃ©rifiables et utiles.
   Un langage commun permet de dÃ©crire les problÃ¨mes et partager leurs
   solutions entre les uns et les autres, et d'autres domaines ont
   Ã©galement utilisÃ© ce concept d'agents abstraits, comme l'Ã©conomie et la
   rÃ©gulation. On pense qu'une Â« architecture agent Â» (comme la Soar de
   Newell) permettrait un jour Ã  des chercheurs de construire des systÃ¨mes
   plus polyvalents et intelligents Ã  base d'agents
   intelligents^[151]^,^[153].

Â« Victoire des Ã©lÃ©gants Â»[modifier | modifier le code]

   Les chercheurs en intelligence artificielle dÃ©veloppent et utilisent
   des outils mathÃ©matiques sophistiquÃ©s comme jamais auparavant^[154].
   Ils prennent conscience que de nombreux problÃ¨mes que l'intelligence
   artificielle doit rÃ©soudre ont dÃ©jÃ  Ã©tÃ© traitÃ©s dans d'autres domaines
   comme les mathÃ©matiques, l'Ã©conomie ou la recherche opÃ©rationnelle. En
   particulier, les mathÃ©matiques permettent Ã  la fois d'amÃ©liorer la
   collaboration avec des disciplines plus solidement fondÃ©es et
   conduisent Ã  des fertilisations croisÃ©es et Ã  la collecte de donnÃ©es
   mesurables et dÃ©montrables ; l'intelligence artificielle progresse vers
   l'Â« orthodoxie scientifique Â». Russell et Norvig 2003 qualifie cela de
   rien de moins qu'une Â« rÃ©volution Â» et de la Â« victoire des
   Ã©lÃ©gants (en)^[155]^,^[156] Â».

   Le livre-charniÃ¨re de 1988 de Judea Pearl^[157] intÃ¨gre les
   probabilitÃ©s et la thÃ©orie de la dÃ©cision avec les rÃ©seaux bayÃ©siens,
   les modÃ¨les de Markov cachÃ©s, la thÃ©orie de l'information, le calcul
   stochastique et plus gÃ©nÃ©ralement l'optimisation mathÃ©matique. Des
   descriptions mathÃ©matiques s'appliquent aux paradigmes primordiaux de
   l'Â« intelligence computationnelle Â» comme les rÃ©seaux neuronaux et les
   algorithmes Ã©volutionnistes^[155].

L'IA, travailleur de l'ombre[modifier | modifier le code]

   Des algorithmes initialement dÃ©veloppÃ©s par des chercheurs en
   intelligence artificielle commencent Ã  faire partie de systÃ¨mes plus
   larges. L'IA a rÃ©solu beaucoup de problÃ¨mes trÃ¨s complexes^[158] et
   leurs solutions ont servi Ã  travers tout le secteur
   technologique^[159], tels que l'exploration de donnÃ©es, la robotique
   industrielle, la logistique^[160], la reconnaissance vocale^[161], des
   applications bancaires^[162], des diagnostics mÃ©dicaux^[162], la
   reconnaissance de formes, et le moteur de recherche de Google^[163].

   Le domaine de l'intelligence artificielle n'a quasiment reÃ§u aucun
   crÃ©dit pour ces rÃ©ussites. Certaines de ses plus grandes innovations
   ont Ã©tÃ© rÃ©duites au statut d'un Ã©niÃ¨me item dans la boÃ®te Ã  outils de
   l'informatique^[164]. Nick Bostrom explique : Â« Beaucoup d'IA de pointe
   a filtrÃ© dans des applications gÃ©nÃ©rales, sans y Ãªtre officiellement
   rattachÃ©e car dÃ¨s que quelque chose devient suffisamment utile et
   commun, on lui retire l'Ã©tiquette d'IA^[165]. Â»

   Beaucoup de chercheurs en intelligence artificielle dans les annÃ©es
   quatre-vingt-dix ont volontairement appelÃ© leurs Ã©tudes par d'autres
   noms, tels que l'informatique, les systÃ¨mes Ã  base de connaissances,
   les systÃ¨mes cognitifs ou l'intelligence computationnelle. Cela peut
   Ãªtre partiellement car ils considÃ¨rent leur domaine comme
   fondamentalement diffÃ©rent de l'IA, mais aussi car ces nouveaux noms
   facilitent les financements. Dans le secteur commercial au-moins, les
   promesses non tenues de l'hiver de l'IA continuent de hanter la
   recherche en intelligence artificielle, comme le New York Times le
   rapporte en 2005 : Â« Les scientifiques en informatique et les
   ingÃ©nieurs logiciel ont Ã©vitÃ© l'expression 'intelligence artificielle'
   par crainte d'Ãªtre considÃ©rÃ©s comme de doux illuminÃ©s
   rÃªveurs^[166]^,^[167]^,^[168]. Â»

2001 et HAL 9000[modifier | modifier le code]

   Articles dÃ©taillÃ©s : 2001, l'OdyssÃ©e de l'espace et HAL 9000.

   La science-fiction avait imaginÃ© pour 2001 l'arrivÃ© de HAL 9000, une
   machine ayant une intelligence comparable, voire excÃ©dant les capacitÃ©s
   des Ãªtres humains.

   En 1968, Arthur C. Clarke et Stanley Kubrick imaginent que dÃ¨s l'annÃ©e
   2001, une machine aura une intelligence comparable, voire excÃ©dant les
   capacitÃ©s des Ãªtres humains. Le personnage qu'ils crÃ©ent, HAL 9000,
   s'appuie sur une opinion rÃ©pandue chez nombre de chercheurs en
   intelligence artificielle Ã  savoir qu'une telle machine existera en
   2001^[169].

   Marvin Minsky s'interroge : Â« pourquoi n'avons-nous pas eu HAL en
   2001^[170] ? Â» et pense que des problÃ¨mes centraux comme le
   raisonnement de culture gÃ©nÃ©rale, sont nÃ©gligÃ©s, car la plupart des
   chercheurs se concentrent sur des aspects tels que des applications
   commerciales des rÃ©seaux neuronaux ou des algorithmes gÃ©nÃ©tiques. John
   McCarthy, d'un autre cÃ´tÃ©, blÃ¢me encore le problÃ¨me de
   qualification^[171]. Pour Ray Kurzweil, le problÃ¨me rÃ©side dans le
   manque de puissance de calcul et, en s'appuyant sur la loi de Moore, il
   prÃ©dit que les machines avec une intelligence comparable Ã  l'humain
   arriveront vers 2030^[172]. Pour d'autres chercheurs, une intelligence
   artificielle forte (ou intelligence artificielle gÃ©nÃ©rale) ne serait
   possible que dans plusieurs dÃ©cennies, voire plusieurs siÃ¨cles^[173].

2000 - 2009[modifier | modifier le code]

   Ã€ partir des annÃ©es 2000, on constate l'arrivÃ©e de plusieurs assistants
   personnels Â« intelligents Â» : Apple Siri en 2007, Google Now en 2012
   (nommÃ© assistant Google depuis 2018), Microsoft Cortana et Amazon Alexa
   en 2014.

   L'intelligence artificielle est un sujet d'actualitÃ© au XXI^e siÃ¨cle.
   En 2004, le Singularity Institute a lancÃ© une campagne Internet appelÃ©e
   3 Laws Unsafe (Â« 3 lois dangereuses Â»), pour sensibiliser Ã
   l'insuffisance des trois lois d'Asimov avant la sortie du film I,
   Robot^[174]^,^[175].

   En 2005, le projet Blue Brain est lancÃ©, qui vise Ã  simuler le cerveau
   des mammifÃ¨res. Il s'agit d'une des mÃ©thodes envisagÃ©es pour rÃ©aliser
   une IA. Ils annoncent de plus comme objectif de fabriquer en dix ans le
   premier Â« vrai Â» cerveau Ã©lectronique^[176]. En mars 2007, le
   gouvernement sud-corÃ©en annonce que plus tard dans l'annÃ©e, il
   Ã©mettrait une charte sur l'Ã©thique des robots, afin de fixer des normes
   pour les utilisateurs et les fabricants. Selon Park Hye-Young, du
   ministÃ¨re de l'Information et de la communication, la Charte reflÃ¨te
   les trois lois d'Asimov : la tentative de dÃ©finition des rÃ¨gles de base
   pour le dÃ©veloppement futur de la robotique. En juillet 2009, en
   Californie, dans une confÃ©rence organisÃ©e par l'Association for the
   Advancement of Artificial Intelligence (AAAI), un groupe
   d'informaticiens se demande s'il devrait y avoir des limites sur la
   recherche qui pourrait conduire Ã  une perte de contrÃ´le des systÃ¨mes
   informatiques par l'humanitÃ©. Il y abordent les progrÃ¨s et le potentiel
   de l'IA, ainsi que les risques associÃ©s aux armes lÃ©thales autonomes,
   au chÃ´mage technologique et aux concepts d'explosion d'intelligence et
   de singularitÃ© technologique^[177].

   En 2009, le Massachusetts Institute of Technology (MIT) a lancÃ© un
   projet visant Ã  repenser la recherche en intelligence artificielle. Il
   rÃ©unira des scientifiques qui ont eu du succÃ¨s dans des domaines
   distincts de l'IA. Neil Gershenfeld dÃ©clare Â« Nous voulons
   essentiellement revenir 30 ans en arriÃ¨re et revisiter certaines idÃ©es
   qui ont Ã©tÃ© gelÃ©es Â»^[178].

   En novembre 2009, l'US Air Force cherche Ã  acquÃ©rir 2 200 PlayStation
   3^[179] pour utiliser le processeur cell Ã  sept ou huit cÅ“urs qu'elle
   contient dans le but d'augmenter les capacitÃ©s de leur superordinateur
   constituÃ© de 336 PlayStation 3 (total thÃ©orique 52,8 petaFLOPS en
   double prÃ©cision). Le nombre sera rÃ©duit Ã  1 700 unitÃ©s le 22 dÃ©cembre
   2009^[180]. Le projet vise le traitement vidÃ©o haute-dÃ©finition, et
   l'Â« informatique neuromorphique Â», ou la crÃ©ation de calculateurs avec
   des propriÃ©tÃ©s/fonctions similaires au cerveau humain^[179].

De 2009 Ã  aujourd'hui[modifier | modifier le code]

   Depuis 2009, le deep learning s'est imposÃ© dans de nombreux domaines
   comme la reconnaissance vocale, la vision par ordinateur ou la
   traduction^[181].

   En 2010, au Royaume-Uni, le neuro-scientifique Demis Hassabis fonde
   l'entreprise DeepMind, avec pour objectif la crÃ©ation d'une
   intelligence artificielle gÃ©nÃ©rale qui serait capable de faire tout ce
   que le cerveau d'un Ãªtre humain pourrait faire^[182]. En 2014, DeepMind
   est rachetÃ©e par Google^[183]. En 2016, l'IA AlphaGo de DeepMind a
   battu le meilleur joueur de go au monde^[184]. Par la suite, DeepMind
   crÃ©a des programmes d'apprentissage par renforcement profond de plus en
   plus gÃ©nÃ©ralistes, dont AlphaGo Zero, AlphaZero et MuZero^[185].
   AlphaStar, crÃ©Ã© en 2019, a atteint le niveau de grand-maÃ®tre au jeu de
   stratÃ©gie en temps rÃ©el Starcraft 2^[186]. Gato, rÃ©alisÃ© en 2022, est
   capable de rÃ©aliser environ 600 tÃ¢ches diffÃ©rentes sans nÃ©cessiter de
   rÃ©entraÃ®nement^[187]. En 2023, DeepMind est fusionnÃ©e avec Google Brain
   et renommÃ©e Â« Google DeepMind Â»^[188].

   Le 16 fÃ©vrier 2011, Watson, le superordinateur conÃ§u par IBM, remporte
   deux des trois manches du jeu tÃ©lÃ©visÃ© Jeopardy! en battant largement
   ses deux concurrents humains en gains cumulÃ©s. Pour cette IA, la
   performance a rÃ©sidÃ© dans le fait de rÃ©pondre Ã  des questions de
   culture gÃ©nÃ©rale (et non un domaine technique prÃ©cis) dans des dÃ©lais
   trÃ¨s courts. En fÃ©vrier 2016, l'artiste et designer Aaron Siegel
   propose de faire de Watson un candidat Ã  l'Ã©lection prÃ©sidentielle
   amÃ©ricaine afin de lancer le dÃ©bat sur Â« le potentiel de lâ€™intelligence
   artificielle dans la politique Â»^[189].

   En 2012, un rÃ©seau de neurones utilisant 16 000 Microprocesseur cÅ“urs
   de processeur de 1000 processeurs d'ordinateur est capable, aprÃ¨s
   entraÃ®nement, de reconnaÃ®tre un chat sans qu'il lui ait Ã©tÃ© appris Ã
   reconnaÃ®tre un chat^[190].

   En 2012, un rÃ©seau neuronal convolutif nommÃ© AlexNet affiche des
   performances records en vision par ordinateur, notamment grÃ¢ce Ã  son
   utilisation de cartes graphiques pour dÃ©cupler les capacitÃ©s de calcul,
   cette technique s'Ã©tant ensuite banalisÃ©e. Peu aprÃ¨s, Google acquiert
   la startup DNNresearch de Geoffrey Hinton qui a dÃ©veloppÃ©
   AlexNet^[191]. Raymond Kurzweil est engagÃ© en dÃ©cembre 2012 par Google
   afin de participer et d'amÃ©liorer l'apprentissage automatique^[183]. En
   mai 2013, Google ouvre un laboratoire de recherches dans les locaux de
   la NASA. GrÃ¢ce Ã  un super calculateur quantique conÃ§u par D-Wave
   Systems et qui serait d'aprÃ¨s cette sociÃ©tÃ© 11 000 fois plus performant
   qu'un ordinateur classique^[192], ils espÃ¨rent ainsi faire progresser
   l'intelligence artificielle, notamment l'apprentissage automatique. En
   2017, des chercheurs de Google ont conÃ§u l'architecture transformeur,
   dotÃ©e d'un mÃ©canisme d'attention, qui a par la suite servi de base aux
   grands modÃ¨les de langage^[3]. Google a par la suite conÃ§u diffÃ©rents
   grands modÃ¨les de langage, comme LaMDA, PaLM, PaLM 2, Bard et Google
   Gemini.

   En 2015, OpenAI est crÃ©Ã©e avec un capital initial de 1 milliard de
   dollars venant d'investisseurs comme Reid Hoffman, Elon Musk et Peter
   Thiel. Sam Altman, l'ancien dirigeant de l'incubateur de start-up Y
   Combinator, en devient le PDG. Elon Musk quitte OpenAI en 2018. DÃ¨s
   2019, s'engage dans un partenariat avec Microsoft^[193]. Aussi en 2019,
   OpenAI a choisi de ne pas rendre public le code source du programme
   GPT-2, le jugeant capable de gÃ©nÃ©rer des fausses nouvelles rÃ©alistes et
   estimant qu'il risquerait d'Ãªtre utilisÃ© Ã  des fins de
   dÃ©sinformation^[194]. En 2021, Dario Amodei et une dizaine d'autres
   employÃ©s d'OpenAI quittent l'entreprise pour monter Anthropic, une
   start-up d'IA priorisant la sÃ»retÃ© de l'IA^[195]. Ã‰galement en 2021,
   OpenAI s'associe avec Microsoft pour lancer GitHub Copilot, un logiciel
   de complÃ©tion de codebasÃ© sur un grand modÃ¨le de langage^[196]. En
   2022, OpenAI lance DALL-E 2, un modÃ¨le d'IA pouvant gÃ©nÃ©rer des images
   correspondant Ã  des textes, qui se retrouve rapidement concurrencÃ© par
   Midjourney^[197]. En 2022, l'agent conversationnel ChatGPT affiche une
   croissance inÃ©dite de popularitÃ©, atteignant 1 million d'utilisateurs
   en seulement 5 jours^[193] et 100 millions d'utilisateurs en 2
   mois^[198].

   En janvier 2018, des modÃ¨les d'intelligence artificielle dÃ©veloppÃ©s par
   Microsoft et Alibaba rÃ©ussissent chacun de leur cÃ´tÃ© Ã  battre les
   humains dans un test de lecture et de comprÃ©hension de l'universitÃ©
   Stanford. Le traitement du langage naturel imite la comprÃ©hension
   humaine des mots et des phrases et permet aux modÃ¨les d'apprentissage
   automatique de traiter de grandes quantitÃ©s d'informations avant de
   fournir des rÃ©ponses prÃ©cises aux questions qui leur sont posÃ©es^[199].

   En 2023, des grands modÃ¨les multimodaux (capables de traiter plusieurs
   modalitÃ©s comme le texte, les images, le son...) font leur apparition,
   dont Google Gemini^[200] et GPT-4^[201].

RedÃ©finition dans les annÃ©es 2020[modifier | modifier le code]

   Le mardi 12 fÃ©vrier 2019, Ã  Strasbourg, une politique industrielle
   europÃ©enne globale sur lâ€™intelligence artificielle et la robotique,
   conduit Ã  la RÃ©solution du Parlement europÃ©en du 12 fÃ©vrier 2019 sur
   une politique industrielle europÃ©enne globale sur lâ€™intelligence
   artificielle et la robotique^[202].

   Lâ€™intelligence artificielle est redÃ©finie Ã  la vue des progrÃ¨s
   technologiques.

   Pour la CNIL, lâ€™intelligence artificielle nâ€™est pas une technique
   spÃ©cifique mais un ensemble de domaines auxquels appartiennent les
   outils qui entrent dans ces critÃ¨res^[203].

   L'intelligence artificielle est une technique automatisÃ©e suivant une
   logique ou un algorithme dÃ©diÃ© Ã  des tÃ¢ches spÃ©cifiques^[203].

   Le Parlement europÃ©en associe l'intelligence artificielle Ã  la
   reproduction Â« des comportements liÃ©s aux humains, tels que le
   raisonnement, la planification et la crÃ©ativitÃ© Â»^[204].

   La Commission europÃ©enne considÃ¨re l'intelligence artificielle comme un
   ensemble de diverses approches^[204]:
     * apprentissage automatique ;
     * logique et connaissances ; et
     * statistiques, estimation bayÃ©sienne, et mÃ©thodes de recherche et
       dâ€™optimisation.

   L'intelligence artificielle peut Ã©galement dÃ©passer les capacitÃ©s
   humaines^[204].

La recherche en intelligence artificielle en France[modifier | modifier le
code]

   La recherche en intelligence artificielle en France dÃ©bute vers la fin
   des annÃ©es soixante-dix, avec notamment le GR 22 (appelÃ© aussi groupe
   de recherche Claude-FranÃ§ois Picard oÃ¹ travaillent Jacques Pitrat et
   Jean-Louis LauriÃ¨re) Ã  Paris, le GIA (sic) (autour d'Alain Colmerauer)
   Ã  Marseille, le LIMSI Ã  Orsay, le CRIN Ã  Nancy, le CERFIA Ã  Toulouse et
   le Laboria (autour de GÃ©rard Huet et dans un domaine trÃ¨s fondamental)
   Ã  Rocquencourt.

   Un congrÃ¨s national annuel Reconnaissance de formes et intelligence
   artificielle est crÃ©Ã© en 1979 Ã  Toulouse^[Note 9]. En lien avec
   l'organisation de la confÃ©rence International Joint Conference on
   Artificial Intelligence Ã  ChambÃ©ry en 1993, et la crÃ©ation d'un
   GRECO-PRC^[Note 10] intelligence artificielle, en 1983, il donne
   naissance Ã  une sociÃ©tÃ© savante, l'AFIA en 1989, qui, entre autres,
   organise des confÃ©rences nationales en intelligence artificielle^[205].
   C'est de cette Ã©cole franÃ§aise qu'est issu Yann Le Cun.

   En janvier 2017, la CNIL publie un rapport intitulÃ© Â« Comment permettre
   Ã  l'Homme de garder la main ? Â»^[206] incluant des recommandations pour
   la construction d'un modÃ¨le Ã©thique d'intelligence artificielle. En
   septembre 2017, CÃ©dric Villani, premier vice-prÃ©sident de l'Office
   parlementaire d'Ã©valuation des choix scientifiques et technologiques
   (OPECST)^[207], est chargÃ© de mener une consultation publique sur
   l'intelligence artificielle^[208]. Il rend son rapport le 28 mars
   2018^[209]. Le lendemain, Emmanuel Macron annonce un plan de 1,5
   milliards d'euros sur l'ensemble du quinquennat, ainsi qu'une Ã©volution
   de la lÃ©gislation franÃ§aise pour permettre la mise en application de
   l'intelligence artificielle, en particulier concernant la circulation
   des vÃ©hicules autonomes^[210]. Il a exprimÃ© sa vision de l'intelligence
   artificielle, Ã  savoir que les algorithmes utilisÃ©s par l'Ã‰tat doivent
   Ãªtre ouverts, que l'intelligence artificielle doit Ãªtre encadrÃ©e par
   des rÃ¨gles philosophiques et Ã©thiques et qu'il faut s'opposer Ã  l'usage
   d'armes automatiques ou de dispositifs prenant des dÃ©cisions sans
   consulter un humain^[211]^,^[212]. Pour le second quinquennat
   (2022-2026), un plan de financement pour l'IA de 2,22 milliards d'euros
   est prÃ©vu^[213].

Notes et rÃ©fÃ©rences[modifier | modifier le code]

    1. â†‘ Par exemple la machine d'AnticythÃ¨re.
    2. â†‘ Ada Lovelace est gÃ©nÃ©ralement considÃ©rÃ©e comme le premier
       programmeur grÃ¢ce aux notes qu'elle a Ã©crites qui dÃ©taillent
       complÃ©tement une mÃ©thode pour calculer les nombres de Bernoulli
       avec la Machine.
    3. â†‘ Le raisonnement de bon sens est la branche de l'intelligence
       artificielle qui tente de rÃ©pliquer la pensÃ©e humaine. Dans ce
       domaine, il y a :
          + les bases de connaissance de culture gÃ©nÃ©rale,
          + les mÃ©thodes de raisonnement imitant la pensÃ©e humaine
            (raisonnement Ã  base de connaissances par dÃ©faut, raisonnement
            rapide dans un large Ã©ventail de domaines, tolÃ©rance Ã
            l'incertitude, prise de dÃ©cisions sous connaissance incomplÃ¨te
            et correction a posteriori quand les connaissances
            s'amÃ©liorent),
          + le dÃ©veloppement de nouveaux types d'architectures cognitives
            compatibles avec plusieurs mÃ©thodes et reprÃ©sentations de
            raisonnement.
    4. â†‘ Cette condition de puissance est bien nÃ©cessaire ici, mais pas
       suffisante, car les problÃ¨mes d'IA sont intrinsÃ¨quement difficiles
       et complexes.
    5. â†‘ L'ALPAC (Automatic Language Processing Advisory Committee) est le
       comitÃ© amÃ©ricain de sept scientifiques chargÃ© de surveiller les
       progrÃ¨s en matiÃ¨re de traitement du langage.
    6. â†‘ Advice Taker (Â« Preneur de conseils Â» en franÃ§ais) est un
       programme informatique hypothÃ©tique dÃ©crit par MacCarthy dans son
       Programs with Common Sense, 1958. C'est le premier programme Ã
       utiliser la logique en tant qu'outil de reprÃ©sentation et non en
       tant que matiÃ¨re d'Ã©tude.
    7. â†‘ La Strategic Computing Initiative (Â« Initiative Informatique
       StratÃ©gique Â») de la DARPA finance pour plus d'1 milliard de $ de
       projets de recherche en matÃ©riel informatique de pointe et en
       intelligence artificielle sur la dÃ©cennie 1983-1993, depuis la
       conception et fabrication de puces Ã  des logiciels d'intelligence
       artificielle.
    8. â†‘ La durÃ©e d'un cycle de Ferranti Mark I Ã©tait de 1,2 ms, ce qui
       correspond grossiÃ¨rement Ã  environ 833 flops. Deep Blue
       fournissait, lui, 11,38 gigaflops (sans mÃªme prendre en compte le
       matÃ©riel spÃ©cialement conÃ§u pour les Ã©checs qui Ã©quipait Deep
       Blue). Ã€ la louche, ces deux grandeurs diffÃ¨rent d'un facteur 10^7.
    9. â†‘ Reconnaissance des formes et intelligence artificielle, congrÃ¨s
       AFCET-IRIA, Toulouse 12, 13, 14 septembre 1979. Il est intitulÃ©
       Â« 2^e congrÃ¨s Â» et prend la suite du congrÃ¨s AFCET-IRIA
       Reconnaissance des formes et traitement des images en 1978 Ã
       Chatenay-Malabry.
   10. â†‘ Un GRECO est un ancÃªtre des actuels GDR du CNRS et un PRC est un
       programme de recherche concertÃ©e

RÃ©fÃ©rences[modifier | modifier le code]

     * (en) Cet article est partiellement ou en totalitÃ© issu de lâ€™article
       de WikipÃ©dia en anglais intitulÃ© Â« History of artificial
       intelligence Â» (voir la liste des auteurs).

    1. â†‘ (en) Nick Bostrom, Superintelligence: paths, dangers, strategies,
       Oxford University Press, 2017 (ISBN 978-0-19-967811-2), Â« Seasons
       of hope and despair Â»
    2. â†‘ (en) Sharon Goldman, Â« 10 years later, deep learning â€˜revolutionâ€™
       rages on, say AI pioneers Hinton, LeCun and Li Â», sur VentureBeat,
       14 septembre 2022 (consultÃ© le 10 dÃ©cembre 2023)
    3. â†‘ ^a et b (en) Madhumita Murgia, Â« Transformers: the Google
       scientists who pioneered an AI revolution Â», sur www.ft.com
       (consultÃ© le 10 dÃ©cembre 2023)
    4. â†‘ McCorduck 2004
    5. â†‘ Par exemple Kurzweil 2005 maintient que des machines ayant une
       intelligence comparable Ã  celle de l'homme existeront en 2029.
    6. â†‘ Turing 1950, p. 460
    7. â†‘ McCorduck 2004, p. 5â€“35
    8. â†‘ McCorduck 2004, p. 5 ; Russell et Norvig 2003, p. 939
    9. â†‘ McCorduck 2004, p. 15â€“16 ; Buchanan 2005, p. 50 (Golem) ;
       McCorduck 2004, p. 13â€“14 (Paracelse) ; O'Connor 1994 (Takwin)
   10. â†‘ McCorduck 2004, p. 17â€“25
   11. â†‘ Butler 1863
   12. â†‘ Needham 1986, p. 53
   13. â†‘ McCorduck 2004, p. 6
   14. â†‘ Nick 2005
   15. â†‘ McCorduck 2004, p. 17 ; Levitt 2000
   16. â†‘ CitÃ© dans McCorduck 2004, p. 8. Crevier 1993, p. 1 et McCorduck
       2004, p. 6â€“9 traitent des statues sacrÃ©es.
   17. â†‘ D'autres automates importants ont Ã©tÃ© construits par HÃ¢roun
       ar-RachÃ®d (McCorduck 2004), Jacques de Vaucanson (McCorduck 2004)
       et Leonardo Torres Quevedo (McCorduck 2004), sans oublier la
       compagnie de thÃ©Ã¢tre contemporaine Royal de luxe.
   18. â†‘ ^a b c et d Berlinski 2000
   19. â†‘ (es) Carreras Artau et TomÃ¡s y JoaquÃ­n, Historia de la filosofÃ­a
       espaÃ±ola. FilosofÃ­a cristiana de los siglos XIII al XV, vol. I,
       Madrid, 1939
   20. â†‘ (en) Anthony Bonner, The Art and Logic of RamÃ³n Llull : A User's
       Guide, Brill, 2007
   21. â†‘ (en) Anthony Bonner (Ã©d.), Doctor Illuminatus. A Ramon Llull
       Reader, Llull's Influence: The History of Lullism, Princeton
       University, 1985, p. 57-71
   22. â†‘ IA et mÃ©canisme du XVII^e siÃ¨cle :
          + McCorduck 2004, p. 37â€“46
          + Russell et Norvig 2003, p. 6
          + Haugeland 1985, chap. 2
          + Buchanan 2005, p. 53
   23. â†‘ Hobbes et l'I.A. :
          + McCorduck 2004, p. 42
          + Hobbes 1651, chap. 5
   24. â†‘ Leibniz et l'I.A. :
          + McCorduck 2004, p. 41
          + Russell et Norvig 2003, p. 6
          + Berlinski 2000, p. 12
          + Buchanan 2005, p. 53
   25. â†‘ (en) Boole, George, 1815-1864., The laws of thought, 1854., Open
       Court Pub, 1952 (OCLC 615373478).
   26. â†‘ Le lambda-calcul est particuliÃ¨rement important en IA, car il a
       inspirÃ© le langage Lisp (le principal langage utilisÃ© en IA).
       Crevier 1993, p. 190-196,61
   27. â†‘ La machine de Turing :McCorduck 2004, p. 63â€“64, Crevier 1993,
       p. 22â€“24, Russell et Norvig 2003, p. 8 et Ã©galement Turing 1936
   28. â†‘ Menabrea 1843
   29. â†‘ McCorduck 2004, p. 61â€“62, 64â€“66, Russell et Norvig 2003, p. 14â€“15
   30. â†‘ Von Neumann : McCorduck 2004, p. 76â€“80
   31. â†‘ Les dates de dÃ©but et de fin des sections de cet article
       correspondent Ã  Crevier 1993 et Russell et Norvig 2003, p. 16âˆ’27.
       Les thÃ¨mes, tendances et projets sont traitÃ©s dans la pÃ©riode oÃ¹ le
       gros du travail a Ã©tÃ© effectuÃ©.
   32. â†‘ Â« Andreas Kaplan (2022) Artificial Intelligence, Business and
       Civilization - Our Fate Made in Machines, Routledge, ISBN
       9781032155319 Â»
   33. â†‘ McCorduck 2004, p. 51â€“57, 80â€“107, Crevier 1993, p. 27â€“32, Russell
       et Norvig 2003, p. 15, 940, Moravec 1988, p. 3, Cordeschi 2002,
       Chap. 5.
   34. â†‘ McCorduck 2004, p. 98, Crevier 1993, p. 27âˆ’28, Russell et Norvig
       2003, p. 15, 940, Moravec 1988, p. 3, Cordeschi 2002, Chap. 5.
   35. â†‘ McCorduck 2004, p. 51â€“57, 88â€“94, Crevier 1993, p. 30, Russell et
       Norvig 2003, p. 15âˆ’16, Cordeschi 2002, Chap. 5 et voir aussi
       McCulloch et Pitts 1943
   36. â†‘ McCorduck 2004, p. 102, Crevier 1993, p. 34âˆ’35 et Russell et
       Norvig 2003, p. 17
   37. â†‘ cf. (en)A Brief History of Computing sur AlanTuring.net.
   38. â†‘ Jonathan Schaeffer, One Jump Ahead : Challenging Human Supremacy
       in Checkers, Springer, 1997, 585 p. (ISBN 978-0-387-76575-4),
       chap. 6. Aujourd'hui les programmes de jeux dames sont complets au
       sens oÃ¹ ils gagnent contre toute dÃ©fense.
   39. â†‘ McCorduck 2004, p. 70âˆ’72, Crevier 1993, p. 22âˆ’25, Russell et
       Norvig 2003, p. 2âˆ’3,948, Haugeland 1985, p. 6âˆ’9, Cordeschi 2002,
       p. 170â€“176. Voir aussi Turing 1950
   40. â†‘ Russell et Norvig 2003, p. 948 dÃ©clare que Turing rÃ©pond Ã  toutes
       les objections majeures Ã  l'IA qui sont apparues dans les annÃ©es
       qui suivirent la publication de cet article.
   41. â†‘ McCorduck 2004, p. 137â€“170, Crevier 1993, p. 44â€“47
   42. â†‘ McCorduck 2004, p. 123â€“125, Crevier 1993, p. 44âˆ’46 et Russell et
       Norvig 2003, p. 17
   43. â†‘ CitÃ© dans Crevier 1993, p. 46 et Russell et Norvig 2003, p. 17
   44. â†‘ Russell et Norvig 2003, p. 947,952
   45. â†‘ La premiÃ¨re version de ce memorandum a Ã©tÃ© publiÃ© Ã  Carlsbad
       (Nouveau Mexique) en juillet 1949. Il a Ã©tÃ© reproduit dans Machine
       Translation of Languages, Cambridge, Massachusetts, MIT Press,
       1955, 15â€“23 p. (ISBN 0-8371-8434-7, lire en ligne), Â« Translation Â»
   46. â†‘ McCorduck 2004, p. 111â€“136, Crevier 1993, p. 49â€“51 et Russell et
       Norvig 2003, p. 17
   47. â†‘ Voir McCarthy et al. 1955. Voir Ã©galement Crevier 1993, p. 48 oÃ¹
       Crevier dÃ©clare que Â« [cette thÃ¨se] est devenue plus tard connue
       comme lâ€™'hypothÃ¨se des systÃ¨mes de symbole physique' Â». L'hypothÃ¨se
       de systÃ¨me de symbole physique a Ã©tÃ© dÃ©veloppÃ©e et nommÃ©e par
       Newell et Simon dans leur article sur le General Problem Solver.
       Newell et al. 1963 Cela comporte une dÃ©finition plus spÃ©cifique de
       la Â« machine Â» en tant qu'agent qui manipule des symboles (voir
       aussi la philosophie de l'intelligence artificielle).
   48. â†‘ McCorduck 2004, p. 129â€“130 raconte comment les anciens de la
       confÃ©rence de Dartmouth ont dominÃ© les deux premiÃ¨res dÃ©cennies de
       la recherche en IA, les surnommant la Â« facultÃ© invisible Â».
   49. â†‘ McCorduck 2004, p. 123-125
   50. â†‘ Â« Je ne jurerai pas et je ne l'avais pas encore vu avant Â»,
       McCarthy indique Ã  Pamela McCorduck en 1979 Ã  propos du terme
       intelligence artificielle (McCorduck 2004, p. 114). Cependant,
       McCarthy a aussi dÃ©clarÃ© sans Ã©quivoque Â« J'ai inventÃ© le terme Â»
       dans une interview du CNET (Skillings 2006).
   51. â†‘ Crevier 1993, p. 49 Ã©crit que Â« la confÃ©rence est gÃ©nÃ©ralement
       reconnue comme la date de naissance officielle de cette nouvelle
       science. Â»
   52. â†‘ Russell et Norvig ont Ã©crit que Â« c'Ã©tait extraordinaire dÃ¨s
       qu'un ordinateur faisait quoi que ce soit de vaguement malin. Â»
       Russell et Norvig 2003, p. 18
   53. â†‘ Crevier 1993, p. 52âˆ’107, Moravec 1988, p. 9 et Russell et Norvig
       2003, p. 18âˆ’21
   54. â†‘ McCorduck 2004, p. 218, Crevier 1993, p. 108âˆ’109 et Russell et
       Norvig 2003, p. 21
   55. â†‘ Crevier 1993, p. 52âˆ’107, Moravec 1988, p. 9
   56. â†‘ Le raisonnement par tÃ¢tonnements : McCorduck 2004, p. 247â€“248,
       Russell et Norvig 2003, p. 59âˆ’61
   57. â†‘ Heuristique : McCorduck 2004, p. 246, Russell et Norvig 2003,
       p. 21âˆ’22
   58. â†‘ GPS: McCorduck 2004, p. 245â€“250, Crevier 1993, p. GPS?, Russell
       et Norvig 2003, p. GPS?
   59. â†‘ Crevier 1993, p. 51âˆ’58,65âˆ’66 et Russell et Norvig 2003, p. 18âˆ’19
   60. â†‘ McCorduck 2004, p. 268â€“271, Crevier 1993, p. 95âˆ’96, Moravec 1988,
       p. 14âˆ’15
   61. â†‘ McCorduck 2004, p. 286, Crevier 1993, p. 76âˆ’79, Russell et Norvig
       2003, p. 19
   62. â†‘ Crevier 1993, p. 79âˆ’83
   63. â†‘ Crevier 1993, p. 164âˆ’172
   64. â†‘ McCorduck 2004, p. 291â€“296, Crevier 1993, p. 134âˆ’139
   65. â†‘ McCorduck 2004, p. 299â€“305, Crevier 1993, p. 83âˆ’102, Russell et
       Norvig 2003, p. 19 et Copeland 2000
   66. â†‘ McCorduck 2004, p. 300â€“305, Crevier 1993, p. 84âˆ’102, Russell et
       Norvig 2003, p. 19
   67. â†‘ Simon et Newell 1958, p. 7âˆ’8 quoted in Crevier 1993, p. 108. Voir
       aussi Russell et Norvig 2003, p. 21
   68. â†‘ Simon 1965, p. 96 quoted in Crevier 1993, p. 109
   69. â†‘ Minsky 1967, p. 2 citÃ© dans Crevier 1993, p. 109
   70. â†‘ Minsky croit fermement qu'on l'a mal citÃ©. Voir McCorduck 2004,
       p. 272â€“274, Crevier 1993, p. 96 et Darrach 1970.
   71. â†‘ Crevier 1993, p. 64âˆ’65
   72. â†‘ Crevier 1993, p. 94
   73. â†‘ Howe 1994
   74. â†‘ McCorduck 2004, p. 131, Crevier 1993, p. 51. McCorduck remarque
       Ã©galement que les financements est pour la majeure partie focilisÃ©
       sur les anciens de la confÃ©rence de Dartmouth de 1956.
   75. â†‘ Crevier 1993, p. 65
   76. â†‘ Crevier 1993, p. 68âˆ’71, et Turkle 1984
   77. â†‘ Crevier 1993, p. 100âˆ’144 et Russell et Norvig 2003, p. 21âˆ’22
   78. â†‘ McCorduck 2004, p. 104âˆ’107, Crevier 1993, p. 102âˆ’105, Russell et
       Norvig 2003, p. 22
   79. â†‘ Crevier 1993, p. 163âˆ’196
   80. â†‘ Crevier 1993, p. 146
   81. â†‘ Russell et Norvig 2003, p. 20âˆ’21
   82. â†‘ Crevier 1993, p. 146âˆ’148, voir aussi Buchanan 2005, p. 56:(en)
       Â« Early programs were necessarily limited in scope by the size and
       speed of memory Â»
   83. â†‘ Moravec 1976. McCarthy a toujours Ã©tÃ© opposÃ© Ã  Moravec lÃ -dessus,
       dÃ¨s leurs premiers jours ensemble au Laboratoire d'IA de Stanford.
       Il a dÃ©clarÃ© : Â« Je dirais qu'il y a cinquante ans, les capacitÃ©s
       des machines Ã©taient trop faibles, mais il y a trente ans, les
       capacitÃ©s des machines n'Ã©taient plus le vrai problÃ¨me Â» dans une
       interview sur CNET. (Skillings 2006)
   84. â†‘ (en)Â« ROBOT: Mere Machine to Transcendent Mind Â»
   85. â†‘ Russell et Norvig 2003, p. 9,21âˆ’22 et Lighthill 1973
   86. â†‘ McCorduck 2004, p. 300,421, Crevier 1993, p. 113âˆ’114, Moravec
       1988, p. 13
   87. â†‘ Lenat et Guha 1989, (Introduction)
   88. â†‘ Russell et Norvig 2003, p. 21
   89. â†‘ McCorduck 2004, p. 456
   90. â†‘ Moravec 1988, p. 15âˆ’16
   91. â†‘ McCarthy et al. 1969, Crevier 1993, p. 117âˆ’119
   92. â†‘ McCorduck 2004, p. 280â€“281, Crevier 1993, p. 110, Russell et
       Norvig 2003, p. 21 et NRC 1999 dans Success in Speech Recognition
       (reconnaissance en reconnaissance de la parole).
   93. â†‘ Crevier 1993, p. 117, Russell et Norvig 2003, p. 22, Howe 1994 et
       voir aussi Lighthill 1973.
   94. â†‘ Russell et Norvig 2003, p. 22, Lighthill 1973, John McCarthy a
       rÃ©pondu que Â« le problÃ¨me de l'explosion combinatoire Ã©tait connu
       en IA depuis le dÃ©part Â» dans (en) Review of Lighthill report
   95. â†‘ Crevier 1993, p. 115âˆ’116 (oÃ¹ ce constat apparaÃ®t). D'autres
       points de vue sont exposÃ©s dans McCorduck 2004, p. 306â€“313 et NRC
       1999 dans Success in Speech Recognition.
   96. â†‘ Crevier 1993, p. 115. Moravec explique que Â« leurs promesses
       initiales Ã  la DARPA ont Ã©tÃ© bien trop optimistes. Bien sÃ»r, ce
       qu'ils livraient derriÃ¨re Ã©tait bien loin du compte. Mais ils
       sentaient qu'ils ne pouvaient promettre moins pour leur prochain
       objectif, et donc ils promirent davantage Â».
   97. â†‘ NRC 1999 dans Shift to Applied Research Increases Investment.
       Bien que le tank autonome fut un Ã©chec, le systÃ¨me de gestion de
       batailles (appelÃ© Â« Dynamic Analysis and Replanning Tool Â») a Ã©tÃ©
       un Ã©norme succÃ¨s, Ã©conomisant des milliards dans la premiÃ¨re guerre
       du Golfe, remboursant les investissements et justifiant la
       politique pragmatique de la DARPA, au-moins Ã  son niveau.
   98. â†‘ Critique de l'IA de Lucas et Penrose : Crevier 1993, p. 22,
       Russell et Norvig 2003, p. 949âˆ’950, Hofstadter 1979, p. 471âˆ’477 et
       aussi Lucas 1961
   99. â†‘ Â« Savoir-faire Â» est une expression de Dreyfus. Il distingue le
       Â« savoir-faire Â» de la Â« connaissance Â» (classique), une version
       moderne de la distinction d'Heidegger entre l'Â« Ã©tant disponible Â»
       (readiness-to-hand en anglais, Zuhandenheit en allemand) et
       l'Â« Ã©tant subsistant Â» (respectivement presence-at-hand et
       Vorhandenheit). (Dreyfus et Dreyfus 1986)
   100. â†‘ Critiques d'Hubert Dreyfus sur l'intelligence
       artificielle (en) : McCorduck 2004, p. 211âˆ’239, Crevier 1993,
       p. 120âˆ’132, Russell et Norvig 2003, p. 950âˆ’952 et Ã©galement Dreyfus
       1965, Dreyfus 1972, Dreyfus et Dreyfus 1986
   101. â†‘ Critique de l'IA de Searle : McCorduck 2004, p. 443âˆ’445, Crevier
       1993, p. 269âˆ’271, Russell et Norvig 2003, p. 958âˆ’960 ainsi que
       Searle 1980
   102. â†‘ CitÃ© dans Crevier 1993, p. 143
   103. â†‘ CitÃ© dans Crevier 1993, p. 122
   104. â†‘ Â« J'Ã©tais alors le seul membre de la communautÃ© d'IA qu'on
       pouvait voir dÃ©jeuner avec Dreyfus. Et j'ai clairement fait
       comprendre qu'on ne traitait pas ainsi un autre Ãªtre humain. Â»
       Joseph Weizenbaum, citÃ© dans Crevier 1993, p. 123.
   105. â†‘ Critique de l'IA de Weizenbaum : McCorduck 2004, p. 356âˆ’373,
       Crevier 1993, p. 132âˆ’144, Russell et Norvig 2003, p. 961 et aussi
       Weizenbaum 1976
   106. â†‘ Frank Rosenblatt a Ã©tÃ© un condisciple de Marvin Minsky Ã  la
       Bronx High School of Science
   107. â†‘ Mounier-Kuhn 2010, p. 266.
   108. â†‘ McCorduck 2004, p. 51, Russell et Norvig 2003, p. 19, 23
   109. â†‘ McCorduck 2004, p. 51, Crevier 1993, p. 190âˆ’192
   110. â†‘ Crevier 1993, p. 193âˆ’196
   111. â†‘ Crevier 1993, p. 145âˆ’149,258âˆ’63
   112. â†‘ Wason 1966 a montrÃ© que les humains Ã©prouvent des difficultÃ©s
       sur des problÃ¨mes complÃ©tement abstraits, mais quand le problÃ¨me
       est reformulÃ© pour permettre l'utilisation de l'intelligence
       sociale plus intuitive, leurs performances augmentent
       considÃ©rablement. (Voir la tÃ¢che de sÃ©lection de Wason) Tversky,
       Slovic et Kahneman 1982 ont montrÃ©, eux, que les humains sont
       mÃ©diocres sur des problÃ¨mes Ã©lÃ©mentaires qui impliquent un
       raisonnement incertain. (Voir la liste de biais cognitifs pour
       plusieurs exemples). Le travail d'Eleanor Rosch est dÃ©crit dans
       Lakoff 1987
   113. â†‘ Une premiÃ¨re occurrence de l'opinion de McCathy apparaÃ®t dans le
       journal Science : Â« C'est de l'IA, donc peu importe que ce soit
       psychologiquement correct Â» (Kolata 1982), et il a confirmÃ© 20 ans
       plus tard son opinion Ã  la confÃ©rence AI@50 (Dartmouth Artificial
       Intelligence Conference: The Next Fifty Years) de 2006 oÃ¹ il
       explique que Â« l'Intelligence artificielle n'est pas, par
       dÃ©finition, la simulation de l'intelligence humaine Â» (Maker 2006).
   114. â†‘ Crevier 1993, p. 175
   115. â†‘ Â« Brouillons contre Ã‰lÃ©gants Â» (Neat vs. scruffy) : McCorduck
       2004, p. 421â€“424 (qui dÃ©crit l'Ã©tat du dÃ©bat en 1984). Crevier
       1993, p. 168 (qui documente l'usage initial du terme par Schank).
       Un autre aspect du conflit est intitulÃ© Â« la distinction
       procÃ©dural/dÃ©claratif Â» mais ne s'est pas rÃ©vÃ©lÃ© important dans les
       recherches en IA ultÃ©rieures.
   116. â†‘ McCorduck 2004, p. 305â€“306, Crevier 1993, p. 170âˆ’173, 246 et
       Russell et Norvig 2003, p. 24. L'article de Minsky sur les cadres :
       Minsky 1974.
   117. â†‘ McCorduck 2004, p. 327â€“335 (Dendral), Crevier 1993, p. 148âˆ’159,
       Russell et Norvig 2003, p. 22âˆ’23
   118. â†‘ Crevier 1993, p. 158âˆ’159 et Russell et Norvig 2003, p. 23âˆ’24
   119. â†‘ Crevier 1993, p. 198
   120. â†‘ McCorduck 2004, p. 434â€“435, Crevier 1993, p. 161âˆ’162,197âˆ’203 et
       Russell et Norvig 2003, p. 24
   121. â†‘ McCorduck 2004, p. 299
   122. â†‘ McCorduck 2004, p. 421
   123. â†‘ RÃ©volution de la connaissance : McCorduck 2004, p. 266â€“276,
       298â€“300, 314, 421, Russell et Norvig 2003, p. 22â€“23
   124. â†‘ Cyc : McCorduck 2004, p. 489, Crevier 1993, p. 239âˆ’243, Russell
       et Norvig 2003, p. 363âˆ’365 et Lenat et Guha 1989
   125. â†‘ McCorduck 2004, p. 436â€“441, Crevier 1993, p. 211, Russell et
       Norvig 2003, p. 24 et voir Ã©galement Feigenbaum et McCorduck 1983
   126. â†‘ Crevier 1993, p. 195
   127. â†‘ Crevier 1993, p. 240.
   128. â†‘ ^a b et c Russell et Norvig 2003, p. 25
   129. â†‘ McCorduck 2004, p. 426â€“432, NRC 1999 dans Shift to Applied
       Research Increases Investment
   130. â†‘ Crevier 1993, p. 214âˆ’215.
   131. â†‘ Crevier 1993, p. 215âˆ’216.
   132. â†‘ Crevier 1993, p. 203. Lâ€™hiver de l'IA est apparu pour la
       premiÃ¨re fois dans le nom d'un sÃ©minaire sur le sujet de
       lâ€™Association for the Advancement of Artificial Intelligence.
   133. â†‘ McCorduck 2004, p. 435, Crevier 1993, p. 209âˆ’210
   134. â†‘ McCorduck 2004, p. 435 (qui cite des raisons institutionnelles
       pour leur ultime Ã©chec), Crevier 1993, p. 204âˆ’208 (qui cite ici la
       difficultÃ© de la maintenance du savoir, c'est-Ã -dire apprentissage
       et mise Ã  jour continus), Lenat et Guha 1989, Introduction (qui met
       l'accent sur l'extrÃªme sensibilitÃ© et l'incapacitÃ© Ã  manipuler des
       qualifications limites)
   135. â†‘ McCorduck 2004, p. 430â€“431
   136. â†‘ ^a et b McCorduck 2004, p. 441, Crevier 1993, p. 212. McCorduck
       Ã©crit Ã  ce sujet : Â« Deux dÃ©cennies et demie plus tard, nous avons
       pu observer que le Japon n'a pas rÃ©ussi Ã  remplir tous ses
       objectifs ambitieux. Â»
   137. â†‘ McCorduck 2004, p. 454â€“462
   138. â†‘ Moravec 1988, p. 20 a Ã©crit : Â« Je suis sÃ»r que la direction de
       bas en haut de la recherche en IA rencontrera un jour la plus
       classique voie de haut en bas, et ce, aprÃ¨s avoir parcouru la
       majoritÃ© du chemin, prÃªte Ã  livrer au monde rÃ©el la compÃ©tence et
       le savoir de culture gÃ©nÃ©rale qui ont Ã©chappÃ© jusqu'ici aux
       programmes de raisonnement de maniÃ¨re si frustrante. Des machines
       complÃ©tement intelligentes couronneront la rÃ©union de ces deux
       efforts. Â»
   139. â†‘ Crevier 1993, p. 183âˆ’190.
   140. â†‘ (en)Elephants Don't Play Chess (PDF)
   141. â†‘ Brooks 1990, p. 3
   142. â†‘ Voir, par exemple, Lakoff et Turner 1989
   143. â†‘ McCorduck 2004, p. 424 discute cet Ã©clatement et la mise au ban
       des objectifs initiaux de l'IA.
   144. â†‘ McCorduck 2004, p. 480â€“483.
   145. â†‘ (en) Page d'accueil de DARPA Grand Challenge Â« Copie archivÃ©e Â»
       (version du 23 juillet 2018 sur Internet Archive).
   146. â†‘ (en)Archive du DARPA Grand Challenge.
   147. â†‘ (en) John Markoff, Â« On 'Jeopardy!' Watson Win Is All but
       Trivial Â», The New York Times,â€ 16 fÃ©vrier 2011 (lire en ligne).
   148. â†‘ Kurzweil 2005, p. 274 Ã©crit que les amÃ©liorations du jeu
       d'Ã©checs en informatique, Â« d'aprÃ¨s la sagesse populaire, sont
       uniquement dues Ã  l'accroissement de la force brute du matÃ©riel
       informatique Â».
   149. â†‘ McCorduck 2004, p. 471â€“478, Russell et Norvig 2003, p. 55, oÃ¹
       ils Ã©crivent : Â« La notion d'agent-entier est dÃ©sormais largement
       acceptÃ©e dans le domaine. Â» On discute du paradigme de l'agent
       intelligent dans les textes majeurs de l'IA, comme Russell et
       Norvig 2003, p. 32âˆ’58, 968âˆ’972, Poole, Mackworth et Goebel 1998,
       p. 7âˆ’21 et Luger et Stubblefield 2004, p. 235âˆ’240
   150. â†‘ Le modÃ¨le d'acteur de Carl Hewitt est le prÃ©curseur de la
       dÃ©finition moderne des agents intelligents. (Hewitt, Bishop et
       Steiger 1973) John Doyle (Doyle 1983) et le classique The Society
       of Mind de Marvin Minsky (Minsky 1986) ont tous les deux utilisÃ©s
       le terme Â« agent Â». Parmi d'autres propositions Â« modulaires Â», on
       trouve l'Â« architecture par prÃ©misses Â» de Rodney Brook, la
       programmation orientÃ©e objet, etc..
   151. â†‘ ^a et b Russell et Norvig 2003, p. 27, 55
   152. â†‘ C'est cette dÃ©finition de l'intelligence artificielle qui est
       globalement acceptÃ©e par tous les textes du xxi^e siÃ¨cle, cf.
       Russell et Norvig 2003, p. 32 et Poole, Mackworth et Goebel 1998,
       p. 1.
   153. â†‘ McCorduck 2004, p. 478
   154. â†‘ McCorduck 2004, p. 486â€“487, Russell et Norvig 2003, p. 25â€“26
   155. â†‘ ^a et b Russell et Norvig 2003, p. 25âˆ’26
   156. â†‘ McCorduck 2004, p. 487: Â« Au moment oÃ¹ j'Ã©cris ces lignes,
       l'intelligence artificielle bÃ©nÃ©ficie d'une hÃ©gÃ©monie Ã©lÃ©gante. Â»
   157. â†‘ Pearl 1988
   158. â†‘ Voir certaines applications de l'intelligence artificielle
   159. â†‘ NRC 1999 dans Â« Artificial Intelligence in the 90s Â», et
       Kurzweil 2005, p. 264
   160. â†‘ Russell et Norvig 2003, p. 28
   161. â†‘ Pour un Ã©tat de l'art de l'intelligence artificielle sur la
       reconnaissance vocale en 2007, lire The Economist 2007
   162. â†‘ ^a et b Â« Des systÃ¨mes inspirÃ©es par l'IA faisaient dÃ©jÃ  partie
       de nombreuses technologies de tous les jours telles que les moteurs
       de recherche Internet, les applications bancaires de traitement de
       transactions et les diagnostics mÃ©dicaux. Â» Nick Bostrom, citÃ© dans
       CNN 2006
   163. â†‘ Olsen 2004,Olsen 2006
   164. â†‘ McCorduck 2004, p. 423, Kurzweil 2005, p. 265, Hofstadter 1979,
       p. 601
   165. â†‘ CNN 2006
   166. â†‘ Markoff 2005
   167. â†‘ The Economist 2007
   168. â†‘ Tascarella 2006
   169. â†‘ Crevier 1993, p. 108âˆ’109
   170. â†‘ Il continue ainsi : Â« La rÃ©ponse est, Je crois que l'on aurait
       puâ€¦ J'ai assistÃ© une fois Ã  une confÃ©rence internationale sur le[s]
       rÃ©seau[x] neurona[ux]. Il y avait quarante mille inscritsâ€¦ maisâ€¦ si
       vous faisiez une confÃ©rence internationale sur, par exemple, les
       reprÃ©sentations multiples du raisonnement de culture gÃ©nÃ©rale, je
       n'ai rÃ©ussi Ã  trouver que 6 ou 7 personnes dans le monde entier. Â»
       Minsky 2001
   171. â†‘ Maker 2006
   172. â†‘ Kurzweil 2005
   173. â†‘ IA faible / IA forte : on en est oÃ¹ au fait ?
   174. â†‘ (en) Â« 3 Laws Unsafe Â» [archive du 27 janvier 2012].
   175. â†‘ (en) Simson Garfinkel, Â« Will Smith, Robot Â», sur MIT Technology
       Review, 16 juillet 2004 (consultÃ© le 2 novembre 2023).
   176. â†‘ Â« Un cerveau artificiel annoncÃ© dans dix ans Â», sur Le Figaro, 8
       septembre 2009.
   177. â†‘ (en) Â« Scientists Worry Machines May Outsmart Man Â», sur New
       York Times, 25 juillet 2009.
   178. â†‘ (en) Â« Science goes back to basics on AI Â», sur BBC News, 8
       dÃ©cembre 2009.
   179. â†‘ ^a et b (en) J. Nicholas Hoover, Â« Air Force To Expand
       PlayStation-Based Supercomputer Â», Information Week,â€ 20 novembre
       2009 (lire en ligne [archive du 8 janvier 2010]).
   180. â†‘ (en) Â« Sony PlayStation 3 Game Consoles : Solicitation Number:
       FA8751-10-R-0003 Â», sur fbo.gov, 22 dÃ©cembre 2009.
   181. â†‘ BenoÃ®t Georges, Â« Intelligence artificielle : de quoi
       parle-t-on ? Â», Constructif,â€ 2019 (lire en ligne)
   182. â†‘ (en) Cade Metz, Karen Weise, Nico Grant et Mike Isaac, Â« Ego,
       Fear and Money: How the A.I. Fuse Was Lit Â», The New York Times,â€ 3
       dÃ©cembre 2023 (ISSN 0362-4331, lire en ligne, consultÃ© le 10
       dÃ©cembre 2023)
   183. â†‘ ^a et b Â« Google achÃ¨te DeepMind, spÃ©cialiste de l'intelligence
       artificielle Â», sur Les Echos investir, 27 janvier 2014 (consultÃ©
       le 11 dÃ©cembre 2023)
   184. â†‘ (en) J. Edward Moreno, Â« Whoâ€™s Who Behind the Dawn of the Modern
       Artificial Intelligence Movement Â», The New York Times,â€ 3 dÃ©cembre
       2023 (ISSN 0362-4331, lire en ligne, consultÃ© le 10 dÃ©cembre 2023)
   185. â†‘ (en) Â« MuZero: Mastering Go, chess, shogi and Atari without
       rules Â», sur Google DeepMind, 23 dÃ©cembre 2020 (consultÃ© le 11
       dÃ©cembre 2023)
   186. â†‘ (en) Nick Statt, Â« DeepMindâ€™s StarCraft 2 AI is now better than
       99.8 percent of all human players Â», sur The Verge, 30 octobre 2019
       (consultÃ© le 12 dÃ©cembre 2023)
   187. â†‘ Â« L'intelligence artificielle "Gato" peut-elle surpasser
       l'intelligence humaine ? Â», sur www.lesnumeriques.com, 3 juin 2022
       (consultÃ© le 19 juin 2023)
   188. â†‘ (en) Victor Dey, Â« Google consolidates AI research labs into
       Google DeepMind to compete with OpenAI Â», VentureBeat, 20 avril
       2023 (consultÃ© le 28 juillet 2023)
   189. â†‘ Morgane Tual, Â« Une intelligence artificielle peut-elle devenir
       prÃ©sidente des Ã‰tats-Unis ? Â», sur Le Monde, 17 fÃ©vrier 2016.
   190. â†‘ (en) Â« A Massive Google Network Learns To Identify â€” Cats Â»,
       NPR,â€ 26 juin 2012 (lire en ligne)
   191. â†‘ (en) Will Douglas Heaven, Â« Rogue superintelligence and merging
       with machines: Inside the mind of OpenAIâ€™s chief scientist Â», sur
       MIT Technology Review (consultÃ© le 12 dÃ©cembre 2023)
   192. â†‘ Karyl-aka, Â« Google investit dans des recherches sur
       l'intelligence artificielle quantique Â», sur CNET France, 17 mai
       2013.
   193. â†‘ ^a et b (en) Grace Kay, Â« The history of ChatGPT creator OpenAI,
       which Elon Musk helped found before parting ways and criticizing Â»,
       sur Business Insider, 1^er fÃ©vrier 2023 (consultÃ© le 11 dÃ©cembre
       2023)
   194. â†‘ (en) Tom Simonite, Â« The AI Text Generator That's Too Dangerous
       to Make Public Â», Wired,â€ 14 fÃ©vrier 2019 (ISSN 1059-1028, lire en
       ligne, consultÃ© le 11 dÃ©cembre 2023)
   195. â†‘ (en) Sebastian Moss, Â« Eleven OpenAI Employees Break Off to
       Establish Anthropic, Raise $124 Million Â», AI Business,â€ 2 juin
       2021 (lire en ligne)
   196. â†‘ (en) Jordan Novet, Â« Microsoft and OpenAI have a new A.I. tool
       that will give coding suggestions to software developers Â», sur
       CNBC, 29 juin 2021 (consultÃ© le 12 dÃ©cembre 2023)
   197. â†‘ (en) Laurie Clarke, Â« When AI can make art â€“ what does it mean
       for creativity? Â», The Observer,â€ 12 novembre 2022 (ISSN 0029-7712,
       lire en ligne, consultÃ© le 12 dÃ©cembre 2023)
   198. â†‘ Liam Tung, Â« ChatGPT devient l'application Ã  la croissance la
       plus rapide de tous les temps Â», sur ZDNet France, 4 fÃ©vrier 2023
       (consultÃ© le 11 dÃ©cembre 2023)
   199. â†‘ Â« Alibaba's AI Outguns Humans in Reading Test Â», Bloomberg.com,â€
       15 janvier 2018 (lire en ligne, consultÃ© le 16 janvier 2018).
   200. â†‘ (en) Beatrice Nolan, Â« Here's what we know so far about Google's
       Gemini Â», sur Business Insider (consultÃ© le 12 dÃ©cembre 2023)
   201. â†‘ (en) James Vincent, Â« OpenAI announces GPT-4 â€” the next
       generation of its AI language model Â», sur The Verge, 14 mars 2023
       (consultÃ© le 12 dÃ©cembre 2023)
   202. â†‘ Â« Textes adoptÃ©s - Une politique industrielle europÃ©enne globale
       sur lâ€™intelligence artificielle et la robotique - Mardi 12 fÃ©vrier
       2019 Â», sur www.europarl.europa.eu (consultÃ© le 10 dÃ©cembre 2023)
   203. â†‘ ^a et b Â« Intelligence artificielle, de quoi parle-t-on ? Â», sur
       www.cnil.fr (consultÃ© le 10 dÃ©cembre 2023)
   204. â†‘ ^a b et c Â« Intelligence artificielle Â», sur www.cnil.fr
       (consultÃ© le 10 dÃ©cembre 2023)
   205. â†‘ Â« AFIA - Association FranÃ§aise pour l'Intelligence
       Artificielle Â», sur AFIA (consultÃ© le 19 dÃ©cembre 2017)
   206. â†‘ Â« Comment permettre Ã  l'Homme de garder la main ? Â» [PDF], sur
       Commission nationale de l'informatique et des libertÃ©s, dÃ©cembre
       2017.
   207. â†‘ Â« Office parlementaire d'Ã©valuation des choix scientifiques et
       technologiques Â», sur AssemblÃ©e nationale (consultÃ© le 1^er fÃ©vrier
       2018).
   208. â†‘ Johanna Diaz, Â« Lancement dâ€™une consultation publique sur
       lâ€™intelligence artificielle par CÃ©dric Villani Â», sur Actu IA, 7
       dÃ©cembre 2017.
   209. â†‘ CÃ©dric Villani, Donner un sens Ã  l'intelligence artificielle :
       Pour une stratÃ©gie nationale et europÃ©enne, mars 2018
       (ISBN 978-2-11-145708-9, lire en ligne).
   210. â†‘ Â« Intelligence artificielle : Macron annonce un plan Ã  1,5
       milliard d'euros Â», sur Le Parisien.fr, 29 mars 2018.
   211. â†‘ Â« Pour Emmanuel Macron, lâ€™intelligence artificielle est aussi
       "une rÃ©volution politique" Â», Le Monde (consultÃ© le 1^er avril
       2018).
   212. â†‘ (en) Â« Emmanuel Macron Talks to WIRED About France's AI
       Strategy Â», Wired,â€ 31 mars 2018 (lire en ligne).
   213. â†‘ Â« Le Gouvernement lance la phase recrutement de son plan IA - Le
       Monde Informatique Â», sur LeMondeInformatique, 9 novembre 2021
       (consultÃ© le 10 dÃ©cembre 2023)

Annexes[modifier | modifier le code]

Bibliographie[modifier | modifier le code]

     * (en) David Berlinski, The Advent of the Algorithm : The 300-Year
       Journey from an Idea to the Computer, Harcourt Books, 2000, 345 p.
       (ISBN 0-15-601391-6, OCLC 46890682)
     * (en) Rodney Brooks, Â« Elephants Don't Play Chess Â», Robotics and
       Autonomous Systems, vol. 6,â€ 1990, p. 3âˆ’15
       (DOI 10.1016/S0921-8890(05)80025-9, lire en ligne, consultÃ© le 30
       aoÃ»t 2007)
     * (en) Bruce G. Buchanan, A (Very) Brief History of Artificial
       Intelligence, AI Magazine, 2005 (lire en ligne [archive du 26
       septembre 2007]), p. 53âˆ’60
     * (en) Samuel Butler, Darwin Among the Machines, Christchurch, the
       Press, juin 1863 (lire en ligne)
     * (en) CNN, Â« AI set to exceed human brain power Â», CNN.com,â€ 26
       juillet 2006 (lire en ligne, consultÃ© le 16 octobre 2007).
     * (en) Jack Copeland, Micro-World AI, 2000 (lire en ligne).
     * (en) Roberto Cordeschi, The Discovery of the Artificial, Dordrecht,
       Kluwer, 2002
     * (en) Daniel Crevier, AI : The Tumultuous Search for Artificial
       Intelligence, New York, BasicBooks, 1993, 386 p.
       (ISBN 0-465-02997-3)
     * (en) Brad Darrach, Â« Meet Shakey, the First Electronic Person Â»,
       Life Magazine,â€ 20 novembre 1970, p. 58âˆ’68
     * (en) J. Doyle, Â« What is rational psychology? Toward a modern
       mental philosophy Â», AI Magazine, vol. 4, n^o 3,â€ 1983, p. 50âˆ’53
     * (en) Hubert Dreyfus, Alchemy and AI, RAND Corporation Memo, 1965
     * (en) Hubert Dreyfus, What Computers Can't Do : The Limits of
       Artificial Intelligence, New York, MIT Press, 1972, 354 p.
       (ISBN 0-06-090613-8, OCLC 5056816)
     * (en) Hubert Dreyfus, Stuart Dreyfus et Paul Anthanasiou, Mind Over
       Machine : The Power of Human Intuition and Expertise in the Era of
       the Computer, Free Press, 1986 (ISBN 0-7432-0551-0)
     * (en) The Economist, Â« Are You Talking to Me? Â», The Economist,â€ 7
       juin 2007 (lire en ligne, consultÃ© le 16 octobre 2008)
     * (en) Edward A. Feigenbaum et Pamela McCorduck, The Fifth
       Generation : Artificial Intelligence and Japan's Computer Challenge
       to the World, Michael Joseph, 1983 (ISBN 0-7181-2401-4)
     * (en) Michael Haenlein et Andreas Kaplan, Â« A Brief History of
       Artificial Intelligence: On the Past, Present, and Future of
       Artificial Intelligence Â», California Management Journal,â€ 2019
       (lire en ligne)
     * (en) Jeff Hawkins et Sandra Blakeslee, On Intelligence, New York,
       Owl Books, 2004, 272 p. (ISBN 0-8050-7853-3, OCLC 61273290)
     * (en) D.O. Hebb, The Organization of Behavior : a neuropsychological
       theory, New York, Wiley, 1949, 335 p. (ISBN 0-8058-4300-0,
       OCLC 48871099)
     * (en) Carl Hewitt, Peter Bishop et Richard Steiger, A Universal
       Modular Actor Formalism for Artificial Intelligence, IJCAI, 1973,
       PDF (lire en ligne)
     * (en) Thomas Hobbes, Leviathan, 1651
     * (en) Douglas Hofstadter, GÃ¶del, Escher, Bach : an Eternal Golden
       Braid, Basic Books, 1979, 824 p. (ISBN 0-465-02656-7,
       OCLC 225590743)
     * (en) J. Howe, Artificial Intelligence at Edinburgh University : a
       Perspective, 1994 (lire en ligne)
     * (en) G. Kolata, Â« How can computers get common sense? Â», Science,
       vol. 217, n^o 4566,â€ 1982, p. 1237â€“1238 (PMID 17837639,
       DOI 10.1126/science.217.4566.1237, Bibcode 1982Sci...217.1237K)
     * (en) Ray Kurzweil, The Singularity is Near : When Humans Transcend
       Biology, New York, Penguin, 2005, 652 p. (ISBN 0-14-303788-9 et
       978-0-14-303788-0, OCLC 71826177)
     * (en) George Lakoff, Women, Fire, and Dangerous Things : What
       Categories Reveal About the Mind, Chicago/London, University of
       Chicago Press., 1987, 614 p. (ISBN 0-226-46804-6)
     * (en) Douglas Lenat et R. V. Guha, Building Large Knowledge-Based
       Systems : representation and inference in the Cyc project,
       Addison-Wesley, 1989, 372 p. (ISBN 0-201-51752-3, OCLC 19981533)
     * (en) Gerald M. Levitt, The Turk, Chess Automaton, Jefferson,
       McFarland, 2000, 258 p. (ISBN 0-7864-0778-6)
     * (en) Professor Sir James Lighthill, Artificial Intelligence : a
       paper symposium : Artificial Intelligence: A General Survey,
       Science Research Council, 1973
     * (en) John Lucas, Â« Minds, Machines and GÃ¶del Â», Philosophy,
       vol. 36, n^o XXXVI,â€ 1961, p. 112â€“127
       (DOI 10.1017/S0031819100057983, lire en ligne, consultÃ© le 15
       octobre 2008)
     * (en) Meg Houston Maker, AI@50 : AI Past, Present, Future, Dartmouth
       College, 2006 (lire en ligne [archive du 8 octobre 2008])
     * (en) John Markoff, Â« Behind Artificial Intelligence, a Squadron of
       Bright Real People Â», The New York Times,â€ 14 octobre 2005 (lire en
       ligne, consultÃ© le 16 octobre 2008)
     * (en) John McCarthy, Marvin Minsky, Nathan Rochester et Claude
       Shannon, A Proposal for the Dartmouth Summer Research Project on
       Artificial Intelligence, aoÃ»t 1955 (lire en ligne)
     * (en) John McCarthy, P. J. Hayes, B. J. Meltzer (Ã©diteur) et Donald
       Mitchie (Ã©diteur), Machine Intelligence 4 : Some philosophical
       problems from the standpoint of artificial intelligence, Edinburgh
       University Press, 1969 (lire en ligne), p. 463âˆ’502
     * (en) Pamela McCorduck, Machines Who Think, Natick, A. K. Peters,
       Ltd., 2004, 2^e Ã©d., 565 p. (ISBN 1-56881-205-1)
     * (en) Warren Sturgis McCulloch et W. Pitts, A logical calculus of
       the ideas immanent in nervous activity, vol. 5, Bulletin of
       Mathematical Biophysics, 1943 (DOI 10.1007/BF02478259), chap. 4,
       p. 115âˆ’127
     * (en) Luigi Federico Menabrea et Ada Lovelace, Sketch of the
       Analytical Engine Invented by Charles Babbage, vol. 3, Scientific
       Memoirs, 1843 (lire en ligne) avec des notes du traducteur sur le
       mÃ©moire
     * (en) Marvin Minsky, Computation : Finite and Infinite Machines,
       Englewood Cliffs, N.J., Prentice-Hall, 1967
     * (en) Marvin Minsky et Seymour Papert, Perceptrons : An Introduction
       to Computational Geometry, The MIT Press, 1969 (ISBN 0-262-63111-3,
       OCLC 16924756)
     * (en) Marvin Minsky, A Framework for Representing Knowledge, 1974
       (lire en ligne)
     * (en) Marvin Minsky, The Society of Mind, New-York, Simon and
       Schuster, 1986, 339 p. (ISBN 0-671-65713-5, OCLC 223353010, lire en
       ligne)
     * (en) Marvin Minsky, It's 2001. Where Is HAL?, D^r Dobb's
       Technetcast, 2001 (lire en ligne)
     * (en) Hans Moravec, The Role of Raw Power in Intelligence, 1976
       (lire en ligne)
     * (en) Hans Moravec, Mind Children : The Future of Robot and Human
       Intelligence, Harvard University Press, 1988, 214 p.
       (ISBN 0-674-57618-7, OCLC 245755104, lire en ligne)
     * Pierre-Ã‰ric Mounier-Kuhn, L'informatique en France de la Seconde
       Guerre mondiale au Plan Calcul : l'Ã©mergence d'une science, Paris,
       Presses universitaires de Paris-Sorbonne, coll. Â« Centre Roland
       Mousnier Â», 2010, 718 p. (ISBN 978-2-84050-654-6 et 2840506548)
     * (en) Allen Newell, H. A. Simon, E.A. Feigenbaum (Ã©diteur) et J.
       Feldman (Ã©diteur), Computers and Thought : GPS: A Program that
       Simulates Human Thought, New York, McGraw-Hill, 1963, 535 p.
       (ISBN 0-262-56092-5, OCLC 246968117)
     * (en) Martin Nick, Al Jazari : The Ingenious 13th Century Muslin
       Mechanic, Al Shindagah, 2005 (lire en ligne)
     * (en) NRC, Funding a Revolution : Government Support for Computing
       Research, National Academy Press, 1999 (ISBN 0-309-06278-0,
       OCLC 246584055), Â« Developments in Artificial Intelligence Â»
     * (en) Kathleen Malone O'Connor, The alchemical creation of life
       (takwin) and other concepts of Genesis in medieval Islam,
       University of Pennsylvania, 1994 (lire en ligne)
     * (en) Stefanie Olsen, Â« Newsmaker: Google's man behind the
       curtain Â», CNET,â€ 10 mai 2004 (lire en ligne, consultÃ© le 17
       octobre 2008)
     * (en) Stefanie Olsen, Â« Spying an intelligent search engine Â»,
       CNET,â€ 18 aoÃ»t 2006 (lire en ligne, consultÃ© le 17 octobre 2008)
     * (en) J. Pearl, Probabilistic Reasoning in Intelligent Systems :
       Networks of Plausible Inference, San Mateo (Californie), Morgan
       Kaufmann, 1988 (ISBN 1-55860-479-0, OCLC 249625842)
     * (en) David Poole, Alan Mackworth et Randy Goebel, Computational
       Intelligence : A Logical Approach, New York, Oxford University
       Press., 1998, 558 p. (ISBN 0-19-510270-3, lire en ligne)
     * (en) Stuart J. Russell et Peter Norvig, Artificial Intelligence : A
       Modern Approach, Upper Saddle River, Prentice Hall, 2003, 2^e Ã©d.
       (ISBN 0-13-790395-2, lire en ligne)
     * (en) Arthur L. Samuel, Â« Some studies in machine learning using the
       game of checkers Â», IBM Journal of Research and Development,
       vol. 3, n^o 3,â€ juillet 1959, p. 210âˆ’219 (DOI 10.1147/rd.33.0210,
       lire en ligne, consultÃ© le 20 aoÃ»t 2007)
     * (en) John Searle, Â« Minds, Brains and Programs Â», Behavioral and
       Brain Sciences, vol. 3, n^o 3,â€ 1980, p. 417â€“457
       (DOI 10.1017/S0140525X00005756, lire en ligne, consultÃ© le 13 mai
       2009)
     * (en) H. A. Simon et Allen Newell, Heuristic Problem Solving : The
       Next Advance in Operations Research, vol. 6, Operations Research,
       1958 (DOI 10.1287/opre.6.1.1)
     * (en) H. A. Simon, The Shape of Automation for Men and Management,
       New York, Harper & Row, 1965
     * (en) Jonathan Skillings, Â« Newsmaker: Getting machines to think
       like us Â», CNET,â€ 2006 (lire en ligne, consultÃ© le 8 octobre 2008)
     * (en) Patty Tascarella, Â« Robotics firms find fundraising struggle,
       with venture capital shy Â», Pittsburgh Business Times,â€ 11 aoÃ»t
       2006 (lire en ligne, consultÃ© le 8 octobre 2008).
     * (en) Alan Turing, On Computable Numbers, with an Application to the
       Entscheidungsproblem, Proceedings of the London Mathematical
       Society, 1936 (DOI 10.1112/plms/s2-42.1.230, lire en ligne),
       chap. 42, p. 230â€“265
     * (en) Alan Turing, Â« Computing Machinery and Intelligence Â», Mind,
       vol. LIX, n^o 236,â€ octobre 1950, p. 433â€“460 (ISSN 0026-4423, lire
       en ligne [archive du 2 juillet 2008])
     * (en) Joseph Weizenbaum, Computer Power and Human Reason, W.H.
       Freeman & Company, 1976 (ISBN 0-14-022535-8, OCLC 10952283)
     * (en) Joseph Needham, Science and Civilization in China : Volume 2,
       Taipei, Caves Books Ltd, 1986
     * (en) John Haugeland, Artificial Intelligence : The Very Idea,
       Cambridge, MIT Press, 1985 (ISBN 0-262-08153-9)
     * (en) George Lakoff et Mark Turner, More than cool reason : a field
       guide to poetic metaphor, 1989
     * (en) George Luger et William Stubblefield, Artificial
       intelligence : structures and strategies for complex problem
       solving, Redwood City (Calif.)/Menlo Park (Calif.)/Reading (Mass.)
       etc., The Benjamin/Cummings Publishing Company, Inc., 2004,
       5^e Ã©d., 740 p. (ISBN 0-8053-4780-1, lire en ligne)
     * (en) Sherry Turkle, The second self : computers and the human
       spirit, New York, Simon & Schuster, Inc., 1984, 386 p.
       (ISBN 978-0-262-70111-2)
     * (en) Peter Cathcart Wason et Shapiro, New horizons in psychology,
       Harmondsworth, Penguin, 1966
     * (en) A. Tversky, P. Slovic et D. Kahneman, Judgment Under
       Uncertainty : Heuristics and Biases, New York, Cambridge University
       Press, 1982

Articles connexes[modifier | modifier le code]

     * Cerveau artificiel
     * Histoire des ordinateurs
     * Histoire de l'informatique
     * Intelligence artificielle
     * Intelligence artificielle amicale
     * Philosophie de l'intelligence artificielle
     * Principaux projets et rÃ©alisations en intelligence artificielle
     * RÃ©volution numÃ©rique

   v Â· m
   Histoire des sciences
   Chronologie
     * AlgÃ¨bre
     * Astronomie
          + Stellaire
          + SystÃ¨me solaire
     * Biologie
     * Botanique
     * Chimie
     * Entomologie
     * Informatique
     * MÃ©canique classique
     * Optique
     * Ornithologie
     * Pathologie vÃ©gÃ©tale
     * Place des femmes en science
     * SantÃ© et mÃ©decine
     * Techniques

   Sciences et techniques par civilisation
     * Ã‰gypte
     * GrÃ¨ce
     * Rome
     * Chine
     * Inde
     * Byzance
     * Monde arabe
     * Moyen Ã‚ge
     * Empire ottoman
     * Europe des LumiÃ¨res
     * Renaissance

   Histoires des disciplines
     * Anthropologie
     * ArchÃ©ologie
     * Astronomie
          + Gravitation
     * Biologie
          + Biologie marine
          + Biologie molÃ©culaire
          + Ã‰volution
     * Botanique
     * Chimie
          + Ã‰lectrochimie
          + Ã‰lÃ©ments
     * Cryptologie
     * Ã‰cologie
     * Ã‰conomie
     * Ã‰lectrophysiologie
     * GÃ©nÃ©tique
     * GÃ©ographie
     * GÃ©ologie
     * Histoire naturelle
     * Ichtyologie
     * Informatique
     * Intelligence artificielle
     * Linguistique
     * Logique
     * MathÃ©matiques
          + AlgÃ¨bre
          + Analyse
          + Calcul infinitÃ©simal
          + Analyse fonctionnelle
          + GÃ©omÃ©trie
          + ProbabilitÃ©
          + Statistique
          + TrigonomÃ©trie
     * MÃ©decine
     * MÃ©tÃ©orologie
     * MÃ©thode scientifique
     * MinÃ©ralogie
     * PalÃ©oanthropologie
     * PalÃ©ontologie
     * Phycologie
     * Physique
          + Ã‰lectricitÃ©
          + MÃ©canique
          + MÃ©canique quantique
          + MagnÃ©tisme
          + Optique
          + RelativitÃ© gÃ©nÃ©rale
          + RelativitÃ© restreinte Article de qualitÃ©
          + ThÃ©orie des champs
     * Psychologie
          + Psychologie cognitive
          + Psychologie analytique
          + Psychanalyse
     * Techniques
     * Volcanologie
     * Zoologie
          + Primatologie

   v Â· m
   Intelligence artificielle (IA)
   Concepts
     * Effet IA
     * Grand modÃ¨le de langage
     * Hallucination (IA)
     * IA gÃ©nÃ©rale
     * IA gÃ©nÃ©rative

   Techniques
     * Analyse prÃ©dictive
     * Apprentissage automatique
     * Apprentissage non supervisÃ©
     * Apprentissage profond
     * Apprentissage supervisÃ©
     * ModÃ¨le de fondation
     * ModÃ¨le des croyances transfÃ©rables
     * IA symbolique
     * RÃ©seau bayÃ©sien
     * RÃ©seau de neurones artificiels
     * RÃ©seau neuronal convolutif
     * Transformeur

   Applications
     * Art crÃ©Ã© par IA
     * ChatGPT
     * DeepL
     * Diagnostic (IA)
     * Ã‰criture assistÃ©e par IA
     * IA dans la santÃ©
     * IA dans le jeu vidÃ©o
     * Perception artificielle
     * Planification (IA)
     * Robotique
     * Traduction automatique
     * Traitement automatique du langage naturel
     * VÃ©hicule autonome
     * Vision par ordinateur

   Enjeux et philosophie
     * Alignement de l'IA
     * Chambre chinoise
     * Conscience artificielle
     * ContrÃ´le des capacitÃ©s de l'IA
     * Ã‰thique de l'IA
     * IA digne de confiance
     * Philosophie de l'IA
     * SÃ»retÃ© de l'IA

   Histoire et Ã©vÃ©nements
     * Histoire de l'intelligence artificielle
     * Logic Theorist (1955)
     * Perceptron (1957)
     * General Problem Solver (1959)
     * Prolog (1972)
     * Matchs Deep Blue contre Kasparov (1996-1997)
     * Match AlphaGo - Lee Sedol (2016)

   Science-fiction
     * Anticipation (IA)
     * IA-complet
     * IA gÃ©nÃ©rale
     * Risque de catastrophe planÃ©taire liÃ© Ã  l'intelligence artificielle
       gÃ©nÃ©rale
     * Superintelligence

       RÃ¨glementation
     * LÃ©gislation sur l'IA
     * RÃ©glementation de l'IA

   Organisations
     * Agence francophone pour l'IA
     * Google DeepMind
     * OpenAI
     * Partenariat sur l'IA

   Ouvrages
     * DÃ©claration de MontrÃ©al pour un dÃ©veloppement responsable de
       l'intelligence artificielle
     * Lettre ouverte sur l'IA
     * Intelligence artificielle : une approche moderne
     * I.A. La Plus Grande Mutation de l'Histoire

     * icÃ´ne dÃ©corative Portail de la robotique
     * icÃ´ne dÃ©corative Portail de lâ€™informatique
     * icÃ´ne dÃ©corative Portail de la psychologie
     * icÃ´ne dÃ©corative Portail du Web sÃ©mantique
     * icÃ´ne dÃ©corative Portail de lâ€™histoire des sciences

   Erreur de rÃ©fÃ©renceâ€¯: Des balises <ref> existent pour un groupe nommÃ©
   Â«â€¯alphaâ€¯Â», mais aucune balise <references group="alpha"/>
   correspondante nâ€™a Ã©tÃ© trouvÃ©e
   Ce document provient de
   Â« https://fr.wikipedia.org/w/index.php?title=Histoire_de_l%27intelligen
   ce_artificielle&oldid=210526127 Â».
   CatÃ©goriesâ€¯:
     * Intelligence artificielle
     * Histoire par domaine scientifique

   CatÃ©gories cachÃ©esâ€¯:
     * Article contenant un appel Ã  traduction en anglais
     * Article Ã  rÃ©fÃ©rence nÃ©cessaire
     * Portail:Robotique/Articles liÃ©s
     * Portail:Ã‰lectricitÃ© et Ã©lectronique/Articles liÃ©s
     * Portail:GÃ©nie mÃ©canique/Articles liÃ©s
     * Portail:Technologies/Articles liÃ©s
     * Portail:Informatique/Articles liÃ©s
     * Portail:Sciences/Articles liÃ©s
     * Portail:Psychologie/Articles liÃ©s
     * Portail:Sciences humaines et sociales/Articles liÃ©s
     * Portail:Web sÃ©mantique/Articles liÃ©s
     * Portail:Histoire des sciences/Articles liÃ©s
     * Portail:Histoire/Articles liÃ©s
     * Article avec des erreurs de rÃ©fÃ©rence

     * La derniÃ¨re modification de cette page a Ã©tÃ© faite le 13 dÃ©cembre
       2023 Ã  22:25.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les mÃªmes conditions ; dâ€™autres
       conditions peuvent sâ€™appliquer. Voyez les conditions dâ€™utilisation
       pour plus de dÃ©tails, ainsi que les crÃ©dits graphiques. En cas de
       rÃ©utilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       WikipediaÂ® est une marque dÃ©posÃ©e de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance rÃ©gie par le paragraphe 501(c)(3) du
       code fiscal des Ã‰tats-Unis.

     * Politique de confidentialitÃ©
     * Ã€ propos de WikipÃ©dia
     * Avertissements
     * Contact
     * Code de conduite
     * DÃ©veloppeurs
     * Statistiques
     * DÃ©claration sur les tÃ©moins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou dÃ©sactiver la limitation de largeur du contenu
