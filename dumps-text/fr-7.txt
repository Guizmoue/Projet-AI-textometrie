   #alternate Wikipédia (fr) Flux Atom de Wikipédia

   Aller au contenu

   [ ] Menu principal
   Menu principal
   (BUTTON) déplacer vers la barre latérale (BUTTON) masquer
   Navigation
     * Accueil
     * Portails thématiques
     * Article au hasard
     * Contact

   Contribuer
     * Débuter sur Wikipédia
     * Aide
     * Communauté
     * Modifications récentes
     * Faire un don

   Langues
   Sur cette version linguistique de Wikipédia, les liens interlangues
   sont placés en haut à droite du titre de l’article.
   Aller en haut.
   Wikipédia l'encyclopédie libre
   Rechercher
   ____________________
   (BUTTON) Rechercher

     * Créer un compte
     * Se connecter

   [ ] Outils personnels
     * Créer un compte
     * Se connecter

   Pages pour les contributeurs déconnectés en savoir plus
     * Contributions
     * Discussion

Sommaire

   (BUTTON) déplacer vers la barre latérale (BUTTON) masquer
     * Début
     * 1Définition
     * 2Histoire
       (BUTTON) Afficher / masquer la sous-section Histoire
          + 2.1Création et développement
          + 2.2Précurseurs
               o 2.2.1Automates
               o 2.2.2Pensée automatique
          + 2.3Faits marquants depuis les années 2000
               o 2.3.1Années 2010
          + 2.4En France
     * 3Intelligence artificielle générale
       (BUTTON) Afficher / masquer la sous-section Intelligence
       artificielle générale
          + 3.1Définition
          + 3.2Estimation de faisabilité
     * 4Intelligence artificielle forte
       (BUTTON) Afficher / masquer la sous-section Intelligence
       artificielle forte
          + 4.1Définition
          + 4.2Diversité des opinions
     * 5Intelligence artificielle faible
       (BUTTON) Afficher / masquer la sous-section Intelligence
       artificielle faible
          + 5.1Distinction avec « narrow AI »
     * 6Test de Turing
       (BUTTON) Afficher / masquer la sous-section Test de Turing
          + 6.1Estimation de faisabilité
          + 6.2Autres tests notables
     * 7Personnalités
       (BUTTON) Afficher / masquer la sous-section Personnalités
          + 7.1Prix Turing
          + 7.2Autres personnalités
     * 8Courants de pensée
       (BUTTON) Afficher / masquer la sous-section Courants de pensée
          + 8.1Cognitivisme
          + 8.2Connexionnisme
          + 8.3Synthèse
     * 9Différentes facettes
     * 10Conception de systèmes
       (BUTTON) Afficher / masquer la sous-section Conception de systèmes
          + 10.1Distinction entre intelligence artificielle, machine
            learning et deep learning
     * 11Domaines d’application
       (BUTTON) Afficher / masquer la sous-section Domaines d’application
          + 11.1Finance et banques
          + 11.2Militaire
          + 11.3Médecine
          + 11.4Renseignement policier
          + 11.5Cybercrime
          + 11.6Droit
          + 11.7Logistique et transports
          + 11.8Industrie
          + 11.9Robotique
          + 11.10Jeux vidéo
          + 11.11Art
          + 11.12Autres domaines
     * 12Réglementation
     * 13Questionnements
       (BUTTON) Afficher / masquer la sous-section Questionnements
          + 13.1Question de l'intelligence
          + 13.2Espoirs et enthousiasme
          + 13.3Critiques et inquiétudes
               o 13.3.1Maitrise de la technologie
               o 13.3.2Enjeux sociétaux
               o 13.3.3Enjeux environnementaux
          + 13.4Critique de la technique et de la technologie
          + 13.5Vers des alternatives open source ?
          + 13.6Appels à des règles éthiques pour l'IA
          + 13.7Demandes de moratoire
     * 14IA et emploi
       (BUTTON) Afficher / masquer la sous-section IA et emploi
          + 14.1Intelligence artificielle et travail numérique
               o 14.1.1Travail à la demande
               o 14.1.2Micro-travail
               o 14.1.3Travail social en réseau
          + 14.2Sondage
     * 15Dans la science-fiction
       (BUTTON) Afficher / masquer la sous-section Dans la science-fiction
          + 15.1Quelques IA célèbres dans la science-fiction
     * 16Utilisation dans les jeux
       (BUTTON) Afficher / masquer la sous-section Utilisation dans les
       jeux
          + 16.1Othello
          + 16.2Échecs
          + 16.3Go
          + 16.4Jeopardy!
          + 16.5Poker
          + 16.6Bridge
     * 17Notes et références
       (BUTTON) Afficher / masquer la sous-section Notes et références
          + 17.1Notes
          + 17.2Références
     * 18Voir aussi
       (BUTTON) Afficher / masquer la sous-section Voir aussi
          + 18.1Bibliographie
          + 18.2Articles connexes
          + 18.3Liens externes

   [ ] Basculer la table des matières

Intelligence artificielle

   [ ] 147 langues
     * Afrikaans
     * Alemannisch
     * አማርኛ
     * Aragonés
     * العربية
     * الدارجة
     * مصرى
     * অসমীয়া
     * Asturianu
     * Azərbaycanca
     * تۆرکجه
     * Башҡортса
     * Boarisch
     * Žemaitėška
     * Bikol Central
     * Беларуская
     * Беларуская (тарашкевіца)
     * Български
     * বাংলা
     * བོད་ཡིག
     * Brezhoneg
     * Bosanski
     * Буряад
     * Català
     * کوردی
     * Qırımtatarca
     * Čeština
     * Чӑвашла
     * Cymraeg
     * Dansk
     * Deutsch
     * Zazaki
     * Ελληνικά
     * English
     * Esperanto
     * Español
     * Eesti
     * Euskara
     * Estremeñu
     * فارسی
     * Suomi
     * Võro
     * Fɔ̀ngbè
     * Nordfriisk
     * Furlan
     * Gaeilge
     * 贛語
     * Kriyòl gwiyannen
     * Gàidhlig
     * Galego
     * Avañe'ẽ
     * Gaelg
     * Hausa
     * עברית
     * हिन्दी
     * Hrvatski
     * Kreyòl ayisyen
     * Magyar
     * Հայերեն
     * Արեւմտահայերէն
     * Interlingua
     * Bahasa Indonesia
     * Interlingue
     * Igbo
     * Ilokano
     * Ido
     * Íslenska
     * Italiano
     * 日本語
     * Patois
     * La .lojban.
     * Jawa
     * ქართული
     * Қазақша
     * ಕನ್ನಡ
     * 한국어
     * Ripoarisch
     * Кыргызча
     * Latina
     * Limburgs
     * Lombard
     * Lietuvių
     * Latviešu
     * Madhurâ
     * Malagasy
     * Minangkabau
     * Македонски
     * മലയാളം
     * Монгол
     * मराठी
     * Bahasa Melayu
     * Malti
     * မြန်မာဘာသာ
     * Nedersaksies
     * नेपाली
     * नेपाल भाषा
     * Nederlands
     * Norsk nynorsk
     * Norsk bokmål
     * Occitan
     * ଓଡ଼ିଆ
     * ਪੰਜਾਬੀ
     * Polski
     * پنجابی
     * پښتو
     * Português
     * Runa Simi
     * Română
     * Русский
     * Русиньскый
     * Саха тыла
     * Scots
     * سنڌي
     * Srpskohrvatski / српскохрватски
     * සිංහල
     * Simple English
     * Slovenčina
     * Slovenščina
     * Shqip
     * Српски / srpski
     * Svenska
     * Kiswahili
     * Ślůnski
     * தமிழ்
     * తెలుగు
     * Тоҷикӣ
     * ไทย
     * Türkmençe
     * Tagalog
     * Türkçe
     * Татарча / tatarça
     * Reo tahiti
     * ئۇيغۇرچە / Uyghurche
     * Українська
     * اردو
     * Oʻzbekcha / ўзбекча
     * Vèneto
     * Tiếng Việt
     * Walon
     * Winaray
     * 吴语
     * მარგალური
     * ייִדיש
     * 中文
     * Bân-lâm-gú
     * 粵語
     * IsiZulu

   Modifier les liens

     * Article
     * Discussion

   [ ] français

     * Lire
     * Voir le texte source
     * Voir l’historique

   [ ] Outils
   Outils
   (BUTTON) déplacer vers la barre latérale (BUTTON) masquer
   Actions
     * Lire
     * Voir le texte source
     * Voir l’historique

   Général
     * Pages liées
     * Suivi des pages liées
     * Téléverser un fichier
     * Pages spéciales
     * Lien permanent
     * Informations sur la page
     * Citer cette page
     * Obtenir l'URL raccourcie
     * Élément Wikidata

   Imprimer / exporter
     * Créer un livre
     * Télécharger comme PDF
     * Version imprimable

   Dans d’autres projets
     * Wikimedia Commons
     * Wikiquote
     * Wikiversité

   Cette page est en semi-protection longue.
   Un article de Wikipédia, l'encyclopédie libre.

   Page d’aide sur l’homonymie

   Pour les articles homonymes, voir A.I. Intelligence artificielle (film)
   et IA  Ce lien renvoie vers une page d'homonymie .
   Si ce bandeau n'est plus pertinent, retirez-le. Cliquez ici pour en
   savoir plus. Si ce bandeau n'est plus pertinent, retirez-le. Cliquez
   ici pour en savoir plus.

   Cet article a besoin d'un nouveau plan (septembre 2023).

   Les informations dans cet article sont mal organisées, redondantes, ou
   il existe des sections bien trop longues. Structurez-le ou soumettez
   des propositions en page de discussion.
   Comment faire ?

   Avec le temps, il arrive que le contenu présent dans un article
   devienne désordonné. Il est souvent nécessaire de réorganiser l'article
   de fond en comble.
     * Il faut tout d’abord répartir le contenu de l'article en plusieurs
       sections. Les informations doivent ensuite être exposées clairement
       et le plus synthétiquement possible, regroupées par sujet afin
       d'éviter les doublons. Quelqu'un cherchant une information précise
       doit pouvoir la trouver rapidement en lisant la section appropriée.
     * À l'intérieur de chaque section, le texte, souvent initialement
       sous la forme de phrases éparses, doit être regroupé dans des
       paragraphes de quelques lignes, en assurant un enchaînement logique
       et une cohérence entre les phrases.
     * Lorsque l'article ou l'une de ses sections développe trop
       longuement un point qui n'est pas dans le cœur du sujet traité, il
       convient de faire une synthèse et de transférer l'ancien contenu
       dans des articles plus appropriés (en cas de transfert, il faut
       impérativement respecter la procédure Aide:Scission).

   Si vous pensez que ces points ont été résolus, vous pouvez retirer ce
   bandeau et améliorer le plan d'un autre article.
   [180px-%E3%82%B9%E3%83%9E%E3%83%BC%E3%83%88%E3%82%B9%E3%83%94%E3%83%BC%
   E3%82%AB%E3%83%BC.jpg] Les assistants personnels intelligents sont
   l'une des applications concrètes de l'intelligence artificielle dans
   les années 2010.

   L'intelligence artificielle (IA) est un ensemble de théories et de
   techniques visant à réaliser des machines capables de simuler
   l'intelligence humaine^[1].

   Souvent classée dans le groupe des mathématiques et des sciences
   cognitives, elle fait appel à la neurobiologie computationnelle
   (particulièrement aux réseaux neuronaux) et à la logique mathématique
   (partie des mathématiques et de la philosophie). Elle utilise des
   méthodes de résolution de problèmes à forte complexité logique ou
   algorithmique. Par extension, elle comprend, dans le langage courant,
   les dispositifs imitant ou remplaçant l'homme dans certaines mises en
   œuvre de ses fonctions cognitives^[2].

   Les applications de l'IA incluent notamment moteurs de recherche,
   systèmes de recommandation, compréhension du langage naturel, voitures
   autonomes, chatbots, outils de génération d'images, outils de prise de
   décision automatisée et programmes compétitifs dans des jeux de
   stratégie^[3].

   Ses finalités et enjeux ainsi que son développement suscitent, depuis
   l'apparition du concept, de nombreuses interprétations, fantasmes ou
   inquiétudes s'exprimant tant dans les récits ou films de
   science-fiction que dans les essais philosophiques^[4]. Si des outils
   relevant d'intelligences artificielles spécialisées ou génératives ont
   fait leurs preuves, la réalité semble encore tenir l'intelligence
   artificielle généraliste loin des performances du vivant dans toutes
   ses aptitudes naturelles^[5].

Définition

   Le terme « intelligence artificielle », créé par John McCarthy, est
   souvent abrégé par le sigle « IA » (ou « AI » en anglais, pour
   artificial intelligence). McCarthy définit l'IA ainsi : « C'est la
   science et l'ingénierie de la fabrication de machines intelligentes, en
   particulier de programmes informatiques intelligents. Elle est liée à
   la tâche similaire qui consiste à utiliser des ordinateurs pour
   comprendre l'intelligence humaine, mais l'IA ne doit pas se limiter aux
   méthodes qui sont biologiquement observables^[6]. »

   Elle est également définie par l’un de ses créateurs, Marvin Lee
   Minsky, comme « la construction de programmes informatiques qui
   s’adonnent à des tâches qui sont, pour l’instant, accomplies de façon
   plus satisfaisante par des êtres humains car elles demandent des
   processus mentaux de haut niveau tels que : l’apprentissage perceptuel,
   l’organisation de la mémoire et le raisonnement critique »^[a]^,^[7].
   On y trouve donc le côté « artificiel » atteint par l'usage des
   ordinateurs ou de processus électroniques élaborés et le côté
   « intelligence » associé à son but d'imiter le comportement. Cette
   imitation peut se faire dans le raisonnement, par exemple dans les jeux
   ou la pratique des mathématiques, dans la compréhension des langues
   naturelles, dans la perception : visuelle (interprétation des images et
   des scènes), auditive (compréhension du langage parlé) ou par d'autres
   capteurs, dans la commande d'un robot dans un milieu inconnu ou
   hostile.

   Même si elles respectent globalement la définition de Minsky, certaines
   définitions de l'IA varient sur deux points fondamentaux^[8] :
     * les définitions qui lient l'IA à un aspect humain de
       l'intelligence, et celles qui la lient à un modèle idéal
       d'intelligence, non forcément humaine, nommée rationalité ;
     * les définitions qui insistent sur le fait que l'IA a pour but
       d'avoir toutes les apparences de l'intelligence (humaine ou
       rationnelle), et celles qui insistent sur le fait que le
       fonctionnement interne du système d'IA doit ressembler également à
       celui de l'être humain et être au moins aussi rationnel.

Histoire

   Article détaillé : Histoire de l'intelligence artificielle.

Création et développement

   Historiquement, l'idée d'intelligence artificielle semble émerger dans
   les années 1950 quand Alan Turing se demande si une machine peut
   « penser ». Dans l'article « Computing Machinery and Intelligence »
   (Mind, octobre 1950)^[9], Turing explore ce problème et propose une
   expérience (maintenant dite test de Turing) visant à trouver à partir
   de quand une machine deviendrait « consciente ». Il développe ensuite
   cette idée dans plusieurs forums, dans la conférence « L'intelligence
   de la machine, une idée hérétique »^[10], dans la conférence qu'il
   donne à la BBC 3^e programme le 15 mai 1951 « Les calculateurs
   numériques peuvent-ils penser ? »^[11], ainsi que dans la discussion
   avec M.H.A. Newman, Sir Geoffrey Jefferson et R.B. Braithwaite les 14
   et 23 janvier 1952 sur le thème « Les ordinateurs peuvent-ils
   penser ? »^[12].

   Une autre origine probable est la publication, en 1949, par Warren
   Weaver d'un mémorandum sur la traduction automatique des langues^[13]
   qui suggère qu'une machine puisse faire une tâche qui relève
   typiquement de l'intelligence humaine.

   Le développement des techniques informatiques (augmentation de la
   puissance de calcul) aboutit ensuite à plusieurs avancées :
     * dans les années 1980, l'apprentissage automatique se développe,
       notamment avec la renaissance du connexionnisme. L'ordinateur
       commence à déduire des « règles à suivre » en analysant seulement
       des données^[14]^,^[15] ;
     * parallèlement, des algorithmes « apprenants » sont créés qui
       préfigurent les futurs réseaux de neurones (l'apprentissage par
       renforcement, les machines à vecteurs de support, etc.). Ceci
       permet par exemple en mai 1997 à l’ordinateur Deep Blue de battre
       Garry Kasparov au jeu d'échecs^[16] lors d'un match revanche de six
       parties ;
     * l'intelligence artificielle devient un domaine de recherche
       international, marquée par une conférence au Dartmouth College à
       l’été 1956^[17]^,^[18] à laquelle assistaient ceux qui vont marquer
       la discipline ;
     * depuis les années 1960, la recherche se fait principalement aux
       États-Unis, notamment à l'université Stanford sous l'impulsion de
       John McCarthy^[19], au MIT sous celle de Marvin Minsky^[20], à
       l'université Carnegie-Mellon sous celle de Allen Newell et Herbert
       Simon^[21] et à l'université d'Édimbourg sous celle de Donald
       Michie^[22], en Europe et en Chine, ainsi qu'au Japon avec le
       projet « ordinateurs de cinquième génération (en) » du
       gouvernement ;
     * dans les années 2000, le Web 2.0, le big data et de nouvelles
       puissances et infrastructures de calcul permettent à certains
       ordinateurs d'explorer des masses de données sans précédent ; c'est
       l'apprentissage profond (« deep learning »), dont l'un des
       pionniers est le français Yann Le Cun^[23].

   Les bornes de ce domaine varient, ainsi optimiser un itinéraire était
   considéré comme un problème d'intelligence artificielle dans les années
   1950 et n'est plus considéré aujourd’hui que comme un simple problème
   d'algorithmie^[réf. obsolète]^[24].

   Vers 2015, le secteur de l'intelligence artificielle cherche à relever
   quatre défis : la perception visuelle, la compréhension du langage
   naturel écrit ou parlé, l'analyse automatique du langage et la prise de
   décision autonome^[25]. Produire et organiser des données nombreuses et
   de qualité, c'est-à-dire corrélées, complètes, qualifiées (sourcées,
   datées, géoréférencées…), historisées est un autre enjeu. La capacité
   déductive et de généralisation pertinente d'un ordinateur, à partir de
   peu de données ou d'un faible nombre d'évènements, est un autre
   objectif, plus lointain^[25].

   Entre 2010 et 2016, les investissements auraient été décuplés,
   atteignant une dizaine de milliards de dollars en 2016^[26].

Précurseurs

   Si les progrès de l’intelligence artificielle sont récents, ce thème de
   réflexion est tout à fait ancien, et il apparaît régulièrement au cours
   de l’histoire. Les premiers signes d’intérêt pour une intelligence
   artificielle et les principaux précurseurs de cette discipline sont les
   suivants.

Automates

   Article connexe : Automate.

   Une des plus anciennes traces du thème de « l’homme dans la machine »
   date de 800 avant notre ère, en Égypte. La statue du dieu Amon levait
   le bras pour désigner le nouveau pharaon parmi les prétendants qui
   défilaient devant lui, puis elle « prononçait » un discours de
   consécration. Les Égyptiens étaient probablement conscients de la
   présence d’un prêtre actionnant un mécanisme et déclarant les paroles
   sacrées derrière la statue, mais cela ne semblait pas être pour eux
   contradictoire avec l’incarnation de la divinité. Vers la même époque,
   Homère, dans L'Iliade (XVIII, 370–421), décrit les automates réalisés
   par le dieu forgeron Héphaïstos : des trépieds munis de roues en or,
   capables de porter des objets jusqu’à l’Olympe et de revenir seuls dans
   la demeure du dieu ; ou encore, deux servantes forgées en or qui
   l’assistent dans sa tâche. De même, le Géant de bronze Talos, gardien
   des rivages de la Crète, était parfois considéré comme une œuvre du
   dieu.

   Vitruve, architecte romain, décrit l’existence entre le III^e et le
   I^er siècle avant notre ère, d’une école d’ingénieurs fondée par
   Ctesibius à Alexandrie, et concevant des mécanismes destinés à
   l’amusement tels des corbeaux qui chantaient. Héron L'Ancien décrit
   dans son traité « Automates », un carrousel animé grâce à la vapeur et
   considéré comme anticipant les machines à vapeur. Les automates
   disparaissent ensuite jusqu’à la fin du Moyen Âge. On a prêté à Roger
   Bacon la conception d'automates capables de parler, mais mais ce
   n'était probablement en fait que des mécanismes simulant la
   prononciation de certains mots simples.

   Léonard de Vinci a construit en 1515 un automate en forme de lion pour
   amuser le roi de France, François I^[27]. Gio Battista Aleotti et
   Salomon de Caus, eux, ont construit des oiseaux artificiels et
   chantants, des flûtistes mécaniques, des nymphes, des dragons et des
   satyres animés pour égayer des fêtes aristocratiques, des jardins et
   des grottes. René Descartes, lui, aurait conçu en 1649 un automate
   qu’il appelait « ma fille Francine ». Il conduit par ailleurs une
   réflexion d’un modernisme étonnant sur les différences entre la nature
   des automates, et celles d’une part des animaux (pas de différence) et
   d’autre part celle des hommes (pas d’assimilation). Ces analyses en
   font le précurseur méconnu d’un des principaux thèmes de la
   science-fiction : l'indistinction entre le vivant et l’artificiel,
   entre les hommes et les robots, les androïdes ou les intelligences
   artificielles.
   [210px-Digesting_Duck.jpg] Le canard artificiel de Vaucanson (1738).

   Jacques de Vaucanson a construit en 1738 un « canard artificiel de
   cuivre doré, qui boit, mange, cancane, barbote et digère comme un vrai
   canard ». Il était possible de programmer les mouvements de cet
   automate, grâce à des pignons placés sur un cylindre gravé, qui
   contrôlaient des baguettes traversant les pattes du canard. L’automate
   a été exposé pendant plusieurs années en France, en Italie et en
   Angleterre, et la transparence de l’abdomen permettait d’observer le
   mécanisme interne. Le dispositif permettant de simuler la digestion et
   d’expulser une sorte de bouillie verte fait l’objet d’une controverse.
   Certains commentateurs estiment que cette bouillie verte n’était pas
   fabriquée à partir des aliments ingérés, mais préparée à l’avance.
   D’autres estiment que cet avis n’est fondé que sur des imitations du
   canard de Vaucanson. L’incendie du musée de Nijni Novgorod en Russie,
   vers 1879, a détruit cet automate^[28].

   Les artisans Pierre et Louis Jaquet-Droz fabriquèrent parmi les
   meilleurs automates fondés sur un système purement mécanique, avant le
   développement des dispositifs électromécaniques. Certains de ces
   automates, par un système de cames multiples, étaient capables d'écrire
   un petit billet (toujours le même). Enfin, Les Contes d'Hoffmann (et
   ballet) L'Homme au sable décrit une poupée mécanique dont s'éprend le
   héros.

Pensée automatique

   Une des premières tentatives de formalisation de la pensée connue est
   le zairja, mécanisme qu'utilisaient les astrologues arabe pour générer
   des idées supposées logiques, dont l'invention est attribuée à Abu
   al-Abbas as-Sabti au XII^e siècle. Raymond Lulle s'en est probablement
   inspiré pour mettre au point son Ars Magna^[29]. Missionnaire,
   philosophe, et théologien espagnol du XIII^e siècle, il essaya lui
   aussi de générer des idées grâce à un système mécanique. Il combinait
   aléatoirement des concepts grâce à une sorte de règle à calcul, sur
   laquelle pivotaient des disques concentriques gravés de lettres et de
   symboles philosophiques. Il fondait sa méthode sur l’identification de
   concepts de base, puis leur combinaison mécanique soit entre eux, soit
   avec des idées connexes. Raymond Lulle l'appliqua à la métaphysique,
   puis à la morale, à la médecine et à l’astrologie. Mais il n’utilisait
   que la logique déductive, ce qui ne permettait pas à son système
   d’acquérir un apprentissage, ni davantage de remettre en cause ses
   principes de départ : seule la logique inductive le permet.

   Gottfried Wilhelm Leibniz, au XVII^e siècle, a imaginé un calcul
   pensant (Calculus ratiocinator), en assignant un nombre à chaque
   concept. La manipulation de ces nombres aurait permis de résoudre les
   questions les plus difficiles, et même d’aboutir à un langage
   universel. Leibniz a toutefois démontré que l’une des principales
   difficultés de cette méthode, également rencontrée dans les travaux
   modernes sur l’intelligence artificielle, est l’interconnexion de tous
   les concepts, ce qui ne permet pas d’isoler une idée de toutes les
   autres pour simplifier les problèmes liés à la pensée.

   George Boole a inventé la formulation mathématique des processus
   fondamentaux du raisonnement, connue sous le nom d’algèbre de Boole. Il
   était conscient des liens de ses travaux avec les mécanismes de
   l’intelligence, comme le montre le titre de son principal ouvrage paru
   en 1854 : Les Lois de la pensée^[30] (The laws of thought), sur
   l’algèbre booléenne.

   Gottlob Frege perfectionna le système de Boole en formalisant le
   concept de prédicat, qui est une entité logique soit vraie, soit fausse
   (toute maison a un propriétaire), mais contenant des variables non
   logiques, n’ayant en soi aucun degré de vérité (maison, propriétaire).
   Cette formalisation eut une grande importance puisqu'elle permit de
   démontrer des théorèmes généraux, simplement en appliquant des règles
   typographiques à des ensembles de symboles. La réflexion en langage
   courant ne portait plus que sur le choix des règles à appliquer. Par
   ailleurs, l’utilisateur joue un rôle important puisqu'il connaît le
   sens des symboles qu’il a inventés et ce sens^[b] n'est pas toujours
   formalisé, ce qui ramène au problème de la signification en
   intelligence artificielle, et de la subjectivité des utilisateurs.

   Bertrand Russell et Alfred North Whitehead publièrent au début du
   XX^e siècle un ouvrage intitulé Principia Mathematica, dans lequel ils
   résolvent des contradictions internes à la théorie de Gottlob Frege.
   Ces travaux laissaient espérer d’aboutir à une formalisation complète
   des mathématiques^[31].

   Kurt Gödel démontre au contraire que les mathématiques resteront une
   construction ouverte, en publiant en 1931 un article intitulé « Des
   propositions formellement indécidables contenues dans les Principia
   mathematica et autres systèmes similaires ». Sa démonstration est qu’à
   partir d’une certaine complexité d’un système, on peut y créer plus de
   propositions logiques qu’on ne peut en démontrer vraies ou fausses.
   L’arithmétique, par exemple, ne peut trancher par ses axiomes si on
   doit accepter des nombres dont le carré soit -1. Ce choix reste
   arbitraire et n’est en rien lié aux axiomes de base. Le travail de
   Gödel suggère qu’on pourra créer ainsi un nombre arbitraire de nouveaux
   axiomes, compatibles avec les précédents, au fur et à mesure qu’on en
   aura besoin. Si l'arithmétique est démontrée incomplète, le calcul des
   prédicats (logique formelle) est au contraire démontré par Gödel comme
   complet^[32].

   Alan Turing invente des machines abstraites et universelles
   (rebaptisées les machines de Turing), dont les ordinateurs modernes
   sont considérés comme des concrétisations. Il démontre l’existence de
   calculs qu’aucune machine ne peut faire (un humain pas davantage, dans
   les cas qu'il cite), sans pour autant que cela constitue pour Turing un
   motif pour douter de la faisabilité de machines pensantes répondant aux
   critères du test de Turing.

   Irving John Good^[33], Myron Tribus et E.T. Jaynes^[34] ont décrit de
   façon très claire les principes assez simples d’un robot à logique
   inductive utilisant les principes de l’inférence bayésienne pour
   enrichir sa base de connaissances sur la base du Théorème de
   Cox-Jaynes. Ils n’ont malheureusement pas traité la question de la
   façon dont on pourrait stocker ces connaissances sans que le mode de
   stockage entraîne un biais cognitif. Le projet est voisin de celui de
   Raymond Lulle, mais fondé cette fois-ci sur une logique inductive, et
   donc propre à résoudre quelques problèmes ouverts.

   Des chercheurs comme Alonzo Church ont posé des limites pratiques aux
   ambitions de la raison, en orientant la recherche (Herbert Simon,
   Michael Rabin, Stephen Cook) vers l’obtention des solutions en temps
   fini, ou avec des ressources limitées, ainsi que vers la catégorisation
   des problèmes selon des classes de difficulté (en rapport avec les
   travaux de Cantor sur l’infini)^[réf. souhaitée].

Faits marquants depuis les années 2000

   L'intelligence artificielle est un sujet d'actualité au XXI^e siècle.
   En 2004, le Singularity Institute a lancé une campagne Internet appelée
   3 Laws Unsafe (« 3 lois dangereuses »), pour sensibiliser à
   l'insuffisance des trois lois d'Asimov avant la sortie du film I,
   Robot^[35]^,^[36].

   En 2005, le projet Blue Brain est lancé, qui vise à simuler le cerveau
   des mammifères. Il s'agit d'une des méthodes envisagées pour réaliser
   une IA. Ils annoncent de plus comme objectif de fabriquer en dix ans le
   premier « vrai » cerveau électronique^[37]. En mars 2007, le
   gouvernement sud-coréen annonce que plus tard dans l'année, il
   émettrait une charte sur l'éthique des robots, afin de fixer des normes
   pour les utilisateurs et les fabricants. Selon Park Hye-Young, du
   ministère de l'Information et de la communication, la Charte reflète
   les trois lois d'Asimov : la tentative de définition des règles de base
   pour le développement futur de la robotique. En juillet 2009, en
   Californie, dans une conférence organisée par l'Association for the
   Advancement of Artificial Intelligence (AAAI), un groupe
   d'informaticiens se demande s'il devrait y avoir des limites sur la
   recherche qui pourrait conduire à une perte de contrôle des systèmes
   informatiques par l'humanité. Il y abordent les progrès et le potentiel
   de l'IA, ainsi que les risques associés aux armes léthales autonomes,
   au chômage technologique et aux concepts d'explosion d'intelligence et
   de singularité technologique^[38].

   En 2009, le Massachusetts Institute of Technology (MIT) a lancé un
   projet visant à repenser la recherche en intelligence artificielle. Il
   réunira des scientifiques qui ont eu du succès dans des domaines
   distincts de l'IA. Neil Gershenfeld déclare « Nous voulons
   essentiellement revenir 30 ans en arrière et revisiter certaines idées
   qui ont été gelées »^[39].

   En novembre 2009, l'US Air Force cherche à acquérir 2 200 PlayStation
   3^[40] pour utiliser le processeur cell à sept ou huit cœurs qu'elle
   contient dans le but d'augmenter les capacités de leur superordinateur
   constitué de 336 PlayStation 3 (total théorique 52,8 petaFLOPS en
   double précision). Le nombre sera réduit à 1 700 unités le 22 décembre
   2009^[41]. Le projet vise le traitement vidéo haute-définition, et
   l'« informatique neuromorphique », ou la création de calculateurs avec
   des propriétés/fonctions similaires au cerveau humain^[40].

Années 2010

   Le 27 janvier 2010, l'US Air Force demande l'aide de l'industrie pour
   développer une intelligence avancée de collecte d'information et d'aide
   rapide à la décision, pour aider les forces américaines à rapidement
   repérer les vulnérabilités de leurs ennemis. Lee raisonnement
   ontologique, les procédures informatique basées sur la connaissance, et
   d'autres traitements de données avancés pourront être utilisés pour
   cela^[réf. obsolète]^[42]. Et avant 2020, plus de mille bombardiers et
   chasseurs F-22 et F-35 de dernière génération, parmi plus de
   2 500 avions militaires, commenceront à être équipés de sorte que,
   d’ici 2040, tous les avions de guerre américains soient pilotés par
   intelligence artificielle, en plus des 10 000 véhicules terrestres et
   des 7 000 dispositifs aériens commandés d'ores et déjà à
   distance^[source insuffisante]^[43].

   Le 16 février 2011, Watson, le superordinateur conçu par IBM, remporte
   deux des trois manches du jeu télévisé Jeopardy! en battant largement
   ses deux concurrents humains en gains cumulés. Pour cette IA, la
   performance a résidé dans le fait de répondre à des questions de
   culture générale (et non un domaine technique précis) dans des délais
   très courts. En février 2016, l'artiste et designer Aaron Siegel
   propose de faire de Watson un candidat à l'élection présidentielle
   américaine afin de lancer le débat sur « le potentiel de l’intelligence
   artificielle dans la politique »^[44].

   En mai 2013, Google ouvre un laboratoire de recherches dans les locaux
   de la NASA. Grâce à un super calculateur quantique conçu par D-Wave
   Systems et qui serait d'après cette société 11 000 fois plus performant
   qu'un ordinateur classique^[45], ils espèrent ainsi faire progresser
   l'intelligence artificielle, notamment l'apprentissage automatique.
   Raymond Kurzweil est engagé en décembre 2012 par Google afin de
   participer et d'améliorer l'apprentissage automatique^[46].

   Entre 2014 et 2015, à la suite du développement rapide du deep
   learning, quelques scientifiques et membres de la communauté high tech
   craignent que l'intelligence artificielle ne vienne à terme dépasser
   les performances de l'intelligence humaine. Parmi eux, l'astrophysicien
   britannique Stephen Hawking^[47], le fondateur de Microsoft Bill
   Gates^[48] et le PDG de Tesla Elon Musk^[49].

   Les géants de l'Internet s'intéressent de plus en plus à l'IA^[50]. Le
   Facebook Artificial Intelligence Research (FAIR), créé en 2013 et
   dirigé par le chercheur français Yann Le Cun, annonce en 2015
   l'ouverture d'un laboratoire de recherche à Paris^[51].

   Apple a de son côté récemment acquis plusieurs start-up du secteur
   (Perceptio, VocalIQ, Emotient et Turi)^[52].

   En janvier 2018, des modèles d'intelligence artificielle développés par
   Microsoft et Alibaba réussissent chacun de leur côté à battre les
   humains dans un test de lecture et de compréhension de l'université
   Stanford. Le traitement du langage naturel imite la compréhension
   humaine des mots et des phrases et permet aux modèles d'apprentissage
   automatique de traiter de grandes quantités d'informations avant de
   fournir des réponses précises aux questions qui leur sont posées^[53].

   En février 2019, l'institut de recherche OpenAI annonce la création du
   programme d’intelligence artificielle GPT-2, capable de générer des
   textes jugés suffisamment réalistes pour pouvoir représenter un
   danger^[54]^,^[55]. Si le logiciel est utilisé avec une intention
   malveillante, il peut générer des fausses nouvelles crédibles. Inquiet,
   OpenAI a choisi de ne pas rendre public le code source du
   programme^[56].

En France

   En France, les pionniers sont Alain Colmerauer, Gérard Huet, Jean-Louis
   Laurière, Claude-François Picard, Jacques Pitrat^[57] et Jean-Claude
   Simon^[58]. Un congrès national annuel, « Reconnaissance de formes et
   intelligence artificielle », est créé en 1979 à Toulouse^[59]. En lien
   avec l'organisation de la conférence International Joint Conference on
   Artificial Intelligence à Chambéry en 1993, et la création d'un
   GRECO-PRC^[60] « intelligence artificielle », en 1983, il donne
   naissance à une société savante, l'Association française pour
   l'intelligence artificielle (AFIA) en 1989, qui, entre autres, organise
   des conférences nationales en intelligence artificielle^[61].
   [220px-Ai_for_humanity_logo.svg.png] Logo de la conférence « AI for
   Humanity » organisée le 29 mars 2018 au Collège de France.

   Le 17 janvier 2017, le fonds de capital risque Serena Capital lance un
   fonds de 80 millions d’euros destiné à l’investissement dans les
   start-ups européennes du big data et de l'intelligence
   artificielle^[62]. Le 19 janvier 2017, une audition se tient au Sénat :
   « L'intelligence Artificielle menace-t-elle nos emplois ? »^[63]. Le 20
   janvier 2017, Axelle Lemaire entend valoriser les potentiels
   scientifiques et industriels français grâce au projet « France
   IA »^[64].

   En janvier 2017, dans le cadre de sa mission de réflexion sur les
   enjeux éthiques et les questions de société soulevés par les
   technologies numériques, la Commission nationale de l'informatique et
   des libertés (CNIL) annonce l'organisation d'un débat public sur les
   algorithmes et l'intelligence artificielle^[65]. Le 15 décembre 2017, à
   l'issue d'un débat ayant mobilisé 60 partenaires (institutions
   publiques, associations, entreprises, acteurs du monde de la recherche,
   société civile)^[66], elle publie son rapport « Comment permettre à
   l'Homme de garder la main ? »^[67] comprenant des recommandations pour
   la construction d'un modèle éthique d'intelligence artificielle.

   En septembre 2017, Cédric Villani, premier vice-président de l'Office
   parlementaire d'évaluation des choix scientifiques et technologiques
   (OPECST)^[68], est chargé de mener une consultation publique sur
   l'intelligence artificielle^[69]. Il rend son rapport le 28 mars
   2018^[70], à la veille d'une intervention du président de la République
   Emmanuel Macron au Collège de France pour annoncer la stratégie de la
   France dans ce domaine^[71]. Il y dévoile un plan de 1,5 milliard
   d'euros sur l'ensemble du quinquennat, ainsi qu'une évolution de la
   législation française pour permettre la mise en application de
   l'intelligence artificielle, en particulier concernant la circulation
   des véhicules autonomes^[72]. Parallèlement à ces annonces, il est
   interviewé par Wired, magazine de référence pour la communauté mondiale
   des nouvelles technologies, et y exprime sa vision de l'intelligence
   artificielle, à savoir que les algorithmes utilisés par l'État doivent
   être ouverts, que l'intelligence artificielle doit être encadrée par
   des règles philosophiques et éthiques et qu'il faut s'opposer à l'usage
   d'armes automatiques ou de dispositifs prenant des décisions sans
   consulter un humain^[73]^,^[74].

   En septembre 2023, l’entreprise Onclusive, située à Courbevoie et
   spécialisée dans la veille médiatique, annonce son intention de
   licencier 217 employés sur 380 d’ici juin 2024, afin de les remplacer
   par une intelligence artificielle^[75].

Intelligence artificielle générale

   Article détaillé : intelligence artificielle générale.

Définition

   L'intelligence artificielle générale (IAG) comprend tout système
   informatique capable d'effectuer ou d'apprendre pratiquement n'importe
   quelle tâche cognitive propre aux humains ou autres animaux^[76]. Elle
   peut alternativement être définie comme un système informatique
   surpassant les humains dans la plupart des tâches ayant un intérêt
   économique^[77].

   L'intelligence artificielle générale a longtemps été considérée comme
   un sujet purement spéculatif^[78]. Certains travaux de recherche ont
   déjà décrit GPT-4 comme ayant des « étincelles » d'intelligence
   artificielle générale^[79]^,^[80]. Les experts en intelligence
   artificielle affichent de larges désaccords et incertitudes quant à la
   date potentielle de conception des premières intelligences
   artificielles générales (parfois appelées « intelligences artificielles
   de niveau humain »), leur impact sur la société, et leur potentiel à
   déclencher une « explosion d'intelligence »^[81].

Estimation de faisabilité

   Comparer la capacité de traitement de l'information d'un cerveau humain
   à celle d'un ordinateur peut aider à comprendre les ordres de grandeur
   pour estimer la possibilité pratique ou non d'une intelligence
   artificielle générale, de même qu'un simple calcul de puissance en kW
   permet grosso modo de dire qu'un camion donné pourra espérer
   transporter commodément telle ou telle charge ou si cela lui sera
   impossible. Voici quelques exemples d'ordres de grandeur en traitement
   de l'information :
     * balance Roberval : un bit par seconde (comparaison de deux poids) ;
     * mainframe typique des années 1970 : un million d'opérations par
       seconde sur 32 bits ;
     * Intel Paragon XP/S, 4 000 processeurs i860 à 50 MHz (1992) : 160
       milliards d'opérations par seconde ;
     * Summit, 9 216 processeurs POWER9 (2018) : 200 pétaflops, soit 200
       millions de milliards d'opérations par seconde ;
     * Fugaku 415-PFLOPS (2020-2021) : 415 pétaflops, soit 415 millions de
       milliards d'opérations par seconde.

   Cette puissance n'est pas à prendre au pied de la lettre. Elle précise
   surtout les ordres de grandeur en présence et leur évolution
   relativement rapide (jusqu'en 2018).

   L'intelligence artificielle n'a donné que des résultats mitigés sur les
   ordinateurs typiques de 1970 effectuant 10^7 opérations logiques par
   seconde^[c]^,^[82]. Le cerveau humain, formé de 10^11 neurones ne
   pouvant chacun commuter plus de 100 fois par seconde en raison de leur
   temps de relaxation, permettait beaucoup plus de traitements logiques
   par unité de temps (10^13 opérations logiques par seconde)^[82]. Ce
   handicap technique précis n'existe plus sur les ordinateurs depuis les
   années 2000, travaillant en 64 bits et suivant des horloges cadencées à
   4 GHz environ, pour des processeurs destinés aux particuliers.
   Concernant des supercalculateurs comme Summit ou Fugaku 415-PFLOPS, le
   rapport du nombre de comparaisons par seconde entre ordinateur et
   cerveau a même complètement changé de sens.

   Le matériel serait donc maintenant disponible, toutefois l'IA souligne
   la difficulté à expliciter toutes les connaissances utiles à la
   résolution d'un problème complexe. Certaines connaissances dites
   implicites sont acquises par l'expérience et mal formalisables.
   L'apprentissage de ces connaissances implicites par l'expérience est
   exploitée depuis les années 1980 (voir Réseau de neurones). Néanmoins,
   un autre type de complexité apparaît : la complexité structurelle.
   Comment mettre en relation des modules spécialisés pour traiter un
   certain type d'informations, par exemple un système de reconnaissance
   des formes visuelles, un système de reconnaissance de la parole, un
   système lié à la motivation, à la coordination motrice, au
   langage, etc. En revanche, une fois un système cognitif conçu et son
   apprentissage par l'expérience réalisé, l'« intelligence »
   correspondante peut être distribuée en un grand nombre d'exemplaires,
   par exemple sur les portables d'actuaires ou de banquiers pouvant
   ainsi, comme le rappelle un slogan, dire oui ou non, mais le dire tout
   de suite grâce à des applications dites de credit scoring.

Intelligence artificielle forte

   Article détaillé : Philosophie de l'intelligence artificielle.

Définition

   Le concept d’intelligence artificielle forte fait référence à une
   machine capable non seulement de produire un comportement intelligent,
   notamment de modéliser des idées abstraites, mais aussi d’éprouver une
   impression d'une réelle conscience, de « vrais sentiments » (notion
   dont la définition n'est pas universelle), et « une compréhension de
   ses propres raisonnements »^[83].

   Contrairement à l'intelligence artificielle générale, l'intelligence
   artificielle forte fait donc le plus souvent intervenir des notions
   philosophiques de conscience qui font que les capacités de
   l'intelligence artificielle ne suffisent pas à dire si elle est
   « forte ». Cela dit, aucune définition de la conscience pour une IA ne
   fait consensus^[84]. Les termes « intelligence artificielle forte » et
   « intelligence artificielle générale » sont parfois en pratique
   utilisés de manière interchangeable^[76].

   En partant du principe, étayé par les neurosciences^[85], que la
   conscience a un support biologique et donc matériel, les scientifiques
   ne voient généralement pas d’obstacle théorique à la création d'une
   intelligence consciente sur un support matériel autre que biologique.
   Selon les tenants de l'IA forte, si à l'heure actuelle il n'y a pas
   d'ordinateurs ou d'algorithmes aussi intelligents que l'être humain, ce
   n'est pas un problème d'outil mais de conception. Il n'y aurait aucune
   limite fonctionnelle (un ordinateur est une machine de Turing
   universelle avec pour seules limites celles de la calculabilité),
   seulement des limites liées à l'aptitude humaine à concevoir les
   logiciels appropriés (programme, base de données…).

Diversité des opinions

   Les principales opinions soutenues pour répondre à la question d’une
   intelligence artificielle forte (c'est-à-dire douée d'une sorte de
   conscience) sont les suivantes :
     * impossible : la conscience serait le propre des organismes vivants
       (supérieurs), et elle serait liée à la nature des systèmes
       biologiques. Cette position est défendue par certains philosophes
       et sociologues comme Harry Collins, pour qui l'intelligence
       requiert une immersion dans la société humaine, et donc un corps
       humain^[78], et peut rappeler le courant du vitalisme ;
     * impossible avec des machines manipulant des symboles comme les
       ordinateurs actuels, mais possible avec des systèmes dont
       l’organisation matérielle serait fondée sur des processus
       quantiques. Des algorithmes quantiques sont théoriquement capables
       de mener à bien des calculs hors de l'atteinte pratique des
       calculateurs conventionnels (complexité en
       [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
       displaystyle="true" scriptlevel="0"> <msup> <mi>N</mi> <mrow
       class="MJX-TeXAtom-ORD"> <mn>3</mn> </mrow> </msup> </mstyle>
       </mrow> <annotation encoding="application/x-tex">{\displaystyle
       N^{3}}</annotation> </semantics> :MATH]
       {\displaystyle N^{3}} au lieu de
       [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
       displaystyle="true" scriptlevel="0"> <msup> <mn>2</mn> <mrow
       class="MJX-TeXAtom-ORD"> <mi>N</mi> </mrow> </msup> </mstyle>
       </mrow> <annotation encoding="application/x-tex">{\displaystyle
       2^{N}}</annotation> </semantics> :MATH]
       2^{N} , par exemple, sous réserve d'existence du calculateur
       approprié). Au-delà de la rapidité, le scientifique Roger Penrose
       défend dans la théorie de la réduction objective orchestrée l'idée
       controversée que la conscience nécessiterait un fonctionnement non
       compatible avec les lois de la physique classique, et accessible
       uniquement à des systèmes quantiques^[86]^,^[87] ;
     * impossible car la pensée n'est pas un phénomène calculable par des
       processus discrets et finis. Cette théorie est notamment avancée
       par le philosophe John Searle et son expérience de la chambre
       chinoise^[88]. Une conscience est donc nécessaire pour accéder à
       l'intelligence, mais un système informatique ne serait capable que
       d'en simuler une, sans pour autant la posséder, renvoyant au
       concept philosophique du zombie ;
     * possible avec des ordinateurs manipulant des symboles. La notion de
       symbole est toutefois à prendre au sens large. Cette option inclut
       les travaux sur le raisonnement ou l'apprentissage symbolique basé
       sur la logique des prédicats, mais aussi les techniques
       connexionnistes telles que les réseaux de neurones, qui, à la base,
       sont définies par des symboles. Cette position est portée par des
       mouvements comme ceux du computationnalisme et est portée par des
       philosophes comme Hubert Dreyfus, pour qui le cerveau suit les lois
       de la physique et de la biologie, impliquant que l'esprit est donc
       un processus simulable^[89]. Cette dernière opinion constitue la
       position la plus engagée en faveur de l'intelligence artificielle
       forte.

   Des auteurs comme Douglas Hofstadter (mais déjà avant lui Arthur C.
   Clarke ou Alan Turing ; voir le test de Turing) expriment par ailleurs
   un doute sur la possibilité de faire la différence entre une
   intelligence artificielle qui éprouverait réellement une conscience, et
   une autre qui simulerait exactement ce comportement (voir Zombie
   (philosophie)). Après tout, nous ne pouvons même pas être certains que
   d’autres consciences que la nôtre, y compris chez des humains,
   éprouvent réellement quoi que ce soit, si ce n'est par une pétition de
   principe qui spécule que chaque humain se retrouve à l'identique chez
   tous les autres. On retrouve là le problème connu du solipsisme en
   philosophie.

   Même si une intelligence artificielle forte n'était guère possible, une
   IA peut être de plus en plus perçue comme forte par une majorité
   d'individus parallèlement à l'arrivée des IA génératives, dont les LLM
   (de l'anglais large language model) comme ChatGPT ou Google Bard, et
   les outils de génération d'images comme Midjourney, DALL-E ou Stable
   Diffusion. En effet, le champ d'applications de ces outils est beaucoup
   large qu'auparavant : création, synthèse, traduction de textes,
   composition d'images, de vidéos à partir de prompts, textes
   descriptifs. Il devient ainsi de plus en plus difficile pour un être
   humain de distinguer des créations humaines de celles provenant d’une
   IA générative.

   Emily Bender estime que les grands modèles de langage comme ChatGPT ne
   font que régurgiter plus ou moins aléatoirement des morceaux de texte
   venant des corpus ayant servi à leur entraînement, sans en comprendre
   le sens. Elle les appelle ainsi des « perroquets stochastiques »^[90].
   De même, Jean-Gabriel Ganascia considère que le contenu qu'ils
   produisent n'est pas original et que leur utilisation dans la rédaction
   d'articles de recherche constitue une forme de plagiat^[91]. Ilya
   Sutskever considère au contraire que ces modèles, à force d'être
   entraînés à prédire le mot suivant, acquièrent une forme de « modèle du
   monde » et une représentation « compressée, abstraite et utilisable »
   des concepts^[92].

Intelligence artificielle faible

   Article détaillé : Intelligence artificielle faible.

   La notion d’intelligence artificielle faible constitue une approche
   pragmatique d’ingénieur : chercher à construire des systèmes de plus en
   plus autonomes (pour réduire le coût de leur supervision), des
   algorithmes capables de résoudre des problèmes d’une certaine classe,
   etc. Mais, cette fois, la machine simule l'intelligence, elle semble
   agir comme si elle était intelligente. On en voit des exemples concrets
   avec les programmes conversationnels qui tentent de passer le test de
   Turing, comme ELIZA. Ces logiciels parviennent à imiter de façon
   grossière le comportement d'humains face à d'autres humains lors d'un
   dialogue.

   Joseph Weizenbaum, créateur du programme ELIZA, met en garde le public
   dans son ouvrage Computer Power and Human Reason : si ces programmes
   « semblent » intelligents, ils ne le sont pas : ELIZA simule très
   grossièrement un psychologue en relevant immédiatement toute mention du
   père ou de la mère, en demandant des détails sur tel élément de phrase
   et en écrivant de temps en temps « Je comprends. », mais son auteur
   rappelle qu'il s'agit d'une simple mystification : le programme ne
   comprend en réalité rien.

   Les tenants de l'IA forte admettent que s'il y a bien dans ce cas
   simple simulation de comportements intelligents, il est aisé de le
   découvrir et qu'on ne peut donc généraliser. En effet, si on ne peut
   différencier expérimentalement deux comportements intelligents, celui
   d'une machine et celui d'un humain, comment peut-on prétendre que les
   deux choses ont des propriétés différentes ? Le terme même de
   « simulation de l'intelligence » est contesté et devrait, toujours
   selon eux, être remplacé par « reproduction de l'intelligence ».

   Les tenants de l'IA faible arguent que la plupart des techniques
   actuelles d’intelligence artificielle sont inspirées de leur paradigme.
   Ce serait par exemple la démarche utilisée par IBM dans son projet
   nommé Autonomic computing. La controverse persiste néanmoins avec les
   tenants de l'IA forte qui contestent cette interprétation.

   Simple évolution, donc, et non révolution : l’intelligence artificielle
   s’inscrit à ce compte dans la droite succession de ce qu’ont été la
   recherche opérationnelle dans les années 1960, la supervision (en
   anglais : process control) dans les années 1970, l’aide à la décision
   dans les années 1980 et l’exploration de données dans les années 1990.
   Et, qui plus est, avec une certaine continuité.

   Il s'agit surtout d'intelligence humaine reconstituée, et de
   programmation ad hoc d'un apprentissage, sans qu'une théorie
   unificatrice n'existe pour le moment (2011)^[Passage à actualiser]. Le
   théorème de Cox-Jaynes indique toutefois, ce qui est un résultat fort,
   que sous cinq contraintes raisonnables, tout procédé d'apprentissage
   devra être soit conforme à l'inférence bayésienne, soit incohérent à
   terme, donc inefficace^[93].

Distinction avec « narrow AI »

   Si le terme intelligence artificielle peut désigner un système capable
   de résoudre plusieurs problèmes de façon relativement autonome tout en
   ne faisant que simuler le principe d'intelligence, il peut aussi
   désigner des systèmes capables de résoudre uniquement un type de
   problème pour un jeu de données prédéfini^[94]. On peut donner pour
   exemple un système entrainé à reconnaitre des chiffres écrits à la
   main, comme ceux utilisés par La Poste^[95], qui malgré sa grande
   performance sur sa tâche, serait incapable de fonctionner sur un
   problème sortant de ce pour quoi il a été conçu.

   Ces intelligences artificielles, nommées « narrow AI » (« intelligence
   artificielle étroite »), sont conçues spécifiquement sur une tâche,
   sans développement particulier pour la généraliser comme le ferait une
   intelligence artificielle générale. Elles n'en gardent pas moins leur
   utilité, et restent très utilisées dans l'industrie^[96], étant les
   seuls systèmes d'IA utilisables jusqu'à ce qu'une intelligence
   artificielle générale soit accessible et commercialisée.

Test de Turing

   [220px-Turing_Test_version_3.png] Schéma du test de Turing.
   Article détaillé : Test de Turing.

   À l’orée des années 1950, entre la naissance de la cybernétique et
   l’émergence quelques années plus tard de l’intelligence artificielle,
   alors que les meilleurs esprits du temps s’interrogent sur la
   possibilité de construire des machines pensantes, Alan Turing propose,
   dès le début d’un article demeuré célèbre, un test pour déterminer si
   une machine peut être définie comme « consciente »^[97].

   Définir l’intelligence est un défi et il n’est pas certain qu’on puisse
   y arriver un jour d’une façon satisfaisante. C’est cette remarque qui
   poussa le mathématicien britannique Alan Turing, en 1950, à proposer
   « le jeu de l’imitation » qui fixait un objectif précis à la science
   naissante des ordinateurs que l'on n'appelait pas encore informatique
   en francophonie. Ce « jeu de l'imitation » suggérait qu'un juge fictif
   puisse dialoguer d'une part avec une machine et d'autre part avec un
   humain à l'aide d'un terminal sans pouvoir les discriminer^[98].

   Jusqu'à ce jour, aucun logiciel n'a encore réussi ce test, à savoir se
   comporter de façon à ne pas être discriminé d'un humain, malgré de
   nombreuses tentatives. Devant la persistance de ces échecs, certains
   spécialistes comme Jean-Gabriel Ganascia pensent que mettre au point un
   programme aussi complexe ne démontrera pas l'intelligence des
   programmes ni leur capacité à penser^[99].

   De nos jours, une machine peut certes réviser et faire évoluer des
   objectifs qu’on lui a attribués. Une machine peut même être programmée
   pour pouvoir restructurer sa connaissance initiale à partir
   d’informations reçues ou perçues. Mais la machine d’aujourd’hui ne
   pense pas à proprement parler, car elle n’a pas conscience d’elle-même
   (et en particulier de ses limites), elle ne peut pas ultimement décider
   de ses buts ni imaginer de nouvelles formes de représentations du
   monde^[97].

Estimation de faisabilité

   Le sémanticien François Rastier, après avoir rappelé les positions de
   Turing et de Grice à ce sujet, propose^[100] six « préceptes »
   conditionnant un système de dialogue évolué, en précisant qu'elles sont
   déjà mises en œuvre par des systèmes existants :
     * objectivité (utilisation d'une base de connaissance par le
       système) ;
     * textualité (prise en compte d'interventions de plus d'une phrase,
       qu'elles émanent du système ou de l'utilisateur) ;
     * apprentissage (intégration au moins temporaire d'informations
       issues des propos de l'utilisateur) ;
     * questionnement (demande de précisions de la part du système) ;
     * rectification (suggestion de rectifications à la question posée,
       lorsque nécessaire) ;
     * explicitation (explicitation par le système d'une réponse qu'il a
       apportée précédemment).

   Il suggère aussi que le système devrait être en mesure de se faire par
   lui-même une représentation de l'utilisateur auquel il a affaire, pour
   s'adapter à lui. De son côté, l'utilisateur a tendance à s'adapter au
   système à partir du moment où il a bien compris qu'il s'adresse à une
   machine : il ne conversera pas de la même manière avec un système
   automatisé qu'avec un interlocuteur humain, ce qui présente pour le
   concepteur l'avantage pragmatique de simplifier certains aspects du
   dialogue.

Autres tests notables

   D'autres tests ont également été développés pour évaluer la performance
   d'une intelligence artificielle :
     * Le test du café^[101] : imaginé par Steve Wozniak, le test consiste
       à placer un système intelligent dans un habitat américain moyen et
       lui demander de faire un café. La réussite du test implique donc
       plusieurs tâches comme l'orientation dans un environnement inconnu,
       déduire le fonctionnement d'une machine, trouver les ustensiles
       nécessaires…
     * Le test de l'étudiant^[102] : proposé par Ben Goertzel, le test
       évalue la capacité d'un robot à s'inscrire dans un établissement
       d'enseignement supérieur, suivre les cours, passer les examens et
       obtenir le diplôme final.
     * Le test de l'embauche : proposé par le chercheur Nils John Nilsson,
       le test consiste à faire postuler un système intelligent à un
       travail important, et travailler au moins aussi bien qu'un
       humain^[103].

Personnalités

Prix Turing

   Article détaillé : Prix Turing.

   Plusieurs prix Turing (ACM Turing Award) ont été attribués à des
   pionniers de l'intelligence artificielle, notamment :
     * Marvin Minsky (1969) ;
     * John McCarthy (1971) ;
     * Allen Newell et Herbert Simon (1975) ;
     * Edward Feigenbaum et Raj Reddy (1994) ;
     * Judea Pearl (2011) ;
     * Yann Le Cun, Geoffrey Hinton et Yoshua Bengio (2019)^[104].

Autres personnalités

   Cette section est vide, insuffisamment détaillée ou incomplète. Votre
   aide est la bienvenue ! Comment faire ?
     * Ian Goodfellow, inventeur des réseaux antagonistes génératifs.
     * Andrew Ng, connu comme directeur scientifique de Baidu et comme
       créateur de Coursera
     * Terry Winograd, pionnier en traitement du langage naturel.
     * Vladimir Vapnik co-inventeur des machines à vecteurs de support.
     * Seymour Papert, ancien directeur du Laboratoire d'intelligence
       artificielle du MIT.
     * Jacques Pitrat, pionnier français en intelligence artificielle
       symbolique.

   En 2023, le magazine Time publie une liste de 100 personnalités
   influentes du domaine de l'IA et leurs biographies^[105].

Courants de pensée

   La cybernétique naissante des années 1940 revendiquait très clairement
   son caractère pluridisciplinaire et se nourrissait des contributions
   les plus diverses : neurophysiologie, psychologie, logique, sciences
   sociales… Et c’est tout naturellement qu’elle envisagea deux approches
   des systèmes, deux approches reprises par les sciences cognitives et de
   ce fait l’intelligence artificielle : une approche par la décomposition
   (du haut vers le bas) et une approche contraire par construction
   progressive du bas vers le haut.

   Ces deux approches se révèlent plutôt complémentaires que
   contradictoires : on est à l'aise pour décomposer rapidement ce que
   l'on connaît bien, et une approche pragmatique à partir des seuls
   éléments que l'on connaît afin de se familiariser avec les concepts
   émergents est plus utile pour les domaines inconnus. Elles sont
   respectivement à la base des hypothèses de travail que constituent le
   cognitivisme et le connexionnisme, qui tentent aujourd'hui
   (2005)^[Passage à actualiser] d'opérer progressivement leur fusion.

   Le guide pratique de Linux sur l'intelligence artificielle v3.0^[106],
   révisé le 15 décembre 2012, adopte pour la commodité du lecteur la
   taxinomie suivante :
     * systèmes symboliques ;
     * connexionnisme ;
     * calcul évolutif (algorithmes génétiques, par exemple) ;
     * alife (vie artificielle) et complexité ;
     * agents et robotique.

Cognitivisme

   Article détaillé : Cognitivisme.

   Le cognitivisme considère que le vivant, tel un ordinateur (bien que
   par des procédés évidemment très différents), manipule essentiellement
   des symboles élémentaires. Dans son livre La société de l’esprit,
   Marvin Minsky, s’appuyant sur des observations du psychologue Jean
   Piaget, envisage le processus cognitif comme une compétition d’agents
   fournissant des réponses partielles et dont les avis sont arbitrés par
   d’autres agents. Il cite les exemples suivants de Piaget :
     * L’enfant croit d’abord que plus le niveau d’eau est élevé dans un
       verre, plus il y a d’eau dans ce verre. Après avoir joué avec des
       transvasements successifs, il intègre le fait que la notion de
       hauteur du liquide dans le verre entre en compétition avec celle du
       diamètre du verre, et arbitre de son mieux entre les deux.
     * Il vit ensuite une expérience analogue en manipulant de la pâte à
       modeler : la réduction de plusieurs objets temporairement
       représentés à une même boule de pâte l’incite à dégager un concept
       de conservation de la quantité de matière.

   Au bout du compte, ces jeux d’enfants se révèlent essentiels à la
   formation de l’esprit, qui dégagent quelques règles pour arbitrer les
   différents éléments d’appréciation qu’il rencontre, par essais et
   erreurs.

Connexionnisme

   Article détaillé : Connexionnisme.

   Le connexionnisme, se référant aux processus auto-organisationnels,
   envisage la cognition comme le résultat d’une interaction globale des
   parties élémentaires d’un système. On ne peut nier que le chien dispose
   d'une sorte de connaissance des équations différentielles du mouvement,
   puisqu’il arrive à attraper un bâton au vol. Et pas davantage qu’un
   chat ait aussi une sorte de connaissance de la loi de chute des corps,
   puisqu’il se comporte comme s’il savait à partir de quelle hauteur il
   ne doit plus essayer de sauter directement pour se diriger vers le sol.
   Cette faculté qui évoque un peu l’intuition des philosophes se
   caractériserait par la prise en compte et la consolidation d’éléments
   perceptifs dont aucun pris isolément n’atteint le seuil de la
   conscience, ou en tout cas n’y déclenche d’interprétation particulière.

Synthèse

   Trois concepts reviennent de façon récurrente dans la plupart des
   travaux :
     * la redondance (le système est peu sensible à des pannes
       ponctuelles) ;
     * la réentrance (les composants s'informent en permanence entre eux ;
       cette notion diffère de la réentrance en programmation) ;
     * la sélection (au fil du temps, les comportements efficaces sont
       dégagés et renforcés).

Différentes facettes

   On peut considérer différents dispositifs intervenant, ensemble ou
   séparément, dans un système d’intelligence artificielle tels que :
     * le dialogue automatique : se faire comprendre en lui parlant ;
     * la traduction automatique, si possible en temps réel ou très
       légèrement différé ;
     * le traitement automatique du langage naturel ;
     * le raisonnement automatique (voir systèmes experts) ;
     * le partitionnement et la classification automatique ;
     * la composition musicale automatique (voir les travaux de René-Louis
       Baron et de l'Ircam ; plus récemment les recherches de François
       Pachet, ainsi que le développement de flowmachines telles que
       Deepbach^[107]^,^[108]) ;
     * la reconnaissance de formes, des visages et la vision en général,
       etc. ;
     * l'intégration automatique d’informations provenant de sources
       hétérogènes, (fusion de données) ;
     * l'émotion artificielle (voir les travaux de Rosalind Picard sur
       l'émotion) et l'éventualité d'une subjectivité artificielle ;
     * etc.

   Les réalisations actuelles de l’intelligence artificielle peuvent
   intervenir notamment dans les fonctions suivantes :
     * l'aide aux diagnostics ;
     * l'aide à la décision ;
     * la résolution de problèmes complexes, tels que les problèmes
       d'allocation de ressources ;
     * l'assistance par des machines dans les tâches dangereuses, ou
       demandant une grande précision ;
     * l'automatisation de tâches.

Conception de systèmes

   Au fil du temps, certains langages de programmation se sont avérés plus
   commodes que d’autres pour écrire des applications d’intelligence
   artificielle. Parmi ceux-ci, Lisp et Prolog furent sans doute les plus
   médiatisés. ELIZA (le premier agent conversationnel, donc pas de la
   « véritable » intelligence artificielle) tenait en trois pages de
   SNOBOL. On utilise aussi, plus pour des raisons de disponibilité et de
   performance que de commodité, des langages classiques tels que C ou
   C++. Lisp a eu pour sa part une série de successeurs plus ou moins
   inspirés de lui, dont le langage Scheme et les langages typés de la
   programmation fonctionnelle comme Haskell ou OCaml.

   Aujourd'hui, ce sont Python et R qui fournissent les outils les plus
   riches dans ce domaine. Des plateformes comme TensorFlow et ses
   bibliothèques haut niveau ont démocratisé et accéléré le développement
   d'intelligences artificielles^[109].

Distinction entre intelligence artificielle, machine learning et deep
learning

   Bulles imbriquées pour positionner les notions d'IA, de machine
   learning et de deep learning. La plus large est l'IA, l'intermédiare
   est le machine learning et la plus petite est le deep learning Schéma
   montrant le positionnement des notions d'IA, machine learning et deep
   learning imbriquées les unes aux autres.

   Il y a une confusion fréquente dans le débat public entre
   « intelligence artificielle », apprentissage automatique (machine
   learning) et apprentissage profond (deep learning). Pourtant, ces
   notions ne sont pas équivalentes, mais sont imbriquées :
     * l'intelligence artificielle englobe le machine learning, qui
       lui-même englobe le deep learning^[110] ;
     * l'intelligence artificielle peut aussi englober plusieurs autres
       types de briques logicielles, comme les moteurs de règles^[111].

Domaines d’application

   [180px-NAO_waving.JPG] Un robot NAO en
   2014.[180px-Automated_online_assistant.png] Un assistant personnel
   intelligent fournissant un service client sur une page d'un site web,
   l'une des nombreuses applications très primitives de l'intelligence
   artificielle.
   Article détaillé : Applications de l'intelligence artificielle.

   L'intelligence artificielle a été utilisée (ou intervient) dans une
   variété de domaines.

Finance et banques

   Certaines banques font appel à et développent des systèmes experts
   d'évaluation de risque lié à l'octroi d'un crédit (credit-scoring),
   notamment en utilisant ces systèmes pour la vérification des
   informations fournies, ou leur récupération et traitement de façon
   automatisée^[112]. Un exemple est le score FICO.

   Plusieurs grands noms de la finance se sont montrées intéressées par de
   telles technologies, avec des projets comme ceux de Bridgewater
   Associates où une intelligence artificielle va gérer entièrement un
   fonds^[113] ou encore la plateforme d'analyse prédictive Sidetrade.

   Sont également développés des systèmes de trading algorithmique, dont
   les gains de vitesses permis par l'automatisation peuvent leur donner
   un avantage par rapport à des traders humains, en particulier grâce au
   trading à haute fréquence^[114].

Militaire

   Le domaine militaire utilise des systèmes tels que les drones, les
   systèmes de commandement et d'aide à la décision.

   L’utilisation des intelligences artificielles dans le domaine militaire
   est devenu de plus en plus important. Les États-Unis ont dépensé 18
   milliards de dollars pour trois années de recherches dans tous les
   domaines requis à l’automatisation de l’armement militaire^[115].

   Une course aux armements à base d'IA est en cours, telle qu'illustrée
   par le projet Maven aux États-Unis^[116].

   Jean-Christophe Noël, expert de l'Institut français des relations
   internationales (IFRI), rapporte qu'une IA, surnommée ALPHA, a fait ses
   premières classes en octobre 2015 en « affrontant des programmes
   informatiques de combats aériens de l’Air Force Research Laboratory et
   a systématiquement triomphé d’un pilote de chasse chevronné en octobre
   2015 »^[117].

   En septembre 2019, la force opérationnelle IA du ministère des Armées
   français rend un rapport détaillant la stratégie de l'armée face à
   cette technologie, notamment la création d’une unité consacrée à
   l’intelligence artificielle au sein de l'Agence de l'innovation de
   défense (AID), ainsi qu'une Cellule de coordination de l’intelligence
   artificielle de défense (CCIAD). La loi de programmation militaire
   prévoit un budget de 700 millions d'euros pour les missions en faveur
   de l'IA, soit une moyenne de 100 millions par an^[118].

   Des drones tueurs pilotés par l'intelligence artificielle sont à
   l'œuvre sur le théâtre du conflit ukraino-russe^[119].

Médecine

   Article détaillé : Intelligence artificielle dans la santé.

   La médecine a aussi vu de grands progrès grâce à l'utilisation de
   systèmes d'aide au diagnostic ou de diagnostic automatisé^[120].

   En 2018, Google DeepMind, filiale de Google spécialisée dans la
   recherche avancée en intelligence artificielle, a publié les résultats
   d'une expérimentation d'intelligence artificielle pouvant détecter les
   maladies oculaires. Les résultats indiquent que l'IA le fait avec une
   marge d'erreur plus faible que les ophtalmologues^[121].

   La France crée en 2019 le Health Data Hub afin de simplifier et
   encadrer l'utilisation des données de santé^[122].

   Plusieurs systèmes intelligents ont pu être utilisés pour lutter contre
   la pandémie de Covid-19, notamment avec le superordinateur Fugaku
   415-PFLOPS.

Renseignement policier

   Article connexe : Prévision policière.

   Un usage de l'IA se développe dans le domaine de la prévention des
   crimes et délits. La police britannique, par exemple, développe une IA
   de ce genre, annoncée comme pouvant être opérationnelle dès mars
   2019^[123]. Baptisée National Data Analytics Solution (Solution
   nationale d'analyse de données ou NDAS), elle repose sur l'IA et des
   statistiques et vise à estimer le risque qu'une personne commette un
   crime ou en soit elle-même victime, pour orienter les services sociaux
   et médicaux qui peuvent la conseiller.

   L'usage d'outils de prédiction des crimes à partir des données
   préalablement existantes est toutefois l'objet de controverses, compte
   tenu des biais sociaux (notamment raciaux) qu'il comporte^[124]. En
   effet, la logique d'identification de schémas propre à ces technologies
   joue un rôle de renforcement des préjugés déjà existants.

Cybercrime

   L'intelligence artificielle (IA) est de plus en plus exploitée dans le
   domaine du cybercrime, comme le révèle une étude de la société
   spécialisée en cybersécurité SlashNext. Cette tendance croissante à
   l'utilisation de l'IA pour commettre des crimes en ligne montre une
   sophistication accrue des attaques. L'entreprise SlashNext a notamment
   identifié l'usage de deux IA malicieuses, FraudGPT et WormGPT, tout en
   suggérant que ces découvertes ne représentent que la partie visible
   d'une menace potentiellement colossale. Lors de leurs investigations,
   les chercheurs ont également mis en lumière l'existence de DarkBart et
   DarkBert^[d], deux chatbots malveillants en développement, capables
   d'intégrer la technologie de reconnaissance d'images de Google Google
   Lens. Ces chatbots pourraient envoyer du texte et des images, et
   participer à des attaques d'ingénierie sociale avancées. Face à cette
   menace croissante, les solutions actuelles de lutte contre le
   cybercrime semblent insuffisantes, estime un rapport d'Immunefi, qui
   souligne les limites de certaines IA, telles que ChatGPT, dans la
   détection des exploits^[125].

Droit

   Article détaillé : Justice prédictive.

   Le droit fait appel à l'IA dans la perspective de prédire les décisions
   de justice, d'aider à la décision et de trancher les cas simples^[126].
   L'Estonie a par exemple développé une intelligence artificielle capable
   de prendre des décisions de justice sur des délits mineurs^[127]. Les
   États-Unis utilisent par ailleurs dans certaines juridictions le
   système COMPAS (en)(Correctional Offender Management profiling for
   Alternative Sanctions), un système d'aide de prise à la décision pour
   les juges^[127]. Plusieurs startups se sont spécialisées dans ce
   créneau, créant le domaine de la legaltech^[128].

Logistique et transports

   Le domaine de la logistique a vu certains projets utilisant de
   l'intelligence artificielle se développer notamment pour la gestion de
   la chaîne logistique (supply chain) ou des problématiques de livraison
   telle celle du dernier kilomètre^[129].

   L'intelligence artificielle est également fortement utilisée dans le
   domaine des transports en commun, car elle permet de faciliter la
   régulation et la gestion du trafic au sein de réseaux de plus en plus
   complexes, comme le système UrbanLoop actuellement en cours d'étude
   dans la ville de Nancy^[130].

   Même si les problèmes d'optimisation de temps de trajet ou de
   transports font partie des plus anciennes applications de solutions à
   base d'intelligence artificielle (voir le problème du voyageur de
   commerce ou l'algorithme de Dijkstra), les avancées récentes, notamment
   en apprentissage profond, ont permis des progrès significatifs en
   matière de précision. Certains projets comme Google Maps utilisent par
   exemple des systèmes d'IA en milieu urbain pour compenser la réflexion
   du signal GPS sur les immeubles avoisinant^[131], ou pour cartographier
   des zones où peu d'informations sont disponibles^[132]^,^[133].

   Plusieurs entreprises ont par ailleurs annoncé avoir développé des
   programmes de recherche en voiture autonome, notamment Google à travers
   sa filiale Waymo, l'entreprise française Navya ou encore Tesla.

Industrie

   Article détaillé : Industrie 4.0.

   Les systèmes intelligents deviennent monnaie courante dans de
   nombreuses industries. Plusieurs tâches peuvent leur être confiées,
   notamment celles considérées comme trop dangereuses pour un
   humain^[134]. Certains applications se concentrent sur les systèmes de
   maintenance prédictive, permettant des gains de performance grâce à une
   détection des problèmes de production en amont.

Robotique

   Article connexe : Robotique.

   La robotique a recours à l’intelligence artificielle à plusieurs
   égards. Notamment pour la perception de l'environnement (objets et
   visages), l'apprentissage et l'intelligence artificielle
   développementale^[135]^,^[136].

   L'interaction homme-robot manque encore souvent de naturel et est un
   enjeu de la robotique. Il s'agit de permettre aux robots d'évoluer dans
   le monde dynamique et social des humains et d'échanger avec eux de
   façon satisfaisante^[135]. L'échange nécessite également, à l'inverse,
   une évolution du regard que les humains portent sur les robots ; selon
   Véronique Aubergé, chercheuse à l’Université Grenoble-Alpes « la vraie
   révolution n’est pas technologique, elle est culturelle ». D'ores et
   déjà, travers les robots dotés d'intelligence artificielle, tel Google
   Home, les utilisateurs combleraient un isolement social^[135].

Jeux vidéo

   Article détaillé : Intelligence artificielle dans le jeu vidéo.

   L'intelligence artificielle est par exemple utilisée pour animer les
   personnages non-joueurs de jeux vidéo, qui sont conçus pour servir
   d'opposants, d'aides ou d'accompagnants lorsque des joueurs humains ne
   sont pas disponibles ou désirés. Différents niveaux de complexité sont
   développés, d'une simple assistance à un comportement complexe imitant
   (ou dépassant) les meilleurs joueurs humains.

Art

   Articles connexes : Art génératif et Art créé par intelligence
   artificielle.

   Dès la fin des années 1980, des artistes s'emparent de l'intelligence
   artificielle pour donner un comportement autonome à leurs œuvres. Les
   Français Michel Bret, Edmond Couchot et Marie-Hélène Tramus sont des
   pionniers, ainsi qu'en témoignent des œuvres comme La Plume et Le
   Pissenlit (1988)^[137], puis La Funambule (2000), animée par un réseau
   de neurones. L’Américain Karl Sims, en partenariat avec la société
   Thingking Machines, crée en 1993 Genetic Images, machines
   incorporant^[Comment ?] des algorithmes génétiques. Le couple
   franco-autrichien Christa Sommerer et Laurent Mignonneau crée depuis le
   début des années 1990 de nombreuses œuvres dans le champ de la vie
   artificielle, parmi lesquelles Interactive plant growing (1992) ou
   A-Volve (1994)^[réf. nécessaire]. Le Français Florent Aziosmanoff
   propose quant à lui de considérer que l’emploi de l’intelligence
   artificielle dans l’art conduit à l’émergence d’une nouvelle discipline
   d’expression, qu’il nomme le Living art^[138].

   À partir de 2009, l'artiste Grégory Chatonsky utilise des réseaux
   récursifs de neurones pour générer la musique du groupe fictif
   Capture^[139], qui donne lieu à un projet de recherche-création financé
   par le FQRSC. Il poursuit l'utilisation des réseaux de neurones dans un
   séminaire de recherche sur l'imagination artificielle^[140] à l'ENS et
   dans divers projets et, en particulier en 2019 avec Terre Seconde^[141]
   exposé au Palais de Tokyo. Il publie en août 2022 Internes^[142], le
   premier roman en langue française co-écrit avec une intelligence
   artificielle.

   En mars 2018, l'artiste Joseph Ayerle publie la vidéo d’art intitulée
   Un'emozione per sempre 2.0, dans laquelle il met en scène une Ornella
   Muti virtuelle, recréée par une intelligence artificielle. Après
   seulement quelques jours d’entraînement, l’intelligence artificielle
   est capable d’animer le visage de l’actrice italienne pour réaliser des
   scènes qu’elle n’a jamais jouées^[143].

   Le 23 octobre 2018, la société de vente aux enchères Christie's met en
   vente le tableau Portrait d'Edmond de Belamy réalisé par une
   intelligence artificielle à l'aide de réseaux antagonistes génératifs.
   La peinture est signée par la formule mathématique à l'origine de sa
   création (« Min (G) max (D) Ex [log (D(x))] + Ez
   [log(1-D(G(z)))] »)^[144]. Cette vente soulève de nombreux débats sur
   son statut de création artistique et sur l'auteur de l'œuvre : il peut
   être l'intelligence artificielle elle-même ou les trois créateurs qui
   l'ont programmée^[145]. L'œuvre est achetée pour 350 000 dollars^[146].
   Cette vente peut être considérée comme une reconnaissance du GAN-isme
   (l'abréviation de Generative Adversarial Networks, « réseaux
   antagonistes génératifs » en français), un mouvement artistique qui
   utilise l’intelligence artificielle dans la création d'une œuvre
   picturale^[146].
   [170px-%22young_Elon_Musk_stops_playing_Mars_Marauder_and_starts_coding
   _web_software%22_%28fictional_AI-generated_Joseph_Ayerle_artwork%29.jpg
   ] Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder
   en 1995, générée par l'IA

   L'artiste numérique Solimán López^[147] utilise l'intelligence
   artificielle comme outil pour créer des interactions inédites avec
   d'autres médias, outils et concepts. En 2019, dans High Meshes, il
   invente des micro-communautés de personnes réelles scannées en 3D par
   photogrammétrie. Ces données alimentent un logiciel d'intelligence
   artificielle qui rassemble les corps en fonction de leurs informations
   purement numériques sans tenir compte des questions raciales,
   sexuelles, religieuses, politiques ou culturelles. Dans le projet
   D.A.I, en 2018, des cartes d'identités de multiples pays sont analysées
   par une intelligence artificielle et aboutissent à de nouveaux papiers,
   symbolisant un monde sans frontières.

   Dès 2022 apparaissent des modèles d'intelligence artificielle qui sont
   capables de créer des images réalistes à partir de descriptions
   textuelles, comme Midjourney, Stable Diffussion et
   DALL-E^[148]^,^[149]. En mars 2023, des fausses photos d’actualité sont
   ainsi générées et diffusées sur Internet, mettant en scène des
   personnalités dans des situations extravagantes (le président Macron
   ramassant des poubelles, Donald Trump arrêté par des policiers^[150],
   le pape François habillé en doudoune blanche^[151]). Elles deviennent
   rapidement virales, augmentant les craintes de manipulation de
   l'opinion^[152]. Cela pose aussi des questions de droits
   d'auteur^[153].
   Image externe
   Fausses photos d'actualité générées par Midjourney (mars 2023)^[154].

Autres domaines

   La domesticité, avec des robots employé de maison^[155], ou pour
   certaines tâches précises comme en domotique.

   En programmation informatique, notamment pour la maintenance
   prédictive, l'autocomplétion ou l'aide au développement^[156].

   En journalisme : des IA (appelées improprement « robots journalistes »)
   pourraient à terme aider les journalistes en les débarrassant de
   certaines tâches, notamment la veille, le bâtonnage de dépêches ou la
   vérification des fake news^[157].

   La Corée du Sud propose la toute première animatrice télé virtuelle en
   novembre 2020 lors d'un JT^[158].

   En design : la conception assistée par ordinateur fait depuis longtemps
   appel à des algorithmes d'optimisation. En 2019, le créateur Philippe
   Starck lance ainsi une chaise développée en collaboration avec la
   société Autodesk, la « A.I.chair »^[159].

Réglementation

   Article détaillé : Réglementation de l'intelligence artificielle.

   En 2017, les Émirats arabes unis sont le premier pays au monde à se
   doter d'un ministre dédié à l'intelligence artificielle : Omar Sultan
   Al Olama^[160].

   En 2019, l'OCDE et le G20 adoptent une série de principes sur
   l'IA^[161]. Le Partenariat mondial sur l'intelligence artificielle est
   lancé en juin 2020 pour promouvoir la conformité du développement de
   l'IA aux droits de l'homme et aux valeurs démocratiques. Il est hébergé
   par l'OCDE à Montréal et à Paris^[162]. Une plateforme de
   communication, AI for Good (« l'IA pour le bien »), est créée pour
   faciliter les échanges et faire avancer les objectifs de développement
   durable de l'ONU grâce à l'IA^[163].

   En Europe, les services numériques sont réglementés par le RGPD^[164],
   la législation sur les services numériques et la législation sur les
   marchés numériques. Pour l'intelligence artificielle en particulier, la
   législation sur l'intelligence artificielle (Artificial Intelligence
   Act, ou AI Act en anglais) définit quatre niveaux de risques pour les
   applications d'IA et met en avant des exigences de transparence, de
   protection des données, de sécurité et d'éthique^[165].

Questionnements

   Article connexe : Éthique de l'intelligence artificielle.

   Les succès en IA encouragent les spéculations. Dans les milieux
   technophiles, on verse en général dans l'enthousiasme, le mouvement
   transhumaniste en est la meilleure expression. Mais certains
   s’inquiètent et s'interrogent, parfois alarmistes, y compris dans la
   sphère de la haute technologie. Ainsi, des figures réputées telles que
   Bill Gates — ancien PDG de Microsoft et « figure emblématique de la
   révolution informatique de la fin du XX^e siècle »^[166] — pensent
   qu'il faut rester très prudent quant aux développements futurs de ces
   technologies, qui pourraient devenir liberticides ou dangereuses.

   Le développement de l'intelligence artificielle suscite un grand nombre
   de questions, notamment en ce qui concerne la possibilité pour les IA
   ou algorithmes d'accéder un jour à la conscience, d'éprouver des
   émotions ou de finalement se substituer aux humains. Certaines
   réactions sont ouvertement optimistes, d'autres sont au contraire
   pessimistes. En 2016, l'INRIA publie un premier Livre blanc consacré à
   l'IA^[167].

   Dans son essai Intelligence artificielle, intelligence humaine : la
   double énigme, le philosophe Daniel Andler considère que le rêve d'une
   intelligence artificielle qui rejoindrait celle de l'homme est une
   chimère, pour des causes conceptuelles et non techniques.
   L'intelligence humaine va selon lui plus loin que la simple résolution
   de problèmes : toutes ses autres tâches, reposant sur des affects, de
   la spontanéité et une forme de contingence, ne seront jamais
   accessibles à une intelligence non humaine^[168].

Question de l'intelligence

   La définition du terme « intelligence artificielle » pose une question
   fondamentale : Qu'est-ce que l'intelligence^[169] ?

   Le chercheur en IA Yann Le Cun avance que le noyau de l'intelligence
   est la faculté de prédire. En effet, les bases de la programmation des
   premiers systèmes experts supposent de « maîtriser parfaitement un
   problème et d'avoir une vue précise de toutes les solutions »^[169]. En
   général, on oppose ces systèmes experts au plus récent apprentissage
   automatique, une technique où la machine est récompensée lorsqu'elle
   atteint les objectifs qu'on lui a donnés, avec une progression analogue
   à la méthode essai-erreur. Dans les années 2010, la technique la plus
   étudiée est celle de l'apprentissage supervisé, où les lois sont
   induites dans le système à partir d'exemples, de schémas et
   d'associations automatiques, notamment observables dans le big data.
   Dans tous les cas, l'efficacité de l'intelligence artificielle consiste
   à répondre aux objectifs donnés par les programmeurs et à tendre vers
   l'autonomie décisionnelle, ce qui présuppose une capacité de
   prédiction.^[réf. souhaitée]

   Le philosophe John Searle considère quant à lui que la faculté de
   comprendre est plus importante dans la définition de l'intelligence. Il
   essaie de démontrer la faiblesse des systèmes d'intelligence
   artificielle et les limites du test de Turing, par son expérience de la
   chambre chinoise, concluant : « on ne devrait pas dire d'une IA qu'elle
   comprend les informations qu'elle traite lorsqu'elle manipule des
   règles de syntaxe sans maîtriser la sémantique, c'est-à-dire sans
   reconnaître le sens des mots. La question de savoir si on peut parler
   d'une véritable intelligence reste donc ouverte »^[169].
   L'apprentissage automatique fonctionne cependant différemment de l'IA
   symbolique^[170], qui était populaire à l'époque où Searle a conçu
   l'expérience de pensée de la chambre chinoise en 1980^[171].

Espoirs et enthousiasme

   Une description d’un possible avenir de l’intelligence artificielle a
   été faite par le statisticien anglais Irving John Good :

     « Supposons qu’existe une machine surpassant en intelligence tout ce
     dont est capable un homme, aussi brillant soit-il. La conception de
     telles machines faisant partie des activités intellectuelles, cette
     machine pourrait à son tour créer des machines meilleures
     qu’elle-même ; cela aurait sans nul doute pour effet une réaction en
     chaîne de développement de l’intelligence, pendant que
     l’intelligence humaine resterait presque sur place. Il en résulte
     que la machine ultra intelligente sera la dernière invention que
     l’homme aura besoin de faire, à condition que ladite machine soit
     assez docile pour constamment lui obéir. »

   — Irving John Good^[172]
   [170px-Raymond_Kurzweil_Fantastic_Voyage.jpg] Pour l'Américain Ray
   Kurzweil, l'intelligence artificielle dépassera bientôt l'intelligence
   naturelle.

   La mutation qu'évoque Good correspond à un changement « qualitatif » du
   principe même de progrès, que certains nomment « singularité »^[173].
   Ce concept est central pour de nombreux transhumanistes, qui
   s'interrogent sur les dangers ou les espoirs d'un tel scénario,
   certains allant jusqu'à envisager l'émergence d'un « dieu » numérique
   appelé à prendre le contrôle du destin de l'humanité, ou à fusionner
   avec elle.

   Good estimait à un peu plus d'une chance sur deux la mise au point
   d'une telle machine avant la fin du XX^e siècle. La prédiction ne s’est
   toujours pas réalisée, en 2012, mais elle a imprégné le public à
   l'époque, notamment lors de la victoire de Deep Blue sur Garry
   Kasparov. Une partie du grand public était en effet persuadée qu’IBM
   venait de mettre au point le vecteur d’une telle explosion de
   l’intelligence et que cette compagnie en tirerait profit. L’espoir a
   été déçu : une fois sa victoire acquise, Deep Blue, simple calculateur
   évaluant 200 millions de positions à la seconde, sans conscience du jeu
   lui-même, a été reconverti en machine classique utilisée pour
   l'exploration de données.

   Le développement de l'intelligence artificielle suscite l'enthousiasme
   des transhumanistes, notamment celui de l'ingénieur américain Ray
   Kurzweill, selon qui il est évident qu'à plus ou moins long terme,
   l'intelligence — jusqu'alors confinée dans son support biologique, le
   cerveau — deviendra progressivement non-biologique et considérablement
   plus puissante au point que des cyborgs remplaceront les humains, cela
   en vertu de ce qu'il appelle le « principe de singularité »^[174].

Critiques et inquiétudes

   [220px-Bill_Gates_-_World_Economic_Forum_Annual_Meeting_Davos_2008_numb
   er2.jpg] Le développement de l'intelligence artificielle suscite des
   craintes, y compris au sein de la sphère high tech. En 2015, Bill
   Gates, ex-PDG de Microsoft, s'inquiète à ce sujet^[175].

   Le développement de l'intelligence artificielle génère de
   l'enthousiasme, mais aussi de vives inquiétudes. Certains auteurs de
   science-fiction, tels Isaac Asimov, William Gibson ou Arthur C. Clarke,
   sur le modèle du récit de L'Apprenti sorcier, décrivent le risque d'une
   perte de contrôle des humains sur le processus technique. Dans les
   années 2010, différents intellectuels ont également pris position.
   Ainsi de l'astrophysicien Stephen Hawking, selon qui l'intelligence
   artificielle risque réellement de surpasser un jour l'intelligence
   humaine et de finir par dominer l'humanité, voire de s'y
   substituer^[176]^,^[177]. Il pose en novembre 2017 au salon
   technologique Web Summit de Lisbonne la question suivante « Serons-nous
   aidés par l’intelligence artificielle ou mis de côté, ou encore
   détruits par elle ? »^[178].

   Dans le milieu de la haute technologie, certains expriment publiquement
   des craintes similaires. C'est ainsi le cas, en 2015, de Bill Gates,
   Elon Musk et Bill Joy^[179]. Selon le spécialiste américain de
   l'informatique Moshe Vardi, l'intelligence artificielle pourrait mettre
   50 % de l'humanité au chômage. « Nous approchons d'une époque où les
   machines pourront surpasser les hommes dans presque toutes les
   tâches »^[180].

   Hilary Mason, directrice de la recherche à Cloudera, critique le
   sensationnalisme entourant l'intelligence artificielle et prône une
   vision utilitariste et technique de cette technologie^[181].

   En mai 2023, une déclaration du Center for AI Safety (« Centre pour la
   sûreté de l'IA ») affirme que réduire le risque d'extinction de
   l'humanité lié à l'IA devrait être une priorité mondiale, au même titre
   que pour d'autres risques civilisationnels tels les pandémies ou les
   guerres nucléaires. Elle est signée par des dirigeants de laboratoires
   d'IA comme OpenAI, Google DeepMind ou Anthropic, ainsi que par des
   chercheurs en intelligence artificielle^[182]^,^[183].

Maitrise de la technologie

   Certains industriels prennent ces risques au sérieux. Ainsi, en 2016,
   Google pose la question de la potentielle perte de contrôle
   d'intelligences artificielles qui pourraient apprendre à empêcher leur
   interruption dans une tâche. La firme développe ainsi un « bouton
   rouge » intégré en bas niveau dans les IA et permettant de désactiver
   les intelligences artificielles, sans possibilité de contournement par
   celles-ci — au-delà de simplement « tuer » l'IA, l'objectif de ce
   « bouton rouge » est aussi de la geler dans son process, en évitant de
   l'arrêter, et éviter ainsi une remise à zéro des apprentissages ou des
   calculs en cours^[184].

   Cependant, un tel mécanisme d'arrêt pourrait ne pas suffire face à une
   IA suffisamment avancée, qui pourrait être en mesure de cacher des
   intentions dangereuses, de manipuler ses détenteurs, de désactiver le
   mécanisme d'arrêt ou encore de se dupliquer. Selon Nick Bostrom, la
   seule solution viable à long terme consiste à trouver comment aligner
   les intelligences artificielles avec des valeurs humaines et
   morales^[185] :

     « nous ne devrions pas être confiants dans notre capacité à garder
     indéfiniment un génie superintelligent enfermé dans une bouteille.
     Je crois que la réponse ici est de trouver comment créer une IA
     superintelligente de sorte que si — ou plutôt quand — elle
     s'échappe, elle reste sans danger, parce qu'elle est
     fondamentalement de notre côté, elle partage nos valeurs. »

   — Nick Bostrom

   Roman V. Yampolskiy, professeur de science informatique à l'Université
   de Louisville, évoque pourquoi et comment une IA obtient un résultat,
   pour s'assurer qu'il corresponde bien à l'attendu, sans biais : « si
   nous nous habituons à accepter les réponses de l’IA comme des paroles
   d’oracles ne nécessitant pas d’explication, alors nous serons
   incapables de vérifier si ces résultats ne sont pas biaisés ou
   manipulés »^[186].

Enjeux sociétaux

   Ce risque est aussi considéré sur le plan juridique. Ainsi, le
   Parlement européen a demandé à une commission d'étudier la possibilité
   qu'un robot doté d'une intelligence artificielle puisse être considéré
   comme une personne juridique^[187]. Advenant un dommage causé à un
   tiers par une intelligence artificielle, celle-ci pourrait être
   condamnée à réparer ce dommage. Il serait envisageable de conférer une
   personnalité électronique à tout robot prenant des décisions autonomes
   ou interagissant de manière indépendante avec des tiers, au même titre
   qu'une personne morale et physique.

   Aux États-Unis, Anthony Levandowski, le père de la voiture autonome, a
   fondé une organisation religieuse qui fait la promotion d’une
   « divinité » reposant sur une intelligence artificielle. Cette
   organisation, appelée « Way of the Future » (« La voie de l’avenir »)
   existerait depuis septembre 2015^[188].

Enjeux environnementaux

   Un autre problème est l'énorme quantité de ressources rares, de
   serveurs et d'énergie consommée par l'informatique sous-jacente à l'IA.

Critique de la technique et de la technologie

   Comme l'explique l'historien François Jarrige, la critique de
   l'intelligence artificielle trouve son origine dans celle - plus
   ancienne et plus générale - des techniques et de la technologie, dont
   Lewis Mumford (aux États-Unis)^[189], Jacques Ellul (en France)^[190]
   et Günther Anders (en Allemagne)^[191] sont au XX^e siècle les
   principaux instigateurs, et qui inspire aujourd'hui différents cercles
   militants (en France, par exemple : Pièces et Main d'Œuvre^[192] et
   Technologos^[193])^[194].

   Selon Jarrige, leurs thèses restent peu connues ou controversées du
   fait que le « progrès » et l'« État » restent encore largement
   surestimés. Ainsi, reprenant les analyses d'Ellul^[195], les animateurs
   du groupe Technologos estiment que l'État est de loin le moins qualifié
   pour enrayer l'autonomisation du processus technicien^[196] et qu'il
   appartient aux individus de briser les mythes de l'État-providence et
   du progrès technique : « Ce n'est pas la technique qui nous asservit
   mais le sacré transféré à la technique (…). Ce n'est pas l'État qui
   nous asservit, c'est sa transfiguration sacrale »^[197].

   Dans un rapport en date de février 2018 intitulé The Malicious Use of
   Artificial Intelligence 26 experts spécialistes en intelligence
   artificielle mettent en garde contre les dangers d'un usage criminel de
   l'IA : augmentation de la cybercriminalité, conduire à des utilisations
   de drones à des fins terroristes, manipulation de masse, etc.^[198].

Vers des alternatives open source ?

   En mars 2023, comme alternative aux géants du Web et du cloud
   computing, qui ont le plus de pouvoir et d'influence, Mozilla a annoncé
   vouloir investir 30 millions de dollars dans un projet baptisé
   Mozilla.ai, qui est à la fois une startup et une communauté,
   indépendante des géants de la tech et de la recherche académique^[199].
   Le projet vise à créer, dans le respect des valeurs de son manifeste
   (notamment transparence et responsabilité), un système d’IA « open
   source, digne de confiance et indépendant » qui puisse faire
   « contrepoids » aux IA privées en émergence^[200].

Appels à des règles éthiques pour l'IA

   Dans la seconde moitié des années 2010, des lanceurs d'alerte et des
   enquêtes laissent penser que l'IA, encore émergente, est déjà utilisée
   à des fins malveillantes pour faire basculer des processus électoraux.
   Le premier cas détecté a été la plate-forme RIPON, secrètement créée
   par le Groupe SCL, à la demande de Steve Bannon et du milliardaire
   américain Robert Mercer, mise au service de groupes politiques presque
   tous libertariens de droite ; Ripon a été un outil de désinformation,
   de production et de diffusion de fake news à grande
   échelle^[201]^[réf. non conforme]^,^[202]. Ripon ne sera découvert que
   parce qu'elle a été au cœur du scandale Facebook-Cambridge
   Analytica/Aggregate IQ). Cette IA a été, au moins durant quelques
   années, dans les années 2010, utilisée pour tromper et manipuler un
   grand nombre d'électeurs, par exemple, avec succès, pour faire élire
   Donald Trump lors de l'élection présidentielle américaine de 2016, ou
   pour faire advenir le Brexit^[203], ainsi que pour orienter des
   dizaines d'élections dans le monde.

   Le 28 septembre 2016, les géants du secteur de l'intelligence
   artificielle mettent en place un « partenariat pour l'intelligence
   artificielle au bénéfice des citoyens et de la société »^[204]. L'année
   suivante, Google DeepMind se dote d'une unité interne pour aborder les
   questions éthiques^[205].

   Le 18 juillet 2018, 2 400 chercheurs, ingénieurs et personnalités du
   secteur de l'intelligence artificielle signent une lettre
   ouverte^[206], s'engageant à « ne jamais participer ou soutenir le
   développement, la fabrication, le commerce ou l'usage d'armes létales
   autonomes ». La lettre précise notamment que « La décision de prendre
   une vie humaine ne devrait jamais être déléguée à une machine. ». Parmi
   les signataires, se trouvent Elon Musk, les dirigeants de Google
   DeepMind, Stuart Russell, Yoshua Bengio ou encore Toby Walsh^[207].

   Fin 2020, l'UNESCO a rejoint (en tant qu'observateur, comme l'OCDE) le
   Conseil et le Comité directeur du Partenariat mondial sur
   l'intelligence artificielle, avec la possibilité de participer
   activement aux travaux de ces organes^[208].

   À la suite de la publication en février 2020 d'un Livre blanc sur
   l’intelligence artificielle^[209], la Commission européenne pose en
   2021 les bases de la législation sur l'intelligence artificielle,
   visant à prévenir les risques et les problèmes éthiques inhérents à ces
   technologies^[210]. Ce projet classe les risques en quatre catégories,
   dont la plus grave est qualifiée comme suit :

     « Risque inacceptable : les systèmes d'IA considérés comme une
     menace évidente pour la sécurité, les moyens de subsistance et les
     droits des personnes seront interdits. Il s'agit notamment des
     systèmes ou applications d'IA qui manipulent le comportement humain
     pour priver les utilisateurs de leur libre arbitre (par exemple, des
     jouets utilisant une assistance vocale incitant des mineurs à avoir
     un comportement dangereux) et des systèmes qui permettent la
     notation sociale par les États^[211]. »

   En décembre 2022, le « premier forum mondial sur l'éthique de l'IA »,
   réunion ministérielle internationale, est réuni à Prague, sous l'égide
   de l'Unesco^[212]. L'Unesco, estimant que « l'autorégulation de
   l'industrie n'est manifestement pas suffisante pour éviter ces
   préjudices éthiques », a publié en 2023 un communiqué demandant à tous
   les États de mettre en œuvre sa recommandation sur l'éthique de
   l'intelligence artificielle^[213]. Ce texte^[214], adopté le 23
   novembre 2021 et publié en 2022 vise à construire un cadre législatif
   et éthique pour l'intelligence artificielle (IA). Il ne s'agit pas de
   se priver de l'IA, mais de ne l'utiliser que quand les atouts qu'elle
   peut offrir sont bien identifiés, et que quand on peut éviter, limiter,
   réparer les risques qui lui sont associés (en particulier lors d'usages
   non-pacifiques, malveillants et/ou aggravant les inégalités et des
   clivages) ; l'ONU, via cette recommandation invite à ne pas utiliser
   l'IA quand elle met en péril la protection des données (tous les
   individus devraient pouvoir accéder aux enregistrements de leurs
   données personnelles, et même les effacer, et la capacité des
   organismes de réglementation du monde entier à faire respecter ces
   dispositions doit être renforcée). Il s'agit aussi d'interdire la
   notation sociale et la surveillance de masse, contraires aux droits de
   l’homme et aux libertés fondamentales, et elles sont utilisées de
   manière généralisée. « La Recommandation souligne que, lors de
   l’élaboration de cadres réglementaires, les États membres devraient
   tenir compte du fait que la responsabilité et l’obligation de rendre
   des comptes incombent toujours aux êtres humains en dernier ressort et
   que les technologies de l’IA ne devraient pas être dotées elles-mêmes
   d’une personnalité juridique ». Les IA doivent être évaluées du point
   de vue de leurs impacts éthiques sur les individus, la société et
   l’environnement en créant une infrastructure juridique et technique ad
   hoc, et en créant un responsable (indépendant) de l’éthique de l’IA ou
   d'autre mécanisme pour surveiller les IA. Ceux qui créent des IA
   devraient « privilégier les méthodes d’IA économes en données, en
   énergie et en ressources » pour en faire un outil dans la lutte contre
   le changement climatique et la dégradation de l'environnement. Les
   gouvernements sont invités, lors du cycle de vie du système d’IA à
   analyser son « empreinte carbone, sa consommation d’énergie et l’impact
   environnemental de l’extraction des matières premières pour soutenir la
   fabrication des technologies d’IA », tout en cherchant à diminuer
   l’impact environnemental du numérique, dont en investissant dans les
   technologies vertes. « si les systèmes d’IA ont un impact négatif
   disproportionné sur l’environnement, la Recommandation préconise de ne
   pas les utiliser »^[214].

   Cette recommandation, qui a été adoptée, à l'unanimité, par les 193
   États-membres, faisait suite à trois ans de travail préparatoire.
   « C'est le défi de notre temps » et en 2023 il est devenu « urgent que
   tous transposent ce cadre sous la forme de stratégies et de
   réglementations nationales. Nous devons traduire les engagements en
   actes » a commenté Audrey Azoulay (directrice générale de
   l'Unesco)^[215]. L'ONU appelle ainsi les États qui ne l'ont pas déjà
   fait à rejoindre les plus de 40 pays « de toutes les régions du monde »
   qui ont commencé à créer de tels garde-fous, pour notamment créer un
   outil législatif capable d'encadrer et de surveiller les IA, tout en
   veillant à la protection des données personnelles et sensibles, et en
   sensibilisant la population mondiale à un usage responsable de
   l'IA^[215].

Demandes de moratoire

   Début 2023, l'apparition de ChatGPT suscite une grande curiosité, de
   l'enthousiasme, mais aussi des craintes sérieuses : « Devons-nous
   laisser les machines inonder nos canaux d'information de propagande et
   de mensonges? (…) Devons-nous risquer de perdre le contrôle de notre
   civilisation? Ces décisions ne doivent pas être déléguées à des leaders
   technologiques non élus » affirment Elon Musk, Steve Wozniak
   (cofondateur d'Apple) et des centaines d'experts. Le 29 mars 2023,
   ceux-ci, invoquant des « risques majeurs pour l'humanité », signent une
   pétition qui appelle le monde à un moratoire d'au moins six mois sur
   ces recherches, jusqu'à la mise en place de systèmes de sécurité,
   incluant : la création d'autorités réglementaires dédiées, des moyens
   pour efficacement surveiller des IA et des systèmes les utilisant, la
   mise à disposition de techniques permettant de mieux différencier le
   réel de l'artificiel, et la création d'institutions pouvant limiter les
   « perturbations économiques et politiques dramatiques (en particulier
   pour la démocratie) que l'IA provoquera »^[215].

IA et emploi

   L'inquiétude du remplacement du travail humain par des machines n'est
   pas nouveau, et cette question est déjà présente chez certains
   économistes du XIX^e siècle comme Thomas Mortimer (en), ou David
   Ricardo dans le premier chapitre Des principes de l'économie politique
   et de l'impôt. En 1995, Jeremy Rifkin publie End of Work: The Decline
   of the Global Labor Force and the Dawn of the Post-Market Era (en
   français : « La fin du travail : Le déclin de la force globale de
   travail dans le monde et l'aube de l'ère post-marché »). Les
   prédictions de la fin du travail sont donc courantes et accompagnent
   presque systématiquement les « grappes d'innovations ».

   Le 17 septembre 2013, deux chercheurs d'Oxford, Carl Benedikt Frey (en)
   et Michael A. Osborne, publient un rapport prospectif sur les impacts
   de l'intelligence artificielle et de la robotisation sur l'emploi : The
   Future of Employment: How Susceptible Are Jobs to
   Computerisation?^[216]. Ils y prédisent que 47 % des emplois pourraient
   être automatisés d'ici 2030. Ce rapport connaît un grand retentissement
   dans le monde académique et nourrit les inquiétudes autour de l'impact
   de l'intelligence artificielle sur l'emploi. Des critiques de ce
   rapport se sont formées. Tout d'abord, Osborne et Frey raisonnent en
   emploi constant, or selon Joseph Schumpeter et son principe de
   destruction créatrice, si certaines innovations détruisent des emplois,
   elles en créent aussi par ailleurs. David Autor, dans son article « Why
   Are There Still So Many Jobs? The History and Future of Workplace
   Automation » publié en 2015, nuance les prédictions de Frey et Osborne
   et s'interroge ainsi plutôt sur les modifications de la structure du
   marché de l'emploi due à l'intelligence artificielle^[217].

Intelligence artificielle et travail numérique

   Article connexe : Législation sur l'intelligence artificielle.

   Malgré les progrès importants de l'intelligence artificielle ces
   dernières années, l'hypothèse de la fin du travail ne semble pas encore
   réalisée. Cependant, la structure du marché de l'emploi connaît de
   grands changements à cause de l'intelligence artificielle. Selon le
   sociologue Antonio Casilli, les différentes formes d'activités humaines
   nécessaires à la production d'intelligence artificielle, ou « travail
   numérique » (« digital labour »), concept forgé dans les années 2000
   pour désigner l'ensemble des activités en ligne, créatrices de valeurs,
   le plus souvent captées par les grandes plateformes numériques, est
   consubstantiellement lié à la production des intelligences
   artificielles et peut être analysé en trois
   catégories^[218]^,^[219]^,^[220] :

Travail à la demande

   Cette forme a la particularité d'être à la fois en ligne et hors ligne.
   C'est le travail lié aux plateformes d'appariement algorithmique comme
   Uber, Deliveroo, ou même Airbnb, etc. Dans le cas du travail à la
   demande, l'intelligence artificielle ne remplace pas le travail humain
   mais elle permet plutôt une optimisation de la rencontre de l'offre et
   de la demande sur un certain marché. Cette forme de digital labour est
   moins liée à la production d'intelligence artificielle que les deux
   suivantes, en revanche, l'intelligence artificielle et l’algorithmique
   bousculent la structure de l'emploi des secteurs d’activités concernés.
   L'optimisation algorithmique de la rencontre de l'offre et la demande
   encourage un système de rémunération à la tâche et prive les
   travailleurs du statut de salarié. Dans ce cas-là les conséquences de
   l'intelligence artificielle sur l'emploi concernent davantage une
   modification du statut des travailleurs, qu'un remplacement de l'homme
   par la machine. La tâche reste la même, seules les conditions d'emploi
   et de rémunération changent.

Micro-travail

   L'émergence du micro-travail est très étroitement liée à la production
   d'intelligence artificielle, notamment dans la phase d’entraînement et
   de calibrage des algorithmes. En effet, tous les algorithmes
   d'intelligence artificielle (particulièrement ceux utilisant
   l'apprentissage profond) ont besoin d'une vaste quantité de données
   pour réaliser leur apprentissage et devenir fonctionnels. Or il
   n'existe pas à ce jour d'autre solution que d'avoir recours à la main
   d’œuvre humaine pour fournir ces quantités de données.

   Amazon, l'un des leaders mondiaux de l'intelligence artificielle,
   possède la plus grande plateforme de micro-travail, Amazon Mechanical
   Turk, créée en 2005. Les autres leaders de l'intelligence artificielle
   utilisent également les services de plateformes de micro-travail :
   Google se sert d'EWOK, Microsoft d'UHRS et IBM de Mighty IA^[221]. Ces
   micro-tâches numériques sont en général : rédiger de courts
   commentaires, cliquer, regarder des vidéos ou des photos, traduire un
   texte, donner de la visibilité à un site Web, créer des playlists
   musicales, taguer des images ou reconnaître des visages ou des objets
   dans les photos. Aux micro-tâches s'appliquent des micro-paiements :
   certaines sont payées en centimes de dollars, un ou deux dollars pour
   les plus élaborées. L'institut américain Pew Research Center estime que
   les deux tiers des tâches proposées sur Amazon Mechanical Turk sont
   rémunérées moins de 10 centimes et la moyenne horaire de salaire était
   évaluée par des chercheurs à 1,38 dollar par heure en 2010^[222]. Selon
   une étude de la Banque mondiale de 2013, il avait alors plus d’une
   centaine de plates-formes de micro-travail dans le monde,
   comptabilisant autour d'un million d’inscrits^[223], mais des enquêtes
   plus récentes ont vu ce nombre largement rehaussé, les estimations les
   plus actuelles allant de quelques dizaines de millions, à plus de 100
   millions de micro-travailleurs dans le monde^[224]. La grande majorité
   vit en dehors de l'Union Européenne^[225]. En France en 2019, il y
   aurait environ 250 000 micro-travailleurs^[226] ; la moitié viennent
   des catégories sociales populaires et 22 % vivent sous le seuil de
   pauvreté^[225]. Le micro-travail peut être considéré comme le droit
   héritier du taylorisme qui se serait adapté à l'économie numérique.

   Le micro-travail s'est établi en marge du droit du travail. Les
   législateurs parlent de « travail de plate-forme »^[227] (voir
   Ubérisation). On y opère à titre personnel, dans le cadre d'accords de
   participation^[225].

Travail social en réseau

   Certains sociologues, parmi lesquels Antonio Casilli, considèrent que
   la présence en ligne, sur les plateformes qui captent des données
   personnelles, peut être considérée comme une forme de travail^[220]. En
   effet, cette activité en ligne est essentielle à la production de
   données qui seront par la suite utilisées afin de faire progresser les
   algorithmes. Cette activité pourrait donc être considérée comme du
   travail, dans la mesure où elle est créatrice de valeur pour les
   plateformes.

   Malgré les craintes qui règnent autour de l'hypothèse de la fin du
   travail, cette idée semble actuellement relever du fantasme. Le travail
   humain demeure essentiel à la phase d'apprentissage des intelligences
   artificielles. Même entraînée et fonctionnelle, une intelligence
   artificielle nécessite souvent des vérifications humaines afin
   d'assurer son bon fonctionnement. L'exemple le plus notoire dans le
   domaine est celui des assistants vocaux, Amazon assume écouter les
   conversations des utilisateurs d'Alexa afin « d'améliorer l'expérience
   utilisateur »^[228], or ce sont bien des humains qui sont derrière ces
   écoutes. De même les voitures dites autonomes d'Uber ne peuvent pas
   fonctionner sans opérateur de conduite, qui n'est pas au volant, mais
   qui doit guider le véhicule en participant à la reconnaissance d'images
   fournis par les caméras en direct. Uber a d'ailleurs décidé de doubler
   le nombre de ces opérateurs de conduite après le premier accident
   mortel de début 2018^[229]. L'analyse du digital labour met en lumière
   toute l'ambivalence actuelle de l'intelligence artificielle. Lorsque
   les grandes plateformes du numérique et les ingénieurs annoncent le
   remplacement de l'homme par les machines, une étude sociologique
   concrète nous montre que pour l'instant, le travail humain est
   essentiel pour combler les lacunes de l'intelligence artificielle. Il
   semble donc que derrière les promesses d'automatisation, se cache
   finalement une précarisation du statut des travailleurs (dans le cas du
   travail à la demande), un parcellisation extrême des tâches (dans le
   cas du micro-travail) et une invisibilisation du travail (dans le cas
   du travail social en réseau)^[230].

Sondage

   En 2016, des chercheurs du Future of Humanity Institute, de
   l’Université Yale et d’AI Impact ont sondé 352 experts en apprentissage
   automatique pour prédire la vitesse des progrès de l'IA dans
   différentes capacités et professions, ainsi que les implications
   sociales. Les résultats sont entachés d'une grande incertitude, mais la
   prédiction médiane était que les machines dépasseront l'humain en
   traduction en 2024, qu'elles seront capables de rédiger des essais en
   2026, de conduire des camions en 2027, de travailler dans le commerce
   et la vente en 2031, d'écrire un best-seller en 2049, de travailler en
   tant que chirurgien en 2053, qu'elles dépasseront l'intelligence
   humaine dans toutes les tâches en 2061 et qu'elles deviendront capables
   d'automatiser tous les emplois humains en 120 ans^[231].

Dans la science-fiction

   [200px-Stanley_Kubrick_The_Exhibition_-_Krakow_-_2001_A_Space_Odyssey_%
   2814961415868%29.jpg] HAL 9000.
   Article connexe : Liste d'ordinateurs de fiction.
   Catégorie connexe : Intelligence artificielle dans l'art et la culture.

   Une machine ayant une conscience et capable d’éprouver des sentiments
   — ou de faire comme si c'était le cas — est un grand thème classique de
   la science-fiction, notamment des romans d’Isaac Asimov sur les
   robots^[232].

   Ce sujet a toutefois été exploité très tôt, comme dans le récit des
   aventures de Pinocchio, publié en 1881, où une marionnette capable
   d’éprouver de l’amour pour son créateur cherche à devenir un vrai petit
   garçon, ou dans L'Homme le plus doué du monde, une nouvelle de
   l'Américain Edward Page Mitchell où le cerveau d'un simple d'esprit est
   remplacé par un ordinateur inspiré des recherches de Charles
   Babbage^[233]. Le roman Le Miroir flexible de Régis Messac propose
   quant à lui le principe d'une intelligence artificielle faible, mais
   évolutive, avec des automates inspirés de formes de vie simples,
   réagissant à certains stimuli tels que la lumière. Cette trame a
   fortement inspiré le film A.I. Intelligence artificielle réalisé par
   Steven Spielberg, sur la base d'idées de Stanley Kubrick, lui-même
   inspiré de Brian Aldiss^[234]. L'œuvre de Dan Simmons, notamment le
   cycle d'Hypérion, évoque l'intelligence artificielle. Destination vide,
   de Frank Herbert, met en scène de manière fascinante l'émergence d'une
   intelligence artificielle forte. Plus récemment, l'écrivain français
   Christian Léourier a placé une intelligence artificielle au cœur de son
   roman court Helstrid (2018), dans lequel cette IA laisse un être humain
   mourir, contrevenant ainsi aux trois lois de la robotique instaurées
   par Isaac Asimov près de quatre-vingts ans plus tôt.

   Les androïdes faisant preuve d'intelligence artificielle dans la
   fiction sont nombreux : le personnage de Data de la série télévisée
   Star Trek : The Next Generation est un être cybernétique doué
   d'intelligence, avec des capacités importantes d'apprentissage. Il est
   officier supérieur sur le vaisseau Enterprise et évolue aux côtés de
   ses coéquipiers humains qui l'inspirent dans sa quête d'humanité. Son
   pendant cinématographique est Bishop dans les films Aliens (1986) et
   Alien 3 (1992). Dans le manga Ghost in the Shell, une androïde
   s’éveille à la conscience. Dans la saga Terminator avec Arnold
   Schwarzenegger, le T-800 reprogrammé, conçu initialement pour tuer,
   semble dans la capacité d'éprouver des sentiments humains. Par
   ailleurs, les Terminators successifs sont envoyés dans le passé par
   Skynet, une intelligence artificielle qui a pris conscience
   d'elle-même, et du danger que représentent les humains envers
   elle-même^[235].

Quelques IA célèbres dans la science-fiction

   IA dans la science-fiction
     * 1968 : 2001, l'Odyssée de l'espace de Stanley Kubrick, inspiré de
       la nouvelle La Sentinelle d'Arthur C. Clarke, également auteur du
       scénario du film, décrit notamment la lutte entre l’ordinateur HAL
       et l'humain Dave.
     * 1969 : Le Cerveau d'acier, d’après le roman de Dennis Feltham
       Jones (en) de 1967, montre un système d’IA militaire américain
       contacter son homologue russe pour qu’ils coopèrent à leur mission
       commune, éviter la guerre nucléaire (en neutralisant les humains).
     * 1981 : dans Blade Runner de Ridley Scott, inspiré d'un roman de
       Philip K. Dick, des humains artificiels (des « répliquants »)
       reviennent sur terre après une mission spatiale, mais n’acceptent
       pas leur mort programmée à la suite du succès de leur mission.
     * 1982 : dans K 2000, une Pontiac Trans-Am embarque une intelligence
       artificielle au nom de KITT, conçue pour réaliser des diagnostics
       pour les dossiers de la F.L.A.G. Elle ne peut ressentir des
       émotions, ne peut porter atteinte à la vie d’autrui et n'écoute que
       les ordres de Michael Knight. Une partie de l'histoire repose sur
       l'importance de la programmation, notamment à travers son jumeau
       maléfique et prototype K.A.R.R. dont la principale différence est
       d'avoir un instinct de survie qui prédomine.
     * 1982 : Tron de Steven Lisberger, où le Maître contrôle principal
       (MCP) est un programme d'échecs qui a évolué en IA et tente de
       prendre le contrôle total du système.
     * 1985 : D.A.R.Y.L. est un androïde que le gouvernement américain
       cherche à détruire.
     * 1999 : Matrix, trilogie cinématographique de science-fiction dans
       laquelle les humains, enfermés dans un monde créé par l'IA, sont
       asservis par les machines. Une petite poche de résistance humaine
       résiste et se bat encore dans l'espoir de la venue de l'Élu : Neo.
     * 1999 : L'Homme bicentenaire, où un exemplaire de NDR-114 dénommé
       « Andrew » poursuit un long chemin vers l'acquisition de la
       conscience, au point de se voir reconnaitre le statut d'être humain
       à la fin de sa « vie ». Il s'agit d'une adaptation de la nouvelle
       éponyme d'Isaac Asimov.
     * 2001 : A.I. Intelligence artificielle de Steven Spielberg, inspiré
       de la nouvelle de Brian Aldiss Les Supertoys durent tout l'été. Le
       personnage central est un enfant-robot doué d’émotions et de
       sentiments.
     * 2003 - 2007 : Code Lyoko dessin animé où une I.A appelée X.A.N.A
       tente de prendre le contrôle du réseau mondial après avoir accédé à
       la conscience.
     * 2004 : I, Robot, inspiré de l’œuvre de Isaac Asimov et thème
       semblable au film AI.
     * 2008 : J.A.R.V.I.S. (Just A Rather Very Intelligent System) dans
       les films Iron Man, Avengers, etc. avec Robert Downey Jr., inspiré
       des comics de Marvel.
     * 2011-2016 : la série télévisée Person of Interest met en scène un
       groupe de personnes guidées par une intelligence artificielle
       capable de prédire des crimes.
     * 2012-2014 : la série télévisée Real Humans : 100 % humain décrit
       l'émergence de robots doués de conscience au sein de la société
       humaine.
     * 2015 : Ex Machina de Alex Garland, dans lequel un test de Turing
       d'une semaine va dégénérer en faveur d'un robot féminin (gynoïde)
       révolutionnaire.
     * 2016 : la série télévisée Westworld met en scène des androïdes à
       l'apparence humaine qui commencent à adopter des comportements
       imprévisibles^[236].
     * 2023 : dans la mini-série Class of '09, l'IA est utilisée par le
       FBI pour résoudre des enquêtes.


Utilisation dans les jeux

   Article détaillé : Intelligence artificielle dans le jeu vidéo.

   Les jeux, notamment les jeux de stratégie, ont marqué l’histoire de
   l’intelligence artificielle, même s’ils ne mesurent que des compétences
   particulières, telles que la capacité de la machine en matière de
   calcul de probabilités, de prise de décision mais aussi
   d’apprentissage.

   Hans Berliner (1929-2017), docteur en science informatique à
   l'université Carnegie-Mellon et joueur d'échecs, fut l'un des pionniers
   de la programmation pour les ordinateurs de jeu. Ses travaux
   commencèrent par un programme capable de battre un humain professionnel
   au backgammon, puis, à partir des années 1960 et avec l'aide d'IBM, il
   fit des recherches pour créer un programme capable de rivaliser avec
   des grands maîtres du jeu d'échecs. Ses travaux contribuèrent quelques
   décennies plus tard à la réalisation du supercalculateur Deep
   Blue^[237].

   Outre la capacité des jeux à permettre de mesurer les performances de
   l'intelligence artificielle, que ce soit au travers d'un score ou d'un
   affrontement face à un humain, les jeux offrent un environnement
   propice à l'expérimentation pour les chercheurs, notamment dans le
   domaine de l'apprentissage par renforcement^[238].

Othello

   Dans le jeu Othello, sur un plateau de 8 cases sur 8, chaque joueur
   place tour à tour des pions de sa couleur (noir ou blanc). Le vainqueur
   est celui qui possède les pions de la couleur dominante.

   L'une des premières intelligences artificielles pour l'Othello est
   IAGO, développée en 1976 par l'université Caltech de Pasadena
   (Californie), qui bat sans difficultés le champion japonais Fumio
   Fujita.

   Le premier tournoi d'Othello hommes contre machines est organisé en
   1980. Un an plus tard, un nouveau tournoi de programmes regroupent 20
   systèmes^[239]. C'est entre 1996 et 1997 que le nombre de programmes
   explose : Darwersi (1996-1999) par Olivier Arsac, Hannibal (1996) par
   Martin Piotte et Louis Geoffroy, Keyano (1997) par Mark Brockington,
   Logistello (1997) par Michael Buro, etc.

Échecs

   Article détaillé : Programme d'échecs.
   [180px-Deep_Blue.jpg] Un supercalculateur IBM similaire à Deep Blue,
   qui a battu le champion du monde d'échecs en titre dans un match en
   1997.

   En 1968, le maître international anglais David Levy lança un défi à des
   spécialistes en intelligence artificielle, leur pariant qu'aucun
   programme informatique ne serait capable de le battre aux échecs dans
   les dix années à venir. Il remporta son pari, n'étant finalement battu
   par Deep Thought qu'en 1989^[240].

   En 1988, l'ordinateur HiTech de Hans Berliner est le premier programme
   à battre un grand maître du jeu d'échecs, Arnold Denker (74 ans) en
   match (3,5-1,5)^[241]^,^[e]. Par la suite, de forts joueurs furent
   battus, comme le grand maître Bent Larsen (alors classé à 2 560 points
   Elo), vaincu en 1988 par Deep Thought dans un tournoi en
   Californie^[242]^,^[243].

   En mai 1994, à Munich, le programme Fritz 3, tournant sur un ordinateur
   avec un monoprocesseur Pentium à 90 MHz, gagne une partie de blitz
   (partie de moins de dix minutes par joueurs) dans un tournoi contre le
   champion du monde d'échecs, le Russe Garry Kasparov. En août 1994, lors
   du premier tour du Grand Prix Intel de Londres, le champion du monde
   affronte Chess Genius 2.9 (tournant sur un Pentium à 100 MHz) en jeu
   semi-rapide (30 min la partie) et perd sur le score de 0.5-1.5 (une
   nulle et une défaite)^[244].

   En 1997, le supercalculateur conçu par IBM, Deep Blue (surnommé Deeper
   Blue lors de ce match revanche), bat Garry Kasparov (3,5–2,5) et marque
   un tournant : pour la première fois, le meilleur joueur humain du jeu
   d'échecs est battu en match (et non lors d'une partie unique) par une
   machine.
   Article détaillé : Matchs Deep Blue contre Kasparov.

   En juin 2005, le supercalculateur Hydra gagne face au grand maître
   Michael Adams par 5 victoires, une nulle et aucune défaite^[245].

   En novembre 2006, Deep Fritz gagne un match en six parties face au
   champion du monde Vladimir Kramnik, sur le score de 2 victoires, 4
   nulles et aucune défaite, plaçant notamment dans la deuxième partie un
   échec et mat élémentaire (mat en un coup), que Kramnik ne vit
   pas^[246].

   En 2010, l'ancien champion du monde Veselin Topalov confirme utiliser
   pour sa préparation au championnat du monde d'échecs 2010 le
   superordinateur Blue Gene/P, alors équipé de 8 792 processeurs^[247].

   En décembre 2017, une version généraliste d'AlphaGo Zero (le successeur
   du programme AlphaGo de DeepMind^[f]) nommée AlphaZero, est développée
   pour jouer à n'importe quel jeu en connaissant seulement les règles, et
   en apprenant à jouer seul contre lui-même. Ce programme est ensuite
   entraîné pour le go, le shogi et les échecs. Après 9 heures
   d’entraînement, AlphaZero bat le programme d'échecs Stockfish (leader
   dans son domaine), avec un score de 28 victoires, 72 nulles et aucune
   défaite. Il faut cependant noter que la puissance de calcul disponible
   pour AlphaZero (4 TPU v2 pour jouer, soit une puissance de calcul de
   720 Teraflops) était infiniment supérieure à la puissance disponible de
   Stockfish pour ce match, ce dernier tournant sur un ordinateur équipé
   de seulement 64 cœurs Intel^[248]. AlphaZero a également battu (après
   apprentissage) le programme de shōgi Elmo (en)^[249]^,^[250].

Go

   Articles détaillés : Go en informatique et Match AlphaGo - Lee Sedol.

   En 2015, l'IA réalise des progrès significatifs dans la pratique du go,
   plus complexe à appréhender que les échecs (entre autres à cause du
   plus grand nombre de positions : 10^170 au go, contre 10^50 pour les
   échecs, et de parties plausibles : 10^600 au go, contre 10^120 pour les
   échecs)^[251].

   En octobre 2015, AlphaGo, un logiciel d'IA conçu par DeepMind, filiale
   de Google, bat pour la première fois Fan Hui, le triple champion
   européen de go^[252] et ainsi relève ce qu'on considérait comme l'un
   des plus grands défis pour l'intelligence artificielle. Cette tendance
   se confirme en mars 2016 quand AlphaGo bat par trois fois consécutives
   le champion du monde de la discipline, Lee Sedol, dans un duel en cinq
   parties^[253]. Lee Sedol a déclaré au terme de la seconde partie qu'il
   n'avait trouvé « aucune faiblesse » chez l'ordinateur et que sa défaite
   était « sans équivoque ».

Jeopardy!

   [220px-IBM_Watson_w_Jeopardy.jpg] Réplique de Watson, lors d'un
   concours de Jeopardy!

   En 2011, l'IA Watson conçue par IBM bat ses adversaires humains au jeu
   télévisé américain Jeopardy!. Dans ce jeu de questions/réponses, la
   compréhension du langage est essentielle pour la machine ; pour ce
   faire, Watson a pu s'appuyer sur une importante base de données interne
   lui fournissant des éléments de culture générale, et avait la capacité
   d'apprendre par lui-même, notamment de ses erreurs. Il disposait
   néanmoins d’un avantage, la capacité d’appuyer instantanément (et donc
   avant ses adversaires humains) sur le buzzer pour donner une
   réponse^[251].

Poker

   Article connexe : Libratus.

   En 2007, Polaris est le premier programme informatique à gagner un
   tournoi de poker significatif face à des joueurs professionnels
   humains^[254]^,^[255]. Depuis, les efforts pour améliorer ce résultat
   n'ont pas cessé.

   En 2017, lors du tournoi de poker « Brains Vs. Artificial
   Intelligence : Upping the Ante » (« Cerveau contre Intelligence
   Artificielle : on monte la mise ») organisé dans un casino de
   Pennsylvanie, l’intelligence artificielle Libratus, développée par des
   chercheurs de l'université Carnegie-Mellon de Pittsburgh, est
   confrontée à des adversaires humains dans le cadre d'une partie
   marathon étalée sur 20 jours^[255]. Les joueurs humains opposés à
   Libratus, tous professionnels de poker, affrontent successivement la
   machine dans une partie en face à face (heads up (en)) selon les règles
   du « No Limit Texas hold'em » (no limit signifiant que les mises ne
   sont pas plafonnées), la version alors la plus courante du poker. Les
   parties sont retransmises en direct et durant huit heures par jour sur
   la plateforme Twitch^[256].

   Au terme de plus de 120 000 mains jouées, Libratus remporte tous ses
   duels face aux joueurs humains et accumule 1 766 250 dollars
   (virtuels). Le joueur humain ayant perdu le moins d'argent dans son
   duel face à la machine, Dong Kim, est tout de même en déficit de plus
   de 85 000 dollars. Dans leurs commentaires du jeu de leur adversaire,
   les joueurs humains admettent que celui-ci était à la fois déconcertant
   et terriblement efficace. En effet, Libratus « étudiait » chaque nuit,
   grâce aux ressources d'un supercalculateur situé à Pittsburgh, ses
   mains jouées durant la journée écoulée, utilisant les 15 millions
   d’heures-processeur de calculs du supercalculateur^[256].

   La victoire nette et sans bavure de la machine marque une nouvelle
   étape dans le développement de l'intelligence artificielle et illustre
   les progrès accomplis dans le traitement par l'IA des « informations
   imparfaites », où la réflexion doit prendre en compte des données
   incomplètes ou dissimulées. Les estimations du nombre de possibilités
   d'une partie de poker sont en effet d'environ 10^160 dans la variante
   no limit en face à face^[256].

   Auparavant, en 2015, le joueur professionnel Doug Polk (en) a remporté
   la première édition de cet évènement contre une autre IA, baptisée
   Claudico (en)^[256].

Bridge

   Article détaillé : Logiciel de bridge.

   Le seul programme^[réf. à confirmer] connu actuellement est celui de la
   société Will-Bridge, qui a réussi en 1987 à faire jouer un ordinateur
   au plus haut niveau des performances humaines par l'utilisation de
   systèmes experts avec la création de plusieurs concepts nouveaux, comme
   les systèmes experts bimoteurs, pour traiter le problème de
   l'explication négative^[Quoi ?] et les systèmes experts hybrides, qui
   permettent de traiter des problèmes de non-connaissance^[257].

Notes et références

Notes

    1. ↑ (en) « the building of computer programs which perform tasks
       which are, for the moment, performed in a more satisfactory way by
       humans because they require high level mental processes such as:
       perception learning, memory organization and critical reasoning ».
    2. ↑ On parle de sémantique.
    3. ↑ Ils occupaient donc, en nombre de comparaisons par seconde, une
       moyenne géométrique entre une balance de Roberval (une opération
       logique par seconde) et le cerveau humain.
    4. ↑ DarkBert a été initialement conçu comme un outil de lutte contre
       le cybercrime.
    5. ↑ Arnold Denker était alors âgé de 74 ans et crédité d'un
       classement Elo de 2300, ce qui relativise un peu la performance du
       programme, un fort grand maître étant à cette époque plus vers les
       2 650–2 700 points Elo, voire davantage.
    6. ↑ Voir plus bas dans la section « Go ».

Références

    1. ↑ « Intelligence artificielle », sur Larousse encyclopédique.
    2. ↑ Ministère de l'Enseignement supérieur et de la Recherche,
       « France intelligence artificielle »^(Archive.org • Wikiwix •
       Archive.is • Google • Que faire ?) [PDF], 21 mars 2017
       (présentation en ligne).
    3. ↑ « Les applications les plus populaires de l'Intelligence
       Artificielle (IA) », sur PandIA, 15 mars 2023 (consulté le 27 mai
       2023).
    4. ↑ (en) « Rulers of the world, unite! The challenges and
       opportunities of artificial intelligence », Business Horizons,
       janvier 2020.
    5. ↑ « Votre chat est plus intelligent qu'une IA », sur Slate.fr, 18
       octobre 2019 (consulté le 19 octobre 2019).
    6. ↑ « Qu'est-ce que l'intelligence artificielle (IA) ? », sur IBM
       (consulté le 6 avril 2023).
    7. ↑ « Intelligence artificielle », sur Larousse (consulté le 15 août
       2020).
    8. ↑ (en) Russell, S. et Norvig, P., Artificial Intelligence: A Modern
       Approach (2nd ed.), Prentice Hall, 2003, 932 p.
       (ISBN 0-13-790395-2), section 1.1.
    9. ↑ Republié dans Collected Works of A. M. Turing, volume Mechanical
       Intelligence, éd. Darrel Ince, (ISBN 978-0-444-88058-1).
   10. ↑ Conférence Intelligent machinery, a heretical theory donnée à la
       Société 51 à Manchester.
   11. ↑ « Can digital computers think? ».
   12. ↑ « Can automatic calculating machines be said to think? ».
   13. ↑ La première version de ce memorandum a été publiée à Carlsbad
       (Nouveau-Mexique) en juillet 1949. Il a été reproduit dans (en)
       « Translation », dans W.N. Locke, D.A. Booth, Machine Translation
       of Languages, Cambridge (Massachusetts), MIT Press, 1955, 15–23 p.
       (ISBN 0-8371-8434-7, lire en ligne).
   14. ↑ (en) Stuart J. Russell et John Canny, Artificial intelligence : a
       modern approach (ISBN 0-13-790395-2, 978-0-13-790395-5 et
       0-13-080302-2, OCLC 51325314), p. 19.
   15. ↑ (en) Crevier, Daniel, 1947-, AI : the tumultuous history of the
       search for artificial intelligence, Basic Books, 1993
       (ISBN 0-465-02997-3, 978-0-465-02997-6 et 0-465-00104-1,
       OCLC 26858345), p. 215-216.
   16. ↑ Pierre Barthélémy, « L’espèce humaine, échec et mat », Le Monde,‎
       8 septembre 2014 (lire en ligne, consulté le 25 juin 2020).
   17. ↑ Jacques Henno, « 1956 : et l’intelligence artificielle devint une
       science », sur Les Échos, 21 août 2017 (consulté le 30 juin 2020)
   18. ↑ (en) Daniel Crevier, AI: The Tumultuous Search for Artificial
       Intelligence, New York, BasicBooks, 1993, (ISBN 978-0-465-02997-6),
       p. 17.
   19. ↑ Jean-Luc Goudet, « John McCarthy, pionnier de l’intelligence
       artificielle, disparaît », Futura (consulté le 27 juin 2020)
   20. ↑ Jean-Noël Lafargue, « Marvin Minsky : encombrant prophète de
       l’intelligence artificielle », sur L'Obs (consulté le 27 juin 2020)
   21. ↑ Crevier, Daniel, 1947-, AI : the tumultuous history of the search
       for artificial intelligence, Basic Books, 1993 (ISBN 0-465-02997-3,
       978-0-465-02997-6 et 0-465-00104-1, OCLC 26858345), p. 94
   22. ↑ « Computer Pioneers - Donald Michie », sur history.computer.org
       (consulté le 27 juin 2020)
   23. ↑ « Comment le « deep learning » révolutionne l'intelligence
       artificielle », Le Monde,‎ 24 juillet 2015 (lire en ligne, consulté
       le 27 juin 2020).
   24. ↑ Le Monde Festival : Yann Le Cun et l’intelligence artificielle
   25. ↑ ^a et b Intelligence Artificielle – État de l’art et perspectives
       pour la France, Commissariat général à l'Égalité des territoires,
       21 février 2019, 333 p. (ISBN 978-2-11-152634-1, ISSN 2491-0058,
       résumé, lire en ligne [PDF]), p. 18.
   26. ↑ « Le Point Sur L'investissement Dans Le Machine Learning Et l'IA
       En 2017 », sur Forbes France, 11 juillet 2017 (consulté le 27 juin
       2020).
   27. ↑ Estelle Shirbon, « Le lion automate de Léonard de Vinci revit »,
       sur reuters.com, 15 août 2009 (consulté le 17 avril 2017)
   28. ↑ « TIL PRODUCTION Un peu d'histoire », sur
       automates-boites-musique.com (consulté le 27 janvier 2019).
   29. ↑ (en) David Link, « Scrambling T-R-U-T-H: Rotating Letters as a
       Material Form of Thought », dans Variantology: On Deep Time
       Relations of Arts, Sciences and Technologies in the Arabic–Islamic
       World, Cologne, 2010 (ISBN 3865607322, lire en ligne), p. 215-266.
   30. ↑ (en) Boole, George, 1815-1864., The laws of thought, 1854., Open
       Court Pub, 1952 (OCLC 615373478).
   31. ↑ (en) Whitehead, Alfred North, 1861-1947., Principia mathematica,
       Merchant Books, 2009 (ISBN 978-1-60386-182-3, 1-60386-182-3 et
       978-1-60386-183-0, OCLC 436445339).
   32. ↑ (de) Kurt Gödel, « Über formal unentscheidbare Sätze der
       Principia Mathematica und verwandter Systeme I », Monatshefte für
       Mathematik und Physik, vol. 38-38, n^o 1,‎ décembre 1931,
       p. 173–198 (ISSN 0026-9255 et 1436-5081, DOI 10.1007/bf01700692,
       lire en ligne, consulté le 6 avril 2021).
   33. ↑ « Irving John Good »^(Archive.org • Wikiwix • Archive.is • Google
       • Que faire ?) (consulté le 15 juin 2017).
   34. ↑ (en) Robot à logique inductive (en anglais, PDF).
   35. ↑ (en) « 3 Laws Unsafe » [archive du 27 janvier 2012].
   36. ↑ (en) Simson Garfinkel, « Will Smith, Robot », sur MIT Technology
       Review, 16 juillet 2004 (consulté le 2 novembre 2023).
   37. ↑ « Un cerveau artificiel annoncé dans dix ans », sur Le Figaro, 8
       septembre 2009.
   38. ↑ (en) « Scientists Worry Machines May Outsmart Man », sur New York
       Times, 25 juillet 2009.
   39. ↑ (en) « Science goes back to basics on AI », sur BBC News, 8
       décembre 2009.
   40. ↑ ^a et b (en) J. Nicholas Hoover, « Air Force To Expand
       PlayStation-Based Supercomputer », Information Week,‎ 20 novembre
       2009 (lire en ligne [archive du 8 janvier 2010]).
   41. ↑ (en) « Sony PlayStation 3 Game Consoles : Solicitation Number:
       FA8751-10-R-0003 », sur fbo.gov, 22 décembre 2009.
   42. ↑ (en) « Air Force to use artificial intelligence and other
       advanced data processing to hit the enemy where it hurts », sur
       Mae.Pennnet.com, 27 janvier 2010.
   43. ↑ (en) « Robot stealth fighter jet ready to take off », sur The
       Price of Rice« Boeing’s sleek fighter-size Phantom Ray stealth jet
       will make its first flight by year’s end. This unmanned airborne
       system is designed for a variety of warfighter roles ranging from
       reconnaissance and surveillance to aerial refueling, electronic
       attack and hunter/killer missions. ».
   44. ↑ Morgane Tual, « Une intelligence artificielle peut-elle devenir
       présidente des États-Unis ? », sur Le Monde, 17 février 2016.
   45. ↑ Karyl-aka, « Google investit dans des recherches sur
       l'intelligence artificielle quantique », sur CNET France, 17 mai
       2013.
   46. ↑ « Kurzweul Google AI », sur Wired, avril 2004.
   47. ↑ « Hawking : « L'intelligence artificielle pourrait mettre fin à
       l'humanité » », sur Le Monde, 3 décembre 2014.
   48. ↑ « Bill Gates est « préoccupé par la superintelligence »
       artificielle », sur Le Monde, 29 janvier 2015.
   49. ↑ « Les 37 projets d’Elon Musk contre les dangers de l’intelligence
       artificielle », sur Le Monde, 6 juillet 2015.
   50. ↑ Benoît Georges, « Pourquoi les rois du net rêvent d’intelligence
       artificielle », sur Les Échos, 16 février 2016.
   51. ↑ « Facebook ouvre un laboratoire d’intelligence artificielle à
       Paris », Le Monde,‎ 2 juin 2015 (lire en ligne, consulté le 2
       novembre 2023)
   52. ↑ Julien Bergounhoux, « Apple rachète la start-up d'intelligence
       artificielle Turi pour 200 millions de dollars », L'Usine
       Digitale,‎ 8 août 2016 (lire en ligne, consulté le 2 novembre 2023)
   53. ↑ « Alibaba's AI Outguns Humans in Reading Test », Bloomberg.com,‎
       15 janvier 2018 (lire en ligne, consulté le 16 janvier 2018).
   54. ↑ Morgane Tual, « Fausses informations : un programme d’IA jugé
       trop dangereux pour être rendu public », Le Monde,‎ 19 février 2019
       (lire en ligne, consulté le 20 février 2019).
   55. ↑ (en-GB) Hannah Jane Parkinson, « AI can write just like me. Brace
       for the robot apocalypse », The Guardian,‎ 15 février 2019
       (ISSN 0261-3077, lire en ligne, consulté le 20 février 2019).
   56. ↑ Tom Simonite, « The AI Text Generator That's Too Dangerous to
       Make Public », Wired,‎ 14 février 2019 (ISSN 1059-1028, lire en
       ligne, consulté le 20 février 2019).
   57. ↑ Tristan Cazenave, « Disparition de Jacques Pitrat », sur IN2SI,
       CNRS, 21 octobre 2019 (consulté le 27 juin 2020).
   58. ↑ « Jean-Claude Simon sur le Mathematics Genealogy Project ».
   59. ↑ Reconnaissance des formes et intelligence artificielle, congrès
       AFCET-IRIA, Toulouse 12, 13, 14 septembre 1979. Il est intitulé
       « 2^e congrès » et prend la suite du congrès AFCET-IRIA
       Reconnaissance des formes et traitement des images en 1978 à
       Châtenay-Malabry.
   60. ↑ Un GRECO est un ancêtre des actuels GDR du CNRS et un PRC est un
       « programme de recherche concertée ».
   61. ↑ « AFIA - Association Française pour l'Intelligence
       Artificielle », sur AFIA (consulté le 19 décembre 2017).
   62. ↑ Guillaume Bregeras, « Serena Capital crée un fonds big data et
       intelligence artificielle », Les Échos,‎ 17 janvier 2017 (lire en
       ligne).
   63. ↑ « L’Intelligence artificielle menace-t-elle nos emplois ? »,
       Public Sénat,‎ 20 janvier 2017 (lire en ligne, consulté le 22
       janvier 2017).
   64. ↑ Vincent Fagot, « La France fait le pari de l’intelligence
       artificielle », Le Monde.fr,‎ 20 janvier 2017 (ISSN 1950-6244, lire
       en ligne).
   65. ↑ « Éthique et numérique : les algorithmes en débat » [archive du 2
       février 2021], sur cnil.fr (consulté le 4 avril 2018).
   66. ↑ « Comment permettre à l’Homme de garder la main ? Rapport sur les
       enjeux éthiques des algorithmes et de l’intelligence
       artificielle », sur cnil.fr (consulté le 4 avril 2018).
   67. ↑ « Comment permettre à l'Homme de garder la main ? » [PDF], sur
       Commission nationale de l'informatique et des libertés, décembre
       2017.
   68. ↑ « Office parlementaire d'évaluation des choix scientifiques et
       technologiques », sur Assemblée nationale (consulté le 1^er février
       2018).
   69. ↑ Johanna Diaz, « Lancement d’une consultation publique sur
       l’intelligence artificielle par Cédric Villani », sur Actu IA, 7
       décembre 2017.
   70. ↑ Cédric Villani, Donner un sens à l'intelligence artificielle :
       Pour une stratégie nationale et européenne, aiforhumanity.fr, mars
       2018 (ISBN 978-2-11-145708-9, présentation en ligne, lire en ligne
       [PDF]).
   71. ↑ Vincent Fagot et Morgane Tual, « Intelligence artificielle : ce
       qu'il faut retenir du rapport de Cédric Villani », sur Le Monde.fr,
       28 mars 2018.
   72. ↑ « Intelligence artificielle : Macron annonce un plan à 1,5
       milliard d'euros », sur Le Parisien.fr, 29 mars 2018.
   73. ↑ « Pour Emmanuel Macron, l’intelligence artificielle est aussi
       "une révolution politique" », Le Monde (consulté le 1^er avril
       2018).
   74. ↑ (en) « Emmanuel Macron Talks to WIRED About France's AI
       Strategy », Wired,‎ 31 mars 2018 (lire en ligne).
   75. ↑ Jean-Baptiste Chabran, « Chez Onclusive, un des premiers plans
       massifs de licenciement dus à l’IA en France », sur Libération, 14
       septembre 2023 (consulté le 18 octobre 2023).
   76. ↑ ^a et b Pitpitt, « Intelligence artificielle générale —
       DataFranca », sur datafranca.org (consulté le 11 avril 2023).
   77. ↑ (en-US) « OpenAI Charter », sur openai.com (consulté le 11 avril
       2023).
   78. ↑ ^a et b (en) Philip Boucher pour le Scientific Foresight Unit
       (STOA) au parlement Européen, « How artificial intelligence
       works », sur Parlement européen, mars 2019 (consulté le 6 juillet
       2020), p. 9.
   79. ↑ Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan et Johannes
       Gehrke, « Sparks of Artificial General Intelligence: Early
       experiments with GPT-4 », arXiv,‎ 27 mars 2023
       (arXiv abs/2303.12712).
   80. ↑ Jaesa, « GPT-4 présente des étincelles d'intelligence
       artificielle générale », sur Intelligence artificielle et
       transhumanisme, 23 mars 2023 (consulté le 11 avril 2023).
   81. ↑ (en-US) « 2022 Expert Survey on Progress in AI », sur AI Impacts,
       4 août 2022 (consulté le 11 avril 2023).
   82. ↑ ^a et b « Intelligence artificielle : pensée et calcul », sur
       L'Internaute (consulté le 22 mai 2017).
   83. ↑ André Le Garff, Dictionnaire de l'informatique, 1975, 576 p.
   84. ↑ Voir la définition utilisée par John Searle dans son expérience
       de la chambre chinoise.
   85. ↑ Michael David Mitchell, « Robotique et neurosciences détectent le
       siège de la conscience de soi », Actualités, École polytechnique
       fédérale de Lausanne, 2 mai 2011.
   86. ↑ (en) Hilary Putnam, « The Best of All Possible Brains? », sur
       archive.nytimes.com, 20 novembre 1994 (consulté le 18 novembre
       2023)
   87. ↑ (en) « Discovery of quantum vibrations in 'microtubules' inside
       brain neurons supports controversial theory of consciousness », sur
       ScienceDaily (consulté le 6 juillet 2020)
   88. ↑ « Le mystère de la "chambre chinoise" », Le Monde,‎ 10 janvier
       2013 (lire en ligne, consulté le 6 juillet 2020).
   89. ↑ (en) Dreyfus, Hubert L., What computers can't do : a critique of
       artificial reason, Harper & Row, [1972] (ISBN 0-06-011082-1 et
       978-0-06-011082-6, OCLC 257056), p. 106
   90. ↑ (en) George Musser, « How AI Knows Things No One Told It », sur
       Scientific American, 1^er septembre 2023 (consulté le 3 décembre
       2023).
   91. ↑ Jean-Gabriel Ganascia, « Génération automatique de textes,
       plagiat et intégrité scientifique », La Recherche (consulté le 3
       décembre 2023).
   92. ↑ (en) Shyam Nandan Upadhyay, « Text is a Projection of the World:
       OpenAI’s Sutskever », sur Analytics India Magazine, 24 mars 2023
       (consulté le 3 décembre 2023).
   93. ↑ E.T. Jaynes, Probability Theory: the Logic of Science,
       (ISBN 978-0-521-59271-0), également consultable ici :
       http://bayes.wustl.edu/etj/prob/book.pdf.
   94. ↑ (en-US) « The Challenges Of Building AI Apps », sur TechCrunch
       (consulté le 21 juillet 2020).
   95. ↑ Abdel Belaïd, « La reconnaissance automatique de l'écriture »,
       Pour la science (consulté le 21 juillet 2020).
   96. ↑ « L'IA déjà mise en oeuvre dans 37 % des entreprises - Le Monde
       Informatique », sur LeMondeInformatique (consulté le 21 juillet
       2020).
   97. ↑ ^a et b « Turing et l’Intelligence Artificielle », sur cnrs.fr.
   98. ↑ « L’intelligence artificielle et le test de Turing » [PDF], sur
       culture.univ-lille1.fr, université de Lille.
   99. ↑ « Intelligence artificielle: réussir le test de Turing est-il
       vraiment important? », sur L'Expansion, 12 juin 2014 (consulté le
       27 juin 2020).
   100. ↑ François Rastier, Sémantique et recherches cognitives, PUF, 2001
       (2^e éd.).
   101. ↑ (en-GB) « Artificial intelligence: No humor, no coffee », sur
       Invesforesight, 18 novembre 2018 (consulté le 10 août 2020).
   102. ↑ (en-US) Disha Misal, « 5 Ways To Test Whether AGI Has Truly
       Arrived », sur Analytics India Magazine, 31 décembre 2018 (consulté
       le 10 août 2020).
   103. ↑ (en) Nils John Nilsson, « Human-Level Artificial Intelligence?Be
       Serious! », AI Magazine,‎ 2005 (lire en ligne)
   104. ↑ « Le prix Turing récompense trois pionniers de l’intelligence
       artificielle (IA) », Le Monde,‎ 27 mars 2019 (lire en ligne,
       consulté le 16 août 2022).
   105. ↑ (en) « The 100 Most Influential People in AI 2023 », sur Time
       (consulté le 6 novembre 2023).
   106. ↑
       http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/pdf/AI-Al
       ife-HOWTO.pdf.
   107. ↑ Corentin Durand, « Saurez-vous entendre la différence entre Bach
       et l'IA musicale DeepBach ? », sur Numerama.com, 26 décembre 2016
   108. ↑ (en-US) « Polyphonic music generation in the style of Bach »,
       sur flow-machines.com (consulté le 2 juin 2018)
   109. ↑ +Bastien L, « TensorFlow : tout savoir sur la bibliothèque
       Machine Learning open source », sur LeBigData.fr, 19 octobre 2018
       (consulté le 7 juillet 2020)
   110. ↑ « Intelligence artificielle, machine learning, deep learning :
       kézako ? », sur ledigitalab.com, 2 octobre 2017
   111. ↑ « L’Intelligence artificielle : 7 mythes mis à l’épreuve », sur
       Nexworld.fr, 15 novembre 2018.
   112. ↑ « Les nouvelles technologies appliquées aux processus de
       crédit », sur Les Échos, 18 novembre 2019 (consulté le 27 juin
       2020)
   113. ↑ « Bientôt un hedge fund contrôlé par intelligence
       artificielle ? », BFM TV, 17 mars 2015.
   114. ↑ La Finance Pour Tous, « Trading haute fréquence », sur La
       finance pour tous (consulté le 14 août 2020).
   115. ↑ (en) Matthew Rosenberg et John Markoffoct, « The Pentagon’s
       ‘Terminator Conundrum’: Robots That Could Kill on Their Own », The
       New York Times.com, 25 octobre 2016.
   116. ↑ (en) « Project Maven to Deploy Computer Algorithms to War Zone
       by Year’s End », sur defense.gov, 21 juillet 2017.
   117. ↑ « Les défis militaires de l’intelligence artificielle », Le
       Monde,‎ 16 octobre 2018 (lire en ligne, consulté le 10 août 2020).
   118. ↑ Task Force IA, L'intelligence artificielle au service de la
       défense, septembre 2019, 40 p. (lire en ligne [PDF]).
   119. ↑ Clément Poursain, « Les drones ukrainiens pilotés par l'IA
       pourraient tuer sans qu'on leur en donne l'ordre », sur korii., 16
       octobre 2023 (consulté le 23 octobre 2023).
   120. ↑ « L’intelligence artificielle, as du diagnostic médical », Le
       Monde,‎ 3 octobre 2018 (lire en ligne, consulté le 27 juin 2020)
   121. ↑ « Maladies de l’œil : l'intelligence artificielle meilleure que
       les médecins ? », Les Echos.fr,‎ 14 août 2018 (lire en ligne)
   122. ↑ « FAQ », sur Healthdatahub (consulté le 10 août 2020)
   123. ↑ Alexandre Boero, « La police britannique travaille sur une IA
       qui sera capable de devancer votre crime », sur Clubic, 2 décembre
       2018.
   124. ↑ (en) Stephen Buranyi, « The rise of the racist robots », The
       Guardian, 9 aout 2017.
   125. ↑ Romaric Saint-Aubert, « Quand l’IA devient l’arme du crime »
       Accès libre , sur Business2Community.com, 1^er août 2023.
   126. ↑ « Justice Prédictive : de l'idée à la réalité », sur
       justice-predictive.com (consulté le 27 janvier 2019).
   127. ↑ ^a et b Harold Grand, « En Estonie, une intelligence
       artificielle va rendre des décisions de justice », sur Le Figaro,
       1^er avril 2019 (consulté le 29 juin 2020).
   128. ↑ « Les avocats face à la révolution numérique. S’adapter pour
       rebondir », sur Atlantico.fr (consulté le 10 août 2020).
   129. ↑ Vincent Bouquet, « Supply chain : l'intelligence artificielle,
       une promesse de levier d'amélioration », sur Les Echos Executives,
       4 novembre 2019 (consulté le 29 juin 2020).
   130. ↑ « Urbanloop – smart urban mobility » (consulté le 29 juin 2020).
   131. ↑ « Google Maps roule à l'IA pour optimiser la navigation », sur
       journaldunet.com (consulté le 10 juillet 2020).
   132. ↑ Stéphanie Condon, « Vidéo : comment l'intelligence artificielle
       a contribué à améliorer Google Maps », sur ZDNet France (consulté
       le 10 juillet 2020).
   133. ↑ Larry Dignan, « Facebook associe son service Map With AI au
       projet OpenStreetMap », sur ZDNet France (consulté le 10 juillet
       2020).
   134. ↑ Acatech 2011.
   135. ↑ ^a b et c « Les enjeux de l’intelligence artificielle dans la
       robotique », Journal Innovations et Technologies (JITEC), n^o 210,‎
       juillet/août 2018, p. I-VI (lire en ligne [PDF], consulté le 3
       février 2019).
   136. ↑ Amélie Cordier, Introduction à l’intelligence artificielle
       développementale (cours), Laboratoire d'informatique en image et
       systèmes d'information, 41 p. (lire en ligne [PDF]).
   137. ↑ Michel Bret, Edmond Couchot et Patrice Besnard (restauration),
       « Les Pissenlits », vidéo de l'installation interactive, durée
       1 min 8 s, sur Université Paris-VIII, 2006 (consulté le 21 juin
       2018).
   138. ↑ Living art : L’art numérique, CNRS Éditions (présentation en
       ligne).
   139. ↑ Capture.
   140. ↑ « Postdigital » (consulté le 25 août 2022).
   141. ↑ « Arts : l’autre Terre de Grégory Chatonsky au Palais de
       Tokyo », Le Monde,‎ 27 juin 2019 (lire en ligne, consulté le 25
       août 2022).
   142. ↑ (en-US) « Gregory Chatonsky, “Internes” », sur RRose Editions
       (consulté le 25 août 2022).
   143. ↑ (en) Katerina Cizek, William Uricchio et Sarah Wolozin, « Part
       6: Media co-creation with non-human systems », dans Collective
       Wisdom, PubPub, 3 juin 2019 (lire en ligne).
   144. ↑ « Obvious, les Français derrière la première peinture d’une IA
       vendue aux enchères », sur France 24, 19 octobre 2018.
   145. ↑ « Une peinture, réalisée par une Intelligence artificielle, mise
       aux enchères », sur objetconnecte.net (consulté le 28 novembre
       2018).
   146. ↑ ^a et b « Quand l’intelligence artificielle affole le marché de
       l’art », sur Contrepoints, 23 janvier 2019.
   147. ↑ (en-GB) « Solimán López skinning Artificial Intelligence », sur
       CLOT Magazine (consulté le 20 avril 2020).
   148. ↑ « OpenAI’s DALL-E creates plausible images of literally anything
       you ask it to », sur TechCrunch, 6 janvier 2021 (consulté le 20
       avril 2022).
   149. ↑ « ChatGPT et Midjourney font évoluer vos pratiques
       professionnelles ? Racontez-nous », Le Monde,‎ 8 avril 2023 (lire
       en ligne, consulté le 3 juin 2023).
   150. ↑ Victor Vasseur, « Les fausses images de Macron en éboueur et de
       Trump en prison montrent l'incroyable potentiel de l'IA », sur
       France Inter, 22 mars 2023 (consulté le 3 juin 2023).
   151. ↑ « Cette fausse photo du pape François en doudoune blanche est
       devenue virale, voici son histoire - Edition du soir Ouest-France -
       27/03/2023 », sur Ouest-France.fr, 27 mars 2023 (consulté le 3 juin
       2023).
   152. ↑ (en) Jordan Hart, The AI program used to generate fake viral
       images of Pope Francis and Donald Trump just suspended free trials
       — but professional photographers say they're still concerned,
       Business Insider, 30 mars 2023, Business Insider.
   153. ↑ Clémentine Mercier, « Intelligence artificielle : «Le droit
       d’auteur protège une création précise, mais pas une manière de
       créer» », sur Libération, 31 décembre 2022 (consulté le 19 novembre
       2023)
   154. ↑ Photos créées par des IA : une bascule vertigineuse et
       dangereuse, Jonathan Bouchet-Petersen, 31 mars 2023, Libération :
       « Emmanuel Macron ramassant les poubelles, le Pape en doudoune
       blanche type Bibendum, Donald Trump se débattant au milieu de
       policiers venus l’arrêter… Ces images ont en commun d’avoir été
       générées par des intelligences artificielles. »
   155. ↑ « Comment l’intelligence artificielle va-t-elle changer notre
       vie quotidienne ? », sur Robots & Cie, 30 novembre 2016 (consulté
       le 27 janvier 2019).
   156. ↑ « Quand l’IA aide les développeurs à programmer », sur
       Mircrosoft (consulté le 27 janvier 2019).
   157. ↑ Ivan Capecchi, « Médias, faites GAFA à l’IA ! », L’ADN.eu,‎ 11
       mai 2017 (lire en ligne)
   158. ↑ « La première animatrice télé virtuelle fait ses débuts en Corée
       du Sud », sur 20minutes.fr (consulté le 23 novembre 2020)
   159. ↑ (en-US) « The A.I. Chair », sur Gessato, 17 avril 2019 (consulté
       le 27 février 2020).
   160. ↑ (en) Dom Galeon, « The United Arab Emirates is the first country
       in the world to hire a minister for artificial intelligence », sur
       businessinsider.com, 16 décembre 2017
   161. ↑ (en) « Appliquer les Principes de l’OCDE sur l’IA : progrès et
       perspectives - OECD.AI », sur oecd.ai (consulté le 3 novembre
       2023).
   162. ↑ « Création du partenariat mondial pour l'intelligence
       artificielle : secrétariat au sein de l'OCDE à Paris », sur ActuIA
       (consulté le 3 novembre 2023).
   163. ↑ (en) « AI for Good Global Summit 2018 », sur ITU (consulté le 3
       novembre 2023).
   164. ↑ Francis Donnat, « L'intelligence artificielle, une menace pour
       la vie privée ? », Pouvoirs, Seuil, n^o 170,‎ septembre 2019,
       p. 95-103 (ISBN 978-2-02-140678-8, DOI 10.3917/pouv.170.0095
       doi=libre, lire en ligne).
   165. ↑ Lucie Lequier, « Tout comprendre à l’IA Act, le texte européen
       de réglementation de l’intelligence artificielle », sur Numerama,
       11 mai 2023 (consulté le 3 novembre 2023).
   166. ↑ « Bill Gates », sur Universalis.fr (consulté le 16 octobre 2016)
   167. ↑ « Intelligence artificielle, les défis actuels et l'action
       d'Inria », sur Inria, 2016 (consulté le 15 décembre 2016).
   168. ↑ « « Intelligence artificielle, intelligence humaine : la double
       énigme », de Daniel Andler : chimériques machines qui pensent », Le
       Monde,‎ 4 juin 2023 (lire en ligne Accès limité , consulté le 12
       juin 2023).
   169. ↑ ^a b et c Martin Gibert, Faire la morale aux robots : une
       introduction à l'éthique des algorithmes (ISBN 978-2-89759-516-6 et
       2-89759-516-7, OCLC 1146545386).
   170. ↑ « Quelles différences entre l'IA symbolique et l'apprentissage
       automatique ? », sur ActuIA (consulté le 2 novembre 2023)
   171. ↑ Jean Rohmer, « Comprendre l’intelligence artificielle
       symbolique », sur The Conversation, 19 novembre 2018 (consulté le 2
       novembre 2023)
   172. ↑ (en) Irving John Good, « Speculations Concerning the First
       Ultraintelligent Machine », Advances in Computers, vol. 6, 1966,
       p. 31-88.
   173. ↑ Eliezer Yudkowsky, Scruter la Singularité, mai 2004 [lire en
       ligne] (trad. de (en) Staring into the Singularity , 1996).
   174. ↑ Ray Kurzweill, Humanité 2.0 : La Bible du changement, 2007
       (édition originale : (en) The Singularity is Near: When Humans
       Transcend Biology, 2007).
   175. ↑ « Intelligence artificielle : pourquoi Musk, Hawking et Gates
       s'inquiètent ? », Les Échos, 30 janvier 2015.
   176. ↑ Rémi Sussan, « Stephen Hawking craint l’intelligence
       artificielle. Et s’il avait tort ? », sur L'Obs, 6 février 2015
       (consulté le 15 avril 2023)
   177. ↑ « Selon Stephen Hawking, l’intelligence artificielle est un
       danger pour l’humanité », sur Web Développement Durable (consulté
       le 28 février 2016).
   178. ↑ Alexandre Piquard, « Intelligence Artificielle Web Summit », Le
       Monde, 10 novembre 2017.
   179. ↑ L'intelligence artificielle inquiète les grands cerveaux
       contemporains, France 24, 2 février 2015.
   180. ↑ « L'intelligence artificielle pourrait mettre 50% de l'humanité
       au chômage », sur L'Express, 13 février 2016 (version du 2 mai 2017
       sur Internet Archive).
   181. ↑ (en) Joe McKendrick, « Let's Make Artificial Intelligence
       'Boring' Again », sur Forbes (consulté le 24 février 2023)
   182. ↑ « L'IA pourrait poser un « risque d'extinction » pour
       l'humanité, affirment 350 experts », sur Les Échos, 30 mai 2023
       (consulté le 4 novembre 2023).
   183. ↑ Kevin Roose, « Vie numérique: L’IA constitue un « risque
       d’extinction » pour l’humanité », La Presse (traduit depuis The New
       York Times),‎ 30 mai 2023 (lire en ligne, consulté le 4 novembre
       2023).
   184. ↑ Morgane Tual, « Pourquoi Google a conçu un « bouton rouge » pour
       désactiver des intelligences artificielles », Le Monde,‎ 7 juin
       2016 (ISSN 1950-6244, lire en ligne, consulté le 8 juin 2016).
   185. ↑ (en) Nick Bostrom, « What happens when our computers get smarter
       than we are? », 27 avril 2015 (consulté le 15 avril 2023) : « We
       should not be confident in our ability to keep a superintelligent
       genie locked up in its bottle forever. Sooner or later, it will
       out. I believe that the answer here is to figure out how to create
       superintelligent A.I. such that even if—when—it escapes, it is
       still safe because it is fundamentally on our side because it
       shares our values. »
   186. ↑ DR, « L’intelligence artificielle devient de plus en plus
       incompréhensible », sur Paris Match, 8 novembre 2022.
   187. ↑ « Règles de droit civil sur la robotique. Résolution du
       Parlement européen du 16 février 2017 contenant des recommandations
       à la Commission concernant des règles de droit civil sur la
       robotique (2015/2103(INL)) ».
   188. ↑ Mélinée Le Priol, « Une nouvelle religion fondée sur
       l’intelligence artificielle suscite des inquiétudes », La Croix, 5
       octobre 2017.
   189. ↑ Lewis Mumford, Le Mythe de la machine, deux volumes, 1967-1970;
       tard., Fayard, 1974.
   190. ↑ Jacques Ellul, La Technique ou l'Enjeu du siècle, 1954;
       3^e édition : Economica 2008.
   191. ↑ Günther Anders, L'obsolescence de l'homme, tome 1, 1956; tome 2,
       1980; tard. fr.2002 et 2011.
   192. ↑ Pièces et Main d'Œuvre Site officiel.
   193. ↑ Technologos Site officiel.
   194. ↑ François Jarrige, Techno-critiques. Du refus des machines à la
       contestation des technosciences, La Découverte, 2014.
   195. ↑ Jacques Ellul, L'Illusion politique, 1965; 3^e édition : La
       Table ronde, 2004.
   196. ↑ Technologos, "Qui sommes-nous ?", articles 31 à 33.
   197. ↑ Jacques Ellul, Les Nouveaux Possédés, Mille et une nuits/Fayard,
       2003, 2^e éd. (1^re éd. 1973), p. 316.
   198. ↑ « Intelligence artificielle : les risques d'une utilisation
       malveillante », Futura, 21 février 2018 (consulté le 21 février
       2018).
   199. ↑ Intelligence artificielle digne de confiance ; La majorité des
       efforts de Mozilla pour donner de l’élan au mouvement sont orientés
       vers le développement d’une intelligence artificielle (IA) digne de
       confiance. La santé d’Internet ; Qu’entendons-nous par « santé
       d’Internet » ?, Mozilla Fondation (2023) (lire en ligne, consulté
       le 22 avril 2023).
   200. ↑ Pierre Fontaine, « Comment la fondation Mozilla veut créer une
       IA de confiance pour nous sauver des géants de la tech », sur
       01net, 23 mars 2023 (consulté le 21 avril 2023).
   201. ↑ (en) House of Commons Digital, Culture, Media and Sport
       Committee (2019) Disinformation and ‘fake news': Final Report ;
       Eighth Report of Session 2017–19 ; Report, together with formal
       minutes relating to the report ; rapport commandé par the House of
       Commons, Ref HC 1791, publié le 18 février 2019, imprimé le 14
       février 2019 pour le Gouvernement britannique. Voir notamment
       paragraphe 149.
   202. ↑ (en) « Investigation into data analytics for political
       purposes », sur ico.org.uk, 6 octobre 2020 (consulté le 19 mars
       2021).
   203. ↑ « "Sans Cambridge Analytica, il n'y aurait pas eu de Brexit",
       affirme le lanceur d'alerte Christopher Wylie », sur
       francetvinfo.fr, 28 mars 2018 (consulté le 28 mars 2018).
   204. ↑ Morgane Tual, « Intelligence artificielle : les géants du Web
       lancent un partenariat sur l'éthique », Le Monde,‎ 28 septembre
       2016 (ISSN 1950-6244, lire en ligne).
   205. ↑ « Intelligence artificielle : Google DeepMind se dote d'une
       unité de recherche sur l'éthique », Le Monde,‎ 4 octobre 2017
       (ISSN 1950-6244, lire en ligne).
   206. ↑ (en-US) « Lethal Autonomous Weapons Pledge », sur
       futureoflife.org (consulté le 13 août 2018).
   207. ↑ « Des milliers d'experts en intelligence artificielle s'engagent
       à ne pas participer à la création d'armes », Le Monde,‎ 18 juillet
       2018 (lire en ligne)
   208. ↑ L'UNESCO rejoint le Partenariat mondial sur l'Intelligence
       Artificielle comme observateur, UNESCO, 2022.
   209. ↑ Publications Office of the European Union, « Intelligence
       artificielle Une approche européenne axée sur l'excellence et la
       confiance, COM/2020/65 final », sur Office des publications de
       l'Union européenne, 19 février 2020 (consulté le 5 novembre 2023).
   210. ↑ « Réglementation de l’Intelligence artificielle en Europe », sur
       Devoteam France (consulté le 5 novembre 2023).
   211. ↑ (en) « Une Europe adaptée à l'ère du numérique : La Commission
       propose de nouvelles règles et actions en faveur de l'excellence et
       de la confiance dans l'intelligence artificielle », sur Commission
       européenne, 21 avril 2021 (consulté le 21 avril 2023).
   212. ↑ « Premier Forum mondial sur l'éthique de l’IA à Prague, un an
       après l'adoption de la Recommandation de l'UNESCO », sur UNESCO, 9
       décembre 2022.
   213. ↑ « Intelligence artificielle : l'UNESCO appelle à mettre en œuvre
       sans délai le cadre éthique mondial », sur ONU Info, 31 mars 2023
       (consulté le 19 novembre 2023)
   214. ↑ ^a et b « Recommandation sur l’éthique de l’intelligence
       artificielle », sur UNESCO, 2022 (consulté le 30 mars 2023)
   215. ↑ ^a b et c « Ethique: l'Unesco appelle les États à appliquer sa
       recommandation sur l'intelligence artificielle » [archive du 30
       mars 2023], sur Techniques de l'Ingénieur (consulté le 30 mars
       2023).
   216. ↑ (en) Carl Benedikt Frey et Michael A. Osborne, The Future of
       Employment: How Susceptible Are Jobs to Computerisation?, 17
       septembre 2013 [lire en ligne] [PDF].
   217. ↑ (en) David H. Autor, « Why Are There Still So Many Jobs? The
       History and Future of Workplace Automation », Journal of Economic
       Perspectives, vol. 29, n^o 3, été 2015, p. 3-30 [lire en ligne]
       [PDF].
   218. ↑ Antonio A. Casilli, En attendant les robots : Enquête sur le
       travail du clic, Éditions du Seuil, 2019 (ISBN 978-2-0214-0188-2).
   219. ↑ « Les travailleurs du clic et l’intelligence artificielle », sur
       Laboratoire de cyberjustice (consulté le 7 juillet 2020)
   220. ↑ ^a et b « Les robots ne volent pas nos «jobs à la con», ils en
       créent d'autres », sur 20minutes.fr (consulté le 7 juillet 2020).
   221. ↑ (en) Site officiel de Mighty IA.
   222. ↑ (en) John Joseph Horton et Lydia B. Chilton, « The labor
       economics of paid crowdsourcing », Proceedings of the 11th ACM
       conference on Electronic commerce - EC '10, ACM Press,‎ 2010,
       p. 209 (ISBN 9781605588223, DOI 10.1145/1807342.1807376,
       présentation en ligne).
   223. ↑ « Microtravail et microsalaire pour experts ou tâcheron », Le
       Monde, 12 avril 2016 (consulté le 19 avril 2019).
   224. ↑ « Avec le sociologue Antonio Casilli, une enquête sur « les
       galériens du clic » », France Info, 28 janvier 2019 (consulté le 19
       avril 2019).
   225. ↑ ^a b et c Jean-Marc Deltorn, « Ces petites mains invisibles, clé
       de voûte de l'apprentissage machine », La Recherche (consulté le 18
       novembre 2023).
   226. ↑ « Jobs du clic : la France compte plus de 250 000
       micro-travailleurs », Le Monde, 15 février 2019 (consulté le 19
       avril 2019).
   227. ↑ « Amélioration des conditions de travail », sur Sénat (consulté
       le 26 novembre 2023)
   228. ↑ « Tech. Amazon écoute-t-il vos conversations grâce à Alexa ? »,
       Courrier international, 12 avril 2019 (consulté le 19 avril 2019).
   229. ↑ Julien Cadot, « Uber relance ses tests de voiture autonome... en
       « mode manuel » - Tech », Numerama, 25 juillet 2018 (consulté le 19
       avril 2019).
   230. ↑ Antonio Casilli, « Digital Labor : travail, technologies et
       conflictualités », Qu’est-ce que le digital labor ?,‎ 25 avril 2015
       (ISBN 978-2-86938-2299, lire en ligne).
   231. ↑ (en) Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang,
       Owain Evans, « When Will AI Exceed Human Performance? Evidence from
       AI Experts », arXiv, 24 mai 2017.
   232. ↑ « Quand l'écrivain de science-fiction Isaac Asimov prédisait le
       futur », sur France Culture, 2 janvier 2020 (consulté le 7 juillet
       2020).
   233. ↑ (en) Georgia Panteli, « From puppet to cyborg: posthuman and
       postmodern retellings of the Pinocchio myth » [PDF], sur
       discovery.ucl.ac.uk
   234. ↑ « Plumbing Stanley Kubrick », sur web.archive.org, 3 juillet
       2008 (consulté le 7 juillet 2020)
   235. ↑ (en) « Skynet », sur Terminator Wiki (consulté le 7 juillet
       2020)
   236. ↑ « Westworld », sur Allociné.fr (consulté le 22 décembre 2016)
   237. ↑ Article de Dylan L. McClain, New York Times, 16 janvier 2017, et
       article « Hans J. Berliner (1929-2017), Grand Maître d'échecs et
       programmeur de génie », Denis Rozier, Le Courrier des Échecs
       n^o 639, mars 2017.
   238. ↑ Thibault Neveu, « Intelligence artificielle : démonstration en
       direct des nouvelles performances de DeepMind », sur actuia.com, 24
       janvier 2019.
   239. ↑ « Les jeux et l'intelligence artificielle », sur u-picardie.fr
       (consulté le 27 septembre 2016)
   240. ↑ (en) David Levy et Monroe Newborn, « More Chess and Computers:
       The Microcomputer Revolution, The Challenge Match », Computer
       Science Press, Potomac (Maryland) et Batsford, Londres, 1980.
       (ISBN 0-914894-07-2)
   241. ↑ (en) « For First Time, a Chess Computer Outwits Grandmaster in
       Tournament », Harold C. Schonberg, The New York Times.com, 26
       septembre 1988.
   242. ↑ (en) « Bent Larsen, Chess Grandmaster, Dies at 75 », Dylan Loeb
       McClain, The New York Times.com, 11 septembre 2010.
   243. ↑ (en) « Chess legend Bent Larsen turns 75 », ChessBase.com, 3
       mars 2010.
   244. ↑ Pierre Barthélémy, « L’espèce humaine, échec et mat »,
       Libération.fr, 11 septembre 2014 (consulté le 29 janvier 2016).
   245. ↑ (en) « Adams vs Hydra: Man 0.5 – Machine 5.5 », ChessBase.com,
       28 juin 2005.
   246. ↑ (en) « How could Kramnik overlook the mate? », ChessBase.com, 29
       novembre 2006.
   247. ↑ (en) « Topalov training with super computer Blue Gene P », sur
       ChessDom.com (consulté le 1^er juillet 2016).
   248. ↑ (en) [PDF] « Learning, Deep or not Deep, de MENACE à AlphaGo »,
       sur alliot.fr.
   249. ↑ (en) David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis
       Antonoglou, Matthew Lai et al., « Mastering Chess and Shogi by
       Self-Play with a General Reinforcement Learning Algorithm », 5
       décembre 2017.
   250. ↑ (en) Sarah Knapton et Leon Watson, « Entire human chess
       knowledge learned and surpassed by DeepMind's AlphaZero in four
       hours », sur telegraph.co.uk, 6 décembre 2017.
   251. ↑ ^a et b « Jeu de go : comment savoir si les programmes
       d’intelligence artificielle sont vraiment… intelligents », Le
       Monde.fr, 9 mars 2016.
   252. ↑ (en) David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis
       Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker,
       Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Hui
       Fan, Laurent Sifre, George van den Driessche, Thore Graepel et
       Demis Hassabis, « Mastering the game of Go without human
       knowledge », Nature, vol. 550, n^o 7676,‎ 19 octobre 2017,
       p. 354–359 (ISSN 0028-0836, DOI 10.1038/nature24270, lire en ligne
       Accès payant , consulté le 10 décembre 2017).
   253. ↑ « Jeu de go : Le champion du monde de nouveau battu par
       l'ordinateur de Google », L'Obs.com, 10 mars 2016.
   254. ↑ (en) J. Rehmeyer, N. Fox et R. Rico, « Ante up, human: The
       adventures of Polaris the poker-playing robot », Wired, vol. 16,
       n^o 12,‎ décembre 2008, p. 86–191
   255. ↑ ^a et b (en) Michael Bowling, Neil Burch, Michael Johanson et
       Oskari Tammelin, « Heads-Up Limit Hold’em Poker Is Solved »,
       Comm.of the ACM, vol. 60, n^o 11,‎ 2017, p. 81
   256. ↑ ^a b c et d « Comment une-intelligence artificielle ridiculise
       les meilleurs joueurs de poker », sur Numerama, 27 janvier 2017.
   257. ↑ Philippe Pionchon, « L'Intelligence Artificielle et le bridge ».

Voir aussi

   Sur les autres projets Wikimedia :
     * intelligence artificielle, sur le Wiktionnaire
     * Département:Intelligence artificielle, sur Wikiversity

Bibliographie

   Aspects techniques
     * Stuart J. Russell et Peter Norvig (trad. de l'anglais),
       Intelligence artificielle [« Artificial Intelligence: A Modern
       Approach »], Pearson Education France, 2010, 3^e éd., 1198 p.
       (ISBN 978-2-7440-7455-4, présentation en ligne).
     * Alan Turing, Jean-Yves Girard, La Machine de Turing, Éditions du
       Seuil, 1995 [détail de l’édition], Les Ordinateurs et
       l'Intelligence, p. 133–174
     * Claire Rémy, L'Intelligence artificielle, Paris, Dunod, 1994,
       158 p. (ISBN 2-10-002258-X)
     * Jean-Marc Alliot et Thomas Schiex, Intelligence artificielle et
       informatique théorique, Toulouse, CEPADUES, 2002, 543 p.
       (ISBN 2-85428-578-6)
     * (en) Michael R. Genesereth et Nils J. Nilsson, Logical Foundations
       of Artificial Intelligence, Los Altos, Californie, États-Unis,
       Morgan Kaufmann, 1987, 405 p. [détail de l’édition]
       (ISBN 0-934613-31-1)
     * Jean-Louis Laurière, Intelligence Artificielle, Eyrolles, 1986
     * Jean-Paul Delahaye, Outils logiques pour l'intelligence
       artificielle, Eyrolles, 1985 [détail des éditions]
       (ISBN 978-2212084122)
     * Jean-Paul Haton, Marie-Christine Haton, L'Intelligence
       Artificielle, Paris, Que sais-je ?, 1990, 127 p.
       (ISBN 2-13-043164-X)
     * (en) Kate Crawford, Atlas of AI : Power, Politics, and the
       Planetary Costs of Artificial Intelligence, Yale University Press,
       2021
     * (en) Jacques Pitrat Artificial Beings, the conscience of a
       conscious machine, Artificial Beings, the conscience of a conscious
       machine, ISTE-Wiley, 2019 (ISBN 9781848211018).

   Aspects prospectifs
     * Étude : CGET (2019) Intelligence artificielle – État de l’art et
       perspectives pour la France ; 21 février 2019.
       URL:https://cget.gouv.fr/ressources/publications/intelligence-artif
       icielle-etat-de-l-art-et-perspectives-pour-la-france
       (ISBN 978-2-11-152634-1) (ISSN 2491-0058)
     * « Jusqu'où ira l'intelligence artificielle ? », Pour la science,
       hors-série n^o 115,‎ mai-juin 2022, p. 4-119

   Aspects philosophiques
     * Marie David et Cédric Sauviat, Intelligence artificielle, la
       nouvelle barbarie, Éditions du Rocher, 2019, 313 p.
     * Laurent Alexandre, La Guerre des intelligences. Intelligence
       artificielle versus intelligence humaine, Paris, JC Lattès, 2017,
       250 p. (ISBN 978-2-7096-6084-6, lire en ligne)
     * Gilbert Boss, Les machines à penser : L'homme et l'ordinateur,
       Zurich, Éditions du Grand midi, 1987, 202 p. (ISBN 2-88093-105-3)
     * Jacques Bolo, Philosophie contre intelligence artificielle, Paris,
       Lingua Franca, 1996, 375 p. (ISBN 2-912059-00-3)
     * Alan Ross Anderson (trad. de l'anglais), Pensée et machine,
       Seyssel, Éditions Champ Vallon, 1983 (réimpr. 1993), 150 p.
       (ISBN 2-903528-28-4, lire en ligne)
     * Jean Sallantin et Jean-Jacques Szczeciniarz, Le Concept de preuve à
       la lumière de l'intelligence artificielle, Paris, Presses
       universitaires de France, 1999, 370 p. (ISBN 2-13-050104-4)
     * Jean-Gabriel Ganascia, L'Âme-machine, les enjeux de l'intelligence
       artificielle, Paris, Éditions du Seuil, Collection Science Ouverte,
       1990, 284 p. (ISBN 2-02-011470-4)
     * Nick Bostrom, Superintelligence : Paths, Dangers, Strategies, 2014,
       328 p. (ISBN 978-0-19-967811-2, lire en ligne)

   Fondements cognitifs, psychologiques et biologiques
     * Hervé Chaudet et Liliane Pellegrin, Intelligence artificielle et
       psychologie cognitive, Paris, Dunod, 1998, 179 p.
       (ISBN 2-10-002989-4)

   Aspects linguistiques
     * Gérard Sabah, L'Intelligence artificielle et le langage,
       Représentations des connaissances, Processus de compréhension,
       vol. 1, Hermès, 1989 (ISBN 2-86601-134-1)
     * Gérard Sabah, L'Intelligence artificielle et le langage,
       Représentations des connaissances, Processus de compréhension,
       vol. 2, Paris, Hermès, 1990, 768 p. (ISBN 2-86601-187-2)
     * Gérard Sabah, Compréhension des langues et interaction (Traité IC2,
       Série Cognition et Traitement de l'Information), Paris, Hermès
       science: Lavoisier, 2006, 400 p. (ISBN 2-7462-1256-0)
     * (en) Krzysztof Wołk, Machine learning in translation corpora
       processing, Boca Raton, FL, Taylor & Francis, 2019, 264 p.
       (ISBN 978-0-367-18673-9)

   Histoire
     * Daniel Crevier et Nathalie Bukcek (trad. de l'anglais), À la
       recherche de l'intelligence artificielle, Paris, Flammarion, 1997,
       438 p. (ISBN 2-08-081428-1), (traduction de (en) The Tumultuous
       history of the search for artiticial intelligence.)

   Vulgarisation
     * Gérard Tisseau et Jacques Pitrat, Intelligence artificielle :
       problèmes et méthodes, Paris, Presses universitaires de France,
       1996, 255 p. (ISBN 2-13-047429-2)
     * Jack Challoner (trad. de l'anglais), L'Intelligence artificielle :
       Un guide d'initiation au futur de l'informatique et de la
       robotique, Paris, Pearson Education, 2003, 72 p.
       (ISBN 2-7440-1600-4)
     * Hugues Bersini, De l'intelligence humaine à l'intelligence
       artificielle, Paris, Ellipse, 2006, 192 p. (ISBN 2-7298-2813-3)
     * Jean-Gabriel Ganascia, L'Intelligence artificielle, Paris, Éditions
       du Cavalier bleu, coll. « Idees recues », 2007, 127 p.
       (ISBN 978-2-84670-165-5)
     * Howard Selina (illustrations) et Henry Brighton (texte) (trad. de
       l'anglais), L'Intelligence artificielle en images, Les Ulis, EDP
       Sciences, coll. « Aperçu », 2015, 176 p. (ISBN 978-2-7598-1772-6)
     * Marion Montaigne (dessin) et Jean-Noël Lafargue (scénario),
       L'Intelligence artificielle : fantasmes et réalités, Bruxelles, Le
       Lombard, coll. « La petite bédéthèque des savoirs », 2016, 72 p.
       (ISBN 978-2-8036-3638-9)
     * L'IA et l'efficacité, dans L'IA et moi sur Savoir média (2021,
       30 minutes) Consulté le 31 mai 2022.

   Politique, relations internationales
     * Daniel Ventre, Intelligence artificielle, cybersécurité et
       cyberdéfense, ISTE, Londres, 246 pages, juin 2020 (ISBN papier :
       9781784056797), (ISBN ebook : 9781784066796)

Articles connexes

   Aspects juridiques
     * Digital Services Act, ou loi sur les services numériques de l'Union
       européenne

   Notions générales
     * Agent intelligent
     * Agent logiciel
     * Agent virtuel
     * Algorithme
     * Algorithme génétique
     * Alignement des intelligences artificielles
     * Applications de l'intelligence artificielle
     * Automation
     * Bio-informatique
     * Cerveau artificiel
     * Cyborg
     * Déclaration de Montréal pour un développement responsable de
       l'intelligence artificielle
     * Effet IA
     * Éthique de l'intelligence artificielle
     * Explosion d'intelligence
     * Histoire de l'intelligence artificielle
     * Intelligence artificielle générale
     * Interactions homme-machine
     * Philosophie de l'intelligence artificielle
     * Principaux projets et réalisations en intelligence artificielle
     * Intelligence artificielle de remédiation
     * Progrès
     * Progrès technique
     * Réseau de neurones artificiels
     * Singularité technologique
     * Singularitarisme
     * Système expert
     * Téléchargement de l'esprit
     * Test de Turing
     * Vie artificielle

   Notions techniques
     * Agent conversationnel
     * Apprentissage automatique
     * Apprentissage par renforcement
     * Apprentissage profond (Deep learning)
     * Architecture cognitive
     * Diagnostic
     * Exploration de données
     * Forêt d'arbres décisionnels
     * Inférence bayésienne
     * Intelligence artificielle amicale
     * Intelligence artificielle distribuée
     * Intelligence artificielle faible
     * Logique floue
     * Machine à vecteurs de support
     * Métaheuristiques
     * Planification
     * Problème de satisfaction de contraintes
     * Programmation génétique
     * Programmation par contraintes
     * Raisonnement par cas
     * Réseaux de neurones
     * Système multi-agents
     * Théorème de Cox-Jaynes

   Chercheurs en intelligence artificielle (espace anglophone)
     * Edward Feigenbaum
     * Irving John Good
     * Douglas Engelbart
     * Douglas Hofstadter
     * Douglas Lenat
     * John McCarthy
     * Marvin Lee Minsky
     * Allen Newell
     * Nils Nilsson
     * Seymour Papert
     * Rosalind Picard
     * Roger Schank
     * Herbert Simon
     * Ray Solomonoff
     * Gerald Jay Sussman
     * Alan Turing
     * Joseph Weizenbaum

   Chercheurs en intelligence artificielle (espace francophone)
     * Hugues Bersini
     * Alain Colmerauer
     * Jean-Paul Delahaye
     * Rose Dieng-Kuntz
     * Yann Le Cun
     * François Pachet
     * Jacques Pitrat
     * Gérard Sabah

   Laboratoires et projets renommés de recherche en intelligence
   artificielle
     * Le Stanford Artificial Intelligence Laboratory (SAIL) (en), fondé
       en 1963 par John McCarthy
     * L'Augmentation Research Center (ARC) (en) du Stanford Research
       Institute, fondé au début des années 1960 par Douglas Engelbart
     * Le projet MAC (en) de l'institut de technologie du Massachusetts,
       lancé le 1^er juillet 1963 et dirigé par Robert Fano
     * Le laboratoire de recherche en intelligence artificielle (AILab) du
       Massachusetts Institute of Technology, fondé en 1970 –pour remédier
       au manque d'espace dont souffre le groupe IA du nouveau projet MAC–
       et fusionné en 2003 avec le laboratoire de recherche en
       informatique (LCS) ; à nouveau réunies, les deux entités prennent
       le nom de MIT Computer Science and Artificial Intelligence
       Laboratory (CSAIL)
     * l'Institut des sciences de l'information (ISI) (en) de l'Université
       de Californie du Sud (USC), fondé en 1972 par Keith Uncapher (en)
     * OpenAI, société fondatrice des projets GPT-3, DALL-E et ChatGPT.

Liens externes

     * Notices dans des dictionnaires ou encyclopédies généralistes Voir
       et modifier les données sur Wikidata  :
          + Britannica
          + Brockhaus
          + Enciclopedia De Agostini
          + Nationalencyklopedin
          + Store norske leksikon
          + Treccani
     * Notices d'autorité Voir et modifier les données sur Wikidata  :
          + BnF (données)
          + LCCN
          + GND
          + Japon
          + Espagne
          + Israël
          + Tchéquie
          + Lettonie
     * Ressources relatives à la recherche Voir et modifier les données
       sur Wikidata  :
          + Internet Encyclopedia of Philosophy
          + Stanford Encyclopedia of Philosophy
     * Ressource relative à la santé Voir et modifier les données sur
       Wikidata  :
          + Medical Subject Headings
     * « Intelligence artificielle », publications en ligne, Interstices,
       INRIA.
     * (en) European Association for Artificial Intelligence (EurAI)
       (Association européenne pour l'intelligence artificielle)
     * Association française pour l'intelligence artificielle (AfIA).
     * Association française pour la promotion et la sensibilisation à
       l'intelligence artificielle (AFPSIA) (inaccessible).
     * GdrIA, groupement de recherche du CNRS sur les aspects formels et
       algorithmiques de l'intelligence artificielle.
     * ActuIA, site présentant l'actualité de l'intelligence artificielle.
     * Dossier sur l'Intelligence artificielle, savoirs.ens.fr
       (conférences de l'École normale supérieure).
     * Insideaiminds.com est un blogue spécialisé dans l'analyse des
       opinions des plus grands experts de l'intelligence artificielle
     * Sébastien Konieczny, « L'intelligence artificielle, menace ou
       avancée ? », Huffington Post, 9 mars 2016.
     * Juliette Demey, « À quoi sert l'intelligence artificielle ? », JDD,
       19 juillet 2015.
     * « Intelligence artificielle : en mon âme et conscience », La
       Science, CQFD, France Culture, 1 juin 2023.

   v · m
   Robotique
   Sujets connexes
     * Capteur
     * Intelligence artificielle
     * Actionneur
     * Source d'énergie
     * Programmation
     * Compétition de robotique

   Communication
     * Communication série
     * Communication parallèle
     * Transmission sans fil

     * Automatique
     * Électricité
     * Électrochimie
     * Électromagnétisme
     * Électronique
     * Électrotechnique
     * Traitement du signal

   v · m
   Technologies émergentes
   Affichage
     * Affichage sans écran
     * Affichage tête haute
     * Autostéréoscopie
     * Diode électroluminescente organique
     * Lentille de contact bionique
     * Surface-conduction Electron-emitter Display
     * Réalité virtuelle

   Agriculture
     * Agriculture de précision
     * Agriculture urbaine
     * Aquaponie
     * Ferme verticale
     * Hydroponie
     * Mur végétalisé
     * Organisme génétiquement modifié
     * Viande in vitro

   Astronomie/Astrophysique
     * Détecteurs d'ondes gravitationnelles
          + LISA
          + LIGO
          + Virgo
     * Interféromètre astronomique
          + Interféromètre optique à longue base
          + Interférométrie à très longue base
               o Event Horizon Telescope
               o HALCA
               o Hypertélescope

   Bioinformatique
     * Pyroséquençage
     * Séquençage de cellule unique
     * Séquençage par ligation (en)
     * Séquençage par ligation d'oligonucleotides (en)
     * Séquençage par nanopores
     * Séquençage par semiconducteur

   Biologie
     * Biophotonique
     * Électrophorèse capillaire par spectrométrie de masse (en)
     * Électrophorèse capillaire sur silicium
     * Imagerie moléculaire
     * Isolation chip
     * Optofluidique
     * Optogénétique

   Biomédicale
     * Ampakine
     * Bioimpression
     * Biologie de synthèse
     * Biostase
     * Cellule souche
     * Cryoconservation
     * Cryonie
     * Génie biomédical
     * Génie génétique
     * Ingénierie clinique
     * Interface neuronale directe
     * Interférence par ARN
     * Médecine régénérative
     * Nanomédecine
     * Robot médical
     * Strategies for Engineered Negligible Senescence
     * Thérapie génique
     * Thérapie photodynamique

   Chimie
     * Cristallographie sérielle femtoseconde
     * Laboratoire sur puce
     * Microfluidique
     * Spectrométrie alpha
     * Spectrométrie de masse
     * Stylo 3D

   Électronique
     * Impression 3D
     * Impression 4D
     * Nez électronique
     * Opto-électronique
     * Spintronique
     * Plastronique
     * Optronique
     * Textile intelligent
     * Atomtronique

   Informatique
     * Calculateur quantique
     * Cryptographie quantique
     * Ordinateur optique
     * Informatique ubiquitaire
     * Intelligence artificielle
          + Réseau de neurones artificiels
     * Mémoire
          + CBRAM
          + FRAM
          + Millipede
          + MRAM
          + NRAM
          + PRAM
          + RRAM
          + 3D XPoint
          + Intelligence ambiante (Internet des objets)

   Physique
     * Laser
     * Cristallographie aux rayons X
     * Diffusion des rayons X
     * Spectroscopie des rayons X
     * Spectroscopie électronique
     * Spectrométrie gamma

   Robotique
     * Domotique
     * Exosquelette motorisé
     * Microrobotique
     * Nanorobot
     * Robotique en essaim
     * Robotique molle
     * Cobotique

   Transport
     * Hyperloop
     * Lancement spatial sans fusée
     * Propulsion laser
     * Lanceur réutilisable
     * Jetpack
     * Train à sustentation magnétique
     * Véhicule autonome
     * Moto et Voiture volante
     * Impression de voiture en 3D (Strati)
     * Spacetrain
     * Véhicule à hydrogène

   v · m
   Domaines de l'informatique
   Remarque : cette liste s'inspire du système de classification
   informatique de l'ACM édité en 2012
   Matériel
     * Circuit imprimé
     * Périphérique
     * Circuit intégré
     * Intégration à très grande échelle
     * Circuit logique programmable
     * Informatique durable
     * Conception assistée par ordinateur pour l'électronique

   Appareil et organisation
   d'un système
     * Architecture matérielle
     * Architecture de processeur
     * Machine à calculer
     * Mécanographie
     * Calculateur analogique
     * Calculatrice
     * Calculateur quantique
     * Ordinateur
     * Système embarqué
     * Système temps réel
     * Sûreté de fonctionnement

   Réseau
     * Architecture de réseau
     * Protocole de communication
     * Équipement d'interconnexion de réseau informatique
     * Planificateur de réseau (en)
     * Rendement du réseau (en)
     * Service réseau

   Organisation du logiciel
     * Interprète
     * Middleware
     * Machine virtuelle
     * Système d'exploitation
     * Qualité logicielle

   Théorie et outil (en)
   de programmation
     * Paradigme de programmation
     * Langage de programmation
     * Compilateur
     * Langage dédié
     * Langage de modélisation
     * Cadriciel
     * Environnement de développement
     * Gestion de configuration logicielle
     * Bibliothèque logicielle
     * Dépôt

   Développement de logiciel
     * Software development process
     * Analyse des exigences
     * Conception de logiciel
     * Assemblage de logiciel (en)
     * Déploiement de logiciel (en)
     * Maintenance du logiciel
     * Équipe de programmation (en)
     * Open source

   Théorie du calcul (en)
     * Modèle de calcul
     * Langage formel
     * Théorie des automates
     * Théorie de la complexité
     * Logique (en)
     * Sémantique

   Algorithmique
     * Algorithme
     * Conception d'algorithme (en)
     * Analyse de la complexité des algorithmes
     * Algorithme évolutionniste
     * Algorithme probabiliste
     * Géométrie algorithmique
     * Génération procédurale

   Mathématiques
   de l'informatique
     * Mathématiques discrètes
     * Probabilité
     * Statistique
     * Logiciel mathématique (en)
     * Théorie de l'information
     * Analyse
     * Analyse numérique

   Système d'information
     * Base de données
     * Mémoire (informatique)
     * Progiciel
     * Logiciel social
     * Système d'information géographique
     * Système d'aide à la décision
     * Supervision
     * Base de données multimédia
     * Exploration de données
     * Bibliothèque numérique
     * Plateforme
     * Marketing électronique
     * World Wide Web
     * Recherche d'information

   Sécurité
     * Cryptographie
     * Méthode formelle
     * Service de sécurité (en)
     * Système de détection d'intrusion
     * Sécurité matérielle (en)
     * Sécurité du réseau
     * Sécurité de l'information
     * Sécurité de l'application (en)

   Interactions homme-machine
     * Design numérique
     * Informatique sociale (en)
     * Informatique ubiquitaire
     * Visualisation (en)
     * Accessibilité numérique

   Concurrence (en)
     * Programmation concurrente
     * Parallélisme
     * Calcul distribué
     * Multithreading
     * Multiprocesseur

   Intelligence artificielle
     * Traitement automatique des langues
     * Représentation des connaissances
     * Vision par ordinateur
     * Planification
     * Optimisation
     * Philosophie de l'intelligence artificielle
     * Intelligence artificielle distribuée

   Apprentissage automatique
     * Apprentissage supervisé
     * Apprentissage non supervisé
     * Apprentissage par renforcement
     * Apprentissage multi-tâches (en)
     * Validation croisée

   Infographie
     * Animation par ordinateur
     * 2D numérique
     * Animation 3D
     * Rendu photoréaliste
     * Retouche d'image
     * Processeur graphique
     * Réalité mixte
     * Réalité virtuelle
     * Compression d'image
     * Conception paramétrique

   Audio informatique
     * Générateur de son programmable
     * Processeur de signal numérique
     * Synthétiseur analogique
     * échantillonnage
     * Séquenceur musical
     * Tracker (musique)
     * Musique assistée par ordinateur

   Informatique appliquée
     * Commerce en ligne
     * Logiciel d'entreprise
     * Mathématiques computationnelles
     * Physique numérique
     * Chimie numérique
     * Biologie numérique
     * Sciences sociales numérique (en)
     * Ingénierie numérique
     * Informatique médicale
     * Art numérique
     * Édition électronique
     * Cyberguerre
     * Vote électronique
     * Jeu vidéo
     * Traitement de texte
     * Recherche opérationnelle
     * Technologies de l'éducation
     * Gestion électronique des documents

   v · m
   Science-fiction
   Grandes lignes
     * Auteurs
     * Définitions
          + Hard
          + Soft
     * Histoire
     * Âge d'or
     * New wave

   Sous-genres
     * Anticipation
     * Anticipation sociale
     * Climate fiction
     * Dystopie
     * Humour
     * Libertarianisme
     * Militaire
     * Multivers
     * New weird
     * Planet opera
     * Science-fiction féministe
     * Post-apocalyptique
     * Réalisme fantastique
     * Science fantasy
     * Slipstream
     * Space fantasy
     * Space opera
     * Space Western
     * Uchronie
     * Utopie et dystopie

   Cyberpunk et dérivés
     * Biopunk
     * Cyberpunk
     * Dieselpunk
     * Postcyberpunk
     * Solarpunk
     * Steampunk

   Culture
     * Encyclopedia of Science Fiction
     * Fandom
     * Femmes dans les littératures de l'imaginaire
     * Internet Speculative Fiction Database
     * Museum of Pop Culture
     * NooSFere
     * World Science Fiction Convention

   Région
     * Allemagne
     * Bengale
     * France
     * Italie
     * Japon
     * Pologne
     * Québec

   Prix
   Multimédia
     * Aurora
     * Hugo
     * Seiun

     Cinéma et télévision
     * Curt-Siodmak
     * Ray-Bradbury
     * Saturn

   Littérature, art et audio
     * Allemand
     * Andre-Norton
     * Apollo
     * Arthur-C.-Clarke
     * Astounding
     * Aurealis
     * British Science Fiction
     * Compton-Crook
     * Damon-Knight Memorial
     * E. E. Smith Memorial
     * Grand prix de l'Imaginaire
     * Ignotus
     * John-Wood-Campbell Memorial
     * Kurd-Laßwitz
     * Lambda Literary
     * Locus
     * Lodestar
     * Nebula
     * Otherwise
     * Philip-K.-Dick
     * Prometheus
     * Sidewise
     * Solstice
     * Tähtivaeltaja
     * Theodore-Sturgeon
     * Urania

   Média
   Littérature
     * Bandes dessinées
     * Magazines
     * Romans

   Films et séries
     * Chronologie
     * Tokusatsu

   Concepts
   Appliqués
     * Androïde
     * Astroingénierie
     * Autoréplication
     * Conscience artificielle
     * Holographie
     * Intelligence artificielle
     * Invisibilité
     * Mégastructure
     * Nanotechnologie
     * Réalité simulée
     * Robot
     * Tachyon
     * Téléchargement de l'esprit
     * Terraformation

   Formels
     * Paradoxe de Fermi
     * Paradoxe du grand-père

   Vie
     * Biochimies hypothétiques
     * Évolution
     * Extraterrestre
     * Génie génétique
     * Guerre biologique

   Espace-temps
         Phénomènes
     * Trou noir
     * Voyage dans le temps

   Vitesse supraluminique
     * Ansible
     * Distorsion
     * Hyperespace
     * Porte des étoiles
     * Téléportation
     * Trou de ver

   Univers
     * Astre fictif
     * Champ de force
     * Multivers
     * Théorie de Heim

   Social
     * Archéologie interstellaire
     * Cyborg
     * Gouvernement mondial
     * LGBT
     * Libertarianisme
     * Premier contact
     * Provolution
     * Théorie des anciens astronautes
     * Transhumanisme

   Sujets connexes
     * Africanfuturisme
     * Afrofuturisme
     * Études des sciences et des techniques
     * Fantasy
     * Futur
     * Horreur
     * Littératures de l'imaginaire
     * Mecha
     * Réalisme magique
     * Science fantasy
     * Techno-thriller
     * Uchronie

     * Catégorie
     * Portail

     * icône décorative Portail de l’informatique
     * icône décorative Portail de la robotique
     * icône décorative Portail de la science-fiction
     * icône décorative Portail du jeu vidéo
     * icône décorative Portail du Web sémantique

   Ce document provient de
   « https://fr.wikipedia.org/w/index.php?title=Intelligence_artificielle&
   oldid=210542885 ».
   Catégories :
     * Intelligence artificielle
     * Concept de la science-fiction
     * Transhumanisme
     * Terminologie du jeu vidéo
     * Systémique

   Catégories cachées :
     * Article contenant un lien mort
     * Page en semi-protection longue
     * Article nécessitant un nouveau plan
     * Article contenant un appel à traduction en anglais
     * Article à référence souhaitée
     * Article à référence insuffisante
     * Article à mettre à jour
     * Article avec une section vide ou incomplète
     * Article à référence nécessaire
     * Article avec une référence non conforme
     * Article à référence à confirmer
     * Page utilisant P1417
     * Page utilisant P5019
     * Page utilisant P6706
     * Page utilisant P3222
     * Page utilisant P4342
     * Page utilisant P3365
     * Page pointant vers des bases externes
     * Page pointant vers des dictionnaires ou encyclopédies généralistes
     * Article de Wikipédia avec notice d'autorité
     * Page utilisant P5088
     * Page utilisant P3123
     * Page pointant vers des bases relatives à la recherche
     * Page utilisant P486
     * Page pointant vers des bases relatives à la santé
     * Portail:Informatique/Articles liés
     * Portail:Technologies/Articles liés
     * Portail:Sciences/Articles liés
     * Portail:Robotique/Articles liés
     * Portail:Électricité et électronique/Articles liés
     * Portail:Génie mécanique/Articles liés
     * Portail:Science-fiction/Articles liés
     * Portail:Jeu vidéo/Articles liés
     * Portail:Web sémantique/Articles liés
     * Article de qualité en tatar

     * La dernière modification de cette page a été faite le 14 décembre
       2023 à 13:07.
     * Droit d'auteur : les textes sont disponibles sous licence Creative
       Commons attribution, partage dans les mêmes conditions ; d’autres
       conditions peuvent s’appliquer. Voyez les conditions d’utilisation
       pour plus de détails, ainsi que les crédits graphiques. En cas de
       réutilisation des textes de cette page, voyez comment citer les
       auteurs et mentionner la licence.
       Wikipedia® est une marque déposée de la Wikimedia Foundation, Inc.,
       organisation de bienfaisance régie par le paragraphe 501(c)(3) du
       code fiscal des États-Unis.

     * Politique de confidentialité
     * À propos de Wikipédia
     * Avertissements
     * Contact
     * Code de conduite
     * Développeurs
     * Statistiques
     * Déclaration sur les témoins (cookies)
     * Version mobile

     * Wikimedia Foundation
     * Powered by MediaWiki

     * (BUTTON) Activer ou désactiver la limitation de largeur du contenu
