   Accueil / Forums & Ã©vÃ©nements
   LibÃ©CARE: interview

CÃ©dric Villani : Â«Les algorithmes ont dÃ©jÃ  permis de sauver des viesÂ»

   LibÃ©CARE. Pensez la santÃ© demaindossier
   Dossiers liÃ©s
   Intelligence artificielle : de la fascination Ã  l'inquiÃ©tude
   Pour le mathÃ©maticien et spÃ©cialiste de lâ€™IA, les progrÃ¨s induits par
   les outils de lâ€™intelligence artificielle ne seront utiles quâ€™Ã
   condition de les intÃ©grer dans un cadre oÃ¹ Â«lâ€™interdisciplinaritÃ© est
   reineÂ» et la mise en place dâ€™une politique humaine efficace.
   par Benjamin Leclercq
   publiÃ© le 30 novembre 2023 Ã  17h27

   Innovation, changement climatique, intelligence artificielle,
   Ã©co-anxiÃ©tÃ© : comment mieux rÃ©parer sa santÃ© ? Rendez-vous Ã  Rouen et Ã
   Caen, les 30 novembre, 1er et 2 dÃ©cembre 2023 au MoHo avec le LibÃ©Care
   pour dÃ©battre avec mÃ©decins, intellectuels et experts.

   InvitÃ© du LibÃ©Care, le mathÃ©maticien, ex-dÃ©putÃ© et vulgarisateur
   scientifique CÃ©dric Villani, a fait de lâ€™intelligence artificielle lâ€™un
   de ses sujets de prÃ©dilection. En 2018, ChatGPT nâ€™existait pas encore
   lorsquâ€™il a rÃ©digÃ©, sur commande du gouvernement Philippe, le premier
   rapport public dâ€™ampleur sur lâ€™IA en France. Plus spÃ©cifiquement, le
   mÃ©daillÃ© Fields 2010 coanime depuis six ans un groupe de travail
   conjoint entre lâ€™AcadÃ©mie des sciences et celle de mÃ©decine sur
   lâ€™irruption de lâ€™IA dans la santÃ©.

   Lâ€™IA pÃ©nÃ¨tre rapidement dans lâ€™univers la santÃ©. Alors que sa diffusion
   va sâ€™accÃ©lÃ©rer, quâ€™attendre concrÃ¨tement de ce bond technologique
   annoncÃ© ?

   Câ€™est bien simple : la santÃ© est le domaine dans lequel lâ€™IA a lâ€™impact
   le plus clair et le plus fondamental aujourdâ€™hui. Dans lâ€™analyse de
   donnÃ©es et particuliÃ¨rement de lâ€™imagerie, dans la dÃ©tection de signaux
   faibles ou lâ€™aide aux protocoles de prise en chargeâ€¦ VoilÃ  des annÃ©es
   que les algorithmes font, sur certaines pathologies, des dÃ©tections
   plus fiables que les meilleurs experts ; et cette performance a dÃ©jÃ
   permis de sauver des vies. Les applications sont nombreuses et vont se
   multiplier.
   RÃ©cit

Avec lâ€™intelligence artificielle, la mÃ©decine sort des santÃ©s balisÃ©es

   SantÃ©
   19 juin 2023

   A lâ€™inverse, quâ€™est-ce que lâ€™IA ne produira pas ? Quels fantasmes sur
   ses capacitÃ©s faut-il abandonner dâ€™emblÃ©e ?

   Dâ€™abord, un systÃ¨me mÃ©dical, ce nâ€™est pas seulement une science, câ€™est
   avant tout une architecture humaine complexe, et ces humains ont leur
   art, leurs recettes, leur empathie. Câ€™est donc la premiÃ¨re clÃ© : les
   progrÃ¨s de lâ€™IA ne peuvent Ãªtre utiles que dans le cadre dâ€™une
   politique humaine â€“ formations, carriÃ¨res, compÃ©tences, etc. Ensuite,
   la mÃ©decine prÃ©dictive, infaillible, utilisant les informations
   gÃ©nomiques ou environnementales pour prÃ©dire vos pathologies et votre
   traitement, je nâ€™y crois guÃ¨re â€“ dâ€™ailleurs cela fait bien des annÃ©es
   quâ€™on nous promet la rÃ©volution de la mÃ©decine personnalisÃ©e, sans que
   grand-chose ne se passe. En revanche, on voit Ã©merger une mÃ©decine dont
   les atouts sont de plus en plus nombreux, avec dans chaque spÃ©cialitÃ©
   des progrÃ¨s interdisciplinaires qui mÃªlent biomÃ©decine et analyse
   mathÃ©matique.

   Ne va-t-on pas vers une Â«gadgÃ©tisationÂ» des soins ?

   Je ne crois pas. Bien sÃ»r, certaines pistes technologiques seront
   fausses, et bien sÃ»r, câ€™est au savoir-faire humain de trancher et de
   prendre la responsabilitÃ©â€¦ Mais allez parler de gadget Ã  un diabÃ©tique
   dont la pompe contrÃ´le automatiquement le taux dâ€™insuline sans quâ€™il
   ait Ã  y penser. Ou Ã  une patiente dont lâ€™opÃ©ration a reÃ§u, juste avant
   le geste chirurgical crucial et dangereux, lâ€™approbation dâ€™un logiciel
   indiquant au bloc opÃ©ratoire que Â«lâ€™image est conforme aux rÃ¨gles de
   sÃ©curitÃ©Â».

   Les chercheurs cherchent, des IA naissentâ€¦ Mais oÃ¹ en est-on de leur
   usage rÃ©el ?

   Les IA ne sont pas des outils sur une Ã©tagÃ¨re quâ€™on peut utiliser tels
   quels en mÃ©decine. La science en gÃ©nÃ©ral non plus. Dâ€™ailleurs, on
   estime quâ€™en matiÃ¨re mÃ©dicale environ la moitiÃ© des dÃ©couvertes
   scientifiques ne sont jamais utilisÃ©es, simplement par dÃ©faillance de
   la chaÃ®ne humaine. Lâ€™intÃ©gration aux procÃ©dures, complexe, demande de
   la volontÃ© et du temps â€“ le temps du test, de lâ€™appropriation, de
   lâ€™expÃ©rimentation. Lâ€™Ã©chec retentissant du programme Watson dâ€™IBM [un
   outil nourri de millions de donnÃ©es scientifiques et capable de
   comprendre les subtilitÃ©s du langage naturel, ndlr] tient certainement
   Ã  ce quâ€™il nâ€™a pas rÃ©ussi cette Ã©tape humaine. Aujourdâ€™hui, nous sommes
   globalement trÃ¨s en dessous de notre potentiel, mais je suis bien en
   peine de vous donner une estimation prÃ©cise.
   Reportage

Aux urgences de Rennes, lâ€™intelligence artificielle comme Â«aide Ã  la
dÃ©cisionÂ»

   SantÃ©
   26 sept. 2023abonnÃ©s

   Comment ne pas rater cette mise en Å“uvre ?

   La faÃ§on de travailler ensemble sera au moins aussi importante que la
   qualitÃ© des IA elle-mÃªme. Lâ€™interdisciplinaritÃ© est reine dans ce sujet
   ! MathÃ©matique, biologie, sciences cognitives, numÃ©riques et mÃ©dicalesâ€¦
   Au niveau des Ã©quipes humaines aussi, sur le terrain, câ€™est une
   condition indispensable.

   Dans vos travaux, vous citez IsraÃ«l comme pionniÃ¨re de lâ€™IA dans la
   santÃ©. Comment sâ€™y est-elle prise ?

   IsraÃ«l est lâ€™un des pays les plus avancÃ©s en la matiÃ¨re, et en tout cas
   un modÃ¨le sur ce sujet. Ce nâ€™est pas par hasard, il y a plusieurs
   facteurs qui ont aidÃ© Ã  cela. Une culture de collaboration
   interdisciplinaire trÃ¨s marquÃ©e et une culture dâ€™expÃ©rimentation
   technologique dÃ©complexÃ©e, pour un sujet qui est interdisciplinaire et
   expÃ©rimental. Des bases de donnÃ©es nombreuses et bien construites, et
   de longue date, pour la simple raison que les mÃ©decins, y compris de
   ville, ont Ã©tÃ© contraints et forcÃ©s de passer aux actes numÃ©riques ; il
   en a rÃ©sultÃ© un gros corpus de donnÃ©es exploitables. Il y a aussi eu un
   travail patient pour faire dialoguer le monde de lâ€™algorithmique avec
   celui de la santÃ©, câ€™est le professeur Ran Balicer qui a jouÃ© ce rÃ´le.
   Enfin, le tout est portÃ© par une ambiance technophile, dÃ©pouillÃ©e des
   craintes qui sâ€™expriment ailleurs.

   Vous pensez Ã  la France, oÃ¹ vous trouvez la protection des donnÃ©es de
   santÃ© un peu jusquâ€™au-boutisteâ€¦ ?

   Algorithmes et IA ont besoin de rÃ©gulation, câ€™est Ã©vident et toute
   lâ€™Europe en est convaincue. Cependant, la pratique dÃ©montre amplement
   que la rÃ©glementation est aujourdâ€™hui en France un frein au
   dÃ©veloppement des projets en IA de la santÃ©. Dossiers lourds,
   procÃ©dures fastidieuses, temps dâ€™attente dÃ©raisonnables, contraintes
   intenables : les laboratoires internationaux prÃ©fÃ¨rent rÃ©aliser leurs
   Ã©tudes ailleurs quâ€™en France. La plateforme nationale de donnÃ©es de
   santÃ© (Health Data Hub) est un cas dâ€™Ã©cole en la matiÃ¨re : bonnes
   Ã©quipes, bonne dÃ©marche, mais une lourdeur administrative qui pourrait
   Ãªtre fatale â€“ il vous faut parfois dix mois pour obtenir lâ€™accÃ¨s aux
   donnÃ©es qui permettent de tester votre idÃ©e â€“ parfois vous ne les
   obtenez jamais ! Et le gouvernement a reculÃ© devant lâ€™obstacle quand il
   sâ€™est agi de rendre plus simples les procÃ©dures dâ€™interrogation des
   grandes bases de donnÃ©es.

   Quels risques le dÃ©ploiement de lâ€™IA fait-il peser sur le secteur des
   soins ?

   Toute transformation vient avec des risques, en premier lieu le risque
   de processus humains perturbÃ©s, de dÃ©sorganisation, surtout dans le
   contexte de nos hÃ´pitaux, marquÃ©s par les sous-effectifs, la surcharge
   de travail, le manque dâ€™attractivitÃ© de certains mÃ©tiers clÃ©. Il nâ€™est
   pas aisÃ© dâ€™adopter de nouvelles pratiques quand vous Ãªtes dÃ©jÃ  surmenÃ©.
   La perte de compÃ©tence et de savoir-faire est un autre risque identifiÃ©
   : en dÃ©lÃ©guant Ã  la technologie un ensemble de gestes et de
   connaissances, on en devient dÃ©pendant et lâ€™on sâ€™expose Ã  des ruptures
   de soin, en cas de panne ou de cyberattaque â€“ un flÃ©au qui touche
   dâ€™ailleurs de plus en plus les hÃ´pitaux. Un risque plus insidieux, avec
   lâ€™IA, est le mÃ©lange de fascination et dâ€™incomprÃ©hension des dÃ©cideurs
   Ã  son Ã©gard : cela la rend potentiellement fragile, soumise aux modes,
   avec des risques opposÃ©s (dÃ©fiance ou confiance exagÃ©rÃ©e). Sans oublier
   le risque de techno-blanchiment : croire que lâ€™on va rÃ©soudre nos
   problÃ¨mes de santÃ© en investissant massivement sur la technologie de
   lâ€™IA, au dÃ©triment dâ€™autres investissements de plus grand impact. Lâ€™IA
   amÃ©liorera notre santÃ©, certes, mais en aucun cas ce nâ€™est elle qui va
   sauver notre systÃ¨me de santÃ©.

Pour aller plus loin :

   LibÃ©CARE. Pensez la santÃ© demainIntelligence artificielle : de la
   fascination Ã  l'inquiÃ©tude

Dans la mÃªme rubrique

Les plus lus
