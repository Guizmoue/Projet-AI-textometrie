<html><head></head><body>
<table border='1'>
<tr><th>Contexte gauche</th><th>Mot</th><th>Contexte droit</th></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td>驾驶 汽车 ， 人工智能 （ </td><td>AI</td><td> ） 正在 迅速 地 发展</td></tr>
<tr><td></td><td>AI</td><td> ） ， 因为 它 被</td></tr>
<tr><td></td><td>AI</td><td> ） 。 虽然 专用 人工智能</td></tr>
<tr><td>在 短期 内 ， 保障 </td><td>AI</td><td> 对 社会 有益 的 科研</td></tr>
<tr><td>小 麻烦 。 但 当 </td><td>AI</td><td></td></tr>
<tr><td>计 更 有 智慧 的 </td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> 可能 是 人类 历史 上</td></tr>
<tr><td></td><td>AI</td><td> 的 诞生 戛然而止 ， 除非</td></tr>
<tr><td>会 在 </td><td>AI</td><td> 成为 超级 智能 之前 即可</td></tr>
<tr><td></td><td>AI</td><td> 是 否 会 实现 ，</td></tr>
<tr><td>未 来 人们 受益 于 </td><td>AI</td><td> 的 同时 ， 规避 潜在</td></tr>
<tr><td></td><td>AI</td><td> 不 可能 产生 人类 的</td></tr>
<tr><td></td><td>AI</td><td> 有意识 地 趋善 向 恶</td></tr>
<tr><td>。 当 考虑 </td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> 被 设计 执行 毁灭性 任务</td></tr>
<tr><td>大量 伤亡 。 此外 ， </td><td>AI</td><td></td></tr>
<tr><td>能 无意 中 引发 </td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> ） 中 ， 但 随着</td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> 被 开发 进行 有益 的</td></tr>
<tr><td>看 ， 我们 对 高级 </td><td>AI</td><td> 的 担忧 并非 在于 其</td></tr>
<tr><td></td><td>AI</td><td> 将 非常 善于 完成 其</td></tr>
<tr><td>为何 人们 最近 对 </td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> 研究 的 科学 家 最近</td></tr>
<tr><td>媒体 和 公开信 中 对 </td><td>AI</td><td> 风险 表示 关心 。 为什</td></tr>
<tr><td></td><td>AI</td><td> 的 成功 实现 一直 被</td></tr>
<tr><td>的 突破性 研究 和 许多 </td><td>AI</td><td></td></tr>
<tr><td>家 仍然 猜测 类 人 </td><td>AI</td><td> 在 几 个 世纪 以后</td></tr>
<tr><td>才 可能 发生 ， 大多数 </td><td>AI</td><td> 研究员</td></tr>
<tr><td>由于 </td><td>AI</td><td> 有 可能 变 得 比</td></tr>
<tr><td>于 </td><td>AI</td><td> 的 发展 可能 衍生 出什</td></tr>
<tr><td>持续 蓬勃 发展 。 针对 </td><td>AI</td><td></td></tr>
<tr><td>我们 应该 在 不 阻碍 </td><td>AI</td><td> 发展 的 前提 下 ，</td></tr>
<tr><td>安全 研究 来 加速 对 </td><td>AI</td><td> 科技 的 管理 能力 。</td></tr>
<tr><td>关于 高级 </td><td>AI</td><td> 的 误传</td></tr>
<tr><td>正在 进行 。 当下 ， </td><td>AI</td><td></td></tr>
<tr><td>的 争议 ， 例如 ： </td><td>AI</td><td> 对 就业 市场 未 来</td></tr>
<tr><td></td><td>AI</td><td> 开发 是 否 会 导致</td></tr>
<tr><td>一个 常见 的 误区 与 </td><td>AI</td><td> 的 时间表 有关 ： 那</td></tr>
<tr><td>却 从未 出现 过 。 </td><td>AI</td><td> 这 类 科技 也 在</td></tr>
<tr><td>并 进行 </td><td>AI</td><td></td></tr>
<tr><td>并 不 正确 。 对 </td><td>AI</td><td></td></tr>
<tr><td>有 一些 调查 问卷 向 </td><td>AI</td><td> 研究 人员 询问 他们 对</td></tr>
<tr><td>制造 类 人 </td><td>AI</td><td> 至少 有</td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td>会议 的 </td><td>AI</td><td></td></tr>
<tr><td>相关 的 传言 就是 对 </td><td>AI</td><td></td></tr>
<tr><td>的 人 认为 类 人 </td><td>AI</td><td> 在 几 年 内 就</td></tr>
<tr><td>研究 的 人事 实上 对 </td><td>AI</td><td></td></tr>
<tr><td>不 多 。 当 标准 </td><td>AI</td><td></td></tr>
<tr><td>人们 只 需要 理解 到 </td><td>AI</td><td> 可能 带 来 的 安全</td></tr>
<tr><td>了 安全 起见 ， 投入 </td><td>AI</td><td> 安全 研究 是 非常 合理</td></tr>
<tr><td>于 优先 考虑 短期 内 </td><td>AI</td><td> 所 能 带 来 的</td></tr>
<tr><td>许多 </td><td>AI</td><td> 研究 人员 在 看到 这个</td></tr>
<tr><td>他们 简洁 地 总结 了 </td><td>AI</td><td> 研究 人员 不 担心 的</td></tr>
<tr><td>， 但 它 与 </td><td>AI</td><td> 的 风险 无关 。 如果</td></tr>
<tr><td></td><td>AI</td><td> 所 做 的 事 ，</td></tr>
<tr><td>该 担心 的 不 是 </td><td>AI</td><td> 的 恶意 ， 而</td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td> 研究 人员 的 论文</td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td>对 开发 新 </td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td>小时 ： </td><td>AI</td><td> 安全 研究 人员 的 职业</td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>AI</td><td></td></tr>
<tr><td></td><td>人工智能</td><td> 的 益处 和 风险</td></tr>
<tr><td>的 产物 ， 所以 用 </td><td>人工智能</td><td> 增强 人类 智能 有 促进</td></tr>
<tr><td>什 么 是 </td><td>人工智能</td><td> ？</td></tr>
<tr><td>到 自动 驾驶 汽车 ， </td><td>人工智能</td><td> （</td></tr>
<tr><td>虽然 科幻 小说 经常 将 </td><td>人工智能</td><td></td></tr>
<tr><td>特性 的 机器人 ， 但 </td><td>人工智能</td><td> 可以 涵盖 从 谷歌 （</td></tr>
<tr><td></td><td>人工智能</td><td> 程序</td></tr>
<tr><td>当今 的 </td><td>人工智能</td><td> 被 正确 地 称为 专用</td></tr>
<tr><td></td><td>人工智能</td><td> （ 或 弱</td></tr>
<tr><td>长期 目标 是 创建 通用 </td><td>人工智能</td><td> （</td></tr>
<tr><td>） 。 虽然 专用 </td><td>人工智能</td><td> 能 在 其 特定 的</td></tr>
<tr><td>为何 研究 </td><td>人工智能</td><td> 的 安全性 ？</td></tr>
<tr><td>用 </td><td>人工智能</td><td> ， 将 会 发生 些</td></tr>
<tr><td>但 我们 更 意识 到 </td><td>人工智能</td><td> 系统 具有 有意 或 无意</td></tr>
<tr><td></td><td>人工智能</td><td> 如何 可能 制造 危险 ？</td></tr>
<tr><td>） 是 为 杀戮而生 的 </td><td>人工智能</td><td></td></tr>
<tr><td>存在 于 专用 </td><td>人工智能</td><td> （</td></tr>
<tr><td>未 达到 人类 和 </td><td>人工智能</td><td> 目标 的 一致性 （</td></tr>
<tr><td>， 而 解决 人类 和 </td><td>人工智能</td><td> 目标 一</td></tr>
<tr><td>蚁倒霉 罢了 。 </td><td>人工智能</td><td> 安全 研究 的 一个 关键目</td></tr>
<tr><td>预测 人类 智能 级别 的 </td><td>人工智能</td><td> 在</td></tr>
<tr><td></td><td>人工智能</td><td> 安全 研究 来 加速 对</td></tr>
<tr><td>关于 </td><td>人工智能</td><td> 的 未 来 以及 它</td></tr>
<tr><td>制造 出 超越 人类 的 </td><td>人工智能</td><td> 。 事实上 ， 历史 充满</td></tr>
<tr><td></td><td>人工智能</td><td></td></tr>
<tr><td>人 </td><td>人工智能</td><td> 的 研究 。 他们 企图</td></tr>
<tr><td></td><td>人工智能</td><td> 不 会 在 本世纪 中</td></tr>
<tr><td>我们 与 超越 人类 的 </td><td>人工智能</td><td> 的 距离 进行 了 广泛</td></tr>
<tr><td>本世纪 出现 超越 人类 的 </td><td>人工智能</td><td> 的 概率 为 零 ，</td></tr>
<tr><td>是 ， 超越 人类 的 </td><td>人工智能</td><td> 永远 不 会</td></tr>
<tr><td>会 出现 超越 人类 的 </td><td>人工智能</td><td> 。 例如 ， 在</td></tr>
<tr><td>人类 的 </td><td>人工智能</td><td> 只 可能 在 数百 年</td></tr>
<tr><td>数 担心 超越 人类 的 </td><td>人工智能</td><td> 会 带 来 隐忧 的</td></tr>
<tr><td>的 </td><td>人工智能</td><td> 至少 需要 几十 年 才</td></tr>
<tr><td>与 人类 智能 级别 的 </td><td>人工智能</td><td> 相关 的 安全 问题 非常</td></tr>
<tr><td>误解 是 ， 那些 对 人工智能 感到 担忧 和 提倡 </td><td>人工智能</td><td></td></tr>
<tr><td>， 有些 人 认为 支持 </td><td>人工智能</td><td> 安全 研究 是 极 具</td></tr>
<tr><td>。 事实上 ， 为 </td><td>人工智能</td><td> 安全 研究 能 得到 适当</td></tr>
<tr><td>是 媒体 的 夸大 使 </td><td>人工智能</td><td> 的 安全 课题 看起 来</td></tr>
<tr><td>与 符合 共同 利益 的 </td><td>人工智能</td><td> 运动 的 人 或许 在</td></tr>
<tr><td>地 认为 他 不 在乎 </td><td>人工智能</td><td> 的 安全 。 然而 事实上</td></tr>
<tr><td>关于 超越 人类 的 </td><td>人工智能</td><td> 风险 的 误解</td></tr>
<tr><td>。 根据 定义 ， 超级 </td><td>人工智能</td><td> 非常 善于 实现 其 目标</td></tr>
<tr><td>， 符合 共同 利益 的 </td><td>人工智能</td><td> 运动 主要 关注 的 不</td></tr>
<tr><td>， 他们 关心 的 是 </td><td>人工智能</td><td> 的 目标 与 我们 的</td></tr>
<tr><td>一个 超智慧 和 超富裕 的 </td><td>人工智能</td><td> 可以 很 轻易 地 用</td></tr>
<tr><td>们 合并 ？ 在 </td><td>人工智能</td><td> 的 时代 中 ， 身</td></tr>
</table></body></html>
