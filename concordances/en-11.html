<html><head></head><body>
<table border='1'>
<tr><th>Contexte gauche</th><th>Mot</th><th>Contexte droit</th><th></tr>
<tr><td></td><td>AI</td><td> & SOCIETY</td></tr>
<tr><td>Social choice ethics in </td><td>artificial intelligence</td><td></td></tr>
<tr><td></td><td>AI</td><td> & SOCIETY Aims and scope Submit</td></tr>
<tr><td>approach to the ethics of artificial intelligence (</td><td>AI</td><td>) is to</td></tr>
<tr><td>social choice, in which the </td><td>AI</td><td> is designed to act according</td></tr>
<tr><td>This is found in the </td><td>AI</td><td> ethics of “coherent</td></tr>
<tr><td>the normative basis of </td><td>AI</td><td> social choice ethics is weak</td></tr>
<tr><td>the design of social choice </td><td>AI</td><td> faces three sets of decisions</td></tr>
<tr><td>single view that will guide </td><td>AI</td><td> behavior. These</td></tr>
<tr><td>up front in the initial </td><td>AI</td><td> design—designers</td></tr>
<tr><td>cannot “let the </td><td>AI</td><td> figure it out”. Each set</td></tr>
<tr><td>dilemmas with major consequences for </td><td>AI</td><td> behavior</td></tr>
<tr><td>count future generations or the </td><td>AI</td><td> itself. These</td></tr>
<tr><td>it is not essential for </td><td>AI</td><td>. The essential</td></tr>
<tr><td>J (2015) Fears of an </td><td>AI</td><td> pioneer. Science 349(6245):252</td></tr>
Clark J (2016) Artificial intelligence has a ‘sea of dudes
<tr><td>for modelling human moral faculties. </td><td>AI</td><td> & Soc</td></tr>
Yampolskiy RV (2013) Artificial intelligence safety engineering
<tr><td>Philosophy and theory of </td><td>artificial intelligence</td><td>. Springer, Berlin</td></tr>
<tr><td>D. Social choice ethics in artificial intelligence. </td><td>AI</td><td> & Soc</td></tr>
Artificial intelligence
</table></body></html>
