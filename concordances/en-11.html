<html><head></head><body>
<table border='1'>
<<<<<<< HEAD
<tr><th>Contexte gauche</th><th>Mot</th><th>Contexte droit</th><th></tr>
<tr><td></td><td>AI</td><td> & SOCIETY</td></tr>
<tr><td>Social choice ethics in </td><td>artificial intelligence</td><td></td></tr>
<tr><td></td><td>AI</td><td> & SOCIETY Aims and scope Submit</td></tr>
=======
<tr><th>Contexte gauche</th><th>Mot</th><th>Contexte droit</th></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>AI</td><td> & SOCIETY</td></tr>
<tr><td>Social choice ethics in </td><td>artificial intelligence</td><td></td></tr>
<tr><td>AI & SOCIETY </td><td>Ai</td><td></td></tr>
>>>>>>> 3093dd7580a8e9883ff7935e4ca554f451a6f07a
<tr><td>approach to the ethics of artificial intelligence (</td><td>AI</td><td>) is to</td></tr>
<tr><td>social choice, in which the </td><td>AI</td><td> is designed to act according</td></tr>
<tr><td>This is found in the </td><td>AI</td><td> ethics of “coherent</td></tr>
<tr><td>the normative basis of </td><td>AI</td><td> social choice ethics is weak</td></tr>
<tr><td>the design of social choice </td><td>AI</td><td> faces three sets of decisions</td></tr>
<tr><td>single view that will guide </td><td>AI</td><td> behavior. These</td></tr>
<tr><td>up front in the initial </td><td>AI</td><td> design—designers</td></tr>
<tr><td>cannot “let the </td><td>AI</td><td> figure it out”. Each set</td></tr>
<tr><td>dilemmas with major consequences for </td><td>AI</td><td> behavior</td></tr>
<tr><td>count future generations or the </td><td>AI</td><td> itself. These</td></tr>
<<<<<<< HEAD
<tr><td>it is not essential for </td><td>AI</td><td>. The essential</td></tr>
<tr><td>J (2015) Fears of an </td><td>AI</td><td> pioneer. Science 349(6245):252</td></tr>
Clark J (2016) Artificial intelligence has a ‘sea of dudes
<tr><td>for modelling human moral faculties. </td><td>AI</td><td> & Soc</td></tr>
Yampolskiy RV (2013) Artificial intelligence safety engineering
<tr><td>Philosophy and theory of </td><td>artificial intelligence</td><td>. Springer, Berlin</td></tr>
<tr><td>D. Social choice ethics in artificial intelligence. </td><td>AI</td><td> & Soc</td></tr>
Artificial intelligence
=======
<tr><td>Framework of Five Principles for </td><td>AI</td><td> in Society</td></tr>
<tr><td>Rawlsian ethics to </td><td>AI</td><td></td></tr>
<tr><td></td><td>Artificial Intelligence</td><td> and Ethical Principles</td></tr>
<tr><td>it is not essential for </td><td>AI</td><td>. The essential</td></tr>
<tr><td>Martin (2017) also considers having </td><td>AI</td><td></td></tr>
<tr><td>ethics of other </td><td>AI</td><td></td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td>J (2015) Fears of an </td><td>AI</td><td> pioneer. Science 349(6245):252</td></tr>
<tr><td>Clark J (2016) </td><td>Artificial intelligence</td><td> has a ‘sea of dudes</td></tr>
<tr><td></td><td>ai</td><td> sur l’Application de l</td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td>for modelling human moral faculties. </td><td>AI</td><td> & Soc</td></tr>
<tr><td>Yampolskiy RV (2013) </td><td>Artificial intelligence</td><td> safety engineering</td></tr>
<tr><td>Philosophy and theory of </td><td>artificial intelligence</td><td>. Springer, Berlin</td></tr>
<tr><td>D. Social choice ethics in artificial intelligence. </td><td>AI</td><td> & Soc</td></tr>
<tr><td></td><td>ai</td><td></td></tr>
<tr><td></td><td>Artificial intelligence</td><td></td></tr>
>>>>>>> 3093dd7580a8e9883ff7935e4ca554f451a6f07a
</table></body></html>
