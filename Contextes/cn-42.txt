
AI 也 會 出差 錯 ？ 使用 人工 智慧 可能 帶來 的 倫理 與風險 —— 《 科學月刊 》

--
＋追蹤
相關 標籤 ： AI ( 67 ) AI 人工 智慧 ( 36 ) 人工 智慧 ( 83 ) 倫理 ( 12 ) 演 算法 ( 33 ) 科學月
刊 ( 31 )
--

• 甘偵 蓉｜ 清華 大學 人文社 會 AI 應用 與發展 研究 中心 博士後 研究 學者 。

--
• Facebook 或 Instagram 的 訊息 推薦 、 YouTube 或 Netflix 推薦 觀賞 影片 、 掃瞄 臉部
以 解鎖 手機 ， AI 應用 早已 在 我 們 日常 生活 中 隨處 可 見 。
• AI 應 用 中 四 種 常見 的 倫理 和 風險 ： 演算法 偏誤 、 相關 技術 或 產品 偏 離 原先 使用目 的 、
擁 有 善惡 兩種 用途 ， 以及 演算法 設計 不 良 或 現 有 技術 限制 。
• 近年來 各 國 家 皆 制訂 有 關 AI 發展 的 規範 ， 臺灣則 在 2019 年制 訂「AI 科研 發展 指引
」 ， 期望 能 改善 AI 發展 帶來 的 問題與 風險 。

當談 到 人工 智慧 （ artificial intelligence , AI ） 、 也 就 是 AI 時 ， 讀者 會 想到 什麼 ？ 是
多年 前 由 史匹柏 （ Steven Spielberg ） 導演 的 那 部 《 A . I . 人工 智慧 》 （ A . I . Artificial
Intelligence ） 中 那 個 一直 盼 不 到 人 類 母愛 而 令人心碎 的 機器人 小 男孩 ？ 還 是 由 史密斯 （
--

[ s vg ] [ ] 《 A . I . 人工 智慧 》 （ A . I . Artificial Intelligence ） 電影 海報 ， 上映 於 2001
年 。 圖／IMDb

或 許 未 來 有 一 天 ， 人類 真 的 可以 設計 出 如 電影 中 那些 像 人 一 樣 的 AI 系 統 或 機器人 。 但 目
前 為止 ， 你 常 聽 到 的 AI 其 實 既 很 厲害 又 很 不 厲害 ， 為什麼 呢 ？ 厲害 的 是 它 下 圍棋 可 贏過
世界 冠軍 ， 還 能 夠比 放射 科技 師 更 快 、 更 準確 地 辨識 X 光片 中 疑似 病變 的 細胞 ； 但 它 不 厲
害 的 是 ， 很 會 下 圍棋 的 AI 就 只能 下 圍棋 ， 別說 不 會 打牌 ， 連撲克牌 是 什麼 都 不 知道 ！ 而
且 每 次學 新 事物 幾乎 都 是 打 掉 重 練 ， 得 不 斷 做 好多 考古題 才 有 可能 學 得 會 ， 不 像 人 類 通常
--

不 過 ， 即使 目前 世界 上 的 AI 都 是 這種 只 具備 特定 功能 的 「弱 AI」 （ artificial narrow
intelligence , ANI ） ， 但 已 經為 這個 世界 帶來 相當 大 的 進步與 便利 。 所以 ， 以下 要 談 的 就
--

談 到 這種 只 具 特定 功能 的 ANI ， 讀者 知道 目前 生活 周遭 有 哪 些 事物 有利用 AI 技術 嗎 ？ 其
實 Google 上 的 搜尋 資訊 、 Facebook 或 Instagram 的 訊息 推薦 、 對智慧型 手機 喊 「 Siri
現 在 外面 有 下雨嗎 ？ 」等 功能 ， 或是 以 掃 瞄臉部 解鎖 手機 與進 入 大樓 、 YouTube 或
Netflix 推薦 觀賞 影片 ， 甚至 是 投履歷 求職 、 銀行 審 核貸款 申請 等 都 常用 到 AI 技術 ， 它
早 在 我 們 日常 生活 中 隨處 可 見 。
--
----- 廣告 ， 請繼 續 往 下 閱讀 -----
[ s vg ] [ pexels - c ottonbr o - studio - 5077064 - 419 x 628 ] AI 技術 在 日常 生活 中 隨處 可 見 ， 如
YouTube 推薦 觀 看 影片 。 圖／Pexels

但 也 正是 如此 ， 讓人 們這 幾年 在 使用 AI 時 ， 逐漸 發現 它 可能 造成 的 問題 或 傷害 ， 以下 簡
單介 紹常見 的 四種AI應用 可能 造成 的 倫理 問題 或 風險 。

--

第一 種 是 演 算法 偏誤 （ algorithmic bias ） 。 什麼 是 演 算法 偏誤 ？ 簡單 來說 就 是 AI 在 某
些 群體 的 判斷 準確率 或 預測 結果 上 總 是 很 差 ， 導致 結果 可能 對於 此 群體 造成 系統性 的 不利
--

第一 項 原因 是 ， 建立 AI 模型 的 研究 資料集 有 偏誤 ， 在 性別 、 種族 、 社經 地位 等 特徵 上 ，
沒 有 真實 世界 的 人口 分布 代表性 。 例如 數位 裝置 採用 AI 臉部 辨識 技術 解鎖 ， 原本 是 希望
保護 個人 使用 數位 裝置 的 安全性 ， 結果 皮膚 深 的 人 卻 常常 遇到 辨識 失敗 而 無法 解鎖 。 這通
常 是 因 為 目前 許 多 AI 模型 都 是 以 機器 學習 技術 設計 ， 而 機器 學習 的 主要 特性 就 是 從過 去
人類 留下 的 大量 資料 中 學習 ； 當初 提供 電腦 學習 臉部 辨識 的 圖片 時 ， 如果 多 數 都 是 白皮膚
--

第二 項 產 生演 算法 偏誤 的 原因 是 建立 AI 模型 的 研究 資料 集 不 只 有 偏誤 ， 還 反映 現實社 會
中 的 性別 、 種族 、 社經 地位 等 歧視 ； 例如 美國 警政 單位 以 過往 犯罪 資料 訓練 出 獄後 犯人 再
犯 風險 評估 的 AI 模型 ， 那些 資料 不 意外 地 有色人種 的 犯罪 紀錄遠 多 於 白人 犯罪 紀錄 。 然
而 ， 那些 紀錄 也 反映 美國社 會長 久 以 來對於 有色人種 的 歧視 ， 其中 包含 警察 對於 有色人種
--
力通常 被 派 往 多 黑人 與拉丁裔 人種 居住 的 窮困社 區盤 查 等 。 所以 根據 過往 犯罪 資料 所 訓練
出來 的 AI 模型 ， 不 意外 地 也 就 會預測 有色人種 的 再 犯機率 普遍 來說 比 白人 高 。

--

第三 項 產 生演 算法 偏誤 的 原因 則 是 AI 學會 了 連系 統開發者 都 沒 有 察覺 到 ， 潛藏 在 資料 裡
的 偏誤 。 例如 科技 公司 人資部 門本來 想 借助 AI 更 有 效率 地 篩選 出 適合 來面 試 的 履歷 ， 所
以 挑選 在 該 公司 任職 一定 年 資且 曾 升遷 二 次 的 員工 履歷 來訓 練 AI 模型 。 問題 是 ， 高 科技
公司 向 來男 多 女 少 ， 所 提供 給 AI 學習 的 資料 自然 就 男女 比例 相當 不 均 。 AI 也 就 學會 了 凡
是 出現 偏向 女性 名字 、 嗜好 、 畢業 學校 系 所 等 文字 的 履歷 ， 平均 所 給 的 評分 都 比 出現 偏向
--
[ men - s taring - a t - w oman - applicant - waiting - f o r - j ob - int - 2022 - 12 - 16 - 0 9 - 17 - 36 - u tc - 1020 x 574 ]
潛藏 在 資料裡 的 偏誤 造成 AI 預測 結果 彷彿帶 有 性別 歧視 。 圖／Envato Element s

--
別偏見 ， 像 是 求 才 廣告 基本上 不 能 限定性 別 、 公司 聘雇 員工 應該 達 到 一定 的 性別 比例 等 。
因此 ， 訓練 AI 的 研究 資料 一旦 隱藏類 似 前述性 別 比例 不 均 的 現象 ， 訓練 出來 的 AI 預測
結果 就 彷彿帶 有 性別 歧視 ， 讓人 們過 往 致力 消除性 別 不 平等 的 各種 努力 都 白費 了 ！

其他 AI 應用 帶來 的 倫理 與風 險

除 了 演 算法 偏誤 的 問題 外 ， 第二 種 可能 帶來 的 倫理 問題 或 風險 是 AI 技術 已 經 偏 離 原先 使
用目 的 ， 例如 深偽 技術 （ deepfake ） 原本 用 來解 決圖片 資料量 不 夠 的 問題 ， 後來卻 被 利用
--

第三 種 則 是 有些 AI 技術 或 產品 本身 就 可能 有 善惡 兩種 用途 （ dual - use ） 。 例如 AI 人 臉
辨識 技術 可 用 在 保護 數位 裝置 的 使用者 或 大樓 保全 ， 但 也 可 用來 窺探 或 監控 特定 個人 ； 無
--

以上 介紹 了 AI 常見 的 四 種 倫理 問題 或 風險 ： 演算法 偏誤 、 相關 技術 或 產品 偏 離 原先 使用
目 的 、 擁有善惡 兩種 用途 ， 以及 演算法 設計 不 良 或 現 有 技術 限制 。 但 人 們該 如何 減少 這 些
--

培養 AI 使用 倫理 與風險 的 敏銳度

--
機電子 工程 師學會 （ Institute of Electrical and Electronics Engineers , IEEE ） 或是
國 家 、 國際 非營利 組織 皆 紛 紛 制訂 有 關 AI 發展 的 白皮書 或 倫理 指引 （ ethical
guidelines ） ， 甚至 逐漸朝 向 法律 治理 的 方向 ， 如 歐盟 的 人工 智慧 規則 草案 等 。 儘管 這些
文件 所 提出 的 倫理 價值 、 原則 或 行為 規範 ， 看似 各 有 不 同 ， 但 經過 這些年 的 討論與 摸索 ，
--

[ s vg ] [ pexels - tara - winstead - 8386434 - 942x628 ] 「 人工 智慧 科研 發展 指引」 提出 三 項 倫理
價值 ， 包含 以 人 為本 、 永續 發展 、 多元 包容 。 圖／Pexels
--
臺灣 相 較於 前述 國際 文件 來說 ， 在 制訂 的 時間 上 比 較晚 。 2019 年 由 當時 的 科技部 （ 現改 為
國科會 ） 制訂 「 人工 智慧 科研 發展 指引」 ， 裡面 提出 的 三 項 倫理 價值 以及 八 項 行為 指引 ，
基本上 涵蓋 了 前述 各種 國際 AI 發展 指引 文件 最 常 提及 的 內容 。 所 謂 三 項 倫理 價值 包含 以
人 為本 、 永續 發展 、 多元 包容 ， 行為 指引則 有 共榮 共利 、 安全性 、 問責 與溝通 、 自主 權與
--

未 來 當讀者 看到 又 出 現 哪 些 AI 新 技術 或 產品 時 ， 不 妨試 著評 估 看看 是 否 有 符合 這 三 項 價
值 及 八 項 行為 指引 。 若沒 有 ， 究竟 是 哪 項 不 符合 ？ 不 符合 的 原因 是 上述 所 介紹 常見 的 四 種
--

AI 技術 發展 日新月進 ， 在 日常 生活 中 的 應用 也 愈 來 愈 廣 。 但 考量 法律 條文 有 強制性 ， 在 制
訂時 必 須 相 當謹慎 ， 免得 動輒 得 咎 ， 也 很 可能 在 不 清楚 狀況 下 反而 制訂 了 不 當阻 礙創 新 發
--
無 所 適從 。 因此 可以 想 見 ， 法令 規範 趕 不 上 新 興 科技 所 帶來 的 問題與 風險 本來 就是 常態 ，
而 非 遇到 AI 科技 才 有 這種 情況 。

人 們 若 能 培養 自身 對於 AI 倫理 問題 或 風險 的 敏銳度 ， 便 可 發揮 公民 監督 或 協助 政府 監督
的 力量 ， 評估 AI 開發 或 使用者 有 無善盡 避免 傷害 特定 個人 或 群體 之 嫌 ， 逐漸 改善 AI 開
發者 與 大 眾媒 體常 過度 誇 大 AI 功能 ， 但 對於 可能 帶來 的 倫理 問題 或 風險 卻常 閃爍其詞 或
避 而 不 談 的 不好 現象 。
--
＋追蹤
相關 標籤 ： AI ( 67 ) 人工 智慧 ( 83 ) 動物 溝通 ( 1 ) 動物 語言 ( 1 ) 寵物 溝通 ( 3 ) 擬人化
動物 （ anthropomorphic animals ） ( 2 ) 跨 物種 溝通 ( 1 )
--

為什麼科 學 家 認為 跨 物種 溝通 即 將 成 真 ？ 從 海豚 到 水豚 、 從蜘蛛 到 山豬 ， 人工 智慧 能 成 為
所有 生物 的 萬能 「 翻譯 蒟蒻 」嗎 ？ 當人 類真 的 破解 了 另 一 物 種 的 溝通 方式 ， 未 來會 發生什
--

但 有 越 來 越 多 科 學 家 認為 ， 隨著 人工 智慧 （ AI ） 的 快速 進步 ， 破譯 動物 的 溝通 方式 不 再 是
不 可能 的 事情 。 AI 能 幫 上 什麼 忙 呢 ？ 首先 ， 機器 不 具 備人類 的 偏見 ， 因此 能 幫助 研究者 更
理解 動物 溝通系 統 的 結構 和 功能 ， 同 時辨識 我 們 和 動物 之 間 的 差異 。
--

最 後 ， AI 還 可以 基於 動物 訊號 ， 開發 出 預測 動物 行為 的 模型 。 例如 預測 動物 的 交配 行為 或
遷徙 模式 ， 或 何時 可能 需要 尋 找 庇護 避免 捕食者 。
--

科學 家 正在 使用 人工 智慧 來解讀 各 種物種 的 動物 溝通 方式 。

--

這些 只是 AI 解讀 的 眾 多 物種 中 的 一 部分 ， 其他 還 有 不 少 鳥類 、 靈長類 、 海豚 、 蜘蛛 、 螞
蟻 、 蜂類 ， 或 與人 親近 的 貓 、 狗 、 豬 等 ， 也 都 是 目前 被 科學 家 認為 有 機會 破譯其「 語言 」
--
[ s vg ] [ windows - v ]
論文 好多 看 不 完 ？ 研究生 的 救星 ！ 用 AI 幫 你 分析 統整 ！

[ s vg ] [ ]
畢業生 求職 的 一 大 助力 ！ 讓 AI 幫 你 快速 生成 精美 履歷 、 作品集 ！

--
[ s vg ] [ Chen - Jun - ]
是 什麼 蒙蔽 了 我 的 雙眼 ？ 如何 防範 生成式 AI 的 假資 訊陷阱 ？ —— 專訪 中 研院 資訊 科技 創 新
研究 中心 副 研究 員陳 駿丞
