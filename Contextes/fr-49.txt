
OpenAI promet de suspendre des modèles dangereux d’intelligence artificielle

--
   OpenAI a créé une équipe dédiée à l’identification et à la prévention
   des risques liés à l’intelligence artificielle (IA), qui pourra mener à
   suspendre le lancement d’un modèle d’IA s’il est considéré comme trop
   dangereux.
--
   accéléré d’OpenAI quitte à éluder certaines interrogations sur les
   possibles dérives de l’IA.

   Notre éditorial du 18 décembre 2023: Sans garde-fou, l’IA menace nos
   sociétés
--
   capacités sont supérieures aux logiciels les plus aboutis en matière
   d’IA.

   «Nous pensons que l’étude scientifique des risques de catastrophe
   découlant de l’IA n’est pas du tout à la hauteur», expliquent les
   responsables d’OpenAI dans le document. La création de cadre doit
--

   Retrouvez nos articles sur l'intelligence artificielle.

--

   A ce propos: OpenAI, numéro un mondial de l’intelligence artificielle,
   plonge dans le chaos et son existence est menacée
--

   Intelligence artificielle
     *
